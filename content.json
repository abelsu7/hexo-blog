{"meta":{"title":"Keep Coding","subtitle":"苏易北","description":"Abel Su 的编程笔记","author":"Abel Su","url":"https://abelsu7.top","root":"/"},"pages":[{"title":"编程学习资源","date":"2018-03-05T09:26:03.000Z","updated":"2018-10-16T14:31:09.617Z","comments":true,"path":"bookmarks/index.html","permalink":"https://abelsu7.top/bookmarks/index.html","excerpt":"","text":"持续更新中… 工具网站@card{ Code Climate Hexo.io ITeye Linux中国 Linux基金会 Linux公社 Google Search Console 七牛云 牛客网 剑指Offer | 牛客网 Code Hunt Code Cademy Heroku 码云Gitee 创意Pages简历 Web前端导航 | 腾讯AlloyTeam In the Cloud | Lofyer出品的云计算入门手册 W3school | 领先的Web技术教程 菜鸟教程 | 前端工具，在线编译工具 OpenResty | 低调的大神章亦春 在线SVG to PNG | 在线文件、图片转换 ThreatBook | 微步 小众软件 | 小巧实用的免费绿色软件 网址 简介 推荐指数 MSDN I Tell You 微软原版软件信息收录站 ⭐⭐⭐⭐⭐ 阿里研发工程师Hollis推荐的Java面试题 适用于初中级程序员，不涉及分布式 ⭐⭐⭐⭐⭐ 深度学习 Deep Learning 中文翻译 ⭐⭐⭐⭐⭐ 机器学习 Machine Learning 学习资源 ⭐⭐⭐⭐⭐ Github Rank（China） Github中国区Followers排名，微信员工hzlzh维护 ⭐⭐⭐⭐⭐ hzlzh-BestAPP 优秀App收集，微信员工hzlzh维护，近两年停止维护 ⭐⭐⭐⭐⭐ Material Palette Material Design调色板 ⭐⭐⭐⭐⭐ BootCDN 稳定、快速、免费的前端开源项目CDN加速服务 ⭐⭐⭐⭐⭐ Programming Notes for Professionals books 超赞的免费编程书籍 ⭐⭐⭐⭐⭐ 百度脑图 云端思维导图工具，有时服务不太稳定 ⭐⭐⭐⭐ CNode Node.js专业中文社区，开放API ⭐⭐⭐⭐ 人人都是产品经理 很棒的PM资源汇总站 ⭐⭐⭐⭐ Md2All Markdown排版利器，作者颜家大少 ⭐⭐⭐⭐ U深度 深度公司出品的U盘启动盘制作工具，支持NTFS格式转换 ⭐⭐⭐⭐ U大师 U盘启动盘制作工具，但会安装软件推荐列表，卸载即可 ⭐⭐⭐⭐ Crack the code interview 《Cracking the code interview》题目解答 ⭐⭐⭐⭐ Awesome Adb ADB用法大全 ⭐⭐⭐⭐ APlayer Such a lovely HTML5 music player ⭐⭐⭐⭐ DPlayer Such a lovely HTML5 danmaku video player ⭐⭐⭐⭐ Java工程师成神之路系列文章 Java相关知识点汇总 ⭐⭐⭐⭐ MKDocs Project documentation with Markdown ⭐⭐⭐⭐ Material for MKDocs Material is a theme for MkDocs ⭐⭐⭐⭐ 在线Hash加密算法 在线哈希加密工具 ⭐⭐⭐ ATOOL在线工具 多媒体、站长工具、开发者工具 ⭐⭐⭐ 代码在线运行 tool.lu在线工具 ⭐⭐⭐ 站长之家 站长工具大全 ⭐⭐ PDF转换器 图片转PDF ⭐⭐ } 软件推荐@column-2{ @card{ 全平台 Typora - 优雅的Markdown编辑器 Caffeine - 保持唤醒，防止休眠 7-Zip - 高压缩率的全平台压缩软件，小巧易用 Visual Studio Code - 强大的代码编辑器，插件丰富 aria2 - The next generation download utility } @card{ Windows Wox - Windows端的类Alfred启动器 Cmder - 高颜值的Windows终端模拟器 Putty - a free SSH and telnet client for Windows uGet - Open Source Download Manager } @card{ MacOS iPic - 图床神器，Markdown写作必备 iPicUploader MWeb - 专业的Markdown客户端 } @card{ Linux WineHQ - Wine Is Not an Emulator uGet - Open Source Download Manager } } 文章收藏@card{ 把记事本扔掉!五款专业文本编辑器横评 | 太平洋电脑网 Hexo发博博客引用自带图片的方法 | 简书 hexo文章插入图片但是显示路径却有问题？| SegmentFault ADB cannot bind ‘tcp:5037’ ADB server didn’t ACK | CSDN android模拟器与pc，模拟器与模拟之间用socket进行通信和获得模拟器ip地址程序 | ITeye 编程语言IDE对比 | ITeye 最全的静态网站生成器（开源项目）| ITeye 编程精华资源（ITeye优秀专栏）大汇总 | ITeye Linux中的巨页（hugepage）是什么 | Linux中国 Linux启动过程分析 | Linux中国 Ubuntu 16.04安装JDK | Linux公社 Ubuntu下安装Android Studio | Linux公社 Remote-Desktop-Clinets Hexo博客收录百度和Google | 简书 在改了100份简历之后，牛客网CEO这么说 | 牛客网 2014找工作总结 | CSDN 又一篇面经 | CSDN 牛人博客汇总之摘抄+面经 | CSDN 比特币的基本原理 | 云风的BLOG 前端资源（优秀网站、博客、以及活跃开发者）| CSDN Markdown语法链接通过新窗口打开解决办法 | CSDN Markdown 实现页面内部跳转 | CSDN 七牛图床API接口 | CSDN 谈谈hexo博客写作中的图片问题 | CSDN 什么是拜占庭将军问题 | 深入浅出区块链 IaaS，PaaS，SaaS 的区别 | 阮一峰的网络日志 区块链入门教程 | 阮一峰的网络日志 Git提交空目录的方法 | 脚本之家 mm-spider | Github 可能是目前最好的词云解决方案 wordcloud2 | 郎大为 EFI及EFI SHELL简介 | 笑遍世界 SSH中“HOST KEY VERIFICATION FAILED.“的解决方案 | 笑遍世界 Linux内核编译步骤 | 笑遍世界 《LINUX 101 HACKS》笔记 | 笑遍世界 LINUX SHELL中的条件表达式/比较运算符 | 笑遍世界 LINUX上一个命令计算PI | 笑遍世界 Hexo渲染时排除部分文件或目录 | 二次元の技术宅 Coding帮助文档 | Coding Linux之Ubuntu中计划任务cron学习 | cnBlogs ubuntu开启crontab日志记录及解决No MTA installed, discarding output问题 | 璞玉POOY Linux定时增量更新文件 | 开源中国 ubuntu14.04开启crontab日志 | CSDN Linux定时任务的设置及crontab配置指南 | 脚本之家 Linux crontab定时任务配置方法(详解) Ubuntu cron日志开启与查看的实现步骤 GPU Passthrough, VGA Passthrough in KVM | Lofyer Compile Android Spice(aSpice) | Lofyer MacOS关闭ipv6 | CSDN 50道Java多线程面试题目 | SegmentFault IDEA查看类UML关系图 | Django’s Blog 打造个性超赞博客Hexo+Next+GithubPages的超深度优化 | reuixiy 码农们，你一小时值多少钱？| 唐巧的博客 腾讯爸爸的历史 - 读《腾讯传》| 唐巧 学习如何学习 | 王辉的博客 Hexo插件之百度主动提交链接 | 王辉的博客 Installing openGL and openAL in ubuntu | Stack Overflow 在Windows/Ubuntu下安装OpenGL环境（GLUT/freeglut）与跨平台编译（mingw/g++） | cnblogs GL/gl.h: No such file or directory | CSDN Qt5.5在ubuntu下解决GL/gl.h: No such file or directory与cannot find -lGL | CSDN Windows上的程序员神器——Cmder | 知乎专栏 } KVM相关@card{ KVM虚拟机三大存储模式 | CSDN KVM虚拟机qcow2、raw、vmdk等镜像格式和转换 | CSDN 使用Shell脚本监控KVM虚拟机 | CSDN KVM操作虚拟机常用命令 | CSDN 用Shell脚本监控KVM虚拟机 | CSDN 通过noVNC和websockify连接到QEMU/KVM | CSDN } @column-2{ @card{ Chrome插件推荐 Chrome好用插件安利 OneTab——强烈安利 } @card{ VSCode插件推荐 GitLens Beautify } @card{ WordPress主题推荐 Flat Fashionista 大发的WordPress原创主题 } @card{ Hexo主题推荐 Indigo Tranquilpeak Next jacman Freemind } @card{ Jekyll主题推荐 H2O } @card{ Ghost主题推荐 Casper | The default theme for Ghost } @card{ Python框架 Django Flask } @card{ Java框架 Netty } @card{ IDE快捷键大全 Intellij IDEA Visual Studio Code } @card{ Flutter相关 Flutter.io Flutter教程 | CSDN专栏 Flutter中文开发者论坛 为什么说Flutter是革命性的？| InfoQ Flutter初尝：从Java无缝过渡 | CSDN吴小龙同学 } } Android那些事@card{ 吴小龙同学 | 高级Android开发工程师，坐标无锡 吴小龙同学的友链列表 杰风居 | 冯建，Android探索者，友链超详细 秋百万 | Android开发者 Android官方培训课程中文版(v0.9.7) | 胡凯出品 Gitbook使用 | 吴小龙同学 程序亦非猿 | Android开发者，坐标杭州 胡凯的友情链接 我是一只香脆的大鸡排 | Android开发者 Android Studio中文社区 AndroidDevTools Android Developers Google Developers Android关于arm64-v8a、armeabi-v7a、armeabi-v7a、armeabi、x86下的so文件兼容问题 | CSDN }"},{"title":"关于我","date":"2018-02-05T13:38:59.000Z","updated":"2019-07-21T08:33:41.802Z","comments":true,"path":"about/index.html","permalink":"https://abelsu7.top/about/index.html","excerpt":"","text":"“我还是支持拜仁慕尼黑” @timeline{ 2013 年@item{ 9 月 1 日🏫你好，华工华南理工大学软件工程 2013 级 } 2016 年@item{ 7 月 31 日💻实习SAP 思爱普（中国）深圳分公司Develop Intern } 2017 年@item{ 1 月 31 日🍺大学本科的最后一年 } @item{ 3 月 1 日🎉保研本院华南理工大学软件工程 } @item{ 7 月 1 日👨‍🎓毕业了，时间好快华南理工大学软件工程 学士学位 } @item{ 9 月 1 日🏃‍继续读研，专心练剑华南理工大学软件工程 2017 级 } 2019 年@item{ 6 月 24 日🐧实习腾讯 CSIG 云产品部技术运营中心 } }"},{"title":"tags","date":"2019-09-01T12:47:41.000Z","updated":"2019-09-01T12:48:45.020Z","comments":false,"path":"tags/index.html","permalink":"https://abelsu7.top/tags/index.html","excerpt":"","text":""},{"title":"术语速查","date":"2018-09-25T13:51:01.000Z","updated":"2019-01-11T07:31:35.317Z","comments":true,"path":"wiki/index.html","permalink":"https://abelsu7.top/wiki/index.html","excerpt":"","text":"@card{ 缩写 备注 A Akka 开源工具和运行时，构建 JVM 上的并发/分布式应用 A Alluxio 虚拟的分布式存储系统 A Android demo A AngularJS Google开源 A aria2 开源下载工具 A Atomic 容器 OS C Ceph 分布式文件系统 C Clojure Lisp 在 Java 上的函数式动态方言 C CloudFoundry VMWare开源PaaS C CloudStack C CoreOS 容器 OS，已加入Red Hat C Corretto OpenJDK 发行版，Amazon 开源 D DAS 直连式存储 D Django Python Web 框架 D Dragonfly 云原生镜像分发系统，阿里开源 D Dubbo 阿里开源 E EasyStack 易捷行云 E Elasticsearch 分布式搜索和数据分析引擎 E Erlang 通用的并发程序设计语言 E etcd 开源分布式的键值对数据存储系统，CoreOS 与 K8S 中用到的组件 G Gitter Chat and networking platform, from Gitlab G Grafana 可视化分析工具 G gRPC 高性能RPC通用框架，Google开源 G Guacamole Apache项目 G guestfish 虚拟机镜像管理工具 H HAProxy 高可用、负载均衡 I inotify Linux文件监控机制，内核2.6.13引入 I Istio 微服务架构 K Keepalived 高可用 K KVM Kernel-based Virtual Machine L Lsyncd Linux文件同步工具 L LVS 负载均衡，章文嵩 M Marathon 容器编排引擎 M MariaDB MySQL分支，由开源社区维护 M Material-UI React M Maven Apache 基金会，项目管理工具 M MemCached 分布式内存对象缓存系统 M Mesos Apache 基金会，分布式资源管理框架，简介 M MongoDB 基于分布式文件存储的开源数据库 M MPic 图床神器 M MyBatis 持久层框架，定制化 SQL M MySQL 数据库 N Netty 异步、事件驱动的网络应用程序框架 N NFV 网络功能虚拟化 N ngrok 反向代理，内网穿透 N NoSQL 菜鸟教程 O OpenResty 基于Nginx与Lua的高性能Web平台，OpenResty最佳实践 O OpenShift 开源容器应用平台，Docker引擎，k8s编排 O OpenStack 最新版本Rocky O Open vSwitch Linux 基金会，多层虚拟交换机 P PM2 Node.js 进程管理器，支持负载均衡 P Pouch 阿里开源容器引擎 P Pulumi Cloud Native Infrastructure as Code Q QEMU A generic and open source machine emulator and virtualizer. R Rancher 开源的企业级 K8S 管理平台 R React Facebook开源 R Redis Key-Value 数据库 R REX-Ray 容器存储编排引擎，迁移持久化数据 R RPCX Go 语言的 RPC 框架 S SaltStack 自动化运维 S Serverless S Service Mesh CSDN S Siege 开源的Web压力测试与评测工具 S Spring Boot S Spring Cloud Apache T Tengine 淘宝开源Web Server，基于Nginx T TFTP 简单文件传输协议 V Vagrant 基于Ruby的虚拟化环境构建工具 V Valine 简洁高效的无后端评论系统 V Vue.js 渐进式JavaScript框架，尤雨溪 X Xen 开源的虚拟化Hypervisor Z Zookeeper Apache 基金会，开源的分布式应用程序协调服务 }"},{"title":"友情链接","date":"2018-03-15T12:10:14.000Z","updated":"2019-10-12T10:57:17.073Z","comments":true,"path":"friends/index.html","permalink":"https://abelsu7.top/friends/index.html","excerpt":"","text":"Last Update: 2018-12-7排名不分先后，持续更新中…欢迎留言互换友链~ 写博客的朋友们@card{ 名称 博主 备注 abelsu7.cn 苏易北 之前的旧博客 Disinuo的博客 Disnuo 清华大学软件学院研究生 笑话人生 陈云龙 南京大学软件学院2013级 考拉的网络日志 张卫庆（kooola） 专注大数据相关领域 Li Mengting 李梦婷 北京理工大学计算机系2015级，Java 服务端开发 CodeYourLife wbq813 华南理工大学软件学院研究生 VMCloud 无界工程师实践之路 腾讯云斯达哥的博客 } 技术博客收集@card{ 名称 博主 备注 内存·溢出 为程序员服务 张砷镓 张砷镓 14岁大学毕业，Web开发 陈沙克日志 陈沙克 招银，容器，OpenShift 酷壳 COOLSHELL 陈皓 20年软件开发经验，底层技术平台 metaboy’s blog metaboy 阿里云工程师 笑遍世界 任永杰 《KVM虚拟化技术：实战与原理解析》作者，华工09届校友 云淡风轻 云淡风轻 Valine作者 Deserts Deserts Valine-Admin作者 孙士权的个人博客 孙士权 Gitment作者 不如 不如（buru） 不蒜子作者 Hux Blog 黄玄 前端 Hollis Hollis 《成神之路系列文章》，阿里资深Java研发，公众号Hollis 1 Byte 江宏 LeanCloud创始人，CEO crossoverJie crossover JCSprout发起者，JVM、并发、分布式 RUO DOJO 潘小鶸 云数据库平台技术专家，阿里ApsaraDB 阮一峰的网络日志 阮一峰 上财世界经济博士，支付宝前端 廖雪峰的官方网站 廖雪峰 技术作家，JS、Python、Git教程 纯洁的微笑 技术总监 Java后端、微服务、Spring 小弟调调 jaywcjlove 前端、各类awesome项目 鸟窝 colobu 《Scala集合技术手册》作者，中科大，现在微博做架构和开发 CyC2018 郑永川 中山大学 klion’s blog klionsec 网络安全，博客已停止更新 Sean’s Notes seanlook 腾讯互娱，游戏DBA Jimmy Song 宋净超 蚂蚁金服，Cloud Native，ServiceMesh 深入浅出区块链 Tiny熊 博客园博主 二次元の技术宅 諾小豬 现居苏州 Hawstein’s Blog Hawstein 后端技术负责人，AlgoCasts算法教学视频 云风的BLOG 云风 资深游戏开发者 Yusen’s Blog 王昱森 hexo-theme-indigo作者 H2O 廖柯宇 前端开发，Jekyll主题H2O作者 reuixiy reuixiy 炫酷的Next主题优化 王辉的博客 王辉 hexo-recommended-posts、hexo-blogroll作者 唐巧的博客 唐巧 80后程序员，小猿搜题产品技术负责人，著有《iOS开发进阶》 Hello Java 微信公众号 BlueDavy 林昊，阿里毕玄 始于珞尘 蛰渊 腾讯社交与效果广告部高级工程师，后端开发 闲思录 冯大辉 数据库技术专家，无码科技创始人 Frank’s 技术世界 frank-lam 武汉大学 CS 硕士 MARKSZのBlog Molunerfinn PicGo、hexo-theme-melody 作者 TY·Loafer TY·Loafer 很多 Go 原理剖析的文章 int32bit’s Blog int32bit Linuxer, Vimer, Pythoner, OpenStacker, Docker } 云计算与虚拟化相关@card{ 名称 博主 备注 Some Links Demo Demo Myths-发现大佬 Demo Demo Lofyer 蒋迪 《KVM私有云架构设计与实践》作者 } Android相关@card{ 名称 博主 备注 Gank.io 代码家 干货集中营 吴小龙同学 吴小龙 高级Android开发 胡凯 胡凯 腾讯Android开发 技术小黑屋 资深Android开发者 } 互联网公司网站收集@card{ 公司 名称 腾讯⭐ 腾讯云·云+社区 腾讯 腾讯校园招聘 腾讯 腾讯翻译君 腾讯 腾讯问卷 腾讯 腾讯网站分析 腾讯 腾讯哈勃分析系统-安全工具 腾讯 腾讯开放平台 腾讯 腾讯课堂 腾讯 腾讯天气 腾讯 公众宝小i机器人 腾讯 腾讯CDC 腾讯 腾讯ISUX 腾讯 腾讯MXD移动互联网设计中心 腾讯 腾讯AlloyTeam-卓越的前端团队 腾讯 腾讯网前端研发中心 腾讯 腾讯大讲堂 腾讯 腾讯吐个槽 阿里⭐ 阿里巴巴开源镜像站点 阿里 云栖社区 阿里 阿里巴巴国际UED团队 阿里 阿里中间件团队博客 阿里 阿里巴巴2018实习生招聘直播 百度⭐ 百度技术学院 百度 百度校园招聘 百度 百度校园 百度 百度EFE前端技术体系 百度 百度前端技术学院 百度 百度搜索资源平台 百度 百度开发者中心 百度 百度云加速 百度 百度统计 百度 百度云 百度 百度云观测 百度 百度脑图 谷歌⭐ Google Search Console 谷歌 Google Analytics 谷歌 Google Analytics Solutions 网易⭐ UEDC-网易用户体验中心 网易 网易有道校园招聘 京东⭐ JDC-京东设计中心 美团⭐ 美团点评技术团队 }"},{"title":"categories","date":"2019-09-01T12:49:13.000Z","updated":"2019-09-01T12:49:40.778Z","comments":false,"path":"categories/index.html","permalink":"https://abelsu7.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Vue.js 学习笔记","slug":"vue-notes","date":"2019-11-20T02:22:12.000Z","updated":"2019-11-26T14:45:04.689Z","comments":true,"path":"2019/11/20/vue-notes/","link":"","permalink":"https://abelsu7.top/2019/11/20/vue-notes/","excerpt":"Vue.js：渐进式 JavaScript 框架，相关资料整理","text":"Vue.js：渐进式 JavaScript 框架，相关资料整理 // TODO: To be updated… 1. 使用 vue-cli 构建新项目1.1 安装 vue-cli安装vue-cli： # 安装 Vue CLI &gt; npm install -g @vue/cli # 或者使用 yarn &gt; npm i -g yarn &gt; yarn global add @vue/cli # 验证 Node.js 与 vue-cli 版本 &gt; node -v v12.13.0 &gt; npm -v 6.13.0 &gt; vue -V @vue/cli 4.0.5 &gt; vue Usage: vue &lt;command&gt; [options] u Options: -V, --version output the version number -h, --help output usage information Commands: create [options] &lt;app-name&gt; create a new project powered by vue-cli-service add [options] &lt;plugin&gt; [pluginOptions] install a plugin and invoke its generator in an already created project invoke [options] &lt;plugin&gt; [pluginOptions] invoke the generator of a plugin in an already created project inspect [options] [paths...] inspect the webpack config in a project with vue-cli-service serve [options] [entry] serve a .js or .vue file in development mode with zero config build [options] [entry] build a .js or .vue file in production mode with zero config ui [options] start and open the vue-cli ui init [options] &lt;template&gt; &lt;app-name&gt; generate a project from a remote template (legacy API, requires @vue/cli-init) config [options] [value] inspect and modify the config outdated [options] (experimental) check for outdated vue cli service / plugins upgrade [options] [plugin-name] (experimental) upgrade vue cli service / plugins info print debugging information about your environment Run vue &lt;command&gt; --help for detailed usage of given command. 1.2 构建新项目构建一个新项目： &gt; vue create my-project 或者使用可视化界面： &gt; vue ui 1.3 目录结构vue-cli脚手架生成的项目目录结构大致如下所示： ├── node_modules # 项目依赖包目录 ├── public │ ├── favicon.ico # ico 图标 │ └── index.html # 首页模板 | ├── src │ ├── assets/ # 样式图片目录 │ ├── components/ # 组件目录 │ ├── views/ # 页面目录 │ ├── App.vue # 父组件 │ ├── main.js # 入口文件 │ ├── router.js # 路由配置文件 │ └── store.js # vuex 状态管理文件 | ├── .gitignore # git 忽略文件 ├── .postcssrc.js # postcss 配置文件 ├── babel.config.js # babel 配置文件 ├── package.json # 包管理文件 └── yarn.lock # yarn 依赖信息文件 下图摘自 Vue 项目构建与开发入门 - 劳卜 | 掘金小册： 2. 包管理工具与配置项2.1 npm 与 package.json npm 是 Node Package Manager 的缩写 也是目前世界上最大的开源库生态系统 包管理文件package.json的内容大致如下： 详细的package.json文件配置项可以参考：npm-package.json | npm Documentaion { &quot;name&quot;: &quot;my-project&quot;, &quot;version&quot;: &quot;0.1.0&quot;, &quot;private&quot;: true, &quot;scripts&quot;: { &quot;serve&quot;: &quot;vue-cli-service serve&quot;, &quot;build&quot;: &quot;vue-cli-service build&quot;, &quot;lint&quot;: &quot;vue-cli-service lint&quot; }, &quot;dependencies&quot;: { &quot;vue&quot;: &quot;^2.5.16&quot;, &quot;vue-router&quot;: &quot;^3.0.1&quot;, &quot;vuex&quot;: &quot;^3.0.1&quot; }, &quot;devDependencies&quot;: { &quot;@vue/cli-plugin-babel&quot;: &quot;^3.0.0-beta.15&quot;, &quot;@vue/cli-service&quot;: &quot;^3.0.0-beta.15&quot;, &quot;less&quot;: &quot;^3.0.4&quot;, &quot;less-loader&quot;: &quot;^4.1.0&quot;, &quot;vue-template-compiler&quot;: &quot;^2.5.16&quot; }, &quot;browserslist&quot;: [ &quot;&gt; 1%&quot;, &quot;last 2 versions&quot;, &quot;not ie &lt;= 8&quot; ] } 2.2 npm 常用命令在项目的构建和开发阶段，常用的npm命令有： # 生成 package.json 文件（需要手动选择配置） npm init # 生成 package.json 文件（使用默认配置） npm init -y # 一键安装 package.json 下的依赖包 npm i # 在项目中安装包名为 xxx 的依赖包 npm i xxx # 在项目中安装包名为 xxx 的依赖包（配置在 dependencies 下） npm i xxx --save # 在项目中安装包名为 xxx 的依赖包（配置在 devDependencies 下） npm i xxx --save-dev # 全局安装包名为 xxx 的依赖包 npm i -g xxx # 运行 package.json 中 scripts 下的命令 npm run xxx 比较陌生但实用的有： # 打开 xxx 包的主页 npm home xxx # 打开 xxx 包的代码仓库 npm repo xxx # 将当前模块发布到 npmjs.com，需要先登录 npm publish 2.3 yarn 常用命令 yarn 是由 Facebook 推出并开源的包管理工具，具有速度快、安全性高、可靠性强等优势 yarn的常用命令如下： # 生成 package.json 文件（需要手动选择配置） yarn init # 生成 package.json 文件（使用默认配置） yarn init -y # 一键安装 package.json 下的依赖包 yarn # 在项目中安装包名为 xxx 的依赖包（配置在 dependencies 下）,同时 yarn.lock 也会被更新 yarn add xxx # 在项目中安装包名为 xxx 的依赖包（配置在配置在 devDependencies 下）,同时 yarn.lock 也会被更新 yarn add xxx --dev # 全局安装包名为 xxx 的依 yarn global add xxx # 运行 package.json 中 scripts 下的命令 yarn xxx # 查看 yarn 配置项 yarn config list 比较陌生但实用的有： # 列出 xxx 包的版本信息 yarn outdated xxx # 验证当前项目 package.json 里的依赖版本和 yarn 的 lock 文件是否匹配 yarn check # 将当前模块发布到 npmjs.com，需要先登录 yarn publish 2.4 第三方插件配置例如在package.json中的browserslist配置项，其主要作用是在不同的前端工具之间共享目标浏览器和 Node.js 版本： &quot;browserslist&quot;: [ &quot;&gt; 1%&quot;, // 表示包含所有使用率 &gt; 1% 的浏览器 &quot;last 2 versions&quot;, // 表示包含浏览器最新的两个版本 &quot;not ie &lt;= 8&quot; // 表示不包含 ie8 及以下版本 ] 也可以单独写在.browserslistrc文件中： # Browsers that we support &gt; 1% last 2 versions not ie &lt;= 8 或者在项目终端运行如下命令查看： &gt; npx browserslist and_chr 78 and_ff 68 and_qq 1.2 and_uc 12.12 android 76 baidu 7.12 bb 10 bb 7 chrome 78 chrome 77 chrome 76 edge 18 edge 17 firefox 70 firefox 69 ie 11 ie 10 ie_mob 11 ie_mob 10 ios_saf 13.0-13.2 ios_saf 12.2-12.4 kaios 2.5 op_mini all op_mob 46 op_mob 12.1 opera 64 opera 63 safari 13 safari 12.1 samsung 10.1 samsung 9.2 2.5 vue-cli 包安装除了使用npm和yarn命令对包进行安装和配置之外，vue-cli从3.0版本开始还提供了专属的vue add命令： 该命令安装的包是以@vue/cli-plugin或者vue-cli-plugin开头的包 即只能安装 Vue 集成的包 # vue-cli 会将 eslint 解析为 @vue/cli-plugin-eslint vue add eslint 注意：不同于npm或yarn的安装，vue add不仅会将包安装到项目中，还会改变项目的代码或文件结构 另外vue add中还有两个特例： # 安装 vue-router vue add router # 安装 vuex vue add vuex 这两个命令会直接安装vue-router和vuex并改变你的代码结构，使你的项目集成这两个配置。 3. Webpack3.1 与 vue-cli 2.x 的差异vue-cli 3.x提供了一种开箱即用的模式，无需配置webpack即可运行项目。并且还提供了一个vue.config.js文件来满足开发者对其封装的webpack默认配置的修改： // TODO: To be updated… 参考资料1. JavaScript JavaScript 全栈教程 | 廖雪峰 JavaScript 教程 | 网道 ECMAScript 6 入门 | 阮一峰 2. Node.js教程 官方指南 | Node.js Node.js 教程 | 菜鸟教程 七天学会 Node.js npm 淘宝 NPM 镜像 npm 太慢，淘宝 npm 镜像使用方法 | CSDN axios axios - Promise based HTTP client for the browser and node.js | Github 使用 axios 访问 API | Vue.js axios 库从使用入门到进阶 - jonnyshao | 掘金 axios 的基本使用 | Aitter’s Blog 3. Vue官方文档 Vue.js：渐进式 JavaScript 框架 vue-cli - Vue.js 开发的标准工具 开发教程 Vue 项目构建与开发入门 - 劳卜 | 掘金小册 Vue + webpack 项目实践 | 囧克斯 开源项目 vue-element-admin vue-admin-template | Github electron-vue-admin | Github MVVM 浅谈 MVC、MVP 和 MVVM 架构模式 | Draveness MVC，MVP 和 MVVM 的图示 | 阮一峰 ESLint @vue/cli-plugin-eslint | Github 深入浅出 eslint —— 关于我学习 eslint 的心得 | 掘金 ESLint 在中大型团队的应用实践 | 美团技术团队 Vue.js + Go Go + Vue.js 开发 Web 应用 | 起风了 使用 Golang 的 Gin 框架和 Vue 编写 Web 应用 | 简书 Vue.js + Element-ui Vue.js (一)：Vue.js + element-ui 扫盲 | CSDN 4. UI 框架 Top 5 React Frameworks / UI Component Libraries for 2019 20+ Best React UI Component Libraries / Frameworks for 2019 | codeinwp Vue、React、Angular 最佳 UI 框架 | FunDebug 构建 React.js 应用的十佳 UI 框架 | 开源中国 Vue Element - 饿了么出品 element-starter - A starter kit for Element UI generated by vue-cli iView - View UI React Ant Design - 阿里出品 Material-UI：当下流行的 React UI 框架 5. Element-ui跨域访问 axios 可以解决跨域访问的问题吗？| SegmentFault vue axios 请求出错 No ‘Access-Control-Allow-Origin’ header is present on the requested resource | 简书 table 布尔值的回填先在&lt;el-table-column&gt;中指定:formatter： &lt;el-table :data=&quot;rows&quot; ref=&quot;datagrid&quot; border=&quot;true&quot; highlight-current-row=&quot;true&quot; style=&quot;width: 100%&quot;&gt; &lt;el-table-column prop=&quot;tableId&quot; label=&quot;表id&quot; :show-overflow-tooltip=&quot;true&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;pk&quot; label=&quot;是否为主键&quot; :formatter=&quot;formatBoolean&quot; :show-overflow-tooltip=&quot;true&quot;&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; 之后在methods中添加formatBoolean： // 布尔值格式化：cellValue为后台返回的值 formatBoolean: function (row, column, cellValue) { var ret = &#39;&#39;; //你想在页面展示的值 if (cellValue) { ret = &quot;是&quot;; //根据自己的需求设定 } else { ret = &quot;否&quot;; } return ret; }, 参见 Element-ui 中 Table 表中 el-table-column 列数据的布尔值回填 | CSDN table 表格内容格式化设置formatter或filter，参见： Vue 项目功能实现：Element UI 表格内容格式化方案 | SegmentFault vue 中使用 element table，表格参数格式化 formatter | 简书 vue 2.0 的 Element UI 的表格 table 列时间戳格式化 | CSDN table 表格筛选坑在于&lt;el-table-column&gt;要加prop和column-key，参见： 筛选 - Table 表格 | Element 使用 element-ui table 组件的筛选功能的一个小坑 | CSDN element 框架中表格的筛选功能使用说明 | CSDN table 多选先手动添加一个&lt;el-table-column&gt;，并设置其type属性为selection： &lt;el-table-column type=&quot;selection&quot; width=&quot;55&quot; /&gt; 添加一个&lt;el-button&gt;，方便清除所有选择： &lt;el-button type=&quot;primary&quot; @click=&quot;toggleSelection()&quot;&gt;取消选择&lt;/el-button&gt; 最后在methods中实现toggleSelection()： toggleSelection(rows) { let selectedRows = this.$refs.userTable.store.states.selection; selectedRows.forEach(row =&gt; { console.log(&quot;id: &quot;, row.id, &quot; name: &quot;, row.name); }); if (rows) { rows.forEach(row =&gt; { this.$refs.userTable.toggleRowSelection(row); }); } else { this.$refs.userTable.clearSelection(); } } 多选的行数据这样获取： let selectedRows = this.$refs.userTable.store.states.selection; 参见： 多选 - 组件 | Element Element UI 表格点击选中行/取消选中 快捷多选 以及快捷连续多选，高亮选中行 - Lozvoe | 掘金 解决 vue 中多选 table 中的数据，将选中的多个数组中的 key 值提交给后端，提交完成后清除勾选框 - Felery | CSDN button 动态设置禁用设置&lt;el-button&gt;的:disabled： 参见 vue element 表格如何动态设置按钮禁用状态？|SegmentFault &lt;template slot-scope=&quot;scope&quot;&gt; //这里需要注意一下 &lt;el-button type=&quot;primary&quot; :disabled=&quot;scope.row.state == &#39;已完成&#39;&quot; size=&quot;small&quot; @click=&quot;dialogFormVisible = true&quot;&gt; 操作 &lt;/el-button&gt; &lt;/template&gt; msgbox 的关闭调用done()关闭： 参见 如何关闭 element-ui 中的 $msgbox | SegmentFault this.$msgbox({ title: &#39;用户下线&#39;, message: &#39;是否下线当前用户？&#39;, showCancelButton: true, confirmButtonText: &#39;确定&#39;, cancelButtonText: &#39;取消&#39;, beforeClose: (action, instance, done) =&gt; { if (action === &#39;confirm&#39;) { done() } else { done() } } }).then(() =&gt; { const axiosIns = axios.create({ baseURL: &#39;http://localhost:8080/api/v1&#39;, timeout: 3000 }) axiosIns .delete(`login/${this.list[index].id}`) .then(res =&gt; { console.log(res) }) .catch(err =&gt; { console.error(err) }) this.list[index].online = false this.$message({ message: `用户 ${this.list[index].id} 已下线`, type: &#39;success&#39;, duration: 2000, showClose: true }) }) Excel 表格参见： vue项目中导入excel文件（使用element-ui）| CSDN Vue + Element 前端导入导出 Excel | SegmentFault vue 中使用 xlsx 导入 excel 文件并解析 json 数据 | MAYMAY 利用 js-xlsx 在 vue 中与 element-ui 结合实现 excel 前端导入 | 简书 vue(Element ui) 结合 xlsx 模块实现前端解析 excel 文件 | 简书 Excel | vue-element-admin 6. 相关文章 Bootstrap 中文网 前端面试题：JS 中的 let 和 var 的区别 | 博客园 Vue.js：轻量高效的前端组件化方案 - 尤雨溪 | CSDN curl 的用法指南 | 阮一峰 🚩推荐阅读（由hexo文章推荐插件驱动）JavaScript获取网页滚动距离及DOM元素宽高属性HTML5 词云 wordcloud2.js 初体验监听物理回退与展开占满全屏归并排序(递归)","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://abelsu7.top/tags/JavaScript/"},{"name":"Node.js","slug":"Node-js","permalink":"https://abelsu7.top/tags/Node-js/"},{"name":"Vue","slug":"Vue","permalink":"https://abelsu7.top/tags/Vue/"},{"name":"Element-ui","slug":"Element-ui","permalink":"https://abelsu7.top/tags/Element-ui/"}]},{"title":"虚拟化相关资料收集","slug":"recent-virt-notes","date":"2019-11-19T09:37:20.000Z","updated":"2019-11-26T07:30:05.033Z","comments":true,"path":"2019/11/19/recent-virt-notes/","link":"","permalink":"https://abelsu7.top/2019/11/19/recent-virt-notes/","excerpt":"近期整理备忘，待更新…","text":"近期整理备忘，待更新… 1. Ceph 通过 libvirt 使用 Ceph RBD | Ceph Documentation 使用 Ceph 作为 QEMU KVM 虚拟机的存储 - 冬日の草原 OpenStack 使用 Ceph 存储后端创建虚拟机快照原理剖析 | int32bit’s Blog OpenStack 使用 Ceph 存储，Ceph 到底做了什么? | int32bit’s Blog libvirt 使用多个 Ceph 集群 | 李睿的博客 CentOS KVM + Ceph | 李小波 初始 Ceph | jeremy 的技术点滴 virt-install 工具安装基于 rbd 磁盘的虚拟机 | opengers 2. Open vSwitch官方文档 OVS - Open vSwitch | Github Open vSwitch Documentation OVS Open vSwitch 使用指南：OVS 常用操作总结 | Fishcried Open vSwitch 架构解析与功能实践 - 范桂飓 | CSDN Open vSwitch 的原理和常用命令 | 开源中国 Open vSwitch 详解 | 简书 Open vSwitch 的 ovs-vsctl 命令详解 | 八戒 研究 Open vSwitch | jeremy 的技术点滴 研究 Open vSwitch | 腾讯云+社区 OVS 初级教程：使用 Open vSwitch 构建虚拟网络 | SDNLAB 云计算底层技术 - 使用 Open vSwitch | opengers VM 跨主机通信 OVS 配置 | 神评网 VXLAN 搭建基于 Open vSwitch 的 VxLAN 隧道实验 | SDNLAB OVS 那些事儿之 VXLAN 隧道协议 | 神评网 GRE 和 VXLAN | 神评网 Linux 上实现 vxlan 网络 | Cizixs 干网络工程的你弄清楚VLAN和VXLAN的区别了吗？| 51CTO 3. Sheepdog Sheepdog Project Sheepdog 安装和使用管理 | 爱开源 挂羊头卖狗肉文件系统到底卖的是啥？| SSDFans Sheepdog 性能 | 开源中国 Sheepdog 之 dog 源码解析 | Harlon’s Blog 分布式存储系统 sheepdog 概述 | 运维之路 Sheepdog 与 KVM | 开源中国 QEMU 从 sheepdog 启动虚拟机的性能非常慢？| SegmentFault 4. Ansible Ansible(一) Try it | Fishcried Ansible(二) 主机管理 | Fishcried Ansible(三) 命令行与配置文件 | Fishcried Ansible(四) 使用Ansible Playbooks | Fishcried Ansible(五) 编写Ansible Role | Fishcried Ansible(六) 常用模块 | Fishcried 5. 虚拟化博客 OenHan leoufung - 六六哥的博客 | CSDN hanbaoying | 随便写写 int32bit’s Blog 冬日の草原 Fishcried - 枯鱼 世民谈云计算 | 博客园 陈沙克日志 任思绪在这里飞 jeremy 的技术点滴 opengers 八戒 SDNLAB | 专注网络创新技术 Cizixs | 蚂蚁金服后端，云计算/容器/网络/分布式 6. 文章收集分布式存储 分布式块存储系统 Ursa 的设计与实现 | 美团技术团队 iSCSI 高可用性研究 | Harlon’s Blog 分布式一致性算法综述 | Harlon’s Blog 初识 glusterfs | jeremy 的技术点滴 KVM 虚拟化 基于 OpenStack Ironic 实现 x86 裸机自动化装机实践与优化 | int32bit’s Blog 如何探测虚拟化环境是物理机、虚拟机还是容器？| int32bit’s Blog KVM 中开启嵌套虚拟化 | Fishcried VM 电源管理 Xen 和 KVM 比较 | 任思绪在这里飞 快速创建 KVM 虚拟机 | jeremy 的技术点滴 试用 WebVirtMgr | jeremy 的技术点滴 云平台核心架构设计要点 | 神评网 virtio virtio-gpu 介绍 | 任思绪在这里飞 Virtio-Balloon 超详细分析 | 任思绪在这里飞 virtio 的工作流程 —— qemu 中 virtio-backend 初始化(1) | 任思绪在这里飞 virtio 的工作流程 —— kernel 中 virtio-pci 初始化(2) | 任思绪在这里飞 QEMU QEMU 中 VNC 流程详解+代码分析 | 任思绪在这里飞 NFV NFV 场景：DPDK-PKtgen 进行网络测试 | 任思绪在这里飞 内核 kprobe 使用实例 | 任思绪在这里飞 Github webvirtcloud - retspen | Github webvirtmgr - retspen (停止维护) | Github 其他 线程池、进程池与内存池 | Harlon’s Blog 🚩推荐阅读（由hexo文章推荐插件驱动）半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述QEMU 1.2.0 入口 main() 函数调用流程分析迁移 VMware 虚拟机到 KVM","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"Ceph","slug":"Ceph","permalink":"https://abelsu7.top/tags/Ceph/"},{"name":"Open vSwitch","slug":"Open-vSwitch","permalink":"https://abelsu7.top/tags/Open-vSwitch/"},{"name":"Sheepdog","slug":"Sheepdog","permalink":"https://abelsu7.top/tags/Sheepdog/"}]},{"title":"gops：Go 程序查看和诊断分析工具简介","slug":"gops-intro","date":"2019-11-10T08:37:45.000Z","updated":"2019-11-10T08:55:23.337Z","comments":true,"path":"2019/11/10/gops-intro/","link":"","permalink":"https://abelsu7.top/2019/11/10/gops-intro/","excerpt":"gops 相关资料整理，待更新…","text":"gops 相关资料整理，待更新… // TODO: To be updated… 参考文章 gops - A tool to list and diagnose Go processes currently running on your system | Github gops - Go 程序诊断分析工具 | 格物 gops - liyiheng | Github gops 工作原理 | WOLFOGRE’S BLOG gops 工作原理 - PHPor的Blog gops - Go语言程序查看和诊断工具 - alfred_zhong | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件Go 程序的交叉编译、选择性编译转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"gops","slug":"gops","permalink":"https://abelsu7.top/tags/gops/"}]},{"title":"使用 Gogs 自建 Git 服务","slug":"using-gogs-as-git-server","date":"2019-11-01T07:50:04.000Z","updated":"2019-11-10T08:30:43.529Z","comments":true,"path":"2019/11/01/using-gogs-as-git-server/","link":"","permalink":"https://abelsu7.top/2019/11/01/using-gogs-as-git-server/","excerpt":"Gogs：一款极易搭建的自助 Git 服务, by Unknwon@Github","text":"Gogs：一款极易搭建的自助 Git 服务, by Unknwon@Github 本文基于Gogs 0.11.91.0811 1. 环境要求 数据库：支持 MySQL&gt;=5.7(InnoDB 引擎)、PostgreSQL、MSSQL、TiDB Git：客户端和服务端均需版本&gt;=1.8.3 SSH 服务器： 如果选择在 Windows 系统使用内置的 SSH 服务器，请确保添加ssh-keygen到%PATH%环境变量中 Windows 系统推荐使用 Cygwin OpenSSH 或 Copssh Windows 系统请确保Bash是默认的 Shell 程序，而不是PowerShell 2. 新建用户Gogs 默认以git用户运行，首先以root身份新建用户git并为其设置密码： &gt; sudo adduser git &gt; sudo passwd git 之后切换至git用户，在/home/git/目录下创建.ssh目录： &gt; su git # 切换至 git 用户 &gt; cd /home/git/ /home/git &gt; mkdir .ssh # 创建 .ssh 目录 /home/git &gt; ls -al drwx------ 6 git git 154 Nov 1 22:58 . drwxr-xr-x. 6 root root 58 Nov 1 18:35 .. -rw------- 1 git git 146 Nov 1 22:50 .bash_history -rw-r--r-- 1 git git 18 Apr 11 2018 .bash_logout -rw-r--r-- 1 git git 193 Apr 11 2018 .bash_profile -rw-r--r-- 1 git git 231 Apr 11 2018 .bashrc drwxrwxr-x 3 git git 18 Nov 1 18:36 .cache drwxrwxr-x 3 git git 18 Nov 1 18:36 .config drwxr-xr-x 4 git git 39 Nov 13 2018 .mozilla drwxrwxr-x 2 git git 6 Nov 1 22:58 .ssh -rw-r--r-- 1 git git 658 Oct 31 2018 .zshrc 注：之后的操作全部以git用户进行操作 3. 二进制安装 Gogs 支持二进制、源码、包管理、Docker、Vagrant、基于 K8s 的 Helm Charts 等多种安装方式 从 Gogs 的Releases页面下载linux_amd64zip，之后解压： /home/git &gt; wget https://github.com/gogs/gogs/releases/download/v0.11.91/linux_amd64.zip /home/git &gt; unzip linux_amd64.zip /home/git &gt; cd gogs /home/git/gogs &gt; ls -hl total 55M -rwxr-xr-x 1 git git 55M Aug 12 10:26 gogs -rw-r--r-- 1 git git 1.1K Jun 5 2018 LICENSE drwxr-xr-x 8 git git 101 Aug 12 10:26 public -rw-r--r-- 1 git git 8.4K Aug 12 10:25 README.md -rw-r--r-- 1 git git 5.5K Aug 12 10:25 README_ZH.md drwxr-xr-x 7 git git 195 Aug 12 10:26 scripts drwxr-xr-x 11 git git 174 Aug 12 10:26 templates /home/git/gogs &gt; pwd /home/git/gogs 4. 自定义配置文件 Gogs 的默认配置文件位于源码中的conf/app.ini，该文件从v0.6.0版本开始被嵌入到二进制中 为了使自定义配置能覆盖原有的默认配置，需要在gogs目录下手动创建自定义配置文件custom/conf/app.ini，在该文件中修改相应选项的值即可： /home/git/gogs &gt; mkdir -p custom/conf /home/git/gogs &gt; vim custom/conf/app.ini 参见官方文档：配置与运行 - Gogs 例如自定义仓库根目录、数据库配置： [repository] ROOT = /home/gogs-repos [database] USER = admin PASSWD = ****** 这样可以保护自定义配置不被破坏： 从二进制安装的用户，可以直接替换二进制及其它文件而不至于重新编写自定义配置 从源码安装的用户，可以避免由于版本管理系统导致的文件修改冲突 5. 创建数据库及用户首先建立好数据库gogs，文件scripts/mysql.sql是数据库的初始化 SQL 语句： SET GLOBAL innodb_file_per_table = ON, innodb_file_format = Barracuda, innodb_large_prefix = ON; DROP DATABASE IF EXISTS gogs; CREATE DATABASE IF NOT EXISTS gogs CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 执行下列命令即可初始化gogs数据库： mysql -u root -p &lt; scripts/mysql.sql 此外还需要登录 MySQL 创建新用户gogs，并将数据库gogs的所有权限都赋予该用户： mysql&gt; CREATE USER &#39;gogs&#39;@&#39;localhost&#39; identified by &#39;YOUR_PASSWORD&#39;; mysql&gt; GRANT ALL PRIVILEGES ON gogs.* to &#39;gogs&#39;@&#39;localhost&#39;; mysql&gt; FLUSH PRIVILEGES; 如需更新密码： mysql&gt; ALTER USER &#39;gogs&#39;@&#39;localhost&#39; identified by &#39;NEW_PASSWORD&#39;; 6. 运行 Gogs./gogs web前台运行： /home/gogs &gt; ./gogs web 2019/11/01 17:48:31 [TRACE] Custom path: /home/gogs/custom 2019/11/01 17:48:31 [TRACE] Log path: /home/gogs/log 2019/11/01 17:48:31 [TRACE] Log Mode: Console (Trace) 2019/11/01 17:48:31 [ INFO] Gogs 0.11.91.0811 2019/11/01 17:48:31 [ INFO] Cache Service Enabled 2019/11/01 17:48:31 [ INFO] Session Service Enabled 2019/11/01 17:48:31 [ INFO] SQLite3 Supported 2019/11/01 17:48:31 [ INFO] Run Mode: Development 2019/11/01 17:48:31 [ INFO] Listen: http://0.0.0.0:3000 ... 或者nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 &amp;后台运行： # 后台运行 gogs，stderr 重定向至 stdout，stdout 重定向至 gogs.out /home/gogs $ nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 &amp; [1] 8346 /home/gogs $ jobs -l # 查看后台任务 [1] + 8346 running nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 /home/gogs $ cat gogs.out # 查看 gogs 在 gogs.out 中的输出 nohup: ignoring input 2019/11/01 18:01:33 [TRACE] Custom path: /home/gogs/custom 2019/11/01 18:01:33 [TRACE] Log path: /home/gogs/log 2019/11/01 18:01:33 [TRACE] Log Mode: Console (Trace) 2019/11/01 18:01:33 [ INFO] Gogs 0.11.91.0811 2019/11/01 18:01:33 [ INFO] Cache Service Enabled 2019/11/01 18:01:33 [ INFO] Session Service Enabled 2019/11/01 18:01:33 [ INFO] SQLite3 Supported 2019/11/01 18:01:33 [ INFO] Run Mode: Development 2019/11/01 18:01:33 [ INFO] Listen: http://0.0.0.0:3000 /home/gogs $ fg %1 # 切至前台运行 [1] + 8346 running nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 ^Z # 暂停并放入后台 [1] + 8346 suspended nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 /home/gogs $ jobs -l [1] + 8346 suspended nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 /home/gogs $ bg %1 # 后台继续运行 [1] + 8346 continued nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 /home/gogs $ jobs -l [1] + 8346 running nohup ./gogs web &gt; gogs.out 2&gt;&amp;1 参见： Linux 后台运行程序 | Huoty’s Blog Linux 系统上执行任务在前台和后台之间的转换 | Running Linux 后台进程管理以及 ctrl+z（挂起）、ctrl+c（中断）、ctrl+\\（退出）和 ctrl+d（EOF）的区别 | CSDN Linux 的 nohup 命令的用法 - 和白月黑羽学 Python | 博客园 最后访问http://localhost:3000/install，即可根据提示进行安装配置： // TODO: To be updated… 参考文章 Gogs: 一款极易搭建的自助 Git 服务 初体验之开源 Git 服务 Gogs - 寒露君 | 掘金 使用 Gogs 搭建自己的 Git 服务器 | My Nook 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件Go 程序的交叉编译、选择性编译转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Git","slug":"Git","permalink":"https://abelsu7.top/tags/Git/"},{"name":"Gogs","slug":"Gogs","permalink":"https://abelsu7.top/tags/Gogs/"}]},{"title":"在 Gin 中使用 swaggo 自动生成 RESTful API 文档","slug":"go-gin-swagger","date":"2019-10-31T03:37:30.000Z","updated":"2019-11-10T09:17:40.595Z","comments":true,"path":"2019/10/31/go-gin-swagger/","link":"","permalink":"https://abelsu7.top/2019/10/31/go-gin-swagger/","excerpt":"swaggo: Automatically generate RESTful API documentation with Swagger 2.0 for Go.","text":"swaggo: Automatically generate RESTful API documentation with Swagger 2.0 for Go. // TODO: To be updated… 目录 待更新 1. 快速开始下载swaggo： &gt; go get -u github.com/swaggo/swag/cmd/swag 2. swag cli&gt; swag init -h NAME: swag init - Create docs.go USAGE: swag init [command options] [arguments...] OPTIONS: --generalInfo value, -g value Go file path in which &#39;swagger general API Info&#39; is written (default: &quot;main.go&quot;) --dir value, -d value Directory you want to parse (default: &quot;./&quot;) --propertyStrategy value, -p value Property Naming Strategy like snakecase,camelcase,pascalcase (default: &quot;camelcase&quot;) --output value, -o value Output directory for all the generated files(swagger.json, swagger.yaml and doc.go) (default: &quot;./docs&quot;) --parseVendor Parse go files in &#39;vendor&#39; folder, disabled by default --parseDependency Parse go files in outside dependency folder, disabled by default // TODO: To be updated… 参考文章Github 项目 swaggo/swag - Automatically generate RESTful API documentation with Swagger 2.0 for Go | Github swaggo/gin-swagger - gin middleware to automatically generate RESTful API documentation with Swagger 2.0 | Github Swagger - API Development for Everyone Gin &amp; RESTful API 《基于 Go 语言构建企业级的 RESTful API 服务》| 掘金小册 教程：使用 go 的 gin 和 gorm 框架来构建 RESTful API 微服务 | LearnKu Build RESTful API service in golang using gin-gonic framework | Medium 对比 RESTful 与 SOAP，深入理解 RESTful | 紫川秀的博客 RESTful API 设计规范 | 紫川秀的博客 Gin - 高性能 Golang Web 框架的介绍和使用 | 代码成诗 swaggo 教程 如何使用 swagger 设计出漂亮的 RESTful API | 紫川秀的博客 Go 学习笔记 (六) - 使用 swaggo 自动生成 Restful API 文档 | Razeen’s Blog Gin 实践 连载八：为它加上 Swagger - 煎鱼 | SegmentFault 3.8 为它加上 Swagger - 跟煎鱼学 Go | GitBook doc.json 重定向至 about:blank doc.json link redirecting to blank page #194 - swaggo/swag | Github validator 结构字段验证 package validator | GoDoc 5.4 validator 请求校验 - Go 语言高级编程 | GitBook Golang 中的跨语言调用 - 习之北 | 须臾之学 结构字段验证 - validator.v9 | 博客园 An easy way to validate Go request | Medium.com Gin 框架 - 数据绑定和验证 | 掘金 Gin 框架构建 RESTFul API 之请求参数验证 | 忘归 binding 请求绑定 BindJSON validation failed for a required integer field that has zero value - gin | Github bug:c.BindJSON(&amp;req) - gin | Github Binding JSON having fields with empty string generates validation error - gin | Github Binding failed on int required field when value is 0 - gin | Github Bind validation bug with int zero value - gin | Github 模型绑定和验证 | Gin Web Framework Model binding and validation - gin-gonic/gin | Github Gin 路由冲突 Gin 的基数树路由局限及最佳实践 | 敬维 5.2 router 请求路由 - 《Go 语言高级编程》| GitBook Shell 命令获取 IP 地址 Shell 获取 IPv4 和 IPv6 地址的命令 | CSDN Shell 脚本中获取本机 IP 地址的三个方法 | ITeye Shell 命令行获取本机 IP，grep 的练习 | CSDN Linux 地址提示符和获取本机 IP Shell 命令 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务使用 upx 压缩 go build 打包的可执行文件Go 程序的交叉编译、选择性编译转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Gin","slug":"Gin","permalink":"https://abelsu7.top/tags/Gin/"},{"name":"RESTful","slug":"RESTful","permalink":"https://abelsu7.top/tags/RESTful/"},{"name":"Web 开发","slug":"Web-开发","permalink":"https://abelsu7.top/tags/Web-开发/"},{"name":"Swagger","slug":"Swagger","permalink":"https://abelsu7.top/tags/Swagger/"}]},{"title":"使用 upx 压缩 go build 打包的可执行文件","slug":"go-build-compress-using-upx","date":"2019-10-24T15:24:04.000Z","updated":"2019-10-25T09:40:43.202Z","comments":true,"path":"2019/10/24/go-build-compress-using-upx/","link":"","permalink":"https://abelsu7.top/2019/10/24/go-build-compress-using-upx/","excerpt":"节约空间，能省一点是一点","text":"节约空间，能省一点是一点 go build使用的是静态编译，会将程序的依赖一起打包，这样一来编译得到的可执行文件可以直接在目标平台运行，无需运行环境（例如 JRE）或动态链接库（例如 DLL）的支持。 虽然 Go 的静态编译很方便，但也存在一个问题：打包生成的可执行文件体积较大，毕竟相关的依赖都被打包进来了。今天就来尝试一下压缩 Go 编译得到的可执行文件的体积。 1. 添加 -ldflags 参数在程序编译的时候可以加上-ldflags &quot;-s -w&quot;参数来优化编译，原理是通过去除部分链接和调试等信息来减小编译生成的可执行程序体积，具体参数如下： -a：强制编译所有依赖包 -s：去掉符号表信息，不过panic的时候stace trace就没有任何文件名/行号信息了 -w：去掉DWARF调试信息，不过得到的程序就不能使用gdb进行调试了 注：不建议-w和-s同时使用 2. 编译优化示例未添加编译参数，main.exe原体积约为19.6M： &gt; go build main.go # 直接编译 &gt; ls -al main.exe # 约为 19.6M -rwxr-xr-x 1 abelsu7 197609 20556800 10月 25 15:52 main.exe* 添加-w参数，去掉调试信息，体积减小至约15.8M： &gt; go build -ldflags &quot;-w&quot; main.go # 添加 -w，去掉调试信息 &gt; ls -al main.exe # 约为 15.8M -rwxr-xr-x 1 abelsu7 197609 16569344 10月 25 15:54 main.exe* 添加-s参数，去掉符号表，体积减小至约14.7M： &gt; go build -ldflags &quot;-s&quot; main.go # 添加 -s，去掉符号表 &gt; ls -al main.exe # 约为 14.7M -rwxr-xr-x 1 abelsu7 197609 15397888 10月 25 15:59 main.exe* 同时添加-w -s参数，体积同样约为14.7M： &gt; go build -ldflags &quot;-w -s&quot; main.go # 同时添加 -w -s &gt; ls -al main.exe # 同样约为 14.7M -rwxr-xr-x 1 abelsu7 197609 15397888 10月 25 16:04 main.exe* 可以看到添加-s参数时，可执行文件体积减小最多 若对符号表无需求，-ldflags直接添加&quot;-s&quot;即可 3. 使用 upxUPX - the Ultimate Packer for eXecutables 是一款开源的可执行文件压缩程序，可以压缩常见平台下的可执行程序包。 3.1 安装 upx 在 Releases 页面下载对应平台的upx，MacOS 和 Linux 可以直接安装发行版： # For MacOS &gt; brew install upx # For CentOS/Fedora/RHEL &gt; yum install upx &gt; yum info upx Installed Packages Name : upx Arch : x86_64 Version : 3.95 Release : 4.el7 Size : 1.8 M Repo : installed From repo : epel Summary : Ultimate Packer for eXecutables URL : http://upx.sourceforge.net/ License : GPLv2+ and Public Domain Description : UPX is a free, portable, extendable, high-performance executable : packer for several different executable formats. It achieves an : excellent compression ratio and offers very fast decompression. Your : executables suffer no memory overhead or other drawbacks. 3.2 直接编译后压缩直接go build后压缩，main.exe体积从19.6M压缩至9.1M，为原体积的46.48%： &gt; go build main.go &gt; ls -al main.exe # 约为 19.6M -rwxr-xr-x 1 abelsu7 197609 20556800 10月 25 16:32 main.exe* &gt; upx main.exe # 压缩至原体积的 46.48% Ultimate Packer for eXecutables Copyright (C) 1996 - 2018 UPX 3.95w Markus Oberhumer, Laszlo Molnar &amp; John Reiser Aug 26th 2018 File size Ratio Format Name -------------------- ------ ----------- ----------- 20556800 -&gt; 9554944 46.48% win64/pe main.exe Packed 1 file. &gt; ls -al main.exe # 约为 9.1M -rwxr-xr-x 1 abelsu7 197609 9554944 10月 25 16:32 main.exe* 3.3 编译优化后压缩添加-ldflags &quot;-s&quot;后压缩，main.exe体积从14.7M压缩至4.8M，为原体积的32.42%： &gt; go build -ldflags &quot;-s&quot; main.go &gt; ls -al main.exe # 约为 14.7M -rwxr-xr-x 1 abelsu7 197609 15397888 10月 25 16:38 main.exe* &gt; upx main.exe # 压缩至原体积的 32.42% Ultimate Packer for eXecutables Copyright (C) 1996 - 2018 UPX 3.95w Markus Oberhumer, Laszlo Molnar &amp; John Reiser Aug 26th 2018 File size Ratio Format Name -------------------- ------ ----------- ----------- 15397888 -&gt; 4992512 32.42% win64/pe main.exe Packed 1 file. &gt; ls -al main.exe # 约为 4.8M -rwxr-xr-x 1 abelsu7 197609 4992512 10月 25 16:38 main.exe* 最终经过-ldflags编译优化和upx压缩，main.exe体积从19.6M压缩至4.8M，约为原体积的24.5%，效果还是很明显的 3.4 交叉编译后压缩另外，upx不仅可以压缩当前主机平台的可执行程序，只要是支持的平台都可以进行压缩。因此可以先在本机进行交叉编译，之后使用上述方法压缩可执行程序，最后再将可执行程序传至目标平台运行。 关于交叉编译，可以参考上一篇文章：Go 程序的交叉编译、选择性编译 | 苏易北 以在windows/amd64下交叉编译linux/amd64为例，main体积从19.9M压缩至4.8M，约为原体积的24.2%，压缩比例大致相同： # 设置交叉编译环境变量 &gt; set GOOS=Linux &gt; set GOARCH=amd64 &gt; set CGO_ENABLED=0 # 直接交叉编译 &gt; go build main.go &gt; ls -al main # 约为 19.9M -rw-r--r-- 1 abelsu7 197609 20837787 10月 25 16:51 main # 开启编译优化，去掉符号表 &gt; go build -ldflags &quot;-s&quot; main.go &gt; ls -al main # 约为 14.7M -rw-r--r-- 1 abelsu7 197609 15464736 10月 25 16:51 main &gt; upx main # 压缩至原体积的 32.60% Ultimate Packer for eXecutables Copyright (C) 1996 - 2018 UPX 3.95w Markus Oberhumer, Laszlo Molnar &amp; John Reiser Aug 26th 2018 File size Ratio Format Name -------------------- ------ ----------- ----------- 15464736 -&gt; 5041696 32.60% linux/amd64 main Packed 1 file. &gt; ls -al main # 约为 4.8M -rw-r--r-- 1 abelsu7 197609 5041696 10月 25 16:51 main 3.5 upx 的压缩选项下面是upx的一些常用参数： -o：指定输出的文件名 -k：保留备份原文件 -1：最快压缩，共1-9九个级别 -9：最优压缩，与上面对应 -d：解压缩decompress，恢复原体积 -l：显示压缩文件的详情，例如upx -l main.exe -t：测试压缩文件，例如upx -t main.exe -q：静默压缩be quiet -v：显示压缩细节be verbose -f：强制压缩 -V：显示版本号 -h：显示帮助信息 --brute：尝试所有可用的压缩方法，slow --ultra-brute：比楼上更极端，very slow 参考文章 Go 编译生成更小的执行程序 | 一线攻城狮 压缩 go build 打包的可执行文件：3.4MB-&gt;897K | 简书 upx - the Ultimate Packer for eXecutables | Github 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档Go 程序的交叉编译、选择性编译转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"upx","slug":"upx","permalink":"https://abelsu7.top/tags/upx/"}]},{"title":"Go 程序的交叉编译、选择性编译","slug":"go-cross-compile","date":"2019-10-24T08:44:37.000Z","updated":"2019-10-31T10:14:38.020Z","comments":true,"path":"2019/10/24/go-cross-compile/","link":"","permalink":"https://abelsu7.top/2019/10/24/go-cross-compile/","excerpt":"在 Windows、Linux、MacOS 下交叉编译 Golang","text":"在 Windows、Linux、MacOS 下交叉编译 Golang 目录 目录 1. 查看当前 Go 版本支持的编译平台 2. 设置环境变量并交叉编译 2.1 Windows 2.2 Linux 2.3 MacOS 3. 选择性编译 3.1 构建标记：build tag 3.2 文件后缀：_$GOOS.go 4. 示例程序 参考文章 从Golang 1.5开始，交叉编译变得非常便捷： 对于没有使用CGO的程序，只需设置GOOS、GOARCH、CGO_ENABLED这几个环境变量，即可直接利用编译器自带的跨平台特性实现跨平台编译 对于使用CGO的程序，大部分情况下可以通过配置CC环境变量使用自行准备的交叉编译工具进行编译 关于使用CGO情况下的交叉编译，参见 交叉编译 Go 程序 | Holmesian Blog 1. 查看当前 Go 版本支持的编译平台&gt; go version go version go1.13 windows/amd64 &gt; go tool dist list aix/ppc64 android/386 android/amd64 android/arm android/arm64 darwin/386 # Mac i386 darwin/amd64 # Mac amd64 darwin/arm darwin/arm64 dragonfly/amd64 freebsd/386 freebsd/amd64 freebsd/arm illumos/amd64 js/wasm linux/386 # Linux i386 linux/amd64 # Linux amd64 linux/arm linux/arm64 linux/mips linux/mips64 linux/mips64le linux/mipsle linux/ppc64 linux/ppc64le linux/s390x nacl/386 nacl/amd64p32 nacl/arm netbsd/386 netbsd/amd64 netbsd/arm netbsd/arm64 openbsd/386 openbsd/amd64 openbsd/arm openbsd/arm64 plan9/386 plan9/amd64 plan9/arm solaris/amd64 windows/386 # Windows i386 windows/amd64 # Windows amd64 windows/arm &gt; go env set GOHOSTARCH=amd64 # 本机的架构 set GOHOSTOS=windows # 本机的系统 set GOARCH=amd64 # 目标平台的架构，交叉编译时需要设置 set GOOS=windows # 目标平台的系统，交叉编译时需要设置 set CGO_ENABLED=0 # 是否启用 CGO ... 最常用的大概是x86和amd64架构： darwin/386：对应 Mac x86 darwin/amd64：对应 Mac amd64 linux/386：对应 Linux x86 linux/amd64：对应 Linux amd64 Windows/386：对应 Windows x86 Windows/amd64：对应 Windows amd64 2. 设置环境变量并交叉编译2.1 Windows在 Windows 下编译 MacOS 和 Linux 的 64 位程序： # For MacOS/amd64 set CGO_ENABLED=0 set GOOS=darwin set GOARCH=amd64 go build main.go # For Linux/amd64 set CGO_ENABLED=0 set GOOS=linux set GOARCH=amd64 go build main.go 2.2 Linux在 Linux 下编译 MacOS 和 Windows 的 64 位程序： # For MacOS/amd64 CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.go # For Windows/amd64 CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.go 2.3 MacOS在 MacOS 下编译 Windows 和 Linux 的 64 位程序： # For Windows/amd64 CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.go # For Linux/amd64 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 3. 选择性编译虽然 Golang 可以跨平台编译，但系统之间的差异性仍然存在。有些时候我们会直接调用操作系统函数，不同操作系统下的库可能会有不同的实现，比如syscall库。 命令go build没有内置#define或者预处理器之类的处理平台相关的代码取舍，而是采用 Tag 标记和文件后缀的方式实现选择性编译。 3.1 构建标记：build tag为了实现根据不同的目标平台编译对应的源文件，需要在文件顶部添加构建标记build tag： // +build 标记遵循以下规则： A build tag is evaluated as the OR of space-separated options Each option evaluates as the AND of its comma-separated terms Each term is an alphanumeric word or, preceded by !, its negation 简单翻译一下： 空格 为或 逗号,为且 叹号!为非 例如： // +build A,B !C,D // (A &amp;&amp; B) || ((!C) &amp;&amp; D) 再例如： // +build !windows,386 //此文件在非 Windows 操作系统，且为 x86 处理器时编译 构建标记必须出现在文件顶部，可以有多个build tag，之间是AND的关系： // +build linux darwin // +build 386 另外需要注意build tag和package xxx语句之间需要有空行分隔，也就是： // +build linux darwin // +build 386 package mypkg 3.2 文件后缀：_$GOOS.go以_$GOOS.go为后缀的文件只在此平台上编译，其他平台上编译时就当此文件不存在，完整的后缀如： _$GOOS_$GOARCH.go 例如： syscall_linux_amd64.go：只在 Linux/amd64 下编译 syscall_windows_386.go：只在 Windows/i386 下编译 syscall_windows.go：只在 Windows 下编译 4. 示例程序package main import ( &quot;fmt&quot; &quot;runtime&quot; ) func main() { fmt.Printf(&quot;OS: %s\\nArchitecture: %s\\n&quot;, runtime.GOOS, runtime.GOARCH) } Windows/amd64 下为 Windows/amd64 与 Linux/amd64 编译： # For Windows/amd64 &gt; go build cross.go # For Linux/amd64 &gt; set CGO_ENABLED=0 &gt; set GOOS=linux &gt; set GOARCH=amd64 &gt; go build cross.go # Cmder &gt; ls -hl total 3.0M -rw-r--r-- 1 abelsu7 197609 1014K 10月 24 17:26 cross -rwxr-xr-x 1 abelsu7 197609 2.0M 10月 24 17:15 cross.exe* -rw-r--r-- 1 abelsu7 197609 140 10月 24 17:12 cross.go -rw-r--r-- 1 abelsu7 197609 198 10月 23 17:58 go.mod -rw-r--r-- 1 abelsu7 197609 1.5K 10月 23 17:57 go.sum -rw-r--r-- 1 abelsu7 197609 1.9K 10月 24 15:48 main.go Windows 下运行： &gt; .\\cross.exe OS: windows Architecture: amd64 WSL 下运行： &gt; ./cross OS: linux Architecture: amd64 参考文章 交叉编译 Go 程序 | Holmesian Blog 交叉编译 Go 程序 | 鸟窝 Golang 交叉编译与选择性编译 | CSDN Golang 在 Mac、Linux、Windows 下如何交叉编译 | CSDN Golang 交叉编译中的那些坑 | CSDN Cross compilation with Go 1,5 | Dave Cheney Building windows go programs on linux - golang/go | Github Cross Compile in Go (Golang) | Medium.com TinyGo Brings Go To Arduino | Hackaday Better way to install Golang (Go) on Raspberry Pi | E-Tinkers Recipe: Cross Compliling | The Go Cookbook Gin 实践 番外：Golang 交叉编译 - 煎鱼 | SegmentFault Gin 实践 番外：请入门 Makefile - 煎鱼 | SegmentFault 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"交叉编译","slug":"交叉编译","permalink":"https://abelsu7.top/tags/交叉编译/"}]},{"title":"Go 语言使用 present 展示 PPT","slug":"go-present-ppt","date":"2019-10-23T13:25:51.000Z","updated":"2019-10-24T11:08:37.072Z","comments":true,"path":"2019/10/23/go-present-ppt/","link":"","permalink":"https://abelsu7.top/2019/10/23/go-present-ppt/","excerpt":"参考 写给程序员看的”幻灯片“制作教程 - 谢伟 | 知乎","text":"参考 写给程序员看的”幻灯片“制作教程 - 谢伟 | 知乎 // TODO: To be updated… 1. 下载安装 present 包下载安装present： &gt; go get -u -v golang.org/x/tools/cmd/present 演示文档目录下执行命令： &gt; present 访问http://127.0.0.1:3999 2. .slide 文件语法 等我有时间就回来更新！flag++ 参考文章 写给程序员看的”幻灯片“制作教程 - 谢伟 | 知乎 写给程序员看的演示教程：Slide 分享演示 - 谢伟 package present | GoDoc tools - Go Tools mirror | Github mdp - 终端下基于 Markdown 的 PPT 展示工具 | Github 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"PPT","slug":"PPT","permalink":"https://abelsu7.top/tags/PPT/"}]},{"title":"Go 语言使用 os/exec 执行 Shell 命令","slug":"go-exec-shell-command","date":"2019-10-23T13:08:45.000Z","updated":"2019-10-24T14:47:03.294Z","comments":true,"path":"2019/10/23/go-exec-shell-command/","link":"","permalink":"https://abelsu7.top/2019/10/23/go-exec-shell-command/","excerpt":"使用 Golang 执行 Shell 命令的各种姿势","text":"使用 Golang 执行 Shell 命令的各种姿势 // TODO: To be updated… 1. os/exec1.1 只执行命令，不要输出结果执行命令可以使用Run()或者Start()方法，Run()是阻塞的执行，Start()是非阻塞的执行： package main import ( &quot;fmt&quot; &quot;os/exec&quot; ) func main() { command := exec.Command(&quot;ping&quot;,&quot;www.baidu.com&quot;) err := command.Run() // 阻塞执行 if err != nil{ fmt.Println(err.Error()) } } 2. go-sh go-sh - 替代 os/exec 执行命令 | Github 3. ssh 远程执行命令// TODO: To be updated… golang-ssh-01: 执行远程命令 | MojoTech Golang 远程执行命令 | CSDN Go 执行远程 ssh 命令 | bbsmax 如何使用 Go 语言实现远程执行命令 | TeaKKi gossh - 极简的 ssh 管理工具，支持多台主机、远程执行命令、传递文件 | Github gossh 使用示例 | Github Linux 自动化远程管理工具 gossh 开源了 - 李文塔 | CSDN 参考文章相关的库 go-sh - 替代 os/exec 执行命令 | Github go-homedir - 替代 os/user 获取 home 目录，支持交叉编译 | Github gossh - 极简的 ssh 管理工具，支持多台主机、远程执行命令、传递文件 | Github 文章教程 Go 语言中执行命令的几种方式 | 杨彦星 Golang exec 命令执行 | 简书 Golang os/exec 执行外部命令 | 简书 Golang 执行系统命令 os/exec | 01happy 如何用 Go 调用 Windows API | Razeen’s Blog Go 学习笔记 (八) - 使用 os/exec 执行命令 | Razeen’s Blog [译]使用 os/exec 执行命令 | 鸟窝 golang-ssh-01: 执行远程命令 | MojoTech Golang 远程执行命令 | CSDN Go 执行远程 ssh 命令 | bbsmax 如何使用 Go 语言实现远程执行命令 | TeaKKi 其他暂存 Go 学习笔记 (六) - 使用 swaggo 自动生成 Restful API 文档 | Razeen’s Blog Go 语言中关于文件路径的使用总结 | 杨彦星 Go 语言中函数使用不定参数问题 | 杨彦星 Go 语言“可变参数函数”终极指南 | Go 语言中文网 CODING 代码多仓库实践 | CODING 博客 GitLab Centos7 搭建 GitLab 服务器并配置项目全过程 | CSDN 搭建 GitLab 服务 | SegmentFault 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"SSH","slug":"SSH","permalink":"https://abelsu7.top/tags/SSH/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"}]},{"title":"CentOS 7 安装配置 NFS","slug":"centos7-install-nfs","date":"2019-10-17T13:50:59.000Z","updated":"2019-11-19T12:48:03.977Z","comments":true,"path":"2019/10/17/centos7-install-nfs/","link":"","permalink":"https://abelsu7.top/2019/10/17/centos7-install-nfs/","excerpt":"参考 CentOS 7 下 yum 安装和配置 NFS | Zhanming’s blog，补充整理部分内容","text":"参考 CentOS 7 下 yum 安装和配置 NFS | Zhanming’s blog，补充整理部分内容 1. 环境说明本文中的服务器环境如下： Role Hostname OS NFS 服务端 centos-2 CentOS 7.5 NFS 客户端 abelsu7-ubuntu Ubuntu 18.04 注：为简略起见，以下命令均以root身份运行，省略sudo 2. NFS 服务端2.1 安装 nfs-utils 注：对应的 Apt 包为nfs-common &gt; yum info nfs-utils Available Packages Name : nfs-utils Arch : x86_64 Epoch : 1 Version : 1.3.0 Release : 0.65.el7 Size : 412 k Repo : base/7/x86_64 Summary : NFS utilities and supporting clients and daemons for the kernel NFS server URL : http://sourceforge.net/projects/nfs License : MIT and GPLv2 and GPLv2+ and BSD Description : The nfs-utils package provides a daemon for the kernel NFS server and : related tools, which provides a much higher level of performance than the : traditional Linux NFS server used by most users. : : This package also contains the showmount program. Showmount queries the : mount daemon on a remote host for information about the NFS (Network File : System) server on the remote host. For example, showmount can display the : clients which are mounted on that host. : : This package also contains the mount.nfs and umount.nfs program. &gt; yum install nfs-utils # rpcbind 作为依赖会自动安装 2.2 配置并启动服务允许rpcbind.service、nfs.service开机自启： # 允许服务开机自启 &gt; systemctl enable rpcbind &gt; systemctl enable nfs 启动相关服务： # 启动相关服务 &gt; systemctl start rpcbind &gt; systemctl start nfs 防火墙允许服务通过： # 防火墙允许服务通过 &gt; firewall-cmd --zone=public --permanent --add-service={rpc-bind,mountd,nfs} success &gt; firewall-cmd --reload success 2.3 配置共享目录例如需要共享的目录为/mnt/kvm/： # 创建 /mnt/kvm 并修改权限 &gt; cd /mnt /mnt &gt; mkdir kvm /mnt &gt; chmod 755 kvm # 验证目录权限 /mnt &gt; ls -l total 0 drwxr-xr-x 2 root root 59 Oct 17 17:49 kvm 之后修改/etc/exports，将/mnt/kvm/添加进去： &gt; cat /etc/exports # 1. 只允许 abelsu7-ubuntu 访问 /mnt/kvm/ abelsu7-ubuntu(rw,sync,no_root_squash,no_all_squash) # 2. 根据 IP 地址范围限制访问 /mnt/kvm/ 192.168.0.0/24(rw,sync,no_root_squash,no_all_squash) # 3. 使用 * 表示访问不加限制 /mnt/kvm/ *(rw,sync,no_root_squash,no_all_squash) 关于/etc/exports中的参数含义： /mnt/kvm/：需要共享的目录 192.168.0.0/24：客户端 IP 范围，*表示无限制 rw：权限设置，可读可写 sync：同步共享目录 no_root_squash：可以使用root授权 no_all_squash：可以使用普通用户授权 保存之后，重启nfs服务： &gt; systemctl restart nfs 2.4 查看共享目录列表在centos-2本地查看： &gt; showmount -e localhost Export list for localhost: /mnt/kvm abelsu7-ubuntu 3. NFS 客户端3.1 安装 nfs-utils# CentOS/Fedora, etc. &gt; yum install nfs-utils # Ubuntu/Debian, etc. &gt; apt install nfs-common 3.2 配置并启动服务设置rpcbind服务开机启动： &gt; systemctl enable rpcbind 启动rpcbind： &gt; systemctl start rpcbind 客户端不需要打开防火墙，也不需要开启 NFS 服务 3.3 挂载共享目录先查看服务端的共享目录： &gt; showmount -e centos-2 Export list for centos-2: /mnt/kvm abelsu7-ubuntu 在客户端创建并挂载对应目录： &gt; mkdir -p /mnt/kvm &gt; mount -t nfs centos-2:/mnt/kvm /mnt/kvm 最后检查一下是否挂载成功： &gt; df -hT /mnt/kvm Filesystem Type Size Used Avail Use% Mounted on centos-2:/mnt/kvm nfs4 500G 119G 382G 24% /mnt/kvm &gt; mount | grep /mnt/kvm centos-2:/mnt/kvm on /mnt/kvm type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=222.xxx.xxx.xxx,local_lock=none,addr=116.xxx.xxx.xxx) 3.4 配置自动挂载在客户端编辑/etc/fstab： # /etc/fstab: static file system information. # # Use &#39;blkid&#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; # / was on /dev/sda8 during installation UUID=26d36e85-367a-4200-87fb-0505c5837078 / ext4 errors=remount-ro 0 1 # /boot/efi was on /dev/sda1 during installation UUID=000E-274F /boot/efi vfat umask=0077 0 1 # swap was on /dev/sda9 during installation # UUID=ee4da9a3-0288-4f8e-a86e-ab8ac3faa6bc none swap sw 0 0 # For nfs centos-2:/mnt/kvm /mnt/kvm nfs defaults 0 0 最后重新加载systemctl，即可实现重启后自动挂载： &gt; systemctl daemon-reload &gt; mount | grep /mnt/kvm centos-2:/mnt/kvm on /mnt/kvm type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=222.xxx.xxx.xxx,local_lock=none,addr=116.xxx.xxx.xxx) 4. NFS 读写速度测试 待更新… &gt; time dd if=/dev/zero of=/mnt/kvm-lun/test-nfs-speed bs=8k count=1024 &gt; time dd if=/mnt/kvm-lun/test-nfs-speed of=/dev/null bs=8k count=1024 参考文章NFS 安装与配置 CentOS 7 下 yum 安装和配置 NFS | Zhanming’s blog NFS | ArchLinux NFS 服务配置 | 极客学院 NFS 服务器 | 鸟哥的私房菜 NFS 配置不当那些事 | Blood_Zero CentOS 7.1 安装配置 NFS 共享文件系统 | Linux 运维日志 Ubuntu 18.04 下安装 NFS 详细步骤 | CSDN NFS /etc/exports 参数解释 | CSDN 常用 NFS mount 选项介绍 | 博客园 dd 读写速度测试 测试 nfs 文件读写速度 | CSDN NFS 使用详解之三：NFS 传输速度优化 | CSDN cp 命令显示进度 使用 rsync 命令取代 cp 拷贝，可显示进度 | ReMember Ubuntu 下的拷贝 cp 命令无进度条或进度显示的解决 | 梦翔天空 Linux 中 cp 文件或目录时如何显示进度? | CSDN 一个可以显示 Linux 命令运行进度的工具：Coreutils Viewer (cv) | Linux 中国 cv: 显示 cp、mv 等命令的进度 | LinuxToy progress - Linux tool to show progress for cp, mv, dd, … (formerly known as cv) | Github NFS 性能优化 KVM NFS 磁盘性能不佳 | 程序园 NFS 性能优化手册 | CSDN NFS 读写块大小分析 | 开源中国 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux Shell 编程速查在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"NFS","slug":"NFS","permalink":"https://abelsu7.top/tags/NFS/"},{"name":"Yum","slug":"Yum","permalink":"https://abelsu7.top/tags/Yum/"},{"name":"Apt","slug":"Apt","permalink":"https://abelsu7.top/tags/Apt/"}]},{"title":"Mock API Server 初体验","slug":"mock-api-intro","date":"2019-10-10T13:16:57.000Z","updated":"2019-10-10T14:08:04.771Z","comments":true,"path":"2019/10/10/mock-api-intro/","link":"","permalink":"https://abelsu7.top/2019/10/10/mock-api-intro/","excerpt":"前后端分离，Mock Server 初体验","text":"前后端分离，Mock Server 初体验 To be updated… 参考资料在线 Mock Server RAP2 - Smart API manage tool Easy Mock - 可视化、快速生成模拟数据 REST API postman Restlet Client - REST API Testing Swagger 开源项目 Mock.js | 生成随机数据，拦截 Ajax 请求 rap2-delos - 阿里妈妈前端团队出品的开源接口管理工具 RAP 第二代 | Github easy-mock | Github 相关文章 如何优雅的使用 Mock Server | 掘金 浅谈 easy-mock 最好的备胎没有之一 | SegmentFault 活儿好又性感的在线 Mock 平台 - Easy Mock | 掘金 Mock Server 实践 | 美团技术团队 你是如何构建 Web 前端 Mock Serve 的？| 知乎 为什么前后端分离了，你比从前更痛苦？| 开源中国 🚩推荐阅读（由hexo文章推荐插件驱动）在 Gin 中使用 swaggo 自动生成 RESTful API 文档Go Tour 笔记Go Web 编程笔记基于 Golang Web 框架 Gin 搭建 RESTful API 服务","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"RESTful","slug":"RESTful","permalink":"https://abelsu7.top/tags/RESTful/"},{"name":"Web 开发","slug":"Web-开发","permalink":"https://abelsu7.top/tags/Web-开发/"},{"name":"Mock","slug":"Mock","permalink":"https://abelsu7.top/tags/Mock/"}]},{"title":"微服务编排与容器调度","slug":"micro-service-orchestration-and-container-schedule","date":"2019-09-25T14:03:52.000Z","updated":"2019-10-20T09:28:03.737Z","comments":true,"path":"2019/09/25/micro-service-orchestration-and-container-schedule/","link":"","permalink":"https://abelsu7.top/2019/09/25/micro-service-orchestration-and-container-schedule/","excerpt":"相关资料整理，更新中…","text":"相关资料整理，更新中… 目录 目录 1. 微服务需要编排吗？ 1.1 什么是微服务 1.2 编制与编排 2. 微服务编排的流程 2.1 图形化的编排 2.2 编排的模型 2.3 服务雪崩、降级与熔断 2.4 服务参数的适配 3. 微服务基础架构 3.1 核心模块 3.2 微服务架构总体技术体系 3.3 微服务 vs K8s 4. 企业案例 4.1 网易公有云容器平台 1. 通过优化 Scheduler 解决并行调度的问题 2. 通过优化 Controller 加快新任务的调度速度 4.2 网易云轻舟微服务 1. 产品全景 2. 产品功能 4.3 新浪微博混合云 DCP 1. 容器编排 2. 容器编排需要解决的问题 3. 分层的编排 4. 微博混合云 DCP 架构设计 5. DCP 的功能模块 参考文章 1. 微服务需要编排吗？1.1 什么是微服务 一个微服务一般完成某个特定的功能，比如订单管理、客户管理等等 每一个微服务都有自己的业务逻辑和适配器 一些微服务还会发布 API 给其他微服务和应用客户端使用 1.2 编制与编排编制(Orchestration)： 面向可执行的流程 通过一个可执行的流程来协同内部及外部的服务交互 通过中心流程来控制总体的目标、涉及的操作、服务调用顺序 编排(Choreography)： 面向合作 通过消息的交互序列来控制各个部分资源的交互 参与交互的资源都是对等的，没有集中的控制 编排(Choreography)的难点： 编排难调试 由于没有预定义流程，所以很难事前保证流程正确性，基本靠事后分析数据来判断 业务流程的维护比较困难 2. 微服务编排的流程2.1 图形化的编排 采用图形化的编排，可以屏蔽代码细节处理，让整个流程一目了然 原子服务可以提供 REST 接口或者监听事件，可以通过流程编排这些原子服务来实现一个新的复杂服务 2.2 编排的模型 编排的模型包括： 活动模型：赋值、invoke(调用)、空 控制模型：顺序、分支、循环、异常抛出、异常捕获、并行 编排框架还提供了例如本地调用、REST 调用、同步/异步调用等活动，从而在使用上更加方便。 2.3 服务雪崩、降级与熔断 雪崩效应 在调用的时候我们知道有同步和异步的区别： 同步实现起来比较简单 但是在多级级联编排的时候要避免因为某个服务的不可用导致雪崩效应 一般可以通过设置合理的超时时间限流和服务熔断策略来避免 当Service A调用Service B，失败次数达到一定阈值时，Service A就不会再去调用Service B，而是降级去执行本地的方法。 2.4 服务参数的适配 流程编排完成之后，我们还需要给每个被编的服务提供正确的参数，是一个适配的过程 一个编排服务 (abcd) 由 a、b、c、d 服务编排而成 每个服务都会有自己的出参入参 适配的过程就是从上下文中给入参赋值以及将出参的结果写入到上下文中 编排服务执行到不同阶段，组成上下文的模型也是不一样的 从最初服务的开始执行的时候，上下文中只有系统级的参数和入参（请求报文） 到执行完一个被编服务后上下问就会增加这个被编服务的出参（响应报文） 执行上下文是一个不断增大的过程 适配不仅仅存在与编排服务的入参和被编服务的入参之间，还存在于被编服务和在其之前的服务出参之间 3. 微服务基础架构3.1 核心模块 微服务基础架构的核心模块包括： 服务框架 运行时支撑服务 后台服务 服务安全 服务容错 服务监控 服务部署平台 3.2 微服务架构总体技术体系 3.3 微服务 vs K8s 在微服务设计的十个要点中，我们会发现 Kubernetes 都能够有相应的组件和概念，提供相应的支持 其中最后的一块拼图就是服务发现，与熔断限流降级 4. 企业案例4.1 网易公有云容器平台 K8s 的架构本身就是微服务，支持定制化与横向扩展： 在 K8s 中几乎所有的组件都是无状态化的，状态都保存在统一的 etcd 里，扩展性很好，组件之间异步完成自己的任务，将结果放在 etcd 里面，互相不耦合： 网易云对容器创建流程进行了定制化。由于大促和非大促期间，节点的数目相差比较大，因而不能采用事先全部创建好节点的方式，这样会造成资源的浪费，因而中间添加了网易云自己的模块 Controller 和 IaaS 的管理层，使得当创建容器资源不足的时候，动态调用 IaaS 的接口，动态的创建资源。这一切对于客户端和 kubelet 无感知： K8s 的每个组件都可进行独立的优化，互不影响： 1. 通过优化 Scheduler 解决并行调度的问题 大的资源池的调度也是一个很大的问题，因为同样一个资源只能被一个任务使用 如果并行调度，则存在两个并行的调度器同时认为某个资源空闲，于是同时将两个任务调度到同一台机器的竞争情况 为了租户隔离，不同租户之间是不共享虚拟机的，这样不同的组合是可以参考 Mesos 机制进行并行调度的。每个租户仅在属于自己的有限节点中进行调度，大大提高了调度策略的并发性 并且通过预过滤无空闲资源的 Node，调整 predicate 算法进行预过滤，进一步减少调度规模 2. 通过优化 Controller 加快新任务的调度速度 K8s 采用的是微服务常使用的基于事件的编程模型 但基于事件模型的一个缺点是，总是通过 delta 进行事件触发，过了一段时间，就不知道是否同步了，因而需要周期性地 Resync 一下，保证全量的同步之后，然后再进行增量的事件处理 然而问题来了，当 Resync 时，正好遇到一个新容器的创建，则所有的事件在一个队列里面，拖慢了新创建容器的速度 通过保持多个队列，并且队列的优先级 ADD 优于 Update 优于 Delete 优于 Sync，保证相应的实时性 4.2 网易云轻舟微服务1. 产品全景 2. 产品功能 4.3 新浪微博混合云 DCP1. 容器编排 容器编排是跨主机去管理多个集群 Container 的一种行为，随着 Docker 的发展，生态圈越来越完善，比较常见的 Kubernetes，Mesos + Mathon，甚至 DCOS 等都属于此类范畴 容量编排是为了将资源利用率最大化，同时均衡系统因容错需要不断变化的需求 2. 容器编排需要解决的问题 服务定义：一般以 IP + port 唯一标识一个服务，这里端口的分配与管理会成为重点 资源管理：一个服务要运行，需要相应的资源，一般是 CPU/MEM/DISK/NET 等，怎么获取到这些资源，并合理分配是资源管理需要关注的部分，一般采用池化处理（资源池）。这也是编排的核心 容器调度：有了资源，怎么合理的选择资源节点，采取什么策略，怎么做容错处理等等，这些是容器调度需要关注的 服务检测：服务在起来后，要对外提供，需要验证其正确性，这里一般会做端口及业务检测 服务发现：验证通过的服务，如果真正对外提供服务，需要引入流量，也就是自动挂到 LB 上，这也是一种 WEB 类的服务发现 3. 分层的编排新浪混合云系统 DCP 在设计之初遇到了一个很明显的问题：很难用单一的 IaaS，PaaS 或 CaaS 去定义我们的场景： 于是选择了混合云的模式 系统采用分层设计的方法去适应业务场景 不同的层是存在不同的编排方法的： IaaS 的编排核心重点在计算资源 PaaS 的编排核心在于应用 CaaS 的编排核心在于容器即服务 对于新浪混合云 DCP，主要有以下两大方面： 服务的编排：重在弹性，比如扩容，缩容，容器迁移，容错处理，服务发现等 资源的编排：重在资源，对于私有云主要是物理机的管理与分配；对于公有云主要是标准化的 VM 4. 微博混合云 DCP 架构设计 微博目前开发的 DCP 主要包含三层： 资源管理层：分为内网主机和阿里云 ECS，目标是对上层业务提供统一、不可变的基础环境 容器调度层：根据资源区调度并启动容器，提供各种原子性的操作，例如基于任务模式的容器起、停、删、重启、服务注册、服务反注册、服务检测等等 业务编排层：基于调度层的 API，去串起整个业务的常见操作，比如服务部署、扩容、缩容、容器迁移等等 5. DCP 的功能模块 参考文章相关资料 微服务编排之道 | 掘金 微服务核心研究之编排 | 简书 编排的艺术：K8S 中的容器编排和应用编排 - Kuberneteschina | 知乎专栏 几种常见的微服务编排模式 | Neohope’s Blog kubernetes 容器编排系统介绍 | 腾讯云+社区 容器编排的作用和要实现的内容 | CSDN 从 kubernetes 看如何设计超大规模资源调度系统 | CSDN 编排管理成容器云关键 Kubernetes（K8s）和Swarm对比分析 | kubernetes 中文社区 云编排技术：探索您的选择 | IBM Developer Netflix Conductor: A microservices orchestrator | Medium.com Kubernetes 容器编排的三大支柱 | 51CTO 深入 kubernetes 调度之原理分析 | 腾讯云+社区 混合云编排工具 Terraform 简介 | int32bit 网易云🚩推荐阅读（由hexo文章推荐插件驱动）微服务学习资料汇总近期复习合集Kubernetes 实践简明指南Docker 实践简明指南Spring Boot从零入门1_详述Spring Boot从零入门4_日志记录及其配置详解","categories":[{"name":"微服务","slug":"微服务","permalink":"https://abelsu7.top/categories/微服务/"}],"tags":[{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"},{"name":"微服务","slug":"微服务","permalink":"https://abelsu7.top/tags/微服务/"}]},{"title":"Go 语言标准库学习","slug":"go-standard-library","date":"2019-09-20T02:20:56.000Z","updated":"2019-10-15T12:11:42.636Z","comments":true,"path":"2019/09/20/go-standard-library/","link":"","permalink":"https://abelsu7.top/2019/09/20/go-standard-library/","excerpt":"打开 Golang 开发的百宝箱，更新中…","text":"打开 Golang 开发的百宝箱，更新中… 强烈推荐： 《Go语言标准库》The Golang Standard Library by Example | GitBook The-Golang-Standard-Library-by-Example - Golang 标准库 | Github 1. fmt 参见 fmt 包函数列表 - gopkg| Github // Print/Sprint/Fprint func index(w http.ResponseWriter, r *http.Request) { fmt.Println(&quot;Inside handler: index&quot;) name := fmt.Sprintf(&quot;%s&quot;, &quot;abel&quot;) fmt.Fprintf(w, &quot;Hello %s!\\n&quot;, name) } 2. strings 参见 2.1 strings — 字符串操作 | The-Golang-Standard-Library-by-Example // 字符串分割 array := strings.Split(s, &quot;,&quot;) // 字符串清理 func stringsClean(value string) string { newReplacer := strings.NewReplacer(&quot;\\n&quot;, &quot; &quot;,&quot;\\t&quot;, &quot; &quot;) newValue := newReplacer.Replace(value) return strings.TrimSpace(newValue) } 3. sort// 数组排序 sort.Slice(prev, func(i, j int) bool { return prev[i] &gt; prev[j] }) 4. ioutil golang 中读写文件的几种方式 | CSDN Go 语言学习之 ioutil 包 (The way to go) | CSDN Go 语言学习之 os 包中文件相关的操作 (The way to go) | CSDN 5. sync Sync.Pool 浅析 | TY·Loafer 例 1：读取整行输入package main import ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strings&quot; ) func main() { r := bufio.NewReader(os.Stdin) line, _, err := r.ReadLine() if err != nil { fmt.Printf(&quot;error happend: %s\\n&quot;, err) } s := string(line) s = strings.TrimFunc(s, func(r rune) bool { if r == &#39;[&#39; || r == &#39;]&#39; { return true } return false }) fmt.Println(s) array := strings.Split(s, &quot;, &quot;) fmt.Println(array) } ------ [1, 2, 3, 4, 5] 1, 2, 3, 4, 5 [1 2 3 4 5] 参考文章 Go 上手指南 - 谢伟 | Github 对比学习：Golang VS Python3 | 知乎 浅谈 Go 语言实现原理 - Draveness | GitBook 1. 知乎专栏 推荐一个知乎专栏作者：谢伟，知乎专栏『Gopher』- Go 上手指南 Go 内置库第一季：strings - 谢伟 | 知乎 Go 内置库第一季：strconv - 谢伟 | 知乎 Go 内置库第一季：reflect - 谢伟 | 知乎 Go 内置库第一季：json - 谢伟 | 知乎 Go 内置库第一季：error - 谢伟 | 知乎 Go 内置库第一季：time - 谢伟 | 知乎 Go 内置库第一季：net/url - 谢伟 | 知乎 请教：FieldsFunc 函数的用法 | Golang 中国 【Go语言】基本类型排序和 slice 排序 | iTimeTraveler 其他不错的文章： Go Web 教程 - 谢伟 | 知乎 Go GraphQL 教程 - 谢伟 | 知乎 Go 与 Error 的前世今生 - 谢伟 | 知乎 自己构建节假日 API - 谢伟 | 知乎 打造一款 emoji 表情库 - 谢伟 | 知乎 写给程序员看的“幻灯片”制作教程 - 谢伟 | 知乎 2. 51CTO Go 语言开发学习教程 - 天山老妖S | 51CTO Go 语言常用标准库一 - 天山老妖S | 51CTO Go 语言常用标准库二 - 天山老妖S | 51CTO Go 语言常用标准库三 - 天山老妖S | 51CTO Go 语言常用标准库四 - 天山老妖S | 51CTO Go 语言常用标准库五 - 天山老妖S | 51CTO Go 语言常用标准库六 - 天山老妖S | 51CTO Go 语言 MySQL 数据库操作 - 天山老妖S | 51CTO Go 语言 database/sql 接口 - 天山老妖S | 51CTO 3. 标准库相关 《Go语言标准库》The Golang Standard Library by Example | GitBook The-Golang-Standard-Library-by-Example - Golang 标准库 | Github gopkg - astaxie | Github Golang 常用包 | 胡伟煌 Go 常用标准包介绍 - Mr_buffoon | CSDN Go 语言标准库概览 | Tony Bai 4. Github 项目 cos-storager - Go 开发的免费图床 | Github learning_tools - Go 实用工具类 | Github gocui - Minimalist Go package aimed at creating Console User Interfaces | Github lazyredis - 基于 gocui 实现的 redis 命令行客户端 | Github 5. 设计模式 go-patterns - Golang 设计模式 | Github golang-design-pattern - 设计模式 Golang 实现 | Github 6. 开发常用库 Swagger - API Development for Everyone 聊一聊 Go 的那些处理命令行参数和配置文件的库 | SegmentFault 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"标准库","slug":"标准库","permalink":"https://abelsu7.top/tags/标准库/"}]},{"title":"微服务学习资料汇总","slug":"micro-service-notes","date":"2019-09-18T04:35:24.000Z","updated":"2019-10-20T09:35:20.955Z","comments":true,"path":"2019/09/18/micro-service-notes/","link":"","permalink":"https://abelsu7.top/2019/09/18/micro-service-notes/","excerpt":"相关资料整理，更新中…","text":"相关资料整理，更新中… 目录 目录 1. 精选文章 2. Kubernetes 2.1 K8s 各组件之间的网络通信协议 2.2 K8s 架构图 3. 微服务 3.1 微服务简介 3.2 微服务架构 3.3 参考文章 4. Service Mesh 4.1 微服务 vs K8s 4.2 Service Mesh 简介 4.3 参考文章 5. 编排调度 5.1 Apache Mesos 5.2 K8s 5.3 服务雪崩、降级与熔断 6. 企业分享 7. 企业案例 7.1 网易云轻舟微服务 7.2 腾讯云微服务平台 TSF 7.3 华为云微服务引擎 CSE 8. 相关论文 9. 其他参考资料 1. 精选文章 轻量级微服务架构及其最佳实践 | DevOps时代 为什么 kubernetes 天然适合微服务 | 网易云 为什么 kubernetes 天然适合微服务 | 网易云基础服务 Kubernetes 如何打赢容器之战？| 阿里云栖社区 微服务杂谈 | 后端技术杂谈 微服务编排之道 | 掘金 编排的艺术：K8S 中的容器编排和应用编排 - Kuberneteschina | 知乎专栏 微服务核心研究之编排 | 简书 新浪微博混合云架构实践挑战之容器编排设计与实践 | InfoQ 容器 SDN 技术与微服务架构实践 | 七牛云 微服务架构技术栈选型手册 - 杨波 | InfoQ 《微服务架构核心20讲 》PPT - 杨波 | 极客时间 最全的微服务知识科普 | Docker 容器、容器云与Kubernetes技术漫谈 | K8S中文社区 深入解读 Service Mesh 背后的技术细节 - 刘超 | ServiceMesher 2. Kubernetes kubernetes-diagram-902x416.png Kubernetes 是什么？ - Linux 中国 | 知乎 为什么 kubernetes 天然适合微服务 | 网易云基础服务 容器平台选型的十大模式：Docker、DC/OS、K8S 谁与当先？| 网易云基础服务 Kubernetes 如何打赢容器之战？| 阿里云栖社区 11 Ways (Not) to Get Hacked | kubernetes.io What is Kubernetes | kubernetes.io 2019 KubeCon + ClondNativeCon + Open Source Summit有感 | 赵化冰 Kubernetes 架构学习笔记 | kubernetes中文社区 kubernetes 常用命令总结 | kubernetes中文社区 在 Kubernetes 中，如何动态配置本地存储？ | kubernetes中文社区 外部访问 kubernetes 的三种模式 - kubernetes 社区 | 知乎 从零入门 K8s：人人都能看懂 Pod 与容器设计模式 | 阿里巴巴云原生 Kubernetes vs Docker Swarm：完整的比较指南 | 腾讯云+社区 Kubernetes：过去、现在与未来 | 掘金 2.1 K8s 各组件之间的网络通信协议 2.2 K8s 架构图 参考 Kubernetes 设计架构 | kubernetes 中文社区 3. 微服务3.1 微服务简介 微服务杂谈 | 后端技术杂谈 微服务杂谈 | kubernetes中文社区 微服务（Microservice）那点事 | 阿里云栖社区 微服务实战（一）：微服务架构的优势与不足 | DockOne.io 谈谈微服务架构中的基础设施：Service Mesh 与 Istio | 赵化冰 阿里P8架构师谈：微服务技术架构、监控、Docker、服务治理等体系 | 优知学院 3.2 微服务架构 参考资料： 微服务架构技术栈选型手册 - 杨波 | InfoQ 《微服务架构核心20讲 》PPT - 杨波 | 极客时间 微服务架构本质论 | 腾讯云+社区 微服务核心架构梳理 | 掘金 微服务架构 | cnblogs 一篇文章快速理解微服务架构 | dockone.io 微服务架构的优势与不足 | dockone.io 微服务（Microservice）那点事 | 阿里云栖社区 微服务相关文章 | 程序猿 DD 大部分公司在使用的微服务技术架构体系示意图： 一、核心模块 微服务基础架构的核心模块包括： 服务框架 运行时支撑服务 后台服务 服务安全 服务容错 服务监控 服务部署平台 二、技术体系 其中粉红色标注的模块是和微服务关系最密切的模块 三、服务框架选型 Sping Boot、Spring Cloud：可认为是一种 RESTful 框架，序列化协议采用基于文本的 JSON，通讯协议一般基于 HTTP Apache Dubbo：本质上是一套基于 Java 的 RPC 框架，主要面向 Java 技术栈 Motan ：新浪微博开源，功能与 Dubbo 类似，可以认为是一个轻量裁剪版的 Dubbo 四、运行时支撑服务选型 待更新… 3.3 参考文章 Re：从 0 开始的微服务架构：（一）重识微服务架构 - 苏槐 | InfoQ Re：从 0 开始的微服务架构：（二）如何快速体验微服务架构？- 苏槐 | InfoQ Re：从 0 开始的微服务架构：（三）微服务架构 API 的开发与治理 - 苏槐 | InfoQ Re：从 0 开始的微服务架构：（四）如何保障微服务架构下的数据一致性 - 苏槐 | InfoQ Re：从 0 开始的微服务架构：（五）代码给你，看如何用 Docker 支撑微服务 - 苏槐 | InfoQ 微服务的 4 个设计原则和 19 个解决方案 | EAWorld 微服务化的十个设计要点 - 刘超 | 架构师社区 亿级规模的高可用微服务系统，如何轻松设计？| 51CTO技术栈 大规模微服务单元化与高可用设计 | 刘超的通俗云计算 轻量级微服务架构及其最佳实践 | DevOps时代 4. Service Mesh 参见 深入解读 Service Mesh 背后的技术细节 - 刘超 | ServiceMesher 4.1 微服务 vs K8s 微服务设计 Kubernetes 功能 1. API 网关 Ingress 2. 无状态化，区分有状态化和无状态的应用 无状态对应 Deployment，有状态对应 StatefulSet 3. 数据库的横向扩展 headless service 指向 PaaS 服务，或者 StatefulSet 部署 4. 缓存 headless service 指向 PaaS 服务，或者 StatefulSet 部署 5. 服务拆分和服务发现 Service 6. 服务编排与弹性伸缩 Deployment 的 Replicas 7. 统一配置中心 ConfigMap 8. 统一日志中心 DaemonSet 部署日志 Agent 9. 熔断、限流、降级 Service Mesh 10. 全方位的监控（智能管控？） Cadvisor, DaemonSet 部署监控 Agent 在我们微服务设计的十个要点中，我们会发现Kubernetes都能够有相应的组件和概念，提供相应的支持。 其中最后的一块拼图就是服务发现，与熔断限流降级。 众所周知，Kubernetes 的服务发现是通过Service来实现的，服务之间的转发是通过kube-proxy下发 iptables 规则来实现的，这个只能实现最基本的服务发现和转发能力，不能满足高并发应用下的高级的服务特性，比较 SpringCloud 和 Dubbo 有一定的差距，于是 Service Mesh 诞生了，他期望将熔断，限流，降级等特性，从应用层，下沉到基础设施层去实现，从而使得 Kubernetes 和容器全面接管微服务。 待更新… 4.2 Service Mesh 简介 参见 微服务架构之「 下一代微服务 Service Mesh 」| 不止思考 一、什么是 Service MeshService Mesh中文名称为服务网格，因为它的部署图看起来就像一个网格： 图中的绿色小块可以理解为微服务应用，蓝色小块可以理解为 Service Mesh 的轻量级网络代理 简单来说：Service Mesh就是一个基础设施层，它是用于处理微服务中服务与服务之间通信的一种技术。 有了 Service Mesh 之后，在微服务框架中，服务与服务之间的通信就是靠这些网络代理模块来保障。 二、为什么需要 Service Mesh在传统的微服务架构中，随着业务越来越复杂，拆分的服务实例也越来越多，那么各个服务之间的依赖就变成了非常复杂的网络拓扑结构，类似下图： 在如此复杂的分布式部署架构下，微服务中服务依赖调用和数据传输所面临的问题也成倍增加，极大的提高了服务治理的难度。 同时，由于容器化技术的成熟和规模化，微服务都会采用容器化，并朝着云原生应用的方向发展。而传统的微服务架构中，虽然也有服务治理的组件，但是这些组件大多需要在应用代码里进行集成，并不符合云原生的思想。因此，急需一个标准化、能高效部署和运维的微服务体系方案。 因此，Service Mesh 就应运而生了——其目的就是用来解决微服务架构中服务间可靠调用、服务治理等问题。 三、Service Mesh 的原理与应用Service Mesh 由两个核心模块组成，SideCar和Control Plane： 1. Sidecar： Sidecar即上面提到的与服务部署在一起的轻量级网络代理，它的作用就是实现服务框架的各项功能，这样就可以让服务 (Service A 或 B) 回归业务本质。 传统的微服务架构中，各种服务框架的功能 (例如服务发现、负载均衡、限流熔断等) 的代码逻辑或多或少都需要耦合到服务实例的代码中，给服务实例增加了很多业务无关的代码，也提升了复杂度 有了Sidecar之后，服务节点只做业务逻辑自身的功能，服务之间的调用交给了Sidecar，由Sidecar去注册服务、去做服务发现、去做请求路由、去实现熔断限流、去做日志统计。 在这种新的微服务架构中，所有的Sidecar组合在一起，就是一个服务网格了。不过，这个大型的服务网格并不是完全自治的，它还需要一个统一的控制节点，也就是Control Plane。 2. Control Plane： Control Plane是用来从全局的角度控制Sidecar的。例如它负责所有Sidecar的注册，并存储一个统一的路由表，帮助各个Sidecar进行负载均衡和请求调度。 此外，Control Plane还会收集所有Sidecar的监控信息和日志数据，相当于Service Mesh架构的大脑。Control Plane控制着Sidecar来实现服务治理的各项功能。 4.3 参考文章 深入解读 Service Mesh 背后的技术细节 - 刘超 | ServiceMesher Service Mesh：重塑微服务市场 - 敖小剑 | ServiceMesher Istio Service Mesh 教程 - 宋净超 | ServiceMesher 微服务架构之「 下一代微服务 Service Mesh 」| 不止思考 5. 编排调度 微服务编排之道 | 掘金 微服务核心研究之编排 | 简书 编排的艺术：K8S 中的容器编排和应用编排 - Kuberneteschina | 知乎专栏 几种常见的微服务编排模式 | Neohope’s Blog kubernetes 容器编排系统介绍 | 腾讯云+社区 容器编排的作用和要实现的内容 | CSDN 从 kubernetes 看如何设计超大规模资源调度系统 | CSDN 编排管理成容器云关键 Kubernetes（K8s）和Swarm对比分析 | kubernetes 中文社区 云编排技术：探索您的选择 | IBM Developer Netflix Conductor: A microservices orchestrator | Medium.com 5.1 Apache MesosMesos 基于 master/slave 架构，框架决定如何利用资源，master 负责管理机器，slave 会定期的将机器情况报告给 master，master再将信息给框架。 5.2 K8s 可参考 Kubernetes 设计架构 | kubernetes 中文社区 5.3 服务雪崩、降级与熔断 谈谈服务雪崩、降级与熔断 | 博客园 微服务熔断与隔离 | 阿里云栖社区 漫画：什么是服务熔断？- 程序员小灰 | 掘金 6. 企业分享 新浪微博混合云架构实践挑战之概述篇 | InfoQ 新浪微博混合云架构实践挑战之不可变基础设施 | InfoQ 新浪微博混合云架构实践挑战之镜像分发实战 | InfoQ 新浪微博混合云架构实践挑战之容器编排设计与实践 | InfoQ 新浪微博混合云，容器编排设计与实践 | 高效开发运维 来自京东、唯品会对微服务编排、API网关、持续集成的实践分享（上）| 开源中国 来自京东、宅急送对微服务编排、API网关、持续集成的实践分享（下） 容器 SDN 技术与微服务架构实践 | 七牛云 万台规模下的 SDN 控制器集群部署实践 - H3C | InfoQ 华为容器在K8S上的技术实践之路 - 黄毽 | InfoQ ArchSummit 2018 会议 PPT 蚂蚁金服大规模微服务架构下的 Service Mesh 探索之路 | 蚂蚁金服科技 爱奇艺视频后台从”单兵作战”到”团队协作”的微服务实践 | 爱奇艺技术产品团队 Service Mesh 在有赞的实践与发展 | 有赞coder 7. 企业案例7.1 网易云轻舟微服务 官网地址：轻舟微服务 | 网易云 一、产品介绍轻舟微服务是围绕应用和微服务打造的一站式 PaaS 平台，帮助用户快速实现易接入、易运维的微服务解决方案。为致力于数字化转型的企业提供中台服务治理，帮助企业实现建立生态统一标准，优化管理能力及自动化能力。 二、产品全景 三、产品优势基于开源、兼容开源： 全面兼容 Spring Cloud 和 Dubbo 框架 基于 Kubernetes 的容器调度与编排 支持已有服务框架的平滑迁移 低成本、易接入： 支持代码零改动接入微服务框架 非侵入式探针，支持应用拓扑可视化 支持统一的平台认证&amp;权限管控 智能运维&amp;立体化监控： 实时监控，精准掌控服务健康状况 服务拓扑，调用链跟踪可视化呈现 多维度关联分析，预防系统级故障 四、产品功能微服务治理框架： 服务注册/发现 服务治理 服务鉴权 动态配置管理 服务拓扑 智能 API 网关： API 发布管理 API 鉴权 流量控制 降级&amp;熔断 API 测试 分布式事务： 跨服务事务 跨数据源事务 混合事务 事务状态监控 异常事务处理 容器应用管理服务： 应用部署 弹性扩容 高效混合云管理 安全保障 性能监控 DevOps： 流水线管理 打通应用开发工具链：代码、构建、测试、镜像构建、发布、配置、监控 AIOps： 分布式调用链跟踪/查询 指标异常检测 告警关联分析 故障根因分析 7.2 腾讯云微服务平台 TSF 官网地址：腾讯微服务平台 TSF | 腾讯云 一、产品介绍腾讯微服务平台（Tencent Service Framework，TSF）是一个围绕应用和微服务的 PaaS 平台，提供一站式应用全生命周期管理能力和数据化运营支持，提供多维度应用和服务的监控数据，助力服务性能优化。提供基于 Spring Cloud 和 Service Mesh 两种微服务架构的商业化支持。 二、产品特性拥抱开源社区： 拥抱 Spring Cloud 和 Istio 开源社区，提供高可用、可扩展、灵活的微服务技术中台商业版支持 支持异构系统平滑迁移到 TSF 上，降低用户迁移到微服务的时间和人力成本 应用全生命周期管理： 提供从创建应用到运行应用的全生命周期管理，支持创建、部署、回滚、扩容、下线、启动和停止应用 提供虚拟机和容器两种部署方式，满足不同客户的使用需求 细粒度服务治理： 提供服务和 API 级别的服务治理能力 支持控制台上配置服务路由、服务限流、服务鉴权规则 支持分布式配置管理 分布式事务： 集成了分布式事务能力 支持 TCC 模式分布式事务管理功能，解决跨数据库和跨服务的事务问题 灵活运维： 支持日志服务、调用链、服务依赖拓扑图 支持基于监控的弹性伸缩功能 三、应用场景构建分布式系统： 金融业务往往有严格合规性要求，用户能够将业务部署在专用宿主机的云服务器上，在资源共享的同时保证与其他用户的子机物理隔离，满足敏感业务数据保护、磁盘消磁需求。 应用发布和管理： 相对于传统的应用发布需要运维人员登录到每一台服务器进行发布和部署，TSF 针对分布式系统的应用发布和管理，提供了简单易用的可视化控制台。用户通过控制台可以发布应用，包括创建、部署、启动应用，也支持查看应用的部署状态。除此之外，用户可以通过控制台管理应用，包括回滚应用、扩容、缩容和删除应用。 服务治理： 支持服务级别和 API 级别的服务治理能力，包括服务路由、服务限流、服务鉴权功能。服务路由功能支持将请求按权重路由到不同版本的服务上。 7.3 华为云微服务引擎 CSE 官网地址：微服务引擎 CSE | 华为云 一、产品介绍微服务引擎（Cloud Service Engine）提供高性能微服务框架和一站式服务注册、服务治理、动态配置和分布式事务管理控制台，帮助用户实现微服务应用的快速开发和高可用运维；支持 ServiceComb、Spring Cloud 和 Service Mesh 运行环境。 二、功能描述微服务开发框架： 打包了微服务注册、发现、通信和治理等基础能力 支持 REST 和 RPC 协议 微服务治理中心： 提供微服务负载均衡、限流、降级、熔断、容错等治理能力 微服务安全管控： 提供认证鉴权、黑白名单等能力保障微服务访问安全 微服务灰度发布： 支持按权重和接口参数（例如用户群组或用户所属区域等等）定义微服务灰度发布规则 分布式事务管理： 提供最终一致性（TCC）和强一致性（WSAT）事务管理框架 非侵入式接入： 提供 Service Mesh 服务 可实现非侵入式接入已有微服务 统一配置中心： 支持微服务配置项的发布、变更和通知 微服务仪表盘： 提供微服务实例和接口级吞吐量、时延和成功率的实时监控仪表盘 三、应用场景微服务应用高可用运维： 低门槛：通用治理能力沉淀到框架，开发人员只需聚焦业务 简单易用：提供 GUI 一站式治理控制台 准实时：运行状态实时监控，配置下发实时生效 多语言微服务解决方案： 多语言接入：支持 JAVA、GO、.NET、Node.js、PHP、Python 等等 高性能低时延：提供高性能 REST/RPC 协议微服务框架 开源开放：微服务核心框架 ServiceComb 已在 Apache 开源 开源框架微服务应用接入与管理： 零成本迁移：Spring Cloud/Dubbo 应用零修改接入 兼容主流开源生态：兼容 Spring Cloud 主流开源社区，与业界生态能力互通 非侵入解决方案：提供商业版 Service Mesh 8. 相关论文 软件服务的在线演化 - 国防科大计算机学院 | 计算机学报 需求驱动的服务动态自适应与演化方法的研究与实现 | 清华大学软件学院 需求驱动的微服务应用自适应演化框架研究与实现 | 浙江工业大学 基于容器云的微服务系统 | 联通软件研究院 面向 Docker 的微服务部署策略研究 | 厦门大学 微服务环境下容器编排可视化实践研究 | 北方工业大学 云计算环境下基于QoS的服务自适应演化研究 | 东华理工大学 基于环境感知的云服务自适应演化研究 | 东华理工大学 人工智能在网络编排系统中的应用 | 北京邮电大学网络与交换技术国家重点实验室 9. 参考资料开源框架 Apache ServiceComb - 支持多语言的一站式开源微服务解决方案 go-chassis | Github go-chassis’s Documentation 使用 ServiceComb go-chassis 构建微服务 | InfoQ go-chassis/go-bmi | Github 使用 go-chassis 管理 RESTful API 文档 | 掘金 ServiceComb 服务网格与微服务开发框架融合实践 - 田晓亮 | GitChat 华为开源项目 ServiceComb 快速入门 - 李达港 | IT大咖说 相关文章 推荐 30 个用于微服务的顶级工具 | 高效开发运维 《微服务：从设计到部署》 | Github 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度近期复习合集Kubernetes 实践简明指南Docker 实践简明指南Spring Boot从零入门1_详述Spring Boot从零入门4_日志记录及其配置详解","categories":[{"name":"微服务","slug":"微服务","permalink":"https://abelsu7.top/categories/微服务/"}],"tags":[{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"},{"name":"微服务","slug":"微服务","permalink":"https://abelsu7.top/tags/微服务/"}]},{"title":"VS Code 中使用 gopls 补全 Go 代码","slug":"gopls-guide","date":"2019-09-06T02:41:59.000Z","updated":"2019-11-01T03:44:55.400Z","comments":true,"path":"2019/09/06/gopls-guide/","link":"","permalink":"https://abelsu7.top/2019/09/06/gopls-guide/","excerpt":"Go, please","text":"Go, please 1. 背景折腾 VS Code 写 Go 的朋友都有这种体会，VS Code 的 Go 插件体验上还是输给 GoLand 不少，尤其是代码补全和提示，GOPATH没配置好或者项目路径在GOPATH之外就基本残废。 但是我还是坚持用 VS Code，毕竟人家开源，又有微软爸爸背书，相比 GoLand 更加轻量，快捷键用的也更顺手，其实最主要还是没钱 QAQ。 2. goplsgopls 实现了 VS Code 的 Language Server Protocol (LSP)，发音为go please。 Go Team 目前正在积极维护gopls，有望成为之后 VS Code Go 插件的默认补全工具，但目前还是有很多小问题，例如下面这个Known issue： Cursor resets to the beginning or end of file on format: #31937. 相似的问题还有下面这个： Cursor flies to top of file on save and text flashes: #2728 只在 Windows 环境下出现，因为 Windows 默认的换行符是CRLF，而目前gopls的格式化只支持LF换行。 Windows 可以设置&quot;files.eol&quot;: &quot;\\n&quot;暂时规避一下，评论里提到之后会解决这个问题 目前已知的 Known issues： Cursor resets to the beginning or end of file on format: #31937 Editing multiple modules in one editor window: #32394 Language features do not work with cgo: #32898 Does not work with build tags: #29202 Find references and rename only work in a single package: #32869, #32877 Completion does not work well after go or defer statements: #29313 Changes in files outside of the editor are not yet tracked: #31553 期待 Go Team 早日解决🍻 3. VS Code 相关设置 参见 gopls Settings - golang/tools | Github &quot;go.useLanguageServer&quot;: true, &quot;[go]&quot;: { &quot;editor.snippetSuggestions&quot;: &quot;none&quot;, &quot;editor.formatOnSave&quot;: true, &quot;editor.codeActionsOnSave&quot;: { &quot;source.organizeImports&quot;: true } }, &quot;gopls&quot;: { &quot;completeUnimported&quot;: true, &quot;usePlaceholders&quot;: true, &quot;completionDocumentation&quot;: true, &quot;hoverKind&quot;: &quot;SynopsisDocumentation&quot; // No/Synopsis/Full, default Synopsis }, &quot;files.eol&quot;: &quot;\\n&quot;, // formatting only supports LF line endings 此外还有一些ExperimentalFeatures： &quot;go.languageServerExperimentalFeatures&quot;: { &quot;format&quot;: true, &quot;autoComplete&quot;: true, &quot;rename&quot;: true, &quot;goToDefinition&quot;: true, &quot;hover&quot;: true, &quot;signatureHelp&quot;: true, &quot;goToTypeDefinition&quot;: true, &quot;goToImplementation&quot;: true, &quot;documentSymbols&quot;: true, &quot;workspaceSymbols&quot;: true, &quot;findReferences&quot;: true, &quot;diagnostics&quot;: false }, 最后提供一份自用的 VS Code 用户设置，仅供参考：用户设置 - VS Code | Coding-Notes 参考文章gopls gopls documentation - golang/tools | Github x/tools/gopls: formatting resets cursor after save with CRLF line endings - golang/go | Github Cursor flies to top of file on save and text flashes - microsoft/vscode-go | Github gopls - 及时的代码补全 | arbent 在 VS Code 中使用 gopls | SegmentFault VS Code 中的代码自动补全和自动导入包 | 茶歇驿站 VSCode 写 Golang，请切换到 Google 官方语言服务器 gopls，有质的提升 | 论坛爱好者 goproxy goproxy.io goproxy.cn Go extension Go tools that the Go extension depends on - microsoft/vscode-go | Github Visual Studio Code Go 插件文档翻译 | 掘金 Go mod go mod 使用 | 掘金 VSCode 配置 Go 环境及 Go mod 使用 | 方缘之道 开始使用 Go Module - isLishude | 知乎 Go Modules 详解 | 后端进阶 Go Modules 不完全教程 | Golang 成神之路 Go Modules 不完全教程 - Golang Inside | 知乎专栏 Go Module 使用实践及问题解决 | banyu 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://abelsu7.top/tags/VS-Code/"},{"name":"gopls","slug":"gopls","permalink":"https://abelsu7.top/tags/gopls/"}]},{"title":"半虚拟化 I/O 框架 virtio","slug":"virtio-in-kvm","date":"2019-09-02T03:05:18.000Z","updated":"2019-11-19T13:34:08.676Z","comments":true,"path":"2019/09/02/virtio-in-kvm/","link":"","permalink":"https://abelsu7.top/2019/09/02/virtio-in-kvm/","excerpt":"virtio 框架学习，更新中…","text":"virtio 框架学习，更新中… 1. virtio 概述KVM 是必须依赖硬件虚拟化技术辅助（例如 Intel VT-x、AMD-V）的 Hypervisor： CPU：有 VMX root 和 non-root 模式的支持，其运行效率是比较高的 内存：有 Intel EPT/AMD NPT 的支持，内存虚拟化的效率也比较高 I/O：KVM 客户机的 I/O 操作需要VM-Exit到用户态由 QEMU 进行模拟。传统的方式是使用纯软件的方式来模拟 I/O 设备，效率并不高 为了解决 I/O 虚拟化效率低下的问题，可以在客户机中使用半虚拟化驱动（Paravirtualized Drivers，PV Drivers）来提高客户机的 I/O 性能。目前，KVM 中实现半虚拟化驱动的方式就是采用了virtio这个 Linux 下的设备驱动标准框架。 virtio 是 Linux 平台下一种 I/O 半虚拟化框架，由澳大利亚程序员 Rusty Russell 开发。他当时的目的是支持自己的虚拟化解决方案 Lguest，而在 KVM 中也广泛使用了 Virtio 作为半虚拟化 I/O 框架。 2. 软件方式模拟 I/O 设备2.1 基本原理下图是 QEMU 以纯软件方式模拟 I/O 设备的示意图： 当 Guest 中的设备驱动程序发起 I/O 操作请求时，KVM 模块中的 I/O Trap Code 会拦截这次 I/O 请求，经过处理后将本次 I/O 请求的信息存放到 I/O sharing page 中，并通知用户空间的 QEMU QEMU 从 I/O sharing page 中获得 I/O 操作的具体信息后，交由硬件模拟代码（QEMU I/O Emulation Code）来模拟本次 I/O 操作 模拟代码负责和实际的设备驱动进行交互，模拟此次 I/O 操作，获取返回结果并将其放回 I/O Sharing Page 中 最后，KVM 中的 I/O Trap Code 负责读取 I/O Sharing Page 中的操作结果，并将结果返回到客户机中 需要注意的是： 客户机作为一个QEMU 进程，在等待 I/O 时也可能被阻塞 当客户机通过 DMA 方式访问大块 I/O 时，QEMU 不会把 I/O 操作结果放到 I/O 共享页中，而是通过内存映射的方式将结果直接写进客户机的内存中，然后通过 KVM 模块告诉客户机 DMA 操作已经完成 2.2 优缺点 优点：可以通过软件模拟出各类硬件设备，而无需修改客户机操作系统 缺点：每次 I/O 操作的路径较长，有较多的VM-Entry、VM-Exit发生，需要多次上下文切换，也需要多次数据复制，因此性能较差 3. 半虚拟化 I/O 框架 virtio3.1 基本原理 如图所示，virtio 分为了前端驱动和后端驱动： 前端驱动 frontend：如virtio_blk、virtio_net等，是在客户机中存在的驱动程序模块 后端驱动 backend：在 QEMU 中实现 在前后端驱动之间，还定义了两层来支持客户机和 QEMU 之间的通信： virtio 层：虚拟队列接口，它在概念上将前端驱动程序附加到后端处理程序。一个前端驱动程序可以使用 0 个或多个队列，具体数量取决于需求 例如：virtio_net网络驱动程序使用两个虚拟队列（接收/发送），而virtio_blk驱动仅使用一个虚拟队列。虚拟队列实际上被实现为客户机操作系统和 Hypervisor 之间的衔接点，但它可以通过任意方式实现，前提是客户机操作系统和 virtio 后端程序都遵循一定的标准，以相互匹配的方式实现它。 virtio-ring 层：实现了环形缓冲区（ring buffer），用于保存前端驱动和后端处理程序执行的信息，并且它可以一次性保存前端驱动的多次 I/O 请求，再交由后端驱动批量处理，最后实际调用宿主机中的设备驱动来完成物理层面上的 I/O 操作。 这样做就可以根据约定实现批量处理而不是客户机中每次 I/O 请求都需要处理一次，从而提高了客户机与 Hypervisor 之间信息交换的效率 3.2 优缺点 优点：可获得很好的 I/O 性能，接近 Native。所以在使用 KVM 时，如果宿主机和客户机都支持 Virtio，一般都推荐使用 Virtio 以达到更高的 I/O 性能 缺点：必须在客户机中安装前端驱动，且按照 Virtio 的规定格式进行数据传输 4. virtio 的架构virtio 是半虚拟化的解决方案，是半虚拟化 Hypervisor 的一组通用 I/O 设备的抽象。它提供了一套上层应用与各 Hypervisor 虚拟化设备（KVM、Xen、VMware 等）之间的通信框架和编程接口，减少了跨平台所带来的兼容性问题。客户机需要知道自己运行在虚拟化环境中，进而根据 Virtio 标准和 Hypervisor 协作，从而提高 I/O 性能。 前端驱动：Frontend Driver，是位于客户机内核中的驱动程序模块 后端驱动：Backend Driver，在宿主机用户空间的 QEMU 中实现 virtio 是半虚拟化驱动框架，可以提供接近 Native 的 I/O 性能，但是客户机中必须安装特定的 virtio 驱动，并按照 virtio 的规定格式进行数据传输 4.1 版本要求Kernel &gt;= 2.6.25的内核都支持 virtio。由于 virtio 的后端处理程序是在位于用户空间中的 QEMU 中实现的，所以宿主机只需要比较新的内核即可，不需要特别编译 virtio 相关驱动。而客户机需要有特定 virtio 驱动程序的支持，以便客户机处理 I/O 操作请求时调用前端驱动。 客户机内核中关于 virtio 的部分配置如下： # 需要启用的选项 CONFIG_VIRTIO_PCI=m CONFIG_VIRTIO_BALLOON=m CONFIG_VIRTIO_BLK=m CONFIG_VIRTIO_NET=m CONFIG_VIRTIO=m CONFIG_VIRTIO_RING=y # 其他相关的选项 CONFIG_VIRTIO_VSOCKETS=m CONFIG_VIRTIO_VSOCKETS_COMMON=m CONFIG_SCSI_VIRTIO=m CONFIG_VIRTIO_CONSOLE=m CONFIG_HW_RANDOM_VIRTIO=m CONFIG_DRM_VIRTIO_GPU=m CONFIG_VIRTIO_PCI_LEGACY=y CONFIG_VIRTIO_INPUT=m # CONFIG_VIRTIO_MMIO is not set # 在子机中查看 VIRTIO 相关内核模块 &gt; lsmod | grep virtio virtio_balloon 18015 0 virtio_net 28063 0 virtio_blk 18166 2 virtio_pci 22934 0 virtio_ring 22746 4 virtio_blk,virtio_net,virtio_pci,virtio_balloon virtio 14959 4 virtio_blk,virtio_net,virtio_pci,virtio_balloon 4.2 层次结构 如图所示，virtio 大致分为三个层次：前端驱动（位于客户机）、后端驱动（位于 QEMU）以及中间的传输层。 每一个 virtio 设备（块设备、网卡等）在系统层面看来，都是一个 PCI 设备。这些设备之间有共性部分，也有差异部分。 共性部分： 都需要挂接相应的 buffer 队列操作 virtqueue_ops 都需要申请若干个 buffer 队列，当执行 I/O 输出时，需要向队列写入数据 都需要执行 pci_iomap 将设备配置寄存器区间映射到内存区间 都需要设置中断处理 等中断来了，都需要从队列读出数据，并通知客户机系统，数据已入队 差异部分： 与设备相关联的系统、业务、队列中写入的数据含义各不相同 例如，网卡在内核中是一个net_device，与协议栈系统关联起来。同时，向队列中写入什么数据、数据的含义如何，各个设备也不相同。队列中来了什么数据，是什么含义，如何处理，各个设备也不相同 如果每个 virtio 设备都完整的实现自己的功能，就会造成不必要的代码冗余。针对这个问题，virtio 又设计了virtio_pci模块，以处理所有 virtio 设备的共性部分。这样一来所有的 virtio 设备在系统看来都是一个 PCI 设备，其设备驱动都是virtio_pci 但是，virtio_pci并不能完整的驱动任何一个设备。因此，virtio_pci在调用probe()接管每一个设备时，会根据其virtio_device_id来识别出具体是哪一种设备，然后相应的向内核注册一个 virtio 类型的设备。 在注册设备之前，virtio_pci驱动已经为该设备做了许多共性操作，同时还为该设备提供了各种操作的适配接口，这些都通过virtio_config_ops来适配。 4.3 前端代码层次结构相关源码文件Kernel 3.10.0中关于 virito 的重要源码文件如下： drivers/block/virtio_blk.c drivers/char/hw_random/virtio_rng.c drivers/char/virtio_console.c drivers/net/virtio_net.c drivers/scsi/virtio_scsi.c drivers/virtio/virtio_balloon.c drivers/virtio/virtio_mmio.c drivers/virtio/virtio_pci.c drivers/virtio/virtio_ring.c drivers/virtio/virtio.c include/linux/virtio_caif.h include/linux/virtio_config.h include/linux/virtio_console.h include/linux/virtio_mmio.h include/linux/virtio_ring.h include/linux/virtio_scsi.h include/linux/virtio.h include/linux/vring.h include/uapi/linux/virtio_9p.h include/uapi/linux/virtio_balloon.h include/uapi/linux/virtio_blk.h include/uapi/linux/virtio_config.h include/uapi/linux/virtio_console.h include/uapi/linux/virtio_ids.h include/uapi/linux/virtio_net.h include/uapi/linux/virtio_pci.h include/uapi/linux/virtio_ring.h include/uapi/linux/virtio_rng.h tools/virtio/linux/virtio_config.h tools/virtio/linux/virtio_ring.h tools/virtio/linux/virtio.h tools/virtio/linux/vring.h tools/virtio/vitrio_test.c tools/virtio/vringh_test.c linux-3.10 ├─ drivers | ├─ block | | └─ virtio_blk.c | | | ├─ char | | ├─ hw_random | | | └─ virtio_rng.c | | | | | └─ virtio_console.c | | | ├─ net | | └─ virtio_net.c | | | ├─ scsi | | └─ virtio_scsi.c | | | └─ virtio | ├─ virtio_balloon.c | ├─ virtio_mmio.c | ├─ virtio_pci.c | ├─ virtio_ring.c | └─ virtio.c | ├─ include | ├─ linux | | ├─ virtio_caif.h | | ├─ virtio_config.h | | ├─ virtio_console.h | | ├─ virtio_mmio.h | | ├─ virtio_ring.h | | ├─ virtio_scsi.h | | ├─ virtio.h | | └─ vring.h | | | └─ uapi | └─ linux | ├─ virtio_9p.h | ├─ virtio_balloon.h | ├─ virtio_blk.h | ├─ virtio_config.h | ├─ virtio_console.h | ├─ virtio_ids.h | ├─ virtio_net.h | ├─ virtio_pci.h | ├─ virtio_ring.h | └─ virtio_rng.h | └─ tools └─ virtio ├─ linux | ├─ virtio_config.h | ├─ virtio_ring.h | ├─ virtio.h | └─ vring.h | ├─ virtio_test.c └─ vringh_test.c 类结构层次在 virtio 前端驱动即客户机内核中，virtio 的类层次结构如下图所示： virtio_driver最顶级的是virtio_driver，在客户机 OS 中表示前端驱动程序，在include/linux/virtio.h中定义： /** * virtio_driver - operations for a virtio I/O driver * @driver: underlying device driver (populate name and owner). * @id_table: the ids serviced by this driver. * @feature_table: an array of feature numbers supported by this driver. * @feature_table_size: number of entries in the feature table array. * @probe: the function to call when a device is found. Returns 0 or -errno. * @remove: the function to call when a device is removed. * @config_changed: optional function to call when the device configuration * changes; may be called in interrupt context. */ struct virtio_driver { struct device_driver driver; const struct virtio_device_id *id_table; const unsigned int *feature_table; unsigned int feature_table_size; int (*probe)(struct virtio_device *dev); void (*scan)(struct virtio_device *dev); void (*remove)(struct virtio_device *dev); void (*config_changed)(struct virtio_device *dev); #ifdef CONFIG_PM int (*freeze)(struct virtio_device *dev); int (*restore)(struct virtio_device *dev); #endif }; virtio_device_id每个 virtio 设备都有其对应的virtio_device_id，该结构体在include/linux/mod_devicetable.h中定义： struct virtio_device_id { __u32 device; __u32 vendor; }; #define VIRTIO_DEV_ANY_ID 0xffffffff virtio_device与驱动程序匹配的设备由virtio_device封装，它表示在客户机 OS 中的设备，在include/linux/virtio.h中定义： /** * virtio_device - representation of a device using virtio * @index: unique position on the virtio bus * @dev: underlying device. * @id: the device type identification (used to match it with a driver). * @config: the configuration ops for this device. * @vringh_config: configuration ops for host vrings. * @vqs: the list of virtqueues for this device. * @features: the features supported by both driver and device. * @priv: private pointer for the driver&#39;s use. */ struct virtio_device { int index; struct device dev; struct virtio_device_id id; const struct virtio_config_ops *config; const struct vringh_config_ops *vringh_config; struct list_head vqs; /* Note that this is a Linux set_bit-style bitmap. */ unsigned long features[1]; void *priv; }; virtio_config_ops每一个virtio_device都有一个virtio_config_ops类型的指针*config，它定义了配置 virtio 设备的操作，该结构体在include/linux/virtio_config.h中定义： /** * virtio_config_ops - operations for configuring a virtio device * @get: read the value of a configuration field * @set: write the value of a configuration field * @get_status: read the status byte * @set_status: write the status byte * @reset: reset the device * @find_vqs: find virtqueues and instantiate them. * @del_vqs: free virtqueues found by find_vqs(). * @get_features: get the array of feature bits for this device. * @finalize_features: confirm what device features we&#39;ll be using. * @bus_name: return the bus name associated with the device * @set_vq_affinity: set the affinity for a virtqueue. */ struct virtio_config_ops { void (*get)(struct virtio_device *vdev, unsigned offset, void *buf, unsigned len); void (*set)(struct virtio_device *vdev, unsigned offset, const void *buf, unsigned len); u8 (*get_status)(struct virtio_device *vdev); void (*set_status)(struct virtio_device *vdev, u8 status); void (*reset)(struct virtio_device *vdev); int (*find_vqs)(struct virtio_device *, unsigned nvqs, struct virtqueue *vqs[], vq_callback_t *callbacks[], const char *names[]); void (*del_vqs)(struct virtio_device *); u32 (*get_features)(struct virtio_device *vdev); void (*finalize_features)(struct virtio_device *vdev); const char *(*bus_name)(struct virtio_device *vdev); int (*set_vq_affinity)(struct virtqueue *vq, int cpu); }; virtqueue每一个virtqueue包含了对应的virtio_device以及对应的队列操作回调函数，它在include/linux/virtio.h中定义： /** * virtqueue - a queue to register buffers for sending or receiving. * @list: the chain of virtqueues for this device * @callback: the function to call when buffers are consumed (can be NULL). * @name: the name of this virtqueue (mainly for debugging) * @vdev: the virtio device this queue was created for. * @priv: a pointer for the virtqueue implementation to use. * @index: the zero-based ordinal number for this queue. * @num_free: number of elements we expect to be able to fit. * * A note on @num_free: with indirect buffers, each buffer needs one * element in the queue, otherwise a buffer will need one element per * sg element. */ struct virtqueue { struct list_head list; void (*callback)(struct virtqueue *vq); const char *name; struct virtio_device *vdev; unsigned int index; unsigned int num_free; void *priv; }; 5. 相关数据结构5.1 前端 Kernelvirtio_driver在include/linux/virtio.h中定义： /** * virtio_driver - operations for a virtio I/O driver * @driver: underlying device driver (populate name and owner). * @id_table: the ids serviced by this driver. * @feature_table: an array of feature numbers supported by this driver. * @feature_table_size: number of entries in the feature table array. * @probe: the function to call when a device is found. Returns 0 or -errno. * @remove: the function to call when a device is removed. * @config_changed: optional function to call when the device configuration * changes; may be called in interrupt context. */ struct virtio_driver { struct device_driver driver; const struct virtio_device_id *id_table; const unsigned int *feature_table; unsigned int feature_table_size; int (*probe)(struct virtio_device *dev); void (*scan)(struct virtio_device *dev); void (*remove)(struct virtio_device *dev); void (*config_changed)(struct virtio_device *dev); #ifdef CONFIG_PM int (*freeze)(struct virtio_device *dev); int (*restore)(struct virtio_device *dev); #endif }; 这里的virtio_device_id有两个字段： struct virtio_device_id { __u32 device; __u32 vendor; }; #define VIRTIO_DEV_ANY_ID 0xffffffff virtio_device在include/linux/virtio.h中定义： /** * virtio_device - representation of a device using virtio * @index: unique position on the virtio bus * @dev: underlying device. * @id: the device type identification (used to match it with a driver). * @config: the configuration ops for this device. * @vringh_config: configuration ops for host vrings. * @vqs: the list of virtqueues for this device. * @features: the features supported by both driver and device. * @priv: private pointer for the driver&#39;s use. */ struct virtio_device { int index; struct device dev; struct virtio_device_id id; const struct virtio_config_ops *config; const struct vringh_config_ops *vringh_config; struct list_head vqs; /* Note that this is a Linux set_bit-style bitmap. */ unsigned long features[1]; void *priv; }; virtio_config_ops在include/linux/virtio_config.h中定义： /** * virtio_config_ops - operations for configuring a virtio device * @get: read the value of a configuration field * vdev: the virtio_device * offset: the offset of the configuration field * buf: the buffer to write the field value into. * len: the length of the buffer * @set: write the value of a configuration field * vdev: the virtio_device * offset: the offset of the configuration field * buf: the buffer to read the field value from. * len: the length of the buffer * @get_status: read the status byte * vdev: the virtio_device * Returns the status byte * @set_status: write the status byte * vdev: the virtio_device * status: the new status byte * @reset: reset the device * vdev: the virtio device * After this, status and feature negotiation must be done again * Device must not be reset from its vq/config callbacks, or in * parallel with being added/removed. * @find_vqs: find virtqueues and instantiate them. * vdev: the virtio_device * nvqs: the number of virtqueues to find * vqs: on success, includes new virtqueues * callbacks: array of callbacks, for each virtqueue * include a NULL entry for vqs that do not need a callback * names: array of virtqueue names (mainly for debugging) * include a NULL entry for vqs unused by driver * Returns 0 on success or error status * @del_vqs: free virtqueues found by find_vqs(). * @get_features: get the array of feature bits for this device. * vdev: the virtio_device * Returns the first 32 feature bits (all we currently need). * @finalize_features: confirm what device features we&#39;ll be using. * vdev: the virtio_device * This gives the final feature bits for the device: it can change * the dev-&gt;feature bits if it wants. * @bus_name: return the bus name associated with the device * vdev: the virtio_device * This returns a pointer to the bus name a la pci_name from which * the caller can then copy. * @set_vq_affinity: set the affinity for a virtqueue. */ typedef void vq_callback_t(struct virtqueue *); struct virtio_config_ops { void (*get)(struct virtio_device *vdev, unsigned offset, void *buf, unsigned len); void (*set)(struct virtio_device *vdev, unsigned offset, const void *buf, unsigned len); u8 (*get_status)(struct virtio_device *vdev); void (*set_status)(struct virtio_device *vdev, u8 status); void (*reset)(struct virtio_device *vdev); int (*find_vqs)(struct virtio_device *, unsigned nvqs, struct virtqueue *vqs[], vq_callback_t *callbacks[], const char *names[]); void (*del_vqs)(struct virtio_device *); u32 (*get_features)(struct virtio_device *vdev); void (*finalize_features)(struct virtio_device *vdev); const char *(*bus_name)(struct virtio_device *vdev); int (*set_vq_affinity)(struct virtqueue *vq, int cpu); }; virtqueue在include/linux/virtio.h中定义： /** * virtqueue - a queue to register buffers for sending or receiving. * @list: the chain of virtqueues for this device * @callback: the function to call when buffers are consumed (can be NULL). * @name: the name of this virtqueue (mainly for debugging) * @vdev: the virtio device this queue was created for. * @priv: a pointer for the virtqueue implementation to use. * @index: the zero-based ordinal number for this queue. * @num_free: number of elements we expect to be able to fit. * * A note on @num_free: with indirect buffers, each buffer needs one * element in the queue, otherwise a buffer will need one element per * sg element. */ struct virtqueue { struct list_head list; void (*callback)(struct virtqueue *vq); const char *name; struct virtio_device *vdev; unsigned int index; unsigned int num_free; void *priv; }; 5.2 后端 QEMUVirtQueue在hw/virtio/virtio.c中定义： struct VirtQueue { VRing vring; /* Next head to pop */ uint16_t last_avail_idx; /* Last avail_idx read from VQ. */ uint16_t shadow_avail_idx; uint16_t used_idx; /* Last used index value we have sjjignalled on */ uint16_t signalled_used; /* Last used index value we have signalled on */ bool signalled_used_valid; /* Notification enabled? */ bool notification; uint16_t queue_index; int inuse; uint16_t vector; void (*handle_output)(VirtIODevice *vdev, VirtQueue *vq); void (*handle_aio_output)(VirtIODevice *vdev, VirtQueue *vq); VirtIODevice *vdev; EventNotifier guest_notifier; EventNotifier host_notifier; QLIST_ENTRY(VirtQueue) node; }; VRing在hw/virtio/virtio.c中定义： typedef struct VRing { unsigned int num; unsigned int num_default; unsigned int align; hwaddr desc; hwaddr avail; hwaddr used; } VRing; 未完待续… 参考文章相关博客 Virtio 概述和基本原理（KVM 半虚拟化驱动）| 笑遍世界 Virtio：针对 Linux 的 I/O 虚拟化框架 | IBM Developer virtio 基本原理 (kvm 半虚拟化驱动) | 开源中国 说一说虚拟化绕不开的 io 半虚拟化 | 腾讯云加社区 Virtio Vring 工作机制分析 | OenHan KVM Virtio Block 源代码分析 | OenHan vring的创建(基于kernel 3.10, qemu2.0.0) - leoufung| CSDN QEMU 通过virtio接收报文处理流程（QEMU2.0.0）- leoufung | CSDN VIRTIO 的 vring 收发队列创建流程 - leoufung | CSDN VIRTIO 中的前后端配合限速分析 - leoufung | CSDN virtio 路径 | 随便写写 官方文档 Virtio | KVM Documents virtio: Towards a De-Facto Standard For Virtual I/O Devices - Rusty Russell | PDF Virtio-blk Performance Improvement | KVM Forum 2012 太初有道 - 博客园 Virtio 前端驱动详解 - 太初有道 | cnblogs Virtio 后端驱动详解 - 太初有道 | cnblogs Virtio 前后端 notify 机制详解 - 太初有道 | cnblogs intel EPT 机制详解 - 太初有道 | cnblogs KVM 中 EPT 逆向映射机制分析 - 太初有道 | cnblogs QEMU 进程页表和 EPT 的同步问题 - 太初有道 | cnblogs KVM vCPU 线程调度问题的讨论 - 太初有道 | cnblogs virtio 之 vhost 工作原理简析 - 太初有道 | cnblogs PCI 设备详解一 - 太初有道 | cnblogs Lauren 的博客 Virtio 原理简介 | Lauren’s blog Virtio 网络发包过程分析 | Lauren’s blog virtio 前端通知机制分析 | Lauren’s blog 也说自旋锁 | Lauren’s blog 也说自旋锁2 —— qspinlock | Lauren’s blog 其他不错的 Virtio 学习笔记（一）：简介 - 瞧见风 | CSDN Linux 系统检查 virtio 驱动 | 腾讯云文档中心 Virtio 基本概念和设备操作 - Db_Chen | cnblogs virtio 简介 - supersos | cnblogs KVM 地址翻译流程及 EPT 页表的建立过程 - 小C爱学习 | cnblogs 团子的小窝 NUMA 与 SMP | 团子的小窝 系列连载文章 | 团子的小窝 QEMU QEMU/KVM 中的 tracing 工具 - 瞧见风 | CSDN QEMU 网络虚拟化分析 | Lauren’s blog 利用 QEMU GDB 调试 Kernel | Lauren’s blog Linux 云计算网络 Virtio 简介 | Linux 云计算网络 Linux 网络基础知识划重点版（上）| Linux 云计算网络 Linux 网络基础知识划重点版（下）| Linux 云计算网络 50 个你必须掌握的 Kubernetes 面试题 | Linux 云计算网络 王子阳 - 中科院信息工程研究所 virtio 学习 | 王子阳 浮点数拾遗 | 王子阳 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述QEMU 1.2.0 入口 main() 函数调用流程分析迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"},{"name":"virtio","slug":"virtio","permalink":"https://abelsu7.top/tags/virtio/"}]},{"title":"Linux 系统常用监控命令","slug":"most-used-commands-to-diagnose-linux","date":"2019-08-26T10:10:33.000Z","updated":"2019-11-05T03:30:37.652Z","comments":true,"path":"2019/08/26/most-used-commands-to-diagnose-linux/","link":"","permalink":"https://abelsu7.top/2019/08/26/most-used-commands-to-diagnose-linux/","excerpt":"Linux 系统常用监控命令总结","text":"Linux 系统常用监控命令总结 To be updated… 排查 Linux 问题方法以及常用命令) 1. CPUcat /proc/cpuinfo # 物理 CPU 个数 cat /proc/cpuinfo | grep &#39;physical id&#39; | sort | uniq | wc -l # 每个 CPU 核心数 cat /proc/cpuinfo | grep &#39;core id&#39; | sort | uniq | wc -l # 逻辑 CPU cat /proc/cpuinfo | grep &#39;processor&#39; | sort | uniq | wc -l # mpstat mpstat mpstat 2 10 1.1 steal time 理解 CPU steal time - Jessysong | CSDN 理解 CPU steal time | MKY-技术驿站 谁偷走了我的云主机 CPU 时间：理解 CPU Steal Time | 知乎 2. 内存cat /proc/meminfo free -gt df -hT du -csh ./* 操作系统 IPC 共享内存/队列： ipcs #(shmems, queues, semaphores) 平时我们经常需要监控内存的使用状态，常用的命令有free、vmstat、top、dstat -m等。 2.1 free推荐阅读： 通过 free 命令理解 Linux 内存管理 | Cizixs free 命令中 cached 和 buffers 的区别 - 踏雪无痕 | 博客园 &gt; free -h total used free shared buffers cached Mem: 7.7G 6.2G 1.5G 17M 33M 184M -/+ buffers/cache: 6.0G 1.7G Swap: 24G 581M 23G 各行数据含义第一行Mem： total：内存总数7.7G，物理内存大小，就是机器实际的内存 used：已使用内存6.2G，这个值包括了cached和应用程序实际使用的内存 free：空闲的内存1.5G，未被使用的内存大小 shared：共享内存的大小，17M buffers：被缓冲区占用的内存大小，33M cached：被缓存占用的内存大小，184M 其中有： total = used + free 第二行-/+ buffers/cache，代表应用程序实际使用的内存： 前一个值表示used - buffers/cached，表示应用程序实际使用的内存 后一个值表示free + buffers/cached，表示理论上都可以被使用的内存 可以看到，这两个值加起来也是total 第三行swap，代表交换分区的使用情况：总量、使用的和未使用的 缓存 cachecache代表缓存，当系统读取文件时，会先把数据从硬盘读到内存里，因为硬盘比内存慢很多，所以这个过程会很耗时。 为了提高效率，Linux 会把读进来的文件在内存中缓存下来（局部性原理），即使程序结束，cache 也不会被自动释放。因此，当有程序进行大量的读文件操作时，就会发现内存使用率升高了。 当其他程序需要使用内存时，Linux 会根据自己的缓存策略（例如 LRU）将这些没人使用的 cache 释放掉，给其他程序使用，当然也可以手动释放缓存： echo 1 &gt; /proc/sys/vm/drop_caches 缓冲区 buffer考虑内存写文件到硬盘的场景，因为硬盘太慢了，如果内存要等待数据写完了之后才继续后面的操作，效率会非常低，也会影响程序的运行速度，所以就有了缓冲区buffer。 当内存需要写数据到硬盘中时会先放到 buffer 里面，内存很快把数据写到 buffer 中，可以继续其他工作，而硬盘可以在后台慢慢读出 buffer 中的数据并保存起来，这样就提高了读写的效率。 例如把电脑中的文件拷贝到 U 盘时，如果文件特别大，有时会出现这样的情况：明明看到文件已经拷贝完，但系统还是会提示 U 盘正在使用中。这就是 buffer 的原因：拷贝程序虽然已经把数据放到 buffer 中，但是还没有全部写入到 U 盘中 同样的，可以使用sync命令来手动flush buffer中的内容： &gt; sync --help Usage: sync [OPTION] [FILE]... Synchronize cached writes to persistent storage If one or more files are specified, sync only them, or their containing file systems. -d, --data sync only file data, no unneeded metadata -f, --file-system sync the file systems that contain the files --help display this help and exit --version output version information and exit GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt; Full documentation at: &lt;http://www.gnu.org/software/coreutils/sync&gt; or available locally via: info &#39;(coreutils) sync invocation&#39; 交换分区 swap交换分区swap是实现虚拟内存的重要概念。swap就是把硬盘上的一部分空间当作内存来使用，正在运行的程序会使用物理内存，把未使用的内存放到硬盘，叫做swap out。而把硬盘交换分区中的内存重新放到物理内存中，叫做swap in。 交换分区可以在逻辑上扩大内存空间，但是也会拖慢系统速度，因为硬盘的读写速度很慢。Linux 系统会将不经常使用的内存放到交换分区中。 cache 和 buffer 的区别 cache：作为page cache的内存，是文件系统的缓存，在文件层面上的数据会缓存到page cache中 buffer：作为buffer cache的内存，是磁盘块的缓存，直接对磁盘进行操作的数据会缓存到 buffer cache 中 简单来说：page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache中。如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache中。 2.2 vmstatvmstat (Virtual Memory Statics，虚拟内存统计) 是对系统的整体情况进行统计，包括内核进程、虚拟内存、磁盘、中断和 CPU 活动的统计信息： &gt; vmstat --help Usage: vmstat [options] [delay [count]] Options: -a, --active active/inactive memory -f, --forks number of forks since boot -m, --slabs slabinfo -n, --one-header do not redisplay header -s, --stats event counter statistics -d, --disk disk statistics -D, --disk-sum summarize disk statistics -p, --partition &lt;dev&gt; partition specific statistics -S, --unit &lt;char&gt; define display unit -w, --wide wide output -t, --timestamp show timestamp -h, --help display this help and exit -V, --version output version information and exit For more details see vmstat(8). &gt; vmstat -SM 1 100 # 1 表示刷新间隔(秒)，100 表示打印次数，单位 MB procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 470 188 1154 0 0 0 4 3 0 0 0 99 0 0 0 0 0 470 188 1154 0 0 0 0 112 231 1 1 98 0 0 0 0 0 470 188 1154 0 0 0 0 91 176 0 0 100 0 0 0 0 0 470 188 1154 0 0 0 0 118 229 1 0 99 0 0 0 0 0 470 188 1154 0 0 0 0 78 156 0 0 100 0 0 0 0 0 470 188 1154 0 0 0 64 84 186 0 1 97 2 0 procs r列：表示运行和等待 CPU 时间片的进程数，这个值如果长期大于 CPU 个数，就说明 CPU 资源不足，可以考虑增加 CPU b列：表示在等待资源的进程数，例如正在等待 I/O 或者内存交换 memory swpn列：表示切换到交换分区的内存大小，如果swpd的值不为 0 或者比较大，且si、so的值长期为 0，那么这种情况暂时不会影响系统性能 free列：当前空闲的物理内存大小 buff列：表示buffers cache的内存大小，一般对块设备的读写才需要缓冲 cache列：表示page cache的内存大小，一般作为文件系统的缓存，频繁访问的文件都会被 cached。如果 cache 值比较大，就说明 cached 文件数量较多。如果此时 I/O 中的bi比较小，就说明文件系统效率比较好 swap si列：表示swap in，即内存由交换分区放入物理内存中 so列：表示swap out，即将未使用的内存放到硬盘的交换分区中 io bi列：表示从块设备读取的数据总量，即读磁盘，单位KB/s bo列：表示写入块设备的数据总量，即写磁盘，单位KB/s 这里设置的bi+bo参考值为1000，如果超过1000，且wa值比较大，则表示系统磁盘 I/O 性能瓶颈 system in列：表示在某一时间间隔中观察到的每秒设备中断数 cs列：表示每秒产生的上下文切换次数 上面这两个值越大，内核消耗的 CPU 时间就越多 cpu us列：表示用户进程消耗 CPU 的时间百分比。us值比较高时，说明用户进程消耗的 CPU 时间多，如果长期大于 50%，可以考虑优化程序 sy列：表示内核进程消耗 CPU 的时间百分比。sy值比较高时，说明内核消耗的 CPU 时间多，如果us+sy超过 80%，就说明 CPU 资源存在不足 id列：表示 CPU 处在空闲状态的时间百分比 wa列：表示 I/O Wait 所占 CPU 的时间百分比。wa值越高，说明 I/O Wait 越严重。如果wa值超过 20%，说明 I/O Wait 严重 st列：表示 CPU Steal Time，针对虚拟机 3. 网络3.1 接口ifconfig iftop ethtool 3.2 端口# 端口 netstat -ntlp # TCP netstat -nulp # UDP netstat -nxlp # UNIX netstat -nalp # 不仅展示监听端口，还展示其他阶段的连接 lsof -p &lt;PID&gt; -P lsof -i :5900 sar -n DEV 1 # 网络流量 ss ss -s 3.3 tcpdumpsudo tcpdump -i any udp port 20112 and ip[0x1f:02]=0x4e91 -XNnvvv sudo tcpdump -i any -XNnvvv sudo tcpdump -i any udp -XNnvvv sudo tcpdump -i any udp port 20112 -XNnvvv sudo tcpdump -i any udp port 20112 and ip[0x1f:02]=0x4e91 -XNnvvv 4. I/O 性能iotop iostat iostat -kx 2 vmstat -SM vmstat 2 10 dstat dstat --top-io --top-bio 5. 进程top top -H htop ps auxf ps -eLf # 展示线程 ls /proc/&lt;PID&gt;/task 5.1 top例如最常用的top命令： Help for Interactive Commands - procps version 3.2.8 Window 1:Def: Cumulative mode Off. System: Delay 3.0 secs; Secure mode Off. Z,B Global: &#39;Z&#39; change color mappings; &#39;B&#39; disable/enable bold l,t,m Toggle Summaries: &#39;l&#39; load avg; &#39;t&#39; task/cpu stats; &#39;m&#39; mem info 1,I Toggle SMP view: &#39;1&#39; single/separate states; &#39;I&#39; Irix/Solaris mode f,o . Fields/Columns: &#39;f&#39; add or remove; &#39;o&#39; change display order F or O . Select sort field &lt;,&gt; . Move sort field: &#39;&lt;&#39; next col left; &#39;&gt;&#39; next col right R,H . Toggle: &#39;R&#39; normal/reverse sort; &#39;H&#39; show threads c,i,S . Toggle: &#39;c&#39; cmd name/line; &#39;i&#39; idle tasks; &#39;S&#39; cumulative time x,y . Toggle highlights: &#39;x&#39; sort field; &#39;y&#39; running tasks z,b . Toggle: &#39;z&#39; color/mono; &#39;b&#39; bold/reverse (only if &#39;x&#39; or &#39;y&#39;) u . Show specific user only n or # . Set maximum tasks displayed k,r Manipulate tasks: &#39;k&#39; kill; &#39;r&#39; renice d or s Set update interval W Write configuration file q Quit ( commands shown with &#39;.&#39; require a visible task display window ) Press &#39;h&#39; or &#39;?&#39; for help with Windows, any other key to continue 1: 显示各个 CPU 的使用情况 c: 显示进程完整路径 H: 显示线程 P: 排序 - CPU 使用率 M: 排序 - 内存使用率 R: 倒序 Z: Change color mappings B: Disable/enable bold l: Toggle load avg t: Toggle task/cpu stats m: Toggle mem info us - Time spent in user space sy - Time spent in kernel space ni - Time spent running niced user processes (User defined priority) id - Time spent in idle operations wa - Time spent on waiting on IO peripherals (eg. disk) hi - Time spent handling hardware interrupt routines. (Whenever a peripheral unit want attention form the CPU, it literally pulls a line, to signal the CPU to service it) si - Time spent handling software interrupt routines. (a piece of code, calls an interrupt routine...) st - Time spent on involuntary waits by virtual cpu while hypervisor is servicing another processor (stolen from a virtual machine) 5.2 lsoflsof -P -p 123 6. 性能测试stress --cpu 8 \\ --io 4 \\ --vm 2 \\ --vm-bytes 128M \\ --timeout 60s time命令 7. 用户w whoami 8. 系统状态uptime htop vmstat mpstat dstat 9. 硬件设备lspci lscpu lsblk lsblk -fm # 显示文件系统、权限 lshw -c display dmidecode 10. 文件系统# 挂载 mount umount cat /etc/fstab # LVM pvdisplay pvs lvdisplay lvs vgdisplay vgs df -hT lsof 11. 内核、中断cat /proc/modules sysctl -a | grep ... cat /proc/interrupts 12. 系统日志、内核日志dmesg less /var/log/messages less /var/log/secure less /var/log/auth 13. cron 定时任务crontab -l crontab -l -u nobody # 查看所有用户的cron sudo find /var/spool/cron/ | sudo xargs cat 14. 调试工具14.1 perf14.2 stracestrace命令用于打印系统调用、信号： strace -p strace -p 5191 -f strace -e trace=signal -p 5191 -e trace=open -e trace=file -e trace=process -e trace=network -e trace=signal -e trace=ipc -e trace=desc -e trace=memory 14.3 ltraceltrace命令用于打印动态链接库访问： ltrace -p &lt;PID&gt; ltrace -S # syscall 15. 场景案例场景 1：连上服务器之后w # 显示当前登录的用户、登录 IP、正在执行的进程等 last # 看看最近谁登录了服务器、服务器重启时间 uptime # 开机时间、登录用户、平均负载 history # 查看历史命令 场景 2：/proc 目录有哪些信息cat /proc/... cgroups cmdline cpuinfo crypto devices diskstats filesystems iomem ioports kallsyms meminfo modules partitions uptime version vmstat 场景 3：后台执行命令nohup &lt;command&gt; &amp;&gt;[some.log] &amp; 一些命令# 综合 top htop glances dstat &amp; sar mpstat # 性能分析 perf # 进程 ps pstree -p pgrep pkill pidof Ctrl+z &amp; jobs &amp; fg # 网络 ip ifconfig dig ping traceroute iftop pingtop nload netstat vnstat slurm scp tcpdump # 磁盘 I/O iotop iostat # 虚拟机 virt-top # 用户 w whoami # 运行时间 uptime # 磁盘 du df lsblk # 权限 chown chmod # 服务 systemctl list-unit-files # 定位 find locate # 性能测试 time 部分资源 每天学习一个命令 | Verne in Github 10 分钟教你如何划重点 —— Systemd 最全攻略 | 阿里智能运维 20 个命令行工具监控 Linux 系统性能 | Linux Story vmstat 命令查看虚拟内存 | 51CTO Grafana | Github 28 个 UNIX/Linux 的命令行神器 | 酷壳 CoolShell CentOS 7 查看网络带宽使用情况 | 陈沙克日志 【必看】Linux 问题故障定位，看这一篇就够了 | 民工哥技术之路 Load Average 的含义 | 博客园 Linux 性能调优工具 perf 的使用 | cpper 10 个非常赞的 Linux 网络监控工具 | Python 网络爬虫与数据挖掘 参考文章 常用 Linux 系统监控命令 | 神奕的博客 Linux 工具快速教程 | Linux Tools Quick Tutorial 穷佐罗的 Linux 书 | GitBook Brendan D. Gregg BPF Performance Tools | Brendan D. Gregg Systems Performance: Enterprise and the Cloud | Brendan D. Gregg How to use strace and ltrace commands in Linx | The Geek Diary First 5 Minutes Troubleshooting A Server | devo.ps First 5 Commands When I Connect on a Linux Server | Linux.com Linux Performance Analysis in 60,000 Milliseconds | The Netfilx Tech Blog 【PPT】Shared Memory Segments and POSIX Semaphores 通过 free 命令理解 Linux 内存管理 | Cizixs free 命令中 cached 和 buffers 的区别 - 踏雪无痕 | 博客园 Linux du 命令和 df 命令区别 | CSDN du 和 df 文件大小不一致问题排查 | CSDN Linux CPU 资源高、内存高分析 - milkty | 博客园 复习文章 常用 Linux 系统监控命令 | 神奕的博客 Linux 文件系统 inode 介绍 | 卡瓦邦噶 理解 inode | 阮一峰 文件描述符（File Descriptor）简介 | SegmentFault [译] Linux 系统调用权威指南 | ArthurChiao’s Blog 运维岗秋招之路 | 牛客 运维岗位的面试问题 | 牛客 Linux 进程的生命周期 | 卡瓦邦噶 10 分钟教你如何划重点 —— Systemd 最全攻略 | 阿里智能运维 什么是内存(一)：存储器层次结构 - eleven_yw | 博客园 什么是内存(二)：虚拟内存 - eleven_yw | 博客园 关于跨平台的一些认识 - eleven_yw | 博客园 计算机网络的各种基本概念总结（七层模型，TCP，HTTP，socket，RPC等）| CSDN 网络七层模型与四层模型区别 | 掘金 系统负载 理解系统负载 | 三点水 理解 Linux 系统负荷 | 阮一峰 Linux系统中负载（Load Average）的含义与计算方法 | 尽人事，听天命 关于load average的几点总结： 系统负载统计的是运行和等待运行的进程/线程数 Linux 下是5s一采样并计算移动平均 一分钟指数移动平均用到了不止近一分钟的采样数据 有n核，满载的负载就是n 调试工具 【干货】Linux 工具快速教程 | Linux Tools Quick Tutorial The Linux Perf Master | Ribose Yim 穷佐罗的 Linux 书 | GitBook 性能分析利器之 perf 浅析 - WalkerTalking 系统级性能分析工具 perf 的介绍与使用 - Arnold Lu | cnblogs 在 Linux 下做性能分析 3：perf | 知乎专栏 - 软件架构设计 Linux 性能优化 9：KVM 环境 | 知乎专栏 - 软件架构设计 使用 gprof 对程序的性能分析（集合贴）| CSDN 使用 GNU profiler 来提高代码运行速度 | IBM Developer [译] tcpdump 示例教程 | 鸟窝 使用 truss、strace 或 ltrace 诊断软件的”疑难杂症” | IBM Developer 调试工具 ltrace strace ftrace 的使用 | JasonLe 使用 ltrace 跟踪库函数调用 | Liujingwen’s Blog [译] Linux 系统调用权威指南 | ARTHURCHIAO’S BLOG [译] strace 是如何工作的 | ARTHURCHIAO’S BLOG [译] ltrace 是如何工作的 | ARTHURCHIAO’S BLOG tcpdump/wireshark 抓包及分析 | ARTHURCHIAO’S BLOG 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux Shell 编程速查Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://abelsu7.top/tags/运维/"},{"name":"监控命令","slug":"监控命令","permalink":"https://abelsu7.top/tags/监控命令/"}]},{"title":"单独编译 KVM 内核模块","slug":"compile-kvm-module","date":"2019-08-26T07:39:51.000Z","updated":"2019-09-01T13:04:11.042Z","comments":true,"path":"2019/08/26/compile-kvm-module/","link":"","permalink":"https://abelsu7.top/2019/08/26/compile-kvm-module/","excerpt":"摘自 单独编译 KVM 模块 - llwszjj | CSDN","text":"摘自 单独编译 KVM 模块 - llwszjj | CSDN To be updated… 相关命令# 进入 KVM 代码目录 cd /root/kernel-src/kvm-2.6.32/arch/x86/kvm # 开始编译 make -C /lib/modules/`uname -r`/build M=`pwd` clean make -C /lib/modules/`uname -r`/build M=`pwd` modules # 拷贝编译结果出来，并使用 cp *.ko /root/kvm/tools/modules/ cd /root/kvm/tools/modules/ # 卸载旧版本模块 modprobe -r kvm_intel modprobe -r kvm # 安装新版本模块 modprobe irqbypass insmod kvm.ko insmod kvm-intel.ko 参考文章 单独编译 KVM 模块的方法(进行调试) - leoufung | CSDN 单独编译 KVM 模块 - llwszjj | CSDN 单独编译某个内核模块 - ChinaUnix 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtioKernel 2.6.32 中的 KVM API 概述QEMU 1.2.0 入口 main() 函数调用流程分析迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"内核","slug":"内核","permalink":"https://abelsu7.top/tags/内核/"}]},{"title":"Go Tour 笔记","slug":"go-tour-notes","date":"2019-08-18T09:46:57.000Z","updated":"2019-10-10T13:20:54.173Z","comments":true,"path":"2019/08/18/go-tour-notes/","link":"","permalink":"https://abelsu7.top/2019/08/18/go-tour-notes/","excerpt":"摘自 Go 语言之旅","text":"摘自 Go 语言之旅 目录 目录 1. 包、变量和函数 1.1 包 1.2 导入 1.3 导出名 1.4 函数 1.5 基本类型 1.6 零值 1.7 类型转换 1.8 类型推导 1.9 常量 1.10 数值常量 2. 流程控制语句 2.1 for 循环 2.2 if else 语句 2.3 switch 分支 2.4 defer 栈 3. struct、slice、map 3.1 指针 3.2 结构体 3.3 数组 3.4 切片 3.5 Range 3.6 映射 3.7 函数值 3.8 函数的闭包 4. 方法和接口 4.1 方法 4.2 接口 4.3 类型断言 4.4 类型选择 4.5 Stringer 4.6 错误 4.7 Reader 4.8 图像 5. 并发 5.1 协程 goroutine 5.2 通道 channel 5.3 带缓冲的通道 5.4 range 和 close 5.5 select 语句 5.6 sync.Mutex 6. 常用代码 6.1 标准库 6.2 内建函数 7. 练习解答 7.1 循环与函数：牛顿法求平方根 7.2 切片：图像灰度值 7.3 映射：单词统计 7.4 闭包：斐波那契数列 7.5 Stringer 7.6 错误 7.7 Reader 7.8 rot13Reader 7.9 图像 7.10 等价二叉查找树 7.11 Web 爬虫 8. 参考文章 官方文档 Go Blog Go Tour 题解 标准库 51CTO 上的一个系列教程 演讲 PPT Web 编程 1. 包、变量和函数1.1 包 每个 Go 程序都是由包构成的 程序从main包开始运行 包名与导入路径的最后一个元素一致 1.2 导入import ( // 标准库 &quot;fmt&quot; &quot;math&quot; // 本地包 &quot;apiserver/model&quot; &quot;apiserver/log&quot; // 外部包 &quot;github.com/spf13/viper&quot; ) 1.3 导出名导出名以大写字母开头： package main import ( &quot;fmt&quot; &quot;math&quot; ) func main() { fmt.Println(math.Pi) } ------ 3.141592653589793 1.4 函数函数可以有多个返回值： package main import &quot;fmt&quot; func swap(x, y string) (string, string) { return y, x } func main() { a, b := swap(&quot;Hello&quot;, &quot;world&quot;) fmt.Println(a, b) } ------ world Hello 也可以分别为返回值命名： package main import &quot;fmt&quot; func split(sum int) (x, y int) { x = sum * 4 / 9 y = sum - x return } func main() { fmt.Println(split(26)) } ------ 11 15 1.5 基本类型Go 语言的基本类型如下： bool string int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr byte // uint8 的别名 rune // int32 的别名, 表示一个 Unicode 码点 float32 float64 complex64 complex128 测试一下： package main import ( &quot;fmt&quot; &quot;math/cmplx&quot; ) var ( ToBe bool = false MaxInt uint64 = 1&lt;&lt;64 - 1 z complex128 = cmplx.Sqrt(-5 + 12i) ) func main() { fmt.Printf(&quot;Type: %T Value: %v\\n&quot;, ToBe, ToBe) fmt.Printf(&quot;Type: %T Value: %v\\n&quot;, MaxInt, MaxInt) fmt.Printf(&quot;Type: %T Value: %v\\n&quot;, z, z) } ------ Type: bool Value: false Type: uint64 Value: 18446744073709551615 Type: complex128 Value: (2+3i) 1.6 零值 数值：0 布尔：false 字符串：&quot;&quot; package main import &quot;fmt&quot; func main() { var i int var f float64 var b bool var s string fmt.Printf(&quot;%v %v %v %q\\n&quot;, i, f, b, s) } ------ 0 0 false &quot;&quot; 1.7 类型转换表达式T(v)将值v转换为类型T： package main import ( &quot;fmt&quot; &quot;math&quot; ) func main() { var x, y int = 3, 4 var f float64 = math.Sqrt(float64(x*x + y*y)) var z uint = uint(f) fmt.Println(x, y, z) } ------ 3 4 5 1.8 类型推导package main import &quot;fmt&quot; func main() { v1 := 42 fmt.Printf(&quot;v1 is of type %T\\n&quot;, v1) v2 := 3.1415926 fmt.Printf(&quot;v2 is of type %T\\n&quot;, v2) v3 := 0.867 + 0.5i fmt.Printf(&quot;v3 is of type %T\\n&quot;, v3) } ------ v1 is of type int v2 is of type float64 v3 is of type complex128 1.9 常量常量使用const关键字声明，可以是字符、字符、布尔值或数值，且不能用:=语法声明： package main import &quot;fmt&quot; const Pi = 3.14 func main() { const World = &quot;世界&quot; fmt.Println(&quot;Hello&quot;, World) fmt.Println(&quot;Happy&quot;, Pi, &quot;Day&quot;) const Truth = true fmt.Println(&quot;Go rules?&quot;, Truth) } ------ Hello 世界 Happy 3.14 Day Go rules? true 1.10 数值常量数值常量是高精度的值，一个未指定类型的常量由上下文来决定其类型： package main import &quot;fmt&quot; const ( // 将 1 左移 100 位来创建一个非常大的数字 // 即这个数的二进制是 1 后面跟着 100 个 0 Big = 1 &lt;&lt; 100 // 再往右移 99 位，即 Small = 1 &lt;&lt; 1，或者说 Small = 2 Small = Big &gt;&gt; 99 ) func needInt(x int) int { return x * 10 + 1 } func needFloat(x float64) float64 { return x * 0.1 } func main() { fmt.Println(needInt(Small)) fmt.Println(needFloat(Small)) fmt.Println(needFloat(Big)) } ------ 21 0.2 1.2676506002282295e+29 2. 流程控制语句2.1 for 循环for i := 0; i &lt; 10; i++ { sum += i } 省略初始语句及后置语句，可用作while： for sum &lt; 1000 { sum += sum } 无限循环： for { // do something } 2.2 if else 语句if v := math.Pow(x, n); v &lt;lim { return v } else { fmt.Printf(&quot;%g &gt;= %g\\n&quot;, v, lim) } return lim 2.3 switch 分支switch的case语句从上到下顺次执行，直到匹配成功时停止： package main import ( &quot;fmt&quot; &quot;runtime&quot; ) func main() { fmt.Print(&quot;Go runs on &quot;) switch os := runtime.GOOS; os { case &quot;windows&quot;: fmt.Println(&quot;Windows.&quot;) case &quot;darwin&quot;: fmt.Println(&quot;OS X.&quot;) case &quot;linux&quot;: fmt.Println(&quot;Linux.&quot;) default: fmt.Printf(&quot;%s.\\n&quot;, os) } } 没有条件的switch同switch true一样，可以将一长串的if-else写得更清晰： package main import ( &quot;fmt&quot; &quot;time&quot; ) func main() { t := time.Now() switch { case t.Hour() &lt; 12: fmt.Println(&quot;Good morning!&quot;) case t.Hour() &lt; 17: fmt.Println(&quot;Good afternoon!&quot;) default: fmt.Println(&quot;Good evening!&quot;) } } 2.4 defer 栈defer语句会将函数推迟到外层函数返回之后执行： 推迟调用的函数其参数会立即求值，但直到外层函数返回之前，该函数都不会被调用 package main import &quot;fmt&quot; func main() { defer fmt.Println(&quot;world&quot;) fmt.Println(&quot;Hello&quot;) } ------ Hello world 推迟的函数调用会被压入栈中。当外层函数返回时，被推迟的函数会按照后进先出的顺序调用： package main import &quot;fmt&quot; func main() { fmt.Println(&quot;counting&quot;) for i := 0; i &lt; 10; i++ { defer fmt.Println(i) } fmt.Println(&quot;done&quot;) } ------ counting done 9 8 7 6 5 4 3 2 1 0 更多内容参见 Defer, Panic, and Recover | The Go Blog 3. struct、slice、map3.1 指针指针保存了值的内存地址，类型*T是指向T类型值的指针，其零值为nil： var p *int fmt.Println(p) ------ 0xc000062070&lt;nil&gt; 与 C 不同，Go 没有指针运算。 package main import &quot;fmt&quot; func main() { i, j := 42, 2701 p := &amp;i // 指向 i fmt.Println(*p) // 通过指针读取 i 的值 *p = 21 // 通过指针设置 i 的值 fmt.Println(i) // 查看 i 的值 p = &amp;j // 指向 *p = *p / 37 // 通过指针对 j 进行除法运算 fmt.Println(j) // 查看 j 的值 fmt.Print(p) // 查看 j 的地址 } ------ 42 21 73 0xc000062070 3.2 结构体一个结构体struct就是一组字段field。当有一个指向结构体的指针p时，Go 允许使用隐式间接引用，直接通过p.X访问其字段： package main import &quot;fmt&quot; type Vertex struct { X int Y int } func main() { v := Vertex{ X: 1, Y: 2, } p := &amp;v p.X = 1e9 fmt.Println(v) } ------ {1000000000 2} 结构体文法通过直接列出字段的值来新分配一个结构体，使用Name:语法可以仅列出部分字段，特殊的前缀&amp;返回一个指向结构体的指针： package main import &quot;fmt&quot; type Vertex struct { X int Y int } var ( v1 = Vertex{1, 2} v2 = Vertex{ X: 1, Y: 6, } v3 = Vertex{} p = &amp;Vertex{1, 2} ) func main() { fmt.Println(v1, p, v2, v3) } ------ {1 2} &amp;{1 2} {1 6} {0 0} 3.3 数组类型[n]T是独立的类型： var a [10]int 即数组的长度是其类型的一部分，因此数组不能改变大小。 package main import &quot;fmt&quot; func main() { var a [2]string a[0] = &quot;Hello&quot; a[1] = &quot;World&quot; fmt.Println(a[0], a[1]) fmt.Println(a) primes := [6]int{2, 3, 5, 7, 11, 13} fmt.Println(primes) } ------ Hello World [Hello World] [2 3 5 7 11 13] 3.4 切片每个数组的大小都是固定的，而切片则为数组元素提供动态大小的灵活视角。 类型[]T表示一个元素类型为T的切片，通过上界和下界来界定： a[low:high] 这是一个左开右闭区间，两个下标均可以省略： package main import &quot;fmt&quot; func main() { primes := [6]int{2, 3, 5, 7, 11, 13} fmt.Println(primes, len(primes), cap(primes)) var s1 = primes[1:4] fmt.Println(s1, len(s1), cap(s1)) var s2 = primes[:] fmt.Println(s2, len(s2), cap(s2)) } ------ [2 3 5 7 11 13] 6 6 [3 5 7] 3 5 [2 3 5 7 11 13] 6 6 切片就像数组的引用 切片并不存储任何数据，它只是描述了底层数组中的一段 更改切片的元素会修改其底层数组中对应的元素 与它共享底层数组的切片都会观测到这些修改 package main import &quot;fmt&quot; func main() { names := [4]string{ &quot;John&quot;, &quot;Paul&quot;, &quot;George&quot;, &quot;Ringo&quot;, } fmt.Println(&quot;The original array:&quot;, names) a := names[0:2] b := names[1:3] fmt.Println(&quot;\\nSlice a:&quot;, a) fmt.Println(&quot;Slice b:&quot;, b) b[0] = &quot;XXX&quot; fmt.Println(&quot;\\nNow slice a:&quot;, a) fmt.Println(&quot;Now slice b:&quot;, b) fmt.Println(&quot;\\nThe modified array:&quot;, names) } ------ The original array: [John Paul George Ringo] Slice a: [John Paul] Slice b: [Paul George] Now slice a: [John XXX] Now slice b: [XXX George] The modified array: [John XXX George Ringo] 切片文法切片文法类似于没有长度的数组文法： package main import &quot;fmt&quot; func main() { q := []int{2, 3, 5, 7, 11, 13} fmt.Println(q) r := []bool{true, false, true, true, false, true} fmt.Println(r) s := []struct { i int b bool }{ {2, true}, {3, false}, {5, true}, {7, true}, {11, false}, {13, true}, } fmt.Println(s) } ------ [2 3 5 7 11 13] [true false true true false true] [{2 true} {3 false} {5 true} {7 true} {11 false} {13 true}] 默认行为切片下界默认值为0，上界则是该切片的长度。 package main import ( &quot;fmt&quot; &quot;unsafe&quot; ) func main() { s := []int{2, 3, 5, 7, 11, 13} fmt.Println(&quot; s:&quot;, s) s1 := s[1:4] fmt.Println(&quot;s1: &quot;, s1) s2 := s1[:2] fmt.Println(&quot;s2: &quot;, s2) s3 := s2[1:] fmt.Println(&quot;s3: &quot;, s3) s3[0] = 0 fmt.Println(&quot;\\nSizeof int on a 64-bit machine:&quot;, unsafe.Sizeof(s[0])) fmt.Println(&quot;\\ns[0] location:&quot;, &amp;s[0]) fmt.Println(&quot;s[1] location:&quot;, &amp;s[1]) fmt.Println(&quot;s[2] location:&quot;, &amp;s[2]) fmt.Println(&quot;s[3] location:&quot;, &amp;s[3]) } ------ s: [2 3 5 7 11 13] s1: [3 5 7] s2: [3 5] s3: [5] Sizeof int on a 64-bit machine: 8 s[0] location: 0xc00008c030 s[1] location: 0xc00008c038 s[2] location: 0xc00008c040 s[3] location: 0xc00008c048 长度和容量切片拥有长度和容量： 长度就是它所包含的元素个数 容量是从它的第一个元素开始数，到其底层数组元素末尾的个数 package main import &quot;fmt&quot; func main() { s := []int{2, 3, 5, 7, 11, 13} printSlice(s) // 截取切片使其长度为 0 s = s[:0] printSlice(s) // 拓展其长度 s = s[:4] printSlice(s) // 舍弃前两个值 s = s[2:] printSlice(s) } func printSlice(s []int) { fmt.Printf(&quot;len=%d cap=%d %v\\n&quot;, len(s), cap(s), s) } ------ len=6 cap=6 [2 3 5 7 11 13] len=0 cap=6 [] len=4 cap=6 [2 3 5 7] len=2 cap=4 [5 7] nil 切片切片的零值是nil，长度和容量均为0且没有底层数组： package main import &quot;fmt&quot; func main() { var s []int fmt.Println(s, len(s), cap(s)) if s == nil { fmt.Println(&quot;nil!&quot;) } } ------ [] 0 0 nil! 使用 make 创建切片切片可以用内建函数make来创建，make函数会分配一个元素为零值的数组并返回一个引用它的切片： package main import &quot;fmt&quot; func main() { a := make([]int, 5) printSlice(&quot;a&quot;, a) b := make([]int, 0, 5) printSlice(&quot;b&quot;, b) c := b[:2] printSlice(&quot;c&quot;, c) d := c[2:5] printSlice(&quot;d&quot;, d) } func printSlice(s string, x []int) { fmt.Printf(&quot;%s len=%d cap=%d %v\\n&quot;, s, len(x), cap(x), x) } ------ a len=5 cap=5 [0 0 0 0 0] b len=0 cap=5 [] c len=2 cap=5 [0 0] d len=3 cap=3 [0 0 0] 切片的切片切片可以包含切片，类似二维切片的概念： package main import ( &quot;fmt&quot; &quot;strings&quot; ) func main() { board := [][]string{ []string{&quot;_&quot;, &quot;_&quot;, &quot;_&quot;}, []string{&quot;_&quot;, &quot;_&quot;, &quot;_&quot;}, []string{&quot;_&quot;, &quot;_&quot;, &quot;_&quot;}, } board[0][0] = &quot;X&quot; board[2][2] = &quot;O&quot; board[1][2] = &quot;X&quot; board[1][0] = &quot;O&quot; board[0][2] = &quot;X&quot; for i := 0; i &lt; len(board); i++ { fmt.Printf(&quot;%s\\n&quot;, strings.Join(board[i], &quot; &quot;)) } } ------ X _ X O _ X _ _ O append 追加切片元素 参见 Go 切片：用法和本质 | Go Blog Go 提供了内建的append()函数，用于向切片追加新元素： package main import &quot;fmt&quot; func main() { var s []int printSlice(s) // 向切片添加一个 0 s = append(s, 0) printSlice(s) // 这个切片会按需增长 s = append(s, 1) printSlice(s) // 可以一次性添加多个元素 s = append(s, 2, 3, 4) printSlice(s) } func printSlice(s []int) { fmt.Printf(&quot;len=%d cap=%d %v\\n&quot;, len(s), cap(s), s) } ------ len=0 cap=0 [] len=1 cap=2 [0] len=2 cap=2 [0 1] len=5 cap=8 [0 1 2 3 4] // go1.12.6 windows/amd64: len=5 cap=6 [0 1 2 3 4] 当切片长度不超过1024时，每次扩容为原切片长度的两倍（有待考证） 3.5 Rangefor循环的range形式可遍历切片slice或映射map： package main import &quot;fmt&quot; var pow = []int{1, 2, 4, 8, 16, 32, 64, 128} func main() { for i, v := range pow { fmt.Printf(&quot;2^%d = %d\\n&quot;, i, v) } } ------ 2^0 = 1 2^1 = 2 2^2 = 4 2^3 = 8 2^4 = 16 2^5 = 32 2^6 = 64 2^7 = 128 当使用for range遍历时，每次迭代都会返回两个值： 前者i为当前元素的下标 后者v为该下标对应元素的一份副本 因此，通过下标s[i]取值比直接通过v效率更高 可以将下标或值赋予_表示忽略： for i, _ := range pow for _, value := range pow 若只需要索引，忽略第二个变量即可： for i := range pow 3.6 映射映射map将键映射到值。映射的文法与结构体相似，不过必须有键名： package main import &quot;fmt&quot; type Vertex struct { Lat, Long float64 } var m = map[string]Vertex{ &quot;Bell Labs&quot;: Vertex{ 40.68433, -74.39967, }, &quot;Google&quot;: Vertex{ 37.42202, -122.08408, }, } func main() { fmt.Println(m) } ------ map[Bell Labs:{40.68433 -74.39967} Google:{37.42202 -122.08408}] 映射的文法可以直接省略顶级类型的类型名： var m = map[string]Vertex{ &quot;Bell Labs&quot;: {40.68433, -74.39967}, &quot;Google&quot;: {37.42202, -122.08408}, } 修改映射当从映射中读取某个不存在的键时，结果是映射的元素类型的零值。 // 插入或修改元素 m[key] = elem // 删除元素 delete(m, key) // 通过双赋值检测某个键是否存在 elem, ok := m[key] 3.7 函数值函数也是值，可以向其他值一样传递。 函数值可以用作函数的参数或返回值： package main import ( &quot;fmt&quot; &quot;math&quot; ) func compute(fn func(float64, float64) float64) float64 { return fn(3, 4) } func main() { hypot := func(x, y float64) float64 { return math.Sqrt(x*x + y*y) } fmt.Println(hypot(5, 12)) fmt.Println(compute(hypot)) fmt.Println(compute(math.Pow)) } ------ 13 5 81 3.8 函数的闭包Go 的函数可以是一个闭包clojure。 闭包是一个函数值，它引用了其函数体之外的变量。该函数可以访问并赋予其引用的变量的值，换句话说，该函数被这些变量“绑定”在一起。 例如，函数adder()返回一个闭包，每个闭包都被绑定在其各自的sum变量上： package main import &quot;fmt&quot; func adder() func(int) int { sum := 0 return func(x int) int { sum += x return sum } } func main() { pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ { fmt.Println( pos(i), neg(-2*i), ) } } ------ 0 0 1 -2 3 -6 6 -12 10 -20 15 -30 21 -42 28 -56 36 -72 45 -90 4. 方法和接口4.1 方法Go 没有类，不过可以为结构体类型定义方法。 方法就是一类带特殊的接收者参数的函数，接收者位于func关键字和方法名之间： package main import ( &quot;fmt&quot; &quot;math&quot; ) type Vertex struct { X, Y float64 } func (v Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func main() { v := Vertex{3, 4} fmt.Println(v.Abs()) } ------ 5 也可以为非结构体类型声明方法，例如在下面的例子中看到了一个带Abs()方法的数值类型MyFloat： package main import ( &quot;fmt&quot; &quot;math&quot; ) type MyFloat float64 func (f MyFloat) Abs() float64 { if f &lt; 0 { return float64(-f) } return float64(f) } func main() { f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs()) } ------ 1.4142135623730951 需要注意： 接收者（例如MyFloat）的类型定义和方法声明必须在同一包内 不能为内建类型声明方法 指针接收者可以为指针接收者声明方法，这意味着方法内部可以修改接收者指向的值： package main import ( &quot;fmt&quot; &quot;math&quot; ) type Vertex struct { X, Y float64 } func (v Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func (v *Vertex) Scale(f float64) { v.X *= f v.Y *= f } func main() { v := Vertex{3, 4} v.Scale(10) fmt.Println(v.Abs()) } ------ 50 方法与指针重定向带指针参数的函数必须接受一个指针： var v Vertex ScaleFunc(v, 5) // 编译错误！ ScaleFunc(&amp;v, 5) // OK 而以指针为接收者的方法被调用时，接收者既能为值又能为指针： var v Vertex v.Scale(5) // OK p := &amp;v p.Scale(10) // OK 这是因为 Go 会对语句做以下翻译： v.Scale(5) // 以上语句解释为： (&amp;v).Scale(5) 同样的，以值为接收者的方法被调用时，接收者既能为值又能为指针： var v Vertex fmt.Println(v.Abs()) // OK p := &amp;v fmt.Println(p.Abs()) // OK 同样会做以下翻译： p.Abs() // 以上语句翻译为 (*p).Abs() 选择值或指针作为接收者 通常来说，所有给定类型的方法都应该有值或指针接收者，但不应该二者混用 使用指针接收者的原因有二： 方法能够修改其接收者指向的值 可以避免在每次调用方法时复制该值。若值的类型为大型结构体时，这样做会更加高效 例如在下面的示例中，Scale()和Abs()接收者的类型均为*Vertex，即便Abs()并不需要修改其接收者： package main import ( &quot;fmt&quot; &quot;math&quot; ) type Vertex struct { X, Y float64 } func (v *Vertex) Scale(f float64) { v.X = v.X * f v.Y = v.Y * f } func (v *Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func main() { v := &amp;Vertex{3, 4} fmt.Printf(&quot;Before scaling: %+v, Abs: %v\\n&quot;, v, v.Abs()) v.Scale(5) fmt.Printf(&quot;After scaling: %+v, Abs: %v\\n&quot;, v, v.Abs()) } ------ Before scaling: &amp;{X:3 Y:4}, Abs: 5 After scaling: &amp;{X:15 Y:20}, Abs: 25 4.2 接口接口类型是由一组方法签名定义的集合，接口类型的变量可以保存任何实现了这些方法的值： package main import ( &quot;fmt&quot; &quot;math&quot; ) type Abser interface { Abs() float64 } func main() { var a Abser f := MyFloat(-math.Sqrt2) v := Vertex{3, 4} a = f // a MyFloat 实现了 Abser fmt.Println(a.Abs()) a = &amp;v // a *Vertex 实现了 Abser fmt.Println(a.Abs()) } type MyFloat float64 func (f MyFloat) Abs() float64 { if f &lt; 0 { return float64(-f) } return float64(f) } type Vertex struct { X, Y float64 } func (v *Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } ------ 1.4142135623730951 5 接口的隐式实现在 Go 中，接口是隐式实现的，即类型通过实现一个接口的所有方法来实现该接口。 既然无需专门显式声明，也就没有implements关键字。 接口值 接口也是值，可以像其他值一样传递 接口值可以用作函数的参数或返回值 在内部，接口值可以看做包含值和具体类型的元组：(value, type) 接口值保存了一个具体底层类型的具体值 接口值调用方法时会执行其底层类型的同名方法 package main import ( &quot;fmt&quot; &quot;math&quot; ) type I interface { M() } type T struct { S string } func (t *T) M() { fmt.Println(t.S) } type F float64 func (f F) M() { fmt.Println(f) } func main() { var i I i = &amp;T{&quot;Hello&quot;} describe(i) i.M() i = F(math.Pi) describe(i) i.M() } func describe(i I) { fmt.Printf(&quot;(%v, %T)\\n&quot;, i, i) } ------ (&amp;{Hello}, *main.T) Hello (3.141592653589793, main.F) 3.141592653589793 底层值为 nil 的接口值即便接口内的具体值为nil，方法仍然会被nil接收者调用： package main import &quot;fmt&quot; type I interface { M() } type T struct { S string } func (t *T) M() { if t == nil { fmt.Println(&quot;&lt;nil&gt;&quot;) return } fmt.Println(t.S) } func main() { var i I var t *T i = t describe(i) i.M() i = &amp;T{&quot;hello&quot;} describe(i) i.M() } func describe(i I) { fmt.Printf(&quot;(%v, %T)\\n&quot;, i, i) } ------ (&lt;nil&gt;, *main.T) &lt;nil&gt; (&amp;{hello}, *main.T) hello 注意：保存了nil具体值的接口，其自身并不为nil nil 接口值 nil接口值既不保存值也不保存具体类型 为nil接口调用方法会产生运行时错误 package main import &quot;fmt&quot; type I interface { M() } func main() { var i I describe(i) i.M() } func describe(i I) { fmt.Printf(&quot;(%v, %T)\\n&quot;, i, i) } ------ (&lt;nil&gt;, &lt;nil&gt;) panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0xffffffff addr=0x0 pc=0xd9864] goroutine 1 [running]: main.main() /tmp/sandbox062767685/prog.go:12 +0x84 空接口指定了零个方法的接口值被称为空接口： interface{} 空接口可以用来保存任何类型的值，因为每个类型都至少实现了零个方法 空接口被用来处理未知类型的值 package main import &quot;fmt&quot; func main() { var i interface{} describe(i) i = 42 describe(i) i = &quot;hello&quot; describe(i) } func describe(i interface{}) { fmt.Printf(&quot;(%v, %T)\\n&quot;, i, i) } ------ (&lt;nil&gt;, &lt;nil&gt;) (42, int) (hello, string) 4.3 类型断言类型断言提供了访问接口值底层具体值的方式： t, ok := i.(T) 若i保存了一个T，那么t将会是其底层值，而ok为true 否则，ok将为false，而t将为T类型的零值，程序并不会产生panic package main import &quot;fmt&quot; func main() { var i interface{} = &quot;hello&quot; s := i.(string) fmt.Println(s) s, ok := i.(string) fmt.Println(s, ok) f, ok := i.(float64) fmt.Println(f, ok) f = i.(float64) // 报错(panic) fmt.Println(f) } ------ hello hello true 0 false panic: interface conversion: interface {} is string, not float64 goroutine 1 [running]: main.main() /tmp/sandbox590758285/prog.go:17 +0x220 4.4 类型选择类型选择是一种按顺序从几个类型断言中选择分支的结构： package main import &quot;fmt&quot; func do(i interface{}) { switch v := i.(type) { case int: fmt.Printf(&quot;Twice %v is %v\\n&quot;, v, v*2) case string: fmt.Printf(&quot;%q is %v bytes long\\n&quot;, v, len(v)) default: fmt.Printf(&quot;I don&#39;t know about type %T!\\n&quot;, v) } } func main() { do(21) do(&quot;hello&quot;) do(true) } ------ Twice 21 is 42 &quot;hello&quot; is 5 bytes long I don&#39;t know about type bool! 4.5 Stringerfmt包中定义的Stringer接口是最普遍的接口之一： type Stringer interface { String() string } 因此只要实现了String()方法，就可以打印结构体的信息： package main import &quot;fmt&quot; type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(&quot;%v (%v years)&quot;, p.Name, p.Age) } func main() { a := Person{&quot;Arthur Dent&quot;, 42} z := Person{&quot;Zaphod Beeblebrox&quot;, 9001} fmt.Println(a, z) } ------ Arthur Dent (42 years) Zaphod Beeblebrox (9001 years) 4.6 错误Go 程序使用error值来表示错误状态。与fmt.Stringer类似，error类型也是一个内建接口： type error interface { Error() string } 通常函数会返回一个error值，调用它的代码应当判断这个错误是否等于nil来进行错误处理： package main import ( &quot;fmt&quot; &quot;time&quot; ) type MyError struct { When time.Time What string } func (e *MyError) Error() string { return fmt.Sprintf(&quot;at %v, %s&quot;, e.When, e.What) } func run() error { return &amp;MyError{ time.Now(), &quot;it didn&#39;t work&quot;, } } func main() { if err := run(); err != nil { fmt.Println(err) } } ------ at 2019-08-18 12:53:38.540727 +0800 CST m=+0.002985501, it didn&#39;t work 4.7 Readerio包指定了io.Reader接口，它表示从数据流的末尾进行读取。 io.Reader接口有一个Read方法： func (T) Read(b []byte) (n int, err error) 该方法用数据填充给定的字节切片，并返回填充的字节数和错误值。在遇到数据流的结尾时，会返回一个io.EOF错误： package main import ( &quot;fmt&quot; &quot;io&quot; &quot;strings&quot; ) func main() { r := strings.NewReader(&quot;Hello, Reader!&quot;) b := make([]byte, 8) for { n, err := r.Read(b) fmt.Printf(&quot;n = %v err = %v b = %v\\n&quot;, n, err, b) fmt.Printf(&quot;b[:n] = %q\\n&quot;, b[:n]) if err == io.EOF { break } } } ------ n = 8 err = &lt;nil&gt; b = [72 101 108 108 111 44 32 82] b[:n] = &quot;Hello, R&quot; n = 6 err = &lt;nil&gt; b = [101 97 100 101 114 33 32 82] b[:n] = &quot;eader!&quot; n = 0 err = EOF b = [101 97 100 101 114 33 32 82] b[:n] = &quot;&quot; 4.8 图像image包定义了Image接口： package image type Image interface { ColorModel() color.Model Bounds() Rectangle At(x, y int) color.Color } 这些接口和类型由image/color包定义： package main import ( &quot;fmt&quot; &quot;image&quot; ) func main() { m := image.NewRGBA(image.Rect(0, 0, 100, 100)) fmt.Println(m.Bounds()) fmt.Println(m.At(0, 0).RGBA()) } ------ (0,0)-(100,100) 0 0 0 0 5. 并发5.1 协程 goroutineGo 程goroutine是由 Go 运行时管理的轻量级线程： go f(x, y, z) 上面的语句会启动一个新的 Go 程并执行： f(x, y, z) f, x, y, z的求值发生在当前 Go 程中 f的执行发生在新的 Go 程中 package main import ( &quot;fmt&quot; &quot;time&quot; ) func say(s string) { for i := 0; i &lt; 5; i++ { time.Sleep(100 * time.Millisecond) fmt.Println(s) } } func main() { go say(&quot;world&quot;) say(&quot;hello&quot;) } ------ hello world world hello world hello world hello hello Go 程在相同的地址空间中运行，因此在访问共享的内存时必须进行同步。sync包提供了这种能力，不过也可以利用其它方式实现。 5.2 通道 channel信道channel是带有类型的管道，可以通过它使用信道操作符&lt;-来发送或者接收值： ch &lt;- v // 将 v 发送至信道 ch v := &lt;-ch // 从 ch 接收值并赋予 v 根据箭头在信道的方向，左读右写。 和映射与切片一样，信道在使用前必须创建： ch := make(chan int) 默认情况下是阻塞的，这使得 Go 程序可以在没有显式的锁或竞态变量的情况下进行同步： package main import &quot;fmt&quot; func sum(s []int, c chan int) { sum := 0 for i := range s { sum += s[i] } c &lt;- sum // 将和送入 c } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := &lt;-c, &lt;-c // 从 c 中接收 fmt.Println(x, y, x+y) } ------ -5 17 12 5.3 带缓冲的通道信道可以是带缓冲的： ch := make(chan int, 100) 仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接收方会阻塞。 5.4 range 和 close发送者可通过close关闭一个信道来表示没有需要发送的值了。 接收者可通过以下语句判断信道是否已被关闭： v, ok := &lt;-ch // 关闭时 v 为默认零值，ok 为 false 循环for i := range c会不断从信道接收值，直到它被关闭： package main import ( &quot;fmt&quot; ) func fibonacci(n int, c chan int) { x, y := 0, 1 for i := 0; i &lt; n; i++ { c &lt;- x x, y = y, x+y } close(c) } func main() { c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c { fmt.Println(i) } v, ok := &lt;-c fmt.Println(v, ok) } ------ 0 1 1 2 3 5 8 13 21 34 0 false 只有发送者才能关闭信道，而接收者不能 向一个已经关闭的信道发送数据会引发panic 重复关闭信道会引发panic 信道与文件不同，通常情况下无需关闭，只有在必须告诉接收者不再有需要发送的值时才有必要关闭，例如终止一个range循环 5.5 select 语句select语句使一个 Go 程可以等待多个通信操作。 select会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时，会随机选择一个执行： package main import &quot;fmt&quot; func fibonacci(c, quit chan int) { x, y := 0, 1 for { select { case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;quit&quot;) return } } } func main() { c := make(chan int) quit := make(chan int) go func() { for i := 0; i &lt; 10; i++ { fmt.Println(&lt;-c) } quit &lt;- 0 }() fibonacci(c, quit) } ------ 0 1 1 2 3 5 8 13 21 34 quit 当select中的其他分支都没有准备好时，default分支就会执行： select { case i := &lt;-c: // 使用 i default: // 从 c 中接收会阻塞时执行 } 为了在尝试发送或者接收时不发生阻塞，可使用default分支： package main import ( &quot;fmt&quot; &quot;time&quot; ) func main() { tick := time.Tick(100 * time.Millisecond) boom := time.After(500 * time.Millisecond) for { select { case &lt;-tick: fmt.Println(&quot;tick.&quot;) case &lt;-boom: fmt.Println(&quot;BOOM!&quot;) default: fmt.Println(&quot; .&quot;) time.Sleep(50 * time.Millisecond) } } } ------ . . tick. . . tick. . . tick. . . tick. . . BOOM! 5.6 sync.MutexGo 标准库中提供了sync.Mutex互斥锁类型及其两个方法：Lock()、Unlock()： package main import ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot; ) // SafeCounter 的并发使用是安全的 type SafeCounter struct { v map[string]int mux sync.Mutex } // Inc 增加给定 key 的计数器的值 func (c *SafeCounter) Inc(key string) { c.mux.Lock() c.v[key]++ c.mux.Unlock() } // Value 返回给定 key 的计数器的当前值 func (c *SafeCounter) Value(key string) int { c.mux.Lock() defer c.mux.Unlock() return c.v[key] } func main() { c := SafeCounter{ v: make(map[string]int), } for i := 0; i &lt; 1000; i++ { go c.Inc(&quot;somekey&quot;) } time.Sleep(time.Second) fmt.Println(c.Value(&quot;somekey&quot;)) } ------ 1000 可以通过在代码前调用Lock()方法、在代码后调用Unlock()方法来保证一段代码的互斥执行 也可以用defer语句来保证互斥锁一定会被解锁 6. 常用代码6.1 标准库// fmt fmt.Errorf(&quot;%s&quot;, &quot;db connect fail&quot;) // io // math math.Pi // sync // strings strings.Join(board[i], &quot; &quot;) fileds := strings.Fileds(s) // strconv // net/http // net/url // log // types // json // xml // rand fmt.Println(&quot;My favorite number is&quot;, rand.Intn(10)) %d 整型 %s 字符串 %f 浮点数 %T 类型 %v 值，例如 {3 4} %+v 域+值，例如 {X:3 Y:4} %q 带引号的字符串, &quot;s&quot; // time time.Now() time.Now().Hour() time.Sleep(time.Second) // unsafe unsafe.Sizeof() // runtime runtime.GOOS runtime.GOARCH runtime.Version() fmt.Println(runtime.GOMAXPROCS(0)) // errors errors.New() // os.Open() 6.2 内建函数make([]int, 4, 8) // 切片 slice len() cap() append() copy() // 映射 map delete(m, key) // 内建接口 type error interface { Error() } type Stringer interface { String() string } // 通道 for i := range ch close(ch) 7. 练习解答 参见 Golang 官方指导练习 - 掠雪墨影 | CSDN 7.1 循环与函数：牛顿法求平方根package main import ( &quot;fmt&quot; &quot;math&quot; ) func sqrt(x float64) float64 { z := float64(1) for { y := z - (z*z-x)/(2*z) if math.Abs(y-z) &lt; 1e-10 { return y } z = y } } func main() { fmt.Println(sqrt(2)) fmt.Println(math.Sqrt(2)) } ------ 1.4142135623730951 1.4142135623730951 7.2 切片：图像灰度值package main import ( &quot;golang.org/x/tour/pic&quot; ) func Pic(dx, dy int) [][]uint8 { ret := make([][]uint8, dy) for x := 0; x &lt; dy; x++ { ret[x] = make([]uint8, dx) for y := 0; y &lt; dx; y++ { ret[x][y] = uint8(x ^ y) // ret[x][y] = uint8((x + y) / 2) // ret[x][y] = uint8(x * y) // ret[x][y] = uint8(float64(x) * math.Log(float64(y))) // ret[x][y] = uint8(x % (y + 1)) } } return ret } func main() { pic.Show(Pic) } 7.3 映射：单词统计package main import ( &quot;strings&quot; &quot;golang.org/x/tour/wc&quot; ) func WordCount(s string) map[string]int { count := make(map[string]int) for _, word := range strings.Fields(s) { count[word]++ } return count } func main() { wc.Test(WordCount) } 7.4 闭包：斐波那契数列package main import &quot;fmt&quot; // 返回一个“返回int的函数” func fibonacci() func() int { one := 0 two := 1 return func() int { three := one + two one = two two = three return three } } func main() { f := fibonacci() for i := 0; i &lt; 10; i++ { fmt.Println(f()) } } ------ 1 2 3 5 8 13 21 34 55 89 7.5 Stringerpackage main import &quot;fmt&quot; type IPAddr [4]byte func (ip IPAddr) String() string { return fmt.Sprintf(&quot;%v.%v.%v.%v&quot;, ip[0], ip[1], ip[2], ip[3]) } func main() { hosts := map[string]IPAddr{ &quot;loopback&quot;: {127, 0, 0, 1}, &quot;googleDNS&quot;: {8, 8, 8, 8}, } for name, ip := range hosts { fmt.Printf(&quot;%v: %v\\n&quot;, name, ip) } } ------ loopback: 127.0.0.1 googleDNS: 8.8.8.8 7.6 错误package main import ( &quot;fmt&quot; &quot;math&quot; ) type ErrNegativeSqrt float64 func (e ErrNegativeSqrt) Error() string { return fmt.Sprintf(&quot;cannot Sqrt negative number: %v&quot;, float64(e)) } func sqrt(x float64) (float64, error) { if x &lt; 0 { return 0, ErrNegativeSqrt(x) } z := float64(1) for { y := z - (z*z-x)/(2*z) if math.Abs(y-z) &lt; 1e-10 { return y, nil } z = y } } func main() { fmt.Println(sqrt(2)) fmt.Println(sqrt(-2)) } ------ 1.4142135623730951 &lt;nil&gt; 0 cannot Sqrt negative number: -2 7.7 Readerpackage main import ( &quot;strings&quot; &quot;golang.org/x/tour/reader&quot; ) type MyReader struct{} func (MyReader) Read(b []byte) (int, error) { r := strings.NewReader(&quot;A&quot;) n, err := r.Read(b) return n, err } func main() { reader.Validate(MyReader{}) } 7.8 rot13Readerpackage main import ( &quot;io&quot; &quot;os&quot; &quot;strings&quot; ) type rot13Reader struct { r io.Reader } func (self rot13Reader) Read(buf []byte) (int, error) { length, err := self.r.Read(buf) if err != nil { return length, err } for i := 0; i &lt; length; i++ { v := buf[i] switch { case &#39;a&#39; &lt;= v &amp;&amp; v &lt;= &#39;m&#39;: fallthrough case &#39;A&#39; &lt;= v &amp;&amp; v &lt;= &#39;M&#39;: buf[i] = v + 13 case &#39;n&#39; &lt;= v &amp;&amp; v &lt;= &#39;z&#39;: fallthrough case &#39;N&#39; &lt;= v &amp;&amp; v &lt;= &#39;Z&#39;: buf[i] = v - 13 } } return length, nil } func main() { s := strings.NewReader(&quot;Lbh penpxrq gur pbqr!&quot;) r := rot13Reader{s} io.Copy(os.Stdout, &amp;r) } ------ You cracked the code! 7.9 图像package main import ( &quot;image&quot; &quot;image/color&quot; &quot;golang.org/x/tour/pic&quot; ) type Image struct { w int h int } func (self Image) ColorModel() color.Model { return color.RGBAModel } func (self Image) Bounds() image.Rectangle { return image.Rect(0, 0, self.w, self.h) } func (self Image) At(x, y int) color.Color { r := (uint8)((float64)(x) / (float64)(self.w) * 255.0) g := (uint8)((float64)(y) / (float64)(self.h) * 255.0) b := (uint8)((float64)(x*y) / (float64)(self.w*self.h) * 255.0) return color.RGBA{r, g, b, 255} } func main() { m := Image{255, 255} pic.ShowImage(m) } 7.10 等价二叉查找树package main import ( &quot;fmt&quot; &quot;golang.org/x/tour/tree&quot; ) // Walk 步进 tree t 将所有的值从 tree 发送到 channel ch。 func Walk(t *tree.Tree, ch chan int) { if t == nil { return } Walk(t.Left, ch) ch &lt;- t.Value Walk(t.Right, ch) } // Same 检测树 t1 和 t2 是否含有相同的值。 func Same(t1, t2 *tree.Tree) bool { ch1 := make(chan int) ch2 := make(chan int) go Walk(t1, ch1) go Walk(t2, ch2) for i := 0; i &lt; 10; i++ { x, y := &lt;-ch1, &lt;-ch2 fmt.Println(x, y) if x != y { return false } } return true } func main() { fmt.Println(Same(tree.New(1), tree.New(1))) } ------ 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10 true 7.11 Web 爬虫package main import ( &quot;fmt&quot; &quot;sync&quot; ) type Fetcher interface { // Fetch 返回 URL 的 body 内容，并且将在这个页面上找到的 URL 放到一个 slice 中。 Fetch(url string) (body string, urls []string, err error) } // Crawl 使用 fetcher 从某个 URL 开始递归的爬取页面，直到达到最大深度。 func Crawl(url string, depth int, fetcher Fetcher, crawled Crawled, out chan string, end chan bool) { // TODO: 并行的抓取 URL。 // TODO: 不重复抓取页面。 // 下面并没有实现上面两种情况： if depth &lt;= 0 { end &lt;- true return } crawled.mux.Lock() if _, ok := crawled.crawled[url]; ok { crawled.mux.Unlock() end &lt;- true return } crawled.crawled[url] = 1 crawled.mux.Unlock() _, urls, err := fetcher.Fetch(url) if err != nil { fmt.Println(err) end &lt;- true return } out &lt;- url //fmt.Println(&quot;found: &quot;, url, body) for _, u := range urls { go Crawl(u, depth-1, fetcher, crawled, out, end) } for i := 0; i &lt; len(urls); i++ { &lt;-end } end &lt;- true return } type Crawled struct { crawled map[string]int mux sync.Mutex } func main() { crawled := Crawled{make(map[string]int), sync.Mutex{}} out := make(chan string) end := make(chan bool) go Crawl(&quot;http://golang.org/&quot;, 4, fetcher, crawled, out, end) for { select { case url := &lt;-out: fmt.Println(&quot;found: &quot;, url) case &lt;-end: return } } } // fakeFetcher 是返回若干结果的 Fetcher。 type fakeFetcher map[string]*fakeResult type fakeResult struct { body string urls []string } func (f fakeFetcher) Fetch(url string) (string, []string, error) { if res, ok := f[url]; ok { return res.body, res.urls, nil } return &quot;&quot;, nil, fmt.Errorf(&quot;not found: %s&quot;, url) } // fetcher 是填充后的 fakeFetcher。 var fetcher = fakeFetcher{ &quot;http://golang.org/&quot;: &amp;fakeResult{ &quot;The Go Programming Language&quot;, []string{ &quot;http://golang.org/pkg/&quot;, &quot;http://golang.org/cmd/&quot;, }, }, &quot;http://golang.org/pkg/&quot;: &amp;fakeResult{ &quot;Packages&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/cmd/&quot;, &quot;http://golang.org/pkg/fmt/&quot;, &quot;http://golang.org/pkg/os/&quot;, }, }, &quot;http://golang.org/pkg/fmt/&quot;: &amp;fakeResult{ &quot;Package fmt&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, }, &quot;http://golang.org/pkg/os/&quot;: &amp;fakeResult{ &quot;Package os&quot;, []string{ &quot;http://golang.org/&quot;, &quot;http://golang.org/pkg/&quot;, }, }, } ------ found: http://golang.org/ found: http://golang.org/pkg/ found: http://golang.org/pkg/os/ found: http://golang.org/pkg/fmt/ not found: http://golang.org/cmd/ 8. 参考文章官方文档 Go Tour | Golang.org Go Wiki | Github 实效 Go 编程 | Golang.org Effective Go | Golang.org Package builtin - 内建函数 | Golang.org Packages - 标准库 | Golang.org GoDoc | Search for Go Packages Go Blog Defer, Panic, and Recover | Go Blog Go 切片：用法和本质 | Go Blog Go Tour 题解 Golang 官方指导练习 - 掠雪墨影 | CSDN 学习 Javascript 闭包 (Closure) | 阮一峰 Go 标准库 gopkg - astaxie | Github Golang 常用包 | 胡伟煌 Go 常用标准包介绍 - Mr_buffoon | CSDN Go 语言标准库概览 | Tony Bai 推荐一个知乎专栏作者：谢伟，知乎专栏『Gopher』- Go 上手指南 Go 内置库第一季：strings - 谢伟 | 知乎 Go 内置库第一季：strconv - 谢伟 | 知乎 Go 内置库第一季：reflect - 谢伟 | 知乎 Go 内置库第一季：json - 谢伟 | 知乎 Go 内置库第一季：error - 谢伟 | 知乎 Go 内置库第一季：time - 谢伟 | 知乎 Go 内置库第一季：net/url - 谢伟 | 知乎 请教：FieldsFunc 函数的用法 | Golang 中国 【Go语言】基本类型排序和 slice 排序 | iTimeTraveler 其他不错的文章： Go Web 教程 - 谢伟 | 知乎 Go GraphQL 教程 - 谢伟 | 知乎 Go 与 Error 的前世今生 - 谢伟 | 知乎 自己构建节假日 API - 谢伟 | 知乎 打造一款 emoji 表情库 - 谢伟 | 知乎 51CTO 上的一个系列教程 Go 语言开发学习教程 - 天山老妖S | 51CTO Go 语言常用标准库一 - 天山老妖S | 51CTO Go 语言常用标准库二 - 天山老妖S | 51CTO Go 语言常用标准库三 - 天山老妖S | 51CTO Go 语言常用标准库四 - 天山老妖S | 51CTO Go 语言常用标准库五 - 天山老妖S | 51CTO Go 语言常用标准库六 - 天山老妖S | 51CTO Go 语言 MySQL 数据库操作 - 天山老妖S | 51CTO Go 语言 database/sql 接口 - 天山老妖S | 51CTO 设计模式 go-patterns - Golang 设计模式 | Github 演讲 PPT Go: a simple programming environment - Andrew Gerrand | Google Go Concurrency Patterns - Rob Pike | Google Web 编程 build-web-application-with-golang - astaxie | Github Writing Web Applications | golang.org Beego Framework Build a Single-Page App with Go and Vue | okta Go Vue Template - tdewolff | Github 开源图书 go2-book - Go 2 编程指南 | Github advanced-go-programming-book - Go 语言高级编程 | Github 博客框架 go-vue-blog - beego + vue 前后端分离个人博客 | Github go-blog - go 版个人博客 | Github 游戏 Ubuntu 搭建《太鼓达人》在线模拟器 Taiko Web | 腾讯云开发者实验室 taiko-web - Taiko Web mirror on Tencent | 腾讯云开发者平台 Create a simple cross-platform desktop game with Go - sausheong’s space Writing Space Invaders with Go - sausheong’s space 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Web 开发","slug":"Web-开发","permalink":"https://abelsu7.top/tags/Web-开发/"}]},{"title":"Go Web 编程笔记","slug":"go-web-programming","date":"2019-08-15T07:16:25.000Z","updated":"2019-10-24T15:20:01.010Z","comments":true,"path":"2019/08/15/go-web-programming/","link":"","permalink":"https://abelsu7.top/2019/08/15/go-web-programming/","excerpt":"Go Web Programming Notes. To Be Updated…","text":"Go Web Programming Notes. To Be Updated… 1. 快速开始package main import ( &quot;fmt&quot; &quot;net/http&quot; ) func handler(writer http.ResponseWriter, request *http.Request) { fmt.Fprintf(writer, &quot;Hello Web, %s!&quot;, request.URL.Path[1:]) } func main() { http.HandleFunc(&quot;/&quot;, handler) http.ListenAndServe(&quot;:8080&quot;, nil) } HTTP 请求的 URL 格式： http://&lt;servername&gt;/&lt;handlername&gt;?&lt;parameters&gt; 2. HttpRouter相关参考： 08.3. REST - Go Web 编程 | Learnku httprouter - julienschmidt | Github build-web-application-with-golang - astaxie | Github package main import ( &quot;fmt&quot; &quot;log&quot; &quot;net/http&quot; &quot;github.com/julienschmidt/httprouter&quot; ) func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { fmt.Fprint(w, &quot;Welcome!\\n&quot;) } func Hello(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { fmt.Fprintf(w, &quot;hello %s!\\n&quot;, ps.ByName(&quot;name&quot;)) } func getUser(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { uid := ps.ByName(&quot;uid&quot;) fmt.Fprintf(w, &quot;you are get user %s&quot;, uid) } func modifyUser(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { uid := ps.ByName(&quot;uid&quot;) fmt.Fprintf(w, &quot;you are modify user %s&quot;, uid) } func deleteUser(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { uid := ps.ByName(&quot;uid&quot;) fmt.Fprintf(w, &quot;you are delete user %s&quot;, uid) } func addUser(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { uid := ps.ByName(&quot;uid&quot;) fmt.Fprintf(w, &quot;you are add user %s&quot;, uid) } func main() { router := httprouter.New() router.GET(&quot;/&quot;, Index) router.GET(&quot;/hello/:name&quot;, Hello) router.GET(&quot;/user/:uid&quot;, getUser) router.POST(&quot;/adduser/:uid&quot;, addUser) router.DELETE(&quot;/deluser/:uid&quot;, deleteUser) router.PUT(&quot;/moduser/:uid&quot;, modifyUser) log.Fatal(http.ListenAndServe(&quot;:8080&quot;, router)) } 3. http 包建立 Web 服务器 参见 3.2 Go 搭建一个 Web 服务器 - build-web-application-with-golang | Github package main import ( &quot;fmt&quot; &quot;log&quot; &quot;net/http&quot; &quot;strings&quot; ) func sayHelloName(w http.ResponseWriter, r *http.Request) { r.ParseForm() fmt.Println(r.Form) // 解析参数，默认是不会解析的 fmt.Println(&quot;path&quot;, r.URL.Path) // 在服务器端打印 fmt.Println(&quot;scheme&quot;, r.URL.Scheme) fmt.Println(r.Form[&quot;url_long&quot;]) for k, v := range r.Form { fmt.Println(&quot;key:&quot;, k) fmt.Println(&quot;val:&quot;, strings.Join(v, &quot;&quot;)) } fmt.Fprintf(w, &quot;Hello Abel!&quot;) // 写入到 Response 中 } func main() { http.HandleFunc(&quot;/&quot;, sayHelloName) // 设置访问的路由 log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil)) // 设置监听的端口 } GET请求： GET http://localhost:8080?url_long=111&amp;url_long=222 HTTP/1.1 响应： HTTP/1.1 200 OK Date: Mon, 02 Sep 2019 10:24:36 GMT Content-Length: 11 Content-Type: text/plain; charset=utf-8 Connection: close Hello Abel! 服务端输出： &gt; go run main.go map[url_long:[111 222]] path / scheme [111 222] key: url_long val: 111222 4. Go 如何使得 Web 工作4.1 基本概念先理清几个基本概念： Request：用户请求的信息，用来解析用户的请求信息，包括POST、GET、Cookie、URL等信息 Response：服务器需要反馈给客户端的信息 Conn：用户每次的请求连接 Handler：处理请求和生成返回信息的处理逻辑 下图是 Go 实现 Web 服务的工作模式流程图： 4.2 HTTP 包的执行流程HTTP 包的执行流程： 创建Listen Socket，监听指定端口，等待客户端请求的到来 Listen Socket接收客户端的请求，得到Client Socket，接下来通过Client Socket与客户端通信 处理客户端的请求，首先从Client Socket读取 HTTP 请求的协议头，如果是POST方法，还可能要读取客户端提交的数据，然后交给相应的handler处理请求。处理完毕后，handler会准备好客户端需要的数据，通过Client Socket写给客户端 对于上述过程，要想了解 Go 是如何让 Web 运行起来的，需要搞清楚以下三点： 如何监听端口？ 如何接收客户端请求？ 如何分配 handler？ 4.3 如何监听端口？ Go Version: 1.12.6 在之前的代码中可以看到，监听端口的实现是在http.ListenAndServe()函数中： http.ListenAndServe(&quot;:8080&quot;, nil) 该函数首先会初始化一个Server对象，之后调用该对象的同名方法： // ListenAndServe listens on the TCP network address addr and then calls // Serve with handler to handle requests on incoming connections. // Accepted connections are configured to enable TCP keep-alives. // // The handler is typically nil, in which case the DefaultServeMux is used. // // ListenAndServe always returns a non-nil error. func ListenAndServe(addr string, handler Handler) error { server := &amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } Server结构体的ListenAndServe()方法又调用了net.Listen(&quot;tcp&quot;, addr)，也就是底层用 TCP 协议搭建了一个服务，开始监听指定的端口： // ListenAndServe listens on the TCP network address srv.Addr and then // calls Serve to handle requests on incoming connections. // Accepted connections are configured to enable TCP keep-alives. // // If srv.Addr is blank, &quot;:http&quot; is used. // // ListenAndServe always returns a non-nil error. After Shutdown or Close, // the returned error is ErrServerClosed. func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == &quot;&quot; { addr = &quot;:http&quot; } ln, err := net.Listen(&quot;tcp&quot;, addr) // 监听指定的端口 if err != nil { return err } // 接收并处理客户端的请求 return srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)}) } 4.4 如何接收客户端请求？监听端口之后，上述代码最后又调用了srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)})作为返回值，该函数的作用就是接收并处理客户端的请求信息。该函数的具体实现如下： // Serve accepts incoming connections on the Listener l, creating a // new service goroutine for each. The service goroutines read requests and // then call srv.Handler to reply to them. // // HTTP/2 support is only enabled if the Listener returns *tls.Conn // connections and they were configured with &quot;h2&quot; in the TLS // Config.NextProtos. // // Serve always returns a non-nil error and closes l. // After Shutdown or Close, the returned error is ErrServerClosed. func (srv *Server) Serve(l net.Listener) error { // 省略部分代码 for { rw, e := l.Accept() // 1. 接收客户端请求 if e != nil { select { case &lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay &gt; max { tempDelay = max } srv.logf(&quot;http: Accept error: %v; retrying in %v&quot;, e, tempDelay) time.Sleep(tempDelay) continue } return e } tempDelay = 0 c := srv.newConn(rw) // 2. 创建一个新的 Conn c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) // 3. 为每个连接单独开一个 goroutine } } 省略部分代码，重点关注其中的for{}循环： l.Accept()：接收请求，并处理可能出现的错误 srv.newConn(rw)：创建一个新的连接Conn go c.serve(ctx)：为新连接单独开一个goroutine，把请求的数据当作参数扔给这个Conn去服务 4.5 如何分配 handler？那么如何具体分配到相应的函数来处理请求呢？可以看到，在上面的代码中，最后实际调用go c.serve(ctx)处理请求，该函数的实现代码较长，仅截取重要语句如下： // Serve a new connection. func (c *conn) serve(ctx context.Context) { // 省略部分代码 for { // 1. 解析请求，获取 ResponseWriter 及 Request w, err := c.readRequest(ctx) // 省略部分代码 // HTTP cannot have multiple simultaneous active requests.[*] // Until the server replies to this request, it can&#39;t read another, // so we might as well run the handler in this goroutine. // [*] Not strictly true: HTTP pipelining. We could let them all process // in parallel even if their responses need to be serialized. // But we&#39;re not going to implement HTTP pipelining because it // was never deployed in the wild and the answer is HTTP/2. // 2. 进一步处理请求 serverHandler{c.server}.ServeHTTP(w, w.req) } // 省略部分代码 } c.readRequest(ctx)：解析请求，获取对应的ResponseWriter及Request serverHandler.ServeHTTP(w, w.req)：进一步处理请求 结构体serverHandler的ServeHTTP()方法具体实现如下： func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { // 1. 获取 Server 对应的 Handler handler := sh.srv.Handler // 2. 若对应的 Handler 为 nil，则使用 DefaultServeMux if handler == nil { handler = DefaultServeMux } if req.RequestURI == &quot;*&quot; &amp;&amp; req.Method == &quot;OPTIONS&quot; { handler = globalOptionsHandler{} } // 3. 调用相应的函数处理请求 handler.ServeHTTP(rw, req) } 首先通过handler := sh.srv.Handler获取对应的Handler，也就是最开始调用ListenAndServe()时传入的第二个参数。实际上Handler是一个接口类型，只定义了一个方法ServeHTTP()： type Handler interface { ServeHTTP(ResponseWriter, *Request) } 例如之前传入的参数是nil，就会使用默认的DefaultServeMux。该变量是一个路由器（或者说，HTTP 请求多路复用器），用来匹配 URL 并跳转到其相应的 handle 函数，它在 Go 源码的server.go中定义： // ServeMux is an HTTP request multiplexer. // It matches the URL of each incoming request against a list of registered // patterns and calls the handler for the pattern that // most closely matches the URL. // // Patterns name fixed, rooted paths, like &quot;/favicon.ico&quot;, // or rooted subtrees, like &quot;/images/&quot; (note the trailing slash). // Longer patterns take precedence over shorter ones, so that // if there are handlers registered for both &quot;/images/&quot; // and &quot;/images/thumbnails/&quot;, the latter handler will be // called for paths beginning &quot;/images/thumbnails/&quot; and the // former will receive requests for any other paths in the // &quot;/images/&quot; subtree. // // Note that since a pattern ending in a slash names a rooted subtree, // the pattern &quot;/&quot; matches all paths not matched by other registered // patterns, not just the URL with Path == &quot;/&quot;. // // If a subtree has been registered and a request is received naming the // subtree root without its trailing slash, ServeMux redirects that // request to the subtree root (adding the trailing slash). This behavior can // be overridden with a separate registration for the path without // the trailing slash. For example, registering &quot;/images/&quot; causes ServeMux // to redirect a request for &quot;/images&quot; to &quot;/images/&quot;, unless &quot;/images&quot; has // been registered separately. // // Patterns may optionally begin with a host name, restricting matches to // URLs on that host only. Host-specific patterns take precedence over // general patterns, so that a handler might register for the two patterns // &quot;/codesearch&quot; and &quot;codesearch.google.com/&quot; without also taking over // requests for &quot;http://www.google.com/&quot;. // // ServeMux also takes care of sanitizing the URL request path and the Host // header, stripping the port number and redirecting any request containing . or // .. elements or repeated slashes to an equivalent, cleaner URL. type ServeMux struct { mu sync.RWMutex m map[string]muxEntry es []muxEntry // slice of entries sorted from longest to shortest. hosts bool // whether any patterns contain hostnames } type muxEntry struct { h Handler pattern string } // NewServeMux allocates and returns a new ServeMux. func NewServeMux() *ServeMux { return new(ServeMux) } // DefaultServeMux is the default ServeMux used by Serve. var DefaultServeMux = &amp;defaultServeMux var defaultServeMux ServeMux 最开始在main()函数中调用http.HandleFunc(&quot;/&quot;, sayHelloName)时，就注册了请求/的路由规则： func main() { http.HandleFunc(&quot;/&quot;, sayHelloName) // 设置访问的路由 log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil)) // 设置监听的端口 } // HandleFunc registers the handler function for the given pattern // in the DefaultServeMux. // The documentation for ServeMux explains how patterns are matched. func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 这样一来当请求的 URI 为/时，路由就会跳转到/对应的Handler，也就是sayHelloName()本身，最后把结果写入 Response 并反馈给客户端。 4.6 HTTP 连接的处理流程一个 HTTP 连接的处理流程示意图如下： 5. Go 的 http 包详解 参见 3.4 Go 的 http 包详解 - build-web-application-with-golang | Github Go 的http包有两个核心功能：Conn、ServeMux。 5.1 Conn 的 goroutine与其他一些语言编写的 HTTP 服务器不同，Go 为了实现高并发和高性能，使用了goroutine来处理Conn的读写事件，这样每个请求都能保持独立，相互不会阻塞，可以高效的响应网络事件，这是 Go 高效的保证。 Go 在等待客户端请求的Serve()函数里是这样写的： func (srv *Server) Serve(l net.Listener) error { // 省略部分代码 for { rw, e := l.Accept() // 省略错误处理 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) } } 可以看到客户端的每次请求都会创建一个Conn，函数newConn()在server.go中的实现如下： // Create new connection from rwc. func (srv *Server) newConn(rwc net.Conn) *conn { c := &amp;conn{ server: srv, rwc: rwc, } if debugServerConnections { c.rwc = newLoggingConn(&quot;server&quot;, c.rwc) } return c } 可以看到Conn实际上在net包中定义，是一个接口类型，在net.go中的定义如下： // Conn is a generic stream-oriented network connection. // // Multiple goroutines may invoke methods on a Conn simultaneously. type Conn interface { Read(b []byte) (n int, err error) Write(b []byte) (n int, err error) Close() error LocalAddr() Addr RemoteAddr() Addr SetDeadline(t time.Time) error SetReadDeadline(t time.Time) error SetWriteDeadline(t time.Time) error } 客户端的每次请求都会创建一个Conn，这个Conn里面保存了该次请求的信息，然后再传递到对应的handler，该handler中便可以读取到相应的 Header 信息，这样就保证了每个请求的独立性 5.2 ServeMux 的自定义之前调用http.ListenAndServe(&quot;:8080&quot;, nil)时，实际上内部时调用了http包默认的路由器DefaultServeMux，通过路由器把本次请求的信息传递到了后端的处理函数，它是一个ServeMux类型的变量： // DefaultServeMux is the default ServeMux used by Serve. var DefaultServeMux = &amp;defaultServeMux var defaultServeMux ServeMux 结构体ServeMux就是 Go 中的路由器，它在server.go中的定义如下： type ServeMux struct { // 锁，由于请求涉及到并发处理，因此这里需要一个锁机制 mu sync.RWMutex // 路由规则，一个路由表达式 string 对应一个 muxEntry 实体 m map[string]muxEntry es []muxEntry // slice of entries sorted from longest to shortest. // 是否在任意的规则中带有 host 信息 hosts bool // whether any patterns contain hostnames } type muxEntry struct { h Handler // 路由表达式对应哪个 handler pattern string // 路径匹配字符串 } type Handler interface { ServeHTTP(ResponseWriter, *Request) // 路由实现器 } Handler是一个接口，但是之前示例代码中的sayHelloName()函数并没有实现ServeHTTP()这个方法，为什么能作为 Handler 添加到路由器中呢？ 这是因为在http包中还定义了一个类型HandlerFunc，回顾一下之前设置访问路由的语句： http.HandleFunc(&quot;/&quot;, sayHelloName) 这里我们调用了HandleFunc()将sayHelloName()设置为&quot;/&quot;路由对应的Handler，而HandleFunc()实际进行的操作如下： // HandleFunc registers the handler function for the given pattern. func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(&quot;http: nil handler&quot;) } mux.Handle(pattern, HandlerFunc(handler)) } 可以看到这里将handler转换为了HandlerFunc，而它默认实现了ServeHTTP()方法，即我们调用了HandlerFunc(f)，将f强制类型转换为HandlerFunc类型，这样f就拥有了ServeHTTP()方法： 这也是适配器模式在 Go 中的应用 // The HandlerFunc type is an adapter to allow the use of // ordinary functions as HTTP handlers. If f is a function // with the appropriate signature, HandlerFunc(f) is a // Handler that calls f. type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 路由器里存储好了相应的路由规则，那么具体的请求又是怎样分发的呢？实际上，默认的路由器ServeMux实现了ServeHTTP()方法： // ServeHTTP dispatches the request to the handler whose // pattern most closely matches the request URL. func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == &quot;*&quot; { if r.ProtoAtLeast(1, 1) { w.Header().Set(&quot;Connection&quot;, &quot;close&quot;) } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r) } 如上所示，路由器接收到请求之后，如果是*则关闭连接，否则会调用mux.Handler(r)返回对应设置路由的处理 handler，然后执行h.ServeHTTP(w, r)，也就是调用对应路由的 handler 的ServeHTTP接口。 继续来看mux.Handler(r)是如何处理的： func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // CONNECT requests are not canonicalized. if r.Method == &quot;CONNECT&quot; { // If r.URL.Path is /tree and its handler is not registered, // the /tree -&gt; /tree/ redirect applies to CONNECT requests // but the path canonicalization does not. if u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } return mux.handler(r.Host, r.URL.Path) } // 省略部分代码 return mux.handler(host, r.URL.Path) } // handler is the main implementation of Handler. // The path is known to be in canonical form, except for CONNECT methods. func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), &quot;&quot; } return } 可以看到在mux.handler()中是调用mux.match()进行匹配的，函数定义如下： // Find a handler on a handler map given a path string. // Most-specific (longest) pattern wins. func (mux *ServeMux) match(path string) (h Handler, pattern string) { // Check for exact match first. v, ok := mux.m[path] if ok { return v.h, v.pattern } // Check for longest valid match. mux.es contains all patterns // that end in / sorted from longest to shortest. for _, e := range mux.es { if strings.HasPrefix(path, e.pattern) { return e.h, e.pattern } } return nil, &quot;&quot; } 这样一来就清楚了，在match()方法中，会根据mux.m[path]获取请求路径对应的muxEntry，返回muxEntry中保存的Handler以及pattern字符串，最后调用Handler的ServeHTTP()方法就可以执行相应的函数了。 5.3 外部实现自定义路由通过上面的介绍，我们大致了解了 Go 的整个路由过程。除了默认路由器DefaultServeMux，Go 同时也支持外部实现的路由器。 http.ListenAndServe()方法的第二个参数就是用来配置外部路由器的，它是一个Handler接口，即外部路由器只要实现了Handler接口的ServeHTTP()方法，就可以在自己实现的路由器的ServeHTTP()中实现自定义路由功能。 如下所示，实现一个简单的外部路由器MyMux： package main import ( &quot;fmt&quot; &quot;net/http&quot; ) type MyMux struct { } func (p *MyMux) ServeHTTP(w http.ResponseWriter, r *http.Request) { if r.URL.Path == &quot;/&quot; { sayHelloName(w, r) return } http.NotFound(w, r) return } func sayHelloName(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, &quot;Hello My Router!&quot;) } func main() { mux := &amp;MyMux{} http.ListenAndServe(&quot;:8080&quot;, mux) } 请求报文： GET http://localhost:8080 HTTP/1.1 响应报文： HTTP/1.1 200 OK Date: Tue, 03 Sep 2019 02:57:42 GMT Content-Length: 16 Content-Type: text/plain; charset=utf-8 Connection: close Hello My Router! 5.4 Go 代码的执行流程 Go Version: 1.12.6 分析完http包后，现在梳理一下代码的执行过程。例如下面这段代码： package main import ( &quot;fmt&quot; &quot;net/http&quot; ) func index(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, &quot;Hello %s!\\n&quot;, r.URL.Path[1:]) } func main() { http.HandleFunc(&quot;/&quot;, index) http.ListenAndServe(&quot;:8080&quot;, nil) } 首先调用http.HandleFunc()： http.HandleFunc(&quot;/&quot;, index) └─ DefaultServeMux.HandleFunc(pattern, handler) // 若 handler 为 nil，则触发 panic └─ mux.Handle(pattern, HandlerFunc(handler)) // 注册路由 调用DefaultServeMux.HandleFunc() 调用DefaultServeMux.Handle()，注册请求路径所对应的 handler 在DefaultServeMux的map[string]muxEntry中增加对应的 handler 和路由规则 之后调用http.ListenAndServe(&quot;:8080&quot;, nil)： http.ListenAndServe(&quot;:8080&quot;, nil) ├─ server := &amp;Server{Addr: addr, Handler: handler} └─ server.ListenAndServe() ├─ net.Listen(&quot;tcp&quot;, addr) └─ srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)}) ├─ l.Accept() ├─ c := srv.newConn(rw) └─ go c.serve(ctx) ├─ w, err := c.readRequest(ctx) └─ serverHandler{c.server}.ServeHTTP(w, w.req) ├─ handler := sh.srv.Handler // nil 则为 DefaultServeMux └─ handler.ServeHTTP(rw, req) ├─ h, _ := mux.Handler(r) └─ h.ServeHTTP(w, r) 实例化Server 调用server.ListenAndServe() 调用net.Listen(&quot;tcp&quot;, addr)监听端口，即Listen 调用srv.Serve()处理请求，即Serve 在Serve()中启动一个 for 循环，在循环中调用Accept()接收请求 为每个请求实例化一个Conn，开启一个 goroutine 并调用go c.serve(ctx)，为这个请求进行服务 调用c.readRequest(ctx)读取每个请求内容 判断 handler 是否为空，如果为nil则设为DefaultServeMux 调用handler.ServeHTTP(rw, req)，上面的例子中就进入到DefaultServeMux.ServeHTTP(rw, req) 根据 Request 选择 handler，并进入到这个 handler 的ServeHTTP()中 选择 handler： 循环遍历ServeMux的muxEntry，判断是否有路由能满足这个 Request 如果有路由满足，则调用这个路由 handler 的ServeHTTP() 如果没有路由满足，则调用NotFoundHandler的ServeHTTP() 6. 表单6.1 处理表单的输入例如下面的表单login.gtpl： &lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt; 用户名:&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt; 密码:&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;登录&quot;&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 处理表单： package main import ( &quot;fmt&quot; &quot;html/template&quot; &quot;log&quot; &quot;net/http&quot; &quot;strings&quot; ) func sayHelloName(w http.ResponseWriter, r *http.Request) { r.ParseForm() // 解析 URL 传递的参数，对于 POST 则解析 Request Body // 注意：如果没有调用 ParseForm 方法，下面无法获取表单的数据 log.Println(&quot;Inside sayHelloName&quot;) fmt.Printf(&quot;Form:\\t%v\\n&quot;, r.Form) fmt.Printf(&quot;path:\\t%s\\n&quot;, r.URL.Path) fmt.Printf(&quot;scheme:\\t%s\\n&quot;, r.URL.Scheme) fmt.Println(r.Form[&quot;url_long&quot;]) for k, v := range r.Form { fmt.Println(&quot;key:&quot;, k) fmt.Println(&quot;val:&quot;, strings.Join(v, &quot;&quot;)) } fmt.Fprintf(w, &quot;Hello abel!\\n&quot;) } func login(w http.ResponseWriter, r *http.Request) { fmt.Println(&quot;method:&quot;, r.Method) // 获取请求的方法 if r.Method == &quot;GET&quot; { t, _ := template.ParseFiles(&quot;login.gtpl&quot;) log.Println(t.Execute(w, nil)) } else { // 请求的是登录数据，那么执行登录的逻辑判断 r.ParseForm() fmt.Println(&quot;username:&quot;, r.Form[&quot;username&quot;]) fmt.Println(&quot;password:&quot;, r.Form[&quot;password&quot;]) } } func main() { http.HandleFunc(&quot;/&quot;, sayHelloName) http.HandleFunc(&quot;/login&quot;, login) log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil)) } request.Form是一个url.Values类型，里面存储了key=value的信息： package main import ( &quot;fmt&quot; &quot;net/url&quot; ) func main() { v := url.Values{} v.Set(&quot;name&quot;, &quot;abel&quot;) v.Add(&quot;friend&quot;, &quot;arjen&quot;) v.Add(&quot;friend&quot;, &quot;frank&quot;) fmt.Println(v.Encode()) fmt.Println(v.Get(&quot;name&quot;)) fmt.Println(v.Get(&quot;friend&quot;)) fmt.Println(v[&quot;friend&quot;]) } ------ friend=arjen&amp;friend=frank&amp;name=abel abel arjen [arjen frank] 7. 访问数据库8. Session 和数据存储9. 文本文件处理9.1 XML 处理参考资料文章教程 Go Web Programming - sausheong | Github 08.3. REST - Go Web 编程 | Learnku httprouter - julienschmidt | Github build-web-application-with-golang - astaxie | Github Golang: Building a Basic Web Server in Go | Ruan Bekker’s Blog project-layout - Standard Go Project Layout | Github Go Developer Roadmap - Go 开发者路线图 | Github 明白了，原来 Go Web 框架中的中间件都是这样实现的 | 鸟窝 Go 语言的修饰器编程 | 酷壳 CoolShell 教程：使用 go 的 gin 和 gorm 框架来构建 RESTful API 微服务 | LearnKu Build RESTful API service in golang using gin-gonic framework | Medium RESTful RESTful API 设计指南 | 阮一峰 RESTful API 最佳实践 | 阮一峰 RESTful API 规范 | RyuGou 如何给老婆解释什么是Restful | Java3y 对比 RESTful 与 SOAP，深入理解 RESTful | 紫川秀的博客 RESTful API 设计规范 | 紫川秀的博客 如何使用 swagger 设计出漂亮的 RESTful API | 紫川秀的博客 Go 学习笔记 (六) - 使用 swaggo 自动生成 Restful API 文档 | Razeen’s Blog Mock API RAP2 - Smart API manage tool RPC 我们如何在 Go 中使用 gRPC 构建 C/S 结构系统 | lday 数据加密 密码学简介与 Golang 的加密库 Crypto 的使用 | 紫川秀的博客 加密和解密数据 - Go Web 编程 | LearnKu 常见的加密算法 | Go 语言中文网 Golang 常用加密解密算法总结 (AES、DES、RSA、Sha1MD5) | CSDN Go Web 框架 6 款最棒的 Go 语言 Web 框架简介 | Go 语言中文网 Vue + Element vue-element-admin | A magical vue admin vue-element-admin - PanJiaChen | Github electron-vue-admin - PanJiaChen | Github vue-admin-template - PanJiaChen | Github element - A Vue.js 2.0 UI Toolkit for Web | Github element-starter - ElementUI | Github Element 开发指南 Go + Vue Go + Vue.js 开发 Web 应用 | 起风了 使用 Golang 的 Gin 框架和 vue 编写 web 应用 | Go 语言中文网 Go Vue Template - tdewolff | Github GoNews - 基于 go+vue 实现的 golang 每日新闻可视化浏览检索平台 | Github go-vue-example - Example App using Go, Vue.js, Element, Axios | Github Electron go-astilelectron - Build cross platform GUI apps with GO and HTML/JS/CSS (powered by Electron) | Github Koa Koa - 基于 Node.js 平台的下一代 web 开发框架 Koa2 进阶学习笔记 | Gitbook Koa 框架教程 | 阮一峰 Express Express | Fast, unopinionated, minimalist web framework for Node.js 其他 「分分钟上手 VS Code」打造 Go 开发环境 | 艾逗笔 连载文章 | 团子的小窝 Creating a native macOS app on Golang and React.js with full code protection | TrueWebArtisans 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Web 开发","slug":"Web-开发","permalink":"https://abelsu7.top/tags/Web-开发/"}]},{"title":"Kernel 2.6.32 中的 KVM API 概述","slug":"kvm-api-overview","date":"2019-08-11T07:26:48.000Z","updated":"2019-09-01T13:04:11.422Z","comments":true,"path":"2019/08/11/kvm-api-overview/","link":"","permalink":"https://abelsu7.top/2019/08/11/kvm-api-overview/","excerpt":"KVM API 概述，基于 Kernel 2.6.32","text":"KVM API 概述，基于 Kernel 2.6.32 目录 目录 1. 字符设备 /dev/kvm 2. KVM API 功能分类 3. KVM API 操作流程 4. KVM API 概览 4.1 System ioctl 4.2 VM ioctl 4.3 vCPU ioctl 5. API 简单使用示例 参考文章 1. 字符设备 /dev/kvmKVM 的 API 是通过/dev/kvm这个字符设备进行访问的： &gt; ls /dev/kvm -l crw-rw---- 1 root root 10, 232 Jul 29 16:24 /dev/kvm /dev/kvm作为 Linux 的一个标准字符型设备，可以使用常见的系统调用如open()、close()、ioctl()等指令进行操作。不过在 KVM 字符型设备的实现函数中，并没有包含write()、read()等操作，因此所有对 KVM 的操作都是通过ioctl()发送相应的控制字实现的。 内核源码中的Documentation/kvm/api.txt是 KVM API 的说明文档，可以点击 这里 查看 2. KVM API 功能分类根据 API 所提供的功能，又可将其分为以下三类： System ioctl：系统指令，针对 KVM 的全局性参数设置，例如通过KVM_CREATE_VM创建虚拟机 VM ioctl：虚拟机指令，针对指定的 VM 进行控制，例如创建 vCPU、设置虚拟机内存。需要在创建 VM 的进程中调用 VM 指令，以确保进程安全 vCPU ioctl：vCPU 指令，针对指定的 vCPU 进行参数设置，例如寄存器读写、中断控制。需要在创建 vCPU 的线程中调用 vCPU 指令，以确保线程安全 3. KVM API 操作流程通常情况下，对于 KVM API 的操作是从打开/dev/kvm设备文件开始的： 使用open系统调用打开/dev/kvm设备文件后，会获得一个文件描述符fd，然后再通过ioctl发送相应的控制字进行之后的操作 调用KVM_CREATE_VM指令将创建一个虚拟机并返回该虚拟机对应的fd。然后再根据返回的fd对该虚拟机进行控制 调用KVM_CREATE_VCPU指令将创建一个 vCPU，并返回该 vCPU 对应的fd 循环调用KVM_RUN，运行 vCPU，启动虚拟机 需要注意的是，通过fork()调用创建的子进程将继承父进程的文件描述符fd，从而实现多进程访问。而在 KVM API 的内部实现中，并没有针对这种情况进行保护。因此api.txt文档也有提示：VM 指令需要在创建该 VM 的进程中调用，vCPU 指令也需要在创建 vCPU 的线程中调用。 上述流程的伪代码示例如下所示： open(&quot;/dev/kvm&quot;) ioctl(KVM_CREATE_VM) // 创建 VM ioctl(KVM_CREATE_VCPU) // 为 VM 创建 vCPU for (;;) { ioctl(KVM_RUN) // 运行 vCPU，启动 VM switch (exit_reason) { // 捕捉 VM-EXIT 原因进行处理 case KVM_EXIT_IO: /* ... */ case KVM_EXIT_HLT: /* ... */ } } 4. KVM API 概览4.1 System ioctlSystem ioctls 用于控制 KVM 全局的运行环境及参数设置，例如创建虚拟机、检查扩展支持。 通过kvm_main.c中的kvm_dev_ioctl()进行处理，与架构相关的指令（例如 x86）则通过x86.c中的kvm_arch_dev_ioctl()进行处理。 主要指令字如下所示： 指令字 功能说明 返回值 KVM_GET_API_VERSION 查询当前 KVM API 版本 当前版本为 12 KVM_CREATE_VM 创建 KVM 虚拟机 返回创建的 KVM 虚拟机 fd KVM_GET_MSR_INDEX_LIST 获得 MSR 索引列表 返回 kvm_msr_list 类型的链表 msr_list KVM_CHECK_EXTENSION 检查扩展支持情况 返回 0 则不支持，非 0 则支持 KVM_GET_VCPU_MMAP_SIZE 返回ioctl(KVM_RUN)与用户空间共享内存区域大小 mmap 区域大小，单位 bytes 其中最重要的是KVM_CREATE_VM。通过该指令字，KVM 将返回一个文件描述符fd，指向内核空间中新创建的 KVM 虚拟机。 4.2 VM ioctlVM ioctl 用于对虚拟机进行控制，例如内存、vCPU、中断、时钟。 通过kvm_main.c中的kvm_vm_ioctl()进行处理，与架构相关的指令（例如 x86）则通过x86.c中的kvm_arch_vm_ioctl()进行处理。 主要指令字如下所示： 指令字 功能说明 返回值 KVM_CREATE_VCPU 为已经创建好的 VM 添加 vCPU 成功则返回 vCPU fd，失败 -1 KVM_SET_MEMORY_REGION 添加或修改 VM 的内存 成功 0，失败 -1 KVM_SET_USER_MEMORY_REGION api.txt中推荐替代KVM_SET_MEMORY_REGION的新 API 成功 0，失败为负 KVM_GET_DIRTY_LOG 返回上次调用后给定 memory slot 的脏页位图 成功 0，失败 -1 KVM_SET_MEMORY_ALIAS 定义kvm_memory_alias 成功 0，失败 -1 KVM_CREATE_IRQCHIP 创建一个虚拟的 APIC，并且之后创建的 vCPU 都将连接到该 APIC 成功 0，失败 -1 KVM_IRQ_LINE 对给定的虚拟 APIC 触发中断信号 成功 0，失败 -1 KVM_GET_IRQCHIP 读取 APIC 的中断标志信息 成功 0，失败 -1 KVM_SET_IRQCHIP 设置 APIC 的中断标志信息 成功 0，失败 -1 KVM_GET_CLOCK 读取当前 VM kvmclock 中的 timestamp 成功 0，失败 -1 KVM_SET_CLOCK 设置当前 VM kvmclock 中的 timestamp 成功 0，失败 -1 VM ioctl 需要借助通过KVM_CREATE_VM返回的 VM fd 进行操作，例如KVM_CREATE_VCPU： static long kvm_vm_ioctl(struct file *filp, unsigned int ioctl, unsigned long arg) { struct kvm *kvm = filp-&gt;private_data; // VM 对应的 kvm 结构体 void __user *argp = (void __user *)arg; // ioctl 入参 int r; if (kvm-&gt;mm != current-&gt;mm) return -EIO; switch (ioctl) { case KVM_CREATE_VCPU: r = kvm_vm_ioctl_create_vcpu(kvm, arg); // 需要借助 kvm 创建 vCPU if (r &lt; 0) goto out; break; /* ... */ } out: return r; } 4.3 vCPU ioctlvCPU ioctl 用于对具体的 vCPU 进行配置，例如执行 vCPU 指令，设置寄存器、中断等。 通过kvm_main.c中的kvm_vcpu_ioctl()进行处理，与架构相关的指令（例如 x86）则通过x86.c中的kvm_arch_vcpu_ioctl()进行处理。 主要指令字如下所示： 指令字 功能说明 返回值 KVM_RUN 运行 vCPU 成功 0，失败 -1 KVM_GET_REGS 获取通用寄存器信息 成功 0，失败 -1 KVM_SET_REGS 设置通用寄存器信息 成功 0，失败 -1 KVM_GET_SREGS 获取特殊寄存器信息 成功 0，失败 -1 KVM_SET_SREGS 设置特殊寄存器信息 成功 0，失败 -1 KVM_TRANSLATE 将 GVA 翻译为 GPA 成功 0，失败 -1 KVM_INTERRUPT 通过插入一个中断向量，在 vCPU 上产生中断（当 APIC 无效时） 成功 0，失败 -1 KVM_DEBUG_GUEST 开启 Guest OS 的调试模式 成功 0，失败 -1 KVM_GET_MSRS 获取 MSR 寄存器信息 成功 0，失败 -1 KVM_SET_MSRS 设置 MSR 寄存器信息 成功 0，失败 -1 KVM_SET_CPUID 设置 vCPU 的 CPUID 信息 成功 0，失败 -1 KVM_SET_SIGNAL_MASK 设置 vCPU 的中断信号屏蔽 成功 0，失败 -1 KVM_GET_FPU 获取浮点寄存器信息 成功 0，失败 -1 KVM_SET_FPU 设置浮点寄存器信息 成功 0，失败 -1 其中最重要的指令是KVM_RUN。在通过KVM_CREATE_CPU为虚拟机创建 vCPU，并取得 vCPU 对应的 fd 后，就可以调用KVM_RUN启动虚拟机： static long kvm_vcpu_ioctl(struct file *filp, unsigned int ioctl, unsigned long arg) { struct kvm_vcpu *vcpu = filp-&gt;private_data; void __user *argp = (void __user *)arg; int r; /* ... */ switch (ioctl) { case KVM_RUN: // 运行 vCPU r = -EINVAL; if (arg) goto out; r = kvm_arch_vcpu_ioctl_run(vcpu, vcpu-&gt;run); // 实际的执行函数 break; /* ... */ } out: kfree(fpu); kfree(kvm_sregs); return r; } 可以看到调用kvm_arch_vcpu_ioctl_run()时传递了两个参数：vcpu即为当前的 vCPU，而vcpu-&gt;run则指向一个kvm_run结构体（省略部分字段）： /* for KVM_RUN, returned by mmap(vcpu_fd, offset=0) */ struct kvm_run { /* in */ __u8 request_interrupt_window; __u8 padding1[7]; /* out */ __u32 exit_reason; __u8 ready_for_interrupt_injection; __u8 if_flag; __u8 padding2[2]; /* in (pre_kvm_run), out (post_kvm_run) */ __u64 cr8; __u64 apic_base; union { /* KVM_EXIT_UNKNOWN */ struct { __u64 hardware_exit_reason; } hw; /* KVM_EXIT_FAIL_ENTRY */ struct { __u64 hardware_entry_failure_reason; } fail_entry; /* KVM_EXIT_EXCEPTION */ struct { __u32 exception; __u32 error_code; } ex; /* KVM_EXIT_IO */ struct { #define KVM_EXIT_IO_IN 0 #define KVM_EXIT_IO_OUT 1 __u8 direction; __u8 size; /* bytes */ __u16 port; __u32 count; __u64 data_offset; /* relative to kvm_run start */ } io; struct { struct kvm_debug_exit_arch arch; } debug; /* KVM_EXIT_MMIO */ struct { __u64 phys_addr; __u8 data[8]; __u32 len; __u8 is_write; } mmio; /* ... */ }; }; kvm_run定义在include/linux/kvm.h中，通过读取该结构体可以了解 KVM 内部的运行状态，可以类比为计算机芯片中的寄存器组。 5. API 简单使用示例#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;sys/ioctl.h&gt; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #include &lt;linux/kvm.h&gt; #define KVM_FILE &quot;/dev/kvm&quot; int main() { int dev; int ret; dev = open(KVM_FILE, O_RDWR|O_NDELAY); ret = ioctl(dev, KVM_GET_API_VERSION, 0); printf(&quot;----KVM API version is %d----\\n&quot;, ret); ret = ioctl(dev, KVM_CHECK_EXTENSION, KVM_CAP_NR_VCPUS); printf(&quot;----KVM supports MAX_VCPUS per guest(VM) is %d----\\n&quot;, ret); ret = ioctl(dev, KVM_CHECK_EXTENSION, KVM_CAP_NR_MEMSLOTS); printf(&quot;----KVM supports MEMORY_SLOTS per guset(VM) is %d----\\n&quot;, ret); ret = ioctl(dev, KVM_CHECK_EXTENSION, KVM_CAP_IOMMU); if(ret != 0) printf(&quot;----KVM supports IOMMU (i.e. Intel VT-d or AMD IOMMU).----\\n&quot;); else printf(&quot;----KVM doesn&#39;t support IOMMU (i.e. Intel VT-d or AMD IOMMU).----\\n&quot;); return 0; } 编译运行： &gt; vim kvm-api-test.c &gt; gcc kvm-api-test.c -o kvm-api-test &gt; ./kvm-api-test ----KVM API version is 12---- ----KVM supports MAX_VCPUS per guest(VM) is 160---- ----KVM supports MEMORY_SLOTS per guset(VM) is 32---- ----KVM doesn&#39;t support IOMMU (i.e. Intel VT-d or AMD IOMMU).---- 参考文章 Documentation/kvm/api.txt | Kernel 2.6.32.35 KVM 源代码分析 2：虚拟机的创建与运行 | OenHan KVM 源代码分析 3：CPU 虚拟化 | OenHan KVM API 使用实例 - 任永杰 | 笑遍世界 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块QEMU 1.2.0 入口 main() 函数调用流程分析迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"内核","slug":"内核","permalink":"https://abelsu7.top/tags/内核/"}]},{"title":"QEMU 1.2.0 入口 main() 函数调用流程分析","slug":"qemu-main-func","date":"2019-08-11T07:10:31.000Z","updated":"2019-09-01T13:04:11.618Z","comments":true,"path":"2019/08/11/qemu-main-func/","link":"","permalink":"https://abelsu7.top/2019/08/11/qemu-main-func/","excerpt":"QEMU 源码vl.c中的main()函数调用流程分析，基于1.2.0版本","text":"QEMU 源码vl.c中的main()函数调用流程分析，基于1.2.0版本 目录 目录 1. main() 函数的关键点 2. main() 函数调用流程图 3. pstack 打印堆栈 1. main() 函数的关键点KVM 虚拟化由用户空间的 QEMU 和内核中的 KVM 模块配合完成，QEMU 通过ioctl()向/dev/kvm发送指令字，对虚拟机进行操作。配合流程如下： QEMU 的入口main()函数位于vl.c中，重点关注以下几点： 何处创建 KVM 虚拟机并获取 fd？ 虚拟机 CPU、内存在何处进行初始化？ vCPU 子线程在何处创建，如何运行？ 热迁移的 handlers 在何处注册？ 主线程如何监听事件？ 2. main() 函数调用流程图在以上几点做了详细的调用流程展开，其他函数不再深入，部分函数省略，整个main()函数的处理逻辑如下图所示： int main() ├─ atexit(qemu_run_exit_notifiers) // 注册 QEMU 的退出处理函数 ├─ module_call_init(MODULE_INIT_QOM) // 初始化 QOM ├─ runstate_init() ├─ init_clocks() // 初始化时钟源 ├─ module_call_init(MODULE_INIT_MACHINE) ├─ switch(popt-&gt;index) case QEMU_OPTION_XXX // 解析 QEMU 参数 ├─ socket_init() ├─ os_daemonize() ├─ configure_accelerator() // 启用 KVM 加速支持 | └─ kvm_init() // 【1】创建 KVM 虚拟机并获取对应的 fd | ├─ kvm_ioctl(KVM_GET_API_VERSION) // 检查 KVM API 版本 | ├─ kvm_ioctl(KVM_CREATE_VM) // 创建虚拟机，并获取 vmfd | ├─ kvm_arch_init() | └─ memory_listener_register(&amp;kvm_memory_listener) // 注册 kvm_memory_listener | ├─ qemu_init_cpu_loop() // 初始化 vCPU 线程竞争的锁 ├─ qemu_init_main_loop() | └─ main_loop_init() | ├─ qemu_spice_init() // 初始化 SPICE ├─ cpu_exec_init_all() // 【2】初始化虚拟机的地址空间，主要是 QEMU 侧的内存布局 | ├─ memory_map_init() // 初始化 MemoryRegion 及其对应的 FlatView | | ├─ memory_region_init() // 初始化 system_memory/io 这两个全局 MemoryRegion | | ├─ set_system_memory_map() // address_space_memory-&gt;root = system_memory | | | └─ memory_region_update_topology() // 为 MemoryRegion 生成 FlatView | | | └─ address_space_update_topology() // as-&gt;current_map = new_view | | | ├─ generate_memory_topology() // 将 MemoryRegion 的拓扑结构渲染为 FlatRange 数组 | | | | ├─ flatview_init(&amp;view) | | | | ├─ render_memory_region(&amp;view, mr, ...) // 根据 mr 生成 view | | | | └─ flatview_simplify(&amp;view) // 合并相邻的 FlatRange | | | | | | | ├─ address_space_update_topology_pass() | | | | └─ kvm_region_add() // region_add 对应的回调实现 | | | | └─ kvm_set_phys_mem() // 根据传入的 section 填充 KVMSlot | | | | └─ kvm_set_user_memory_region() // 将 QEMU 侧的内存布局注册到 KVM 中 | | | | └─ kvm_ioctl(KVM_SET_USER_MEMORY_REGION) | | | | | | | └─ address_space_update_ioeventfds() | | | | | └─ memory_listener_register() // 注册 core_memory_listener、io_memory_listener | | └─ listener_add_address_space() | | | └─ io_mem_init() // 初始化 I/O MemoryRegion | └─ memory_region_init_io() // ram/rom/unassigned/notdirty/subpage-ram/watch | └─ memory_region_init() | ├─ bdrv_init_with_whitelist() ├─ blk_mig_init() | └─ register_savevm_live(&quot;block&quot;, &amp;savevm_block_handlers, ...) // 注册块设备热迁移的处理函数 | ├─ register_savevm_live(&quot;ram&quot;, &amp;savevm_ram_handlers, ...) // 注册内存热迁移的处理函数 ├─ select_vgahw(vga_model) // 选择 VGA 显卡设备，std/cirrus/vmware/xenfb/qxl/none ├─ select_watchdog(watchdog) ├─ qdev_machine_init() ├─ machine-&gt;init() // QEMU 1.2.0 默认的 QEMUMachine 为 pc_machine_v1_2 | └─ pc_init_pci() | └─ pc_init1() | ├─ pc_cpus_init(cpu_model) // 【3】CPU 初始化，根据 smp_cpus 参数创建对应数量的 vCPU 子线程 | | └─ pc_new_cpu(cpu_model) | | └─ cpu_x86_init(cpu_model) | | └─ x86_cpu_realize() | | └─ qemu_init_vcpu() | | └─ qemu_kvm_start_vcpu() | | └─ qemu_thread_create() // 顺序创建 vCPU 子线程，失败会阻塞 | | └─ qemu_kvm_cpu_thread_fn() | | ├─ kvm_init_vcpu() | | | ├─ kvm_ioctl(KVM_CREATE_VCPU) // 获取 vCPU 对应的 fd | | | └─ kvm_arch_init_vcpu() | | | | | ├─ qemu_kvm_init_cpu_signals() | | ├─ kvm_cpu_exec() | | | └─ kvm_vcpu_ioctl(KVM_RUN) // 运行 vCPU | | | └─ kvm_arch_vcpu_ioctl_run() // 进入内核，由 KVM 处理 | | | └─ __vcpu_run() | | | └─ vcpu_enter_guest() | | | └─ kvm_mmu_reload() | | | └─ kvm_mmu_load() // spin_lock(&amp;vcpu-&gt;kvm-&gt;mmu_lock) | | | | | └─ qemu_kvm_wait_io_event() | | | ├─ kvmclock_create() | ├─ pc_memory_init() // 【4】内存初始化，从 QEMU 进程的地址空间中进行实际的内存分配 | | ├─ memory_region_init_ram() // 创建 pc.ram, pc.rom 并分配内存 | | | ├─ memory_region_init() | | | └─ qemu_ram_alloc() | | | └─ qemu_ram_alloc_from_ptr() | | | | | ├─ vmstate_register_ram_global() // 将 MR 的 name 写入 RAMBlock 的 idstr | | | └─ vmstate_register_ram() | | | └─ qemu_ram_set_idstr() | | | | | ├─ memory_region_init_alias() // 初始化 ram_below_4g, ram_above_4g | | └─ memory_region_add_subregion() // 在 system_memory 中添加 subregions | | └─ memory_region_add_subregion_common() | | └─ memory_region_update_topology() // 为 MemoryRegion 生成 FlatView | | └─ address_space_update_topology() // as-&gt;current_map = new_view | | ├─ generate_memory_topology() // 将 MemoryRegion 的拓扑结构渲染为 FlatRange 数组 | | | ├─ flatview_init(&amp;view) | | | ├─ render_memory_region(&amp;view, mr, ...) // 根据 mr 生成 view | | | └─ flatview_simplify(&amp;view) // 合并相邻的 FlatRange | | | | | ├─ address_space_update_topology_pass() | | | └─ kvm_region_add() // region_add 对应的回调实现 | | | └─ kvm_set_phys_mem() // 根据传入的 section 填充 KVMSlot | | | └─ kvm_set_user_memory_region() // 将 QEMU 侧的内存布局注册到 KVM 中 | | | └─ kvm_ioctl(KVM_SET_USER_MEMORY_REGION) | | | | | └─ address_space_update_ioeventfds() | | | ├─ i440fx_init() | ├─ ioapic_init(gsi_state) | ├─ pc_vga_init() | ├─ pc_basic_device_init() | ├─ pci_piix3_ide_init() | ├─ audio_init() | ├─ pc_cmos_init() | └─ pc_pci_device_init() | ├─ cpu_synchronize_all_post_init() ├─ set_numa_modes() // 设置 NUMA ├─ vnc_display_init() // 初始化 VNC ├─ qemu_spice_display_init() ├─ qemu_run_machine_init_done_notifiers() ├─ os_setup_post() ├─ resume_all_vcpus() ├─ main_loop() // 【5】主线程开启循环，监听事件 | └─ main_loop_wait() | └─ os_host_main_loop_wait() | └─ select() | ├─ bdrv_close_all() ├─ pause_all_vcpus() ├─ net_cleanup() └─ res_free() 大致流程如下图所示（图源自网络），对应 VMX 模式下 root 和 non-root 模式的概念： 左边蓝色部分即为根模式下的 Ring 3，即为用户空间中的 QEMU，通过循环调用ioctl(KVM_RUN)进入内核运行 vCPU，并处理 I/O 请求 中间橙色部分即为根模式下的 Ring 0，即为内核空间中的 KVM，通过VM-Entry进入非根模式，运行 Guest OS，并处理VM-Exit。如果能在内核处理，则处理后再次通过VM-Entry进入 Guest OS；如果不能处理（例如 I/O 请求），则退出到用户空间，由 QEMU 进行处理 右边紫色部分即为非根模式，Guest OS 运行在非根模式下的 Ring 0，所有的敏感指令都被重新定义，以便产生相应的 EXIT_REASON 交给 KVM 处理。Guest OS 中的进程则运行在非根模式下的 Ring 3 3. pstack 打印堆栈通过virsh启动一台 32 核 CPU 的虚拟机，使用pstack打印堆栈验证一下： &gt; pstack $(pidof qemu-system-x86_64) ...(省略重复的堆栈) Thread 6 (Thread 0x7fdcd4dfa700 (LWP 37340)): #0 0x00007fdd46002307 in ioctl () from /lib64/libc.so.6 #1 0x00000000005e4bcb in kvm_vcpu_ioctl () #2 0x00000000005e57d8 in kvm_cpu_exec () #3 0x00000000005a2601 in qemu_kvm_cpu_thread_fn () #4 0x00007fdd462d8893 in start_thread () from /lib64/libpthread.so.0 #5 0x00007fdd46009bfd in clone () from /lib64/libc.so.6 Thread 5 (Thread 0x7fdcbbfff700 (LWP 37341)): #0 0x00007fdd46002307 in ioctl () from /lib64/libc.so.6 #1 0x00000000005e4bcb in kvm_vcpu_ioctl () #2 0x00000000005e57d8 in kvm_cpu_exec () #3 0x00000000005a2601 in qemu_kvm_cpu_thread_fn () #4 0x00007fdd462d8893 in start_thread () from /lib64/libpthread.so.0 #5 0x00007fdd46009bfd in clone () from /lib64/libc.so.6 Thread 4 (Thread 0x7fdcbb5fe700 (LWP 37342)): #0 0x00007fdd46002307 in ioctl () from /lib64/libc.so.6 #1 0x00000000005e4bcb in kvm_vcpu_ioctl () #2 0x00000000005e57d8 in kvm_cpu_exec () #3 0x00000000005a2601 in qemu_kvm_cpu_thread_fn () #4 0x00007fdd462d8893 in start_thread () from /lib64/libpthread.so.0 #5 0x00007fdd46009bfd in clone () from /lib64/libc.so.6 Thread 3 (Thread 0x7fdcbabfd700 (LWP 37343)): #0 0x00007fdd46002307 in ioctl () from /lib64/libc.so.6 #1 0x00000000005e4bcb in kvm_vcpu_ioctl () #2 0x00000000005e57d8 in kvm_cpu_exec () #3 0x00000000005a2601 in qemu_kvm_cpu_thread_fn () #4 0x00007fdd462d8893 in start_thread () from /lib64/libpthread.so.0 #5 0x00007fdd46009bfd in clone () from /lib64/libc.so.6 Thread 2 (Thread 0x7fc4a73fd700 (LWP 37451)): #0 0x00007fdd462dc115 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x0000000000568781 in qemu_cond_wait () #2 0x00000000005952c3 in vnc_worker_thread_loop () #3 0x0000000000595778 in vnc_worker_thread () #4 0x00007fdd462d8893 in start_thread () from /lib64/libpthread.so.0 #5 0x00007fdd46009bfd in clone () from /lib64/libc.so.6 Thread 1 (Thread 0x7fdd47cce700 (LWP 37247)): #0 0x00007fdd460029f3 in select () from /lib64/libc.so.6 #1 0x000000000053b325 in main_loop_wait () #2 0x0000000000536ef4 in main () 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"}]},{"title":"2020 届互联网秋季校园招聘汇总 (2019年秋)","slug":"2019-autumn-offer","date":"2019-07-28T08:20:48.000Z","updated":"2019-11-10T09:21:52.858Z","comments":true,"path":"2019/07/28/2019-autumn-offer/","link":"","permalink":"https://abelsu7.top/2019/07/28/2019-autumn-offer/","excerpt":"2019-09-22 更新","text":"2019-09-22 更新 笔试/面试日历 校园招聘笔试日历 | 牛客 校园招聘在线笔试排期 | 赛码 公司 日期 时间 平台 百度 9.17 (周二) 19:00-21:00 赛码 美团 9.18 (周三) 15:00-17:00 赛码 深信服 16:00-18:00 牛客 电信云 20:30-22:30 牛客 微众 9.19 (周四) 16:00-18:00 赛码 滴滴 19:00-20:40 赛码 腾讯 9.20 (周五) 20:00-22:00 牛客 华为 9.21 (周六) 13:00 面试 天河区酒店 字节跳动 9.22 (周日) 8:00-10:00 牛客 招银网络科技 9.24 (周二) 15:00-? 待定 电信云计算 9.25/26 (周三) 面试 待定 待投递 校招官网 微信 时间 平安科技 平安科技招聘 10.9 网申截止，Q&amp;A 京东 京东招聘 京东数科，Q&amp;A 数字广东 数字广东招聘 内推 1，内推 2 中国移动南方基地 广发银行研发中心 中国电信天翼物联 其他 运维与基础架构部招聘专题 | 网易游戏互娱校园招聘 网申投递指南：竞聘成功率提升30倍的秘籍找到啦！| 网易游戏互娱校园招聘 阿里云智能2020届毕业生招聘正式启动 | 阿里智能运维 字节跳动2020秋招进行中，大量研发笔试题流出 | 字节跳动招聘 【华为 Cloud BU】寻找顶尖学生-华工 | 石墨文档 『校招』大揭秘|这些岗位有大量的招聘需求！| 京东招聘 平安科技 2020 秋招内推 | 牛客 【哔哩哔哩】2020 届校招内推 | 牛客 小米内推 | 牛客 华为Cloud &amp; AI（Cloud BU）2020届校园招聘启动啦~ | CloudAI招聘 【美团内推】赶紧上车，老铁！| 牛客 金山云内推免笔试优先筛选不与网申冲突～技术产品运营大量hc | 牛客 金山云校招岗位 金山云 2020 校园招聘 | 51Job 拼多多校招正式批内推（最后一批 只可内推技术岗）| 牛客 平安科技2020年校招Q&amp;A，内推码：【PJN7MK】| 牛客 【陌陌内推】🔥免笔试直通面试！倒计时开始（回帖成功率更高）| 牛客 🚄有赞2020年校招内推开始了✈️程序员小哥哥帮你内推 | 牛客 已投递 校招官网 微信 时间 腾讯 腾讯招聘 9.15 简历截止 阿里 阿里技术栈 9.12 简历截止，Q&amp;A 字节跳动 字节跳动招聘 9.22 笔试，Q&amp;A 华为 华为招聘 已投递 百度 百度招聘 9.17 19:00 笔试，Q&amp;A 电信云计算 电信云计算校招内推 9.25/26 广州面试，牛客内推 网易游戏 网易游戏综合招聘 9.19 网申截止，Q&amp;A 网易游戏-互娱 网易游戏互娱校园招聘 9.19 内推截止 网易游戏-雷火 网易游戏雷火伏羲招聘 9.12 网申截止，Q&amp;A 滴滴 滴滴出行校园招聘 9.15 网申截止，Q&amp;A 美团点评 美团点评招聘 9.18 15:00 笔试，笔试攻略 深信服 深信服招聘 9.18 笔试，岗位描述 微众银行 WeBank招聘 9.18 网申截止，9.19 笔试 招银网络科技 招银网络科技 9.23 网申截止 已结束 校招官网 微信 时间 网易互联网 网易招聘 已结束 网易有道 有道招聘 9.17 网申截止，已结束 哔哩哔哩 哔哩哔哩招聘 已结束 DJI大疆 DJI大疆招聘 已结束 小米 小米招聘 9.11 笔试，笔试指南 顺丰科技 顺丰科技招聘 已结束 360 360招聘 已结束 笔试题/面经重点复习1. 排序算法常用排序算法复杂度及稳定性： 参见 十大经典排序算法动画与解析，看我就够了 | 五分钟学算法 关于时间复杂度： O(n^2)：各类简单排序，包括直接插入、直接选择、冒泡排序 O(nlogn)：快速排序、堆排序、归并排序 关于稳定性： 稳定的排序算法：冒泡、插入、归并、基数 不稳定的排序算法：选择、快速、希尔、堆 2. TCP 三握四挥TCP 三次握手、四次挥手： 参见： 网络协议笔记 4：传输层之 TCP 协议 | 苏易北 “三次握手，四次挥手”你真的懂吗？| 码农桃花源 TCP 的那些事儿（上）| 酷壳 CoolShell TCP 的那些事儿（下）| 酷壳 CoolShell “三次握手，四次挥手”你真的懂吗？| 码农桃花源 tcpdump 示例教程 | 鸟窝 感受一把面试官通过一道题目引出的关于 TCP 的 5 个连环炮！| 石杉的架构笔记 TCP 的那些事儿（上）| 酷壳 CoolShell TCP 的那些事儿（下）| 酷壳 CoolShell TCP 是什么？面试时必须知道吗？| Gitchat TCP 拥塞控制 | 简书 TCP 对往返时延 RTT 的定义 | 知乎 TCP | Woowen TCP 头格式 TCP 的包是没有 IP 地址的，那是 IP 层上的事。但是有源端口src_port和目标端口dst_port 一个 TCP 连接需要四个元组(src_ip, src_port, dst_ip, dst_port)来表示是同一个连接 Sequence Number：包的序号seq，用来解决网络包乱序 (reordering) 的问题 Acknowledgement Number：就是ACK，表示确认收到了包，用来解决丢包的问题 Window：又叫Advertised-Window，也就是著名的滑动窗口 (Sliding Window)，用于解决流量控制问题 TCP 状态机 TCP 三次握手与四次挥手 对于建立连接的三次挥手： 主要是初始化Sequence Number的值。通信的双方要互相通知对方自己的初始Sequence Number，缩写为ISN即Initial Sequence Number，所以叫SYN，全称Synchronize Sequence Numbers。这个号要作为以后数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输问题而乱序 (TCP 会用这个序号来拼接数据) 确保双方都能明确自己和对方的收、发能力是正常的 (TCP 连接是全双工的) 对于断开连接的四次挥手： 其实仔细看是两次，因为 TCP 是全双工的，所以发送方和接收方都需要FIN和ACK。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了，这时对方会返回一个ACK。此时一个方向的连接关闭，但是另一个方向仍然可以继续传输数据，等到发送完所有的数据后，会发送一个FIN来关闭此方向上的连接，最后由接收方发送ACK确认关闭连接 需要注意的是：接收到FIN报文的一方只能回复一个ACK，是无法马上返回给对方一个FIN报文段的，因为是否结束数据传输由上层的应用层控制 为什么关闭时需要四次挥手？ 当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文，其中ACK报文是用来应答的，SYN报文是用来同步的 但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭Socket 所以只能先回复一个ACK报文，告诉Client端，你发的FIN报文我收到了，等到我Server端所有的报文都发送完了，才能发送FIN报文 因此Server端的ACK和FIN不能一起发送，故需要四次挥手 为什么不能用两次握手进行连接？ 主要是为了防止已失效的连接请求报文段突然又传到了B，避免产生错误 现假定一种异常情况，即A发出的第一个连接请求报文段并没有丢失，而是在某些网络节点长时间滞留了，以致延误到连接释放后的某个时间才到达B。本来这是一个早已失效的报文段。但B受到此失效的连接请求报文段后，就误以为是A又发出一次新的连接请求，于是就向A发出确认报文段，同意建立连接。假定不采用第三次报文握手，那么只要B发出确认，新的连接就建立了 由于现在A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据，但B却以为新的运输连接已经建立了，并一直等待A发来的数据。B的许多资源就这样白白浪费了 采用三次握手连接，可以防止上述现象的发生。例如在刚才的异常情况下，A不会向B的确认发出确认，B由于收不到确认，就知道A并没有要求建立连接，于是B就不会再建立连接 为什么 TIME_WAIT 状态需要 2MSL？ 保证Client发送的最后一个ACK报文段能够到达Server：Server如果没有收到ACK，将不断重复发送FIN，所以Client不能立即关闭，它必须确认Server接收到了该ACK 防止已失效连接的请求报文段出现在本次连接中：A在发送完最后一个ACK报文段后，再经过2MSL时间，就可以使本连接持续时间内所产生的所有报文段都从网络中消失，这样就可以使下一个新的连接中不会出现旧连接中的请求报文段 3. I/O 多路复用I/O 多路复用：select、poll、epoll： 参见 聊聊 IO 多路复用之 select、poll、epoll 详解 | 简书 聊聊 IO 多路复用之 select、poll、epoll 详解 | 简书 聊聊 Linux 五种 I/O 模型 | 简书 聊聊同步、异步、阻塞与非阻塞 | 简书 epoll 和 select | 软件架构设计 - 知乎专栏 epoll 重要源码注释 - lijie | Github epoll 的本质是什么？| 开源中国 【必看】epoll使用详解（精髓）| 博客园 高并发网络编程之 epoll 详解 | CSDN 我读过的最好的 epoll 讲解 | CSDN select、poll、epoll之间的区别总结 | 博客园 IO多路复用之select、poll、epoll详解 | 博客园 linux中的select和epoll模型 | 博客园 4. IPC 通信Linux IPC 通信方式： Linux 下的进程间通信：共享存储 | Linux 中国 Linux 下的进程间通信：使用管道和消息队列 | Linux 中国 Linux 下的进程间通信：套接字和信号 | Linux 中国 Linux 共享内存实现机制的详解 | 脚本之家 深刻理解 Linux 进程间通信（IPC）| IBM Developer 详解共享内存以及所有进程间通信的特点 | CSDN 5. 进程/线程 Linux 进程状态 进程和线程的区别 | CSDN 6. grep/sed/awk Linux 三大利器 grep，sed，awk | SegmentFault 7. Shell 相关8. KVM9. Docker10. K8s 50 个你必须了解的 Kubernetes 面试问题 - 进击的云计算 | 知乎专栏 11. Go Go 重建二叉树 | 简书 package main import ( &quot;fmt&quot; ) type Node struct { value int left *Node right *Node } func main() { preOrder := []int{1, 2, 4, 7, 3, 5, 6, 8} inOrder := []int{4, 7, 2, 1, 5, 3, 8, 6} tree := constructBTree(preOrder, inOrder) preCatTree(tree) inCatTree(tree) } // 重建二叉树 func constructBTree(preOrder, inOrder []int) *Node { l := len(preOrder) if l == 0 { return nil } root := &amp;Node{ value: preOrder[0], } if l == 1 { return root } leftLen, rightLen := 0, 0 for _, v := range inOrder { if v == root.value { break } leftLen++ } rightLen = l - leftLen - 1 if leftLen &gt; 0 { fmt.Println(&quot;左子树&quot;, preOrder[1:leftLen+1], inOrder[0:leftLen]) root.left = constructBTree(preOrder[1:leftLen+1], inOrder[0:leftLen]) } if rightLen &gt; 0 { fmt.Println(&quot;右子树&quot;, preOrder[leftLen+1:], inOrder[leftLen+1:]) root.right = constructBTree(preOrder[leftLen+1:], inOrder[leftLen+1:]) } return root } func preCatTree(t *Node) { fmt.Println(t.value) if t.left != nil { preCatTree(t.left) } if t.right != nil { preCatTree(t.right) } } func inCatTree(t *Node) { if t.left != nil { inCatTree(t.left) } fmt.Println(t.value) if t.right != nil { inCatTree(t.right) } } Go 语言实现二叉树遍历 | AnnatarHe Go 中的锁 | 知乎专栏 Go 实现 LRU 算法 | LittleFeng go 实现 LRU cache | SegmentFault lru_cache.go | Github waitGroup 的使用 如何在waitGroup 的协程中实现一个协程失败，所有协程立刻终止 channel 与 goroutine go 等待一组协程结束的实现方式 | CSDN golang 让协程优雅退出 | CSDN golang 中读写文件的几种方式 | CSDN Go 语言学习之 ioutil 包 (The way to go) | CSDN Go 语言学习之 os 包中文件相关的操作 (The way to go) | CSDN 深入理解 Go - 垃圾回收机制 | TY·Loafer 12. 算法 Learn-Algorithms-With-Go - 使用 Golang 以测试驱动（TDD）的方式编写《剑指Offer》中的算法题 | Github LeetCodeAnimation - 程序员小吴 | Github 程序员小吴的博客 反转链表 13. 数据库 MyISAM 与 InnoDB 性能测试对比 | TY·Loafer 『浅入浅出』MySQL 和 InnoDB | 真没什么逻辑 『浅入深出』MySQL 中事务的实现 | Draveness.me 秒懂 InnoDB 的锁 | RyuGou MySQL FAQ 系列 — 新手必看：一步到位之InnoDB | 老叶茶馆 14. 常见面试题 【重要】访问 URL 的具体过程 数据库 事务 隔离级别 Go、C 读写文件 如何用九条命令在一分钟内检查 Linux 服务器性能？| 知乎 HTTP 协议理解及服务端与客户端的设计实现 | Web开发 15. 计算机网络 参见 42 道计算机网络面试高频题+答案 | Linux云计算网络 42 道计算机网络面试高频题+答案 | Linux云计算网络 TCP 协议的常见面试题 | Linux云计算网络 基础知识 CS-Notes - cyc2018 | Github fullstack-tutorial - frank-lam | Github 面经汇总 StabilityGuide - 稳定性领域知识库 | Github Golang 工程师历年企业笔试真题汇总 | 牛客 运维工程师历年企业笔试真题汇总 | 牛客 网易游戏一面 基础架构方向 | 牛客 秋招总结（运维）| 牛客 秋招基本结束，关于运维的面经 | 牛客 发喜气，字节跳动一面 二面面经，已拿 offer | 牛客 字节跳动面筋（EE后台开发）| 牛客 电信云笔试 - 牛客1.落单的数： package main import ( &quot;fmt&quot; ) func main() { n := 0 ans := 0 cur := 0 fmt.Scan(&amp;n) for i := 0; i &lt; n; i++ { fmt.Scan(&amp;cur) ans ^= cur } fmt.Println(ans) } ------ 7 1 2 2 1 3 4 3 4 2.同构字符串： package main import ( &quot;fmt&quot; &quot;strings&quot; ) func main() { var s, s1, s2 string fmt.Scan(&amp;s) split := strings.Split(s, &quot;;&quot;) s1, s2 = split[0], split[1] len1 := len(s1) len2 := len(s2) if len1 != len2 { fmt.Println(&quot;False&quot;) return } else if len1 == 1 { fmt.Println(&quot;True&quot;) return } record := make(map[byte]byte) for i := 0; i &lt; len1; i++ { if record[s1[i]] == s2[i] { continue } else if record[s1[i]] == 0 { record[s1[i]] = s2[i] } else { fmt.Println(&quot;False&quot;) return } } fmt.Println(&quot;True&quot;) return } ------ ababa;ststs True 3.最大连续子序列的和： package main import ( &quot;fmt&quot; ) func main() { array := make([]int, 0) var a int var ch byte fmt.Scan(&amp;ch) for { n, err := fmt.Scanf(&quot;%d&quot;, &amp;a) if n == 0 { break } if err != nil { fmt.Println(err) break } array = append(array, a) } fmt.Println(search(array)) } func search(a []int) int { l := len(a) curSum := 0 maxSum := 0 for i := 0; i &lt; l; i++ { curSum = 0 for j := i; j &lt; l; j++ { curSum += a[j] if curSum &gt; maxSum { maxSum = curSum } } } return maxSum } ------ [2, 4, -2, 5, -6] 9 字节跳动 - 牛客1.距离最近的厕所： package main import ( &quot;fmt&quot; ) var ( n int s string wcDis [1000000]int ) const ( maxDistance int = 1000001 ) // 离最近厕所的距离，O代表有厕所，保证至少有一个厕所 // // [Input] // 9 // XXOXOOXXX // // [Output] // 2 1 0 1 0 0 1 2 3 func main() { fmt.Scan(&amp;n) fmt.Scan(&amp;s) for i := 0; i &lt; 1000000; i++ { wcDis[i] = maxDistance } for i := 0; i &lt; n; i++ { findWC(i) } } func findWC(cur int) { if s[cur] == &#39;O&#39; { wcDis[cur] = 0 fmt.Printf(&quot;%d &quot;, 0) return } curDis := min(searchLeft(cur), searchRight(cur)) wcDis[cur] = curDis fmt.Printf(&quot;%d &quot;, curDis) } func min(a, b int) int { if a &lt; b { return a } return b } func searchLeft(cur int) int { if cur == 0 { return maxDistance } if s[cur-1] == &#39;O&#39; { return 1 } return wcDis[cur-1] + 1 } func searchRight(cur int) int { disRight := 0 for i := cur + 1; i &lt; n; i++ { disRight++ if s[i] == &#39;O&#39; { return disRight } } return maxDistance } ------ 9 XXOXOOXXX 2 1 0 1 0 0 1 2 3 2.考试跳过的题目： package main import ( &quot;fmt&quot; &quot;sort&quot; ) // 第一行: 测试用例个数 // 第二行: n, m, 分别代表题目总数、时间总数 // 输出: 至少要跳过前面的几道题 // // [Input] // 2 // 5 5 // 1 2 3 4 5 // 4 4 // 4 3 2 1 // // [Output] // 0 0 1 2 4 // 0 1 2 2 func main() { var total int fmt.Scan(&amp;total) for i := 0; i &lt; total; i++ { solve() } } func solve() { var n, m int fmt.Scan(&amp;n, &amp;m) questions := make([]int, n) for i := 0; i &lt; n; i++ { fmt.Scan(&amp;questions[i]) } var curSum = 0 for i := 0; i &lt; n-1; i++ { curSum += questions[i] printAns(questions, i, curSum, n, m) fmt.Print(&quot; &quot;) } curSum += questions[n-1] printAns(questions, n-1, curSum, n, m) fmt.Println() } func printAns(questions []int, curPos, curSum, n, m int) { if curSum &lt;= m { fmt.Print(0) return } prev := make([]int, curPos) copy(prev, questions[0:curPos]) sort.Slice(prev, func(i, j int) bool { return prev[i] &gt; prev[j] }) var curGiveup = 0 for i := 0; i &lt; curPos; i++ { curSum -= prev[i] curGiveup++ if curSum &lt;= m { fmt.Print(curGiveup) return } } } ------ 2 5 5 1 2 3 4 5 4 4 4 3 2 1 0 0 1 2 4 0 1 2 2 🚩推荐阅读（由hexo文章推荐插件驱动）近期复习合集2020 届互联网春招实习汇总 (2019年春)Linux Shell 脚本面试25问golang面试题golang面试题","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"秋招","slug":"秋招","permalink":"https://abelsu7.top/tags/秋招/"},{"name":"面试","slug":"面试","permalink":"https://abelsu7.top/tags/面试/"}]},{"title":"VS Code 使用 Settings Sync 插件同步设置","slug":"vscode-settings-sync","date":"2019-07-21T08:59:46.000Z","updated":"2019-09-01T13:04:11.766Z","comments":true,"path":"2019/07/21/vscode-settings-sync/","link":"","permalink":"https://abelsu7.top/2019/07/21/vscode-settings-sync/","excerpt":"Sync once, enjoy everywhere!","text":"Sync once, enjoy everywhere! To be updated… 参考文章 如何使用 VS Code 的 Settings Sync 插件 | SegmentFault 三分钟教你同步 Visual Studio Code 设置 | 掘金 🚩推荐阅读（由hexo文章推荐插件驱动）VS Code 中使用 gopls 补全 Go 代码使用 GNU Global 在 VS Code 中阅读内核源码VS Code 配置 Go 开发环境解决 VS Code 中 golang.org 被墙导致的 Go 插件安装失败问题","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"VS Code","slug":"VS-Code","permalink":"https://abelsu7.top/tags/VS-Code/"}]},{"title":"使用 GNU Global 在 VS Code 中阅读内核源码","slug":"reading-kernel-src-in-vscode-with-gnu-global","date":"2019-07-16T03:35:03.000Z","updated":"2019-09-01T13:04:11.652Z","comments":true,"path":"2019/07/16/reading-kernel-src-in-vscode-with-gnu-global/","link":"","permalink":"https://abelsu7.top/2019/07/16/reading-kernel-src-in-vscode-with-gnu-global/","excerpt":"Farewell, Source Insight!","text":"Farewell, Source Insight! 更新中… 参考文章 GNU Global VS Code + GNU Global - 打造 Trace Linux Kernel 環境 | Jayce’s Shared Memory Visual Studio Code + GNU Global打造代码编辑神器 | 腾讯云+社区 Ubuntu 安裝 GNU Global(gtags) 阅读Linux内核源码 | CSDN Source Insight 4.0 Source Insight 使用方法逆天整理 | cnblogs Source Insight 4.0 破解和使用 | CSDN Source Insight 常用设置和快捷键大全 | cnblogs 如何使用 Visual Studio Code 阅读 Android 源码 | 程序员虾饺 bootlin/elixir - The Elixir Cross Referencer | Github 🚩推荐阅读（由hexo文章推荐插件驱动）VS Code 中使用 gopls 补全 Go 代码VS Code 使用 Settings Sync 插件同步设置VS Code 配置 Go 开发环境Linux 内核笔记 1：绪论归并排序(递归)快速排序(递归)","categories":[{"name":"C/C++","slug":"C-C","permalink":"https://abelsu7.top/categories/C-C/"}],"tags":[{"name":"C","slug":"C","permalink":"https://abelsu7.top/tags/C/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://abelsu7.top/tags/VS-Code/"},{"name":"GNU","slug":"GNU","permalink":"https://abelsu7.top/tags/GNU/"},{"name":"Kernel","slug":"Kernel","permalink":"https://abelsu7.top/tags/Kernel/"}]},{"title":"Linux 终端修改 ls 命令目录显示颜色","slug":"modify-ls-command-dir-color","date":"2019-07-07T14:35:57.000Z","updated":"2019-09-01T13:04:11.535Z","comments":true,"path":"2019/07/07/modify-ls-command-dir-color/","link":"","permalink":"https://abelsu7.top/2019/07/07/modify-ls-command-dir-color/","excerpt":"保护眼睛，猿猿有责","text":"保护眼睛，猿猿有责 更新中… 参考文章 ls 修改文件夹蓝色 | 简书 ls 命令结果中文件夹颜色（蓝色）的改变方法 | 博客园 Linux 下 ls 命令结果中文件夹颜色（蓝色）的改变方法 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 下使用 Perf 分析系统性能Shell 输入/输出重定向：1>/dev/null、2>&1Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"}]},{"title":"使用 qemu-nbd 挂载虚拟机镜像","slug":"qemu-nbd","date":"2019-07-07T14:29:30.000Z","updated":"2019-10-13T09:53:34.735Z","comments":true,"path":"2019/07/07/qemu-nbd/","link":"","permalink":"https://abelsu7.top/2019/07/07/qemu-nbd/","excerpt":"摘自 通过 qemu-nbd 方式挂载 qcow2 镜像格式 | CSDN","text":"摘自 通过 qemu-nbd 方式挂载 qcow2 镜像格式 | CSDN 更新中… 参考文章 通过 qemu-nbd 方式挂载 qcow2 镜像格式 | CSDN 用 qemu-nbd 实现 mount 虚拟硬盘到 Host 上的功能 | CSDN Linux NBD &amp; qemu-nbd | 博客园 qemu-nbd 方式挂载 qcow2 镜像 | 码迷 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"},{"name":"NBD","slug":"NBD","permalink":"https://abelsu7.top/tags/NBD/"}]},{"title":"QEMU 内存虚拟化源码分析","slug":"kvm-memory-virtualization","date":"2019-07-07T13:34:40.000Z","updated":"2019-11-05T03:29:36.795Z","comments":true,"path":"2019/07/07/kvm-memory-virtualization/","link":"","permalink":"https://abelsu7.top/2019/07/07/kvm-memory-virtualization/","excerpt":"基于 QEMU 1.2.0、Kernel 2.6.32","text":"基于 QEMU 1.2.0、Kernel 2.6.32 1. 内存虚拟化概述1.1 OverviewQEMU-KVM 的内存虚拟化是由 QEMU 和 KVM 二者共同实现的，其本质上是一个将 Guest 虚拟内存转换成 Host 物理内存的过程。概括来看，主要有以下几点： Guest 启动时，由 QEMU 从它的进程地址空间申请内存并分配给 Guest 使用，即内存的申请是在用户空间完成的 通过 KVM 提供的 API，QEMU 将 Guest 内存的地址信息传递并注册到 KVM 中维护，即内存的管理是由内核空间的 KVM 实现的 整个转换过程涉及 GVA、GPA、HVA、HPA 四种地址，Guest 的物理地址空间从 QEMU 的虚拟地址空间中分配 内存虚拟化的关键在于维护 GPA 到 HVA 的映射关系，Guest 使用的依然是 Host 的物理内存 1.2 传统的地址转换64 位 CPU 上支持 48 位的虚拟地址寻址空间，和 52 位的物理地址寻址空间。Linux 采用 4 级页表机制将虚拟地址（VA）转换成物理地址（PA），先从页表的基地址寄存器CR3中读取页表的起始地址，然后加上页号得到对应的页表项，从中取出页的物理地址，加上偏移量就得到 PA。 1.3 QEMU 的内存结构QEMU 利用mmap系统调用，在进程的虚拟地址空间中申请连续大小的空间，作为 Guest 的物理内存。 QEMU 作为 Host 上的一个进程运行，Guest 的每个 vCPU 都是 QEMU 进程的一个子线程。而 Guest 实际使用的仍是 Host 上的物理内存，因此对于 Guest 而言，在进行内存寻址时需要完成以下地址转换过程： Guest虚拟内存地址(GVA) | Guest线性地址 | Guest物理地址(GPA) | Guest ------------------ | Host Host虚拟地址(HVA) | Host线性地址 | Host物理地址(HPA) 其中，虚拟地址到线性地址的转换过程可以省略，因此 KVM 的内存寻址主要涉及以下四种地址的转换： Guest虚拟内存地址(GVA) | Guest物理地址(GPA) | Guest ------------------ | Host Host虚拟地址(HVA) | Host物理地址(HPA) 其中，GVA-&gt;GPA的映射由 Guest OS 维护，HVA-&gt;HPA的映射由 Host OS 维护，因此需要一种机制，来维护GPA-&gt;HVA之间的映射关系。 常用的实现有SPT(Shadow Page Table)和EPT/NPT，前者通过软件维护影子页表，后者通过硬件特性实现二级映射。 1.3.1 影子页表KVM 通过维护记录GVA-&gt;HPA的影子页表 SPT，减少了地址转换带来的开销，可以直接将 GVA 转换为 HPA。 在软件虚拟化的内存转换中，GVA 到 GPA 的转换通过查询 CR3 寄存器来完成，CR3 中保存了 Guest 的页表基地址，然后载入 MMU 中进行地址转换。 在加入了 SPT 技术后，当 Guest 访问 CR3 时，KVM 会捕获到这个操作EXIT_REASON_CR_ACCESS，之后 KVM 会载入特殊的 CR3 和影子页表，欺骗 Guest 这就是真实的 CR3。之后就和传统的访问内存方式一致，当需要访问物理内存的时候，只会经过一层影子页表的转换。 影子页表由 KVM 维护，实际上就是一个 Guest 页表到 Host 页表的映射。KVM 会将 Guest 的页表设置为只读，当 Guest OS 对页表进行修改时就会触发 Page Fault，VM-EXIT 到 KVM，之后 KVM 会对 GVA 对应的页表项进行访问权限检查，结合错误码进行判断： 如果是 Guest OS 引起的，则将该异常注入回去，Guest OS 将调用自己的缺页处理函数，申请一个 Page，并将 Page 的 GPA 填充到上级页表项中 如果是 Guest OS 的页表和 SPT 不一致引起的，则同步 SPT，根据 Guest 页表和 mmap 映射找到 GPA 到 HVA 的映射关系，然后在 SPT 中增加/更新GVA-HPA表项 当 Guest 切换进程时，会把带切换进程的页表基址载入到 Guest 的 CR3 中，导致 VM-EXIT 到 KVM 中。KVM 再通过哈希表找到对应的 SPT，然后加载到机器的 CR3 中。 影子页表的引入，减少了GVA-&gt;HPA的转换开销，但是缺点在于需要为 Guest 的每个进程都维护一个影子页表，这将带来很大的内存开销。同时影子页表的建立是很耗时的，如果 Guest 的进程过多，将导致影子页表频繁切换。因此 Intel 和 AMD 在此基础上提供了基于硬件的虚拟化技术。 1.3.2 EPT 硬件加速 Intel EPT 技术引入了 EPT（Extended Page Table）和 EPTP（EPT base pointer）的概念。EPT 中维护着 GPA 到 HPA 的映射，而 EPTP 负责指向 EPT。 在 Guest OS 运行时，Guest 对应的 EPT 地址被加载到 EPTP，而 Guest OS 当前运行的进程页表基址被加载到 CR3。于是在进行地址转换时，首先通过 CR3 指向的页表实现 GVA 到 GPA 的转换，再通过 EPTP 指向的 EPT 完成 GPA 到 HPA 的转换。当发生 EPT Page Fault 时，需要 VM-EXIT 到 KVM，更新 EPT。 优点：Guest 的缺页在 Guest OS 内部处理，不会 VM-EXIT 到 KVM 中。地址转化基本由硬件（MMU）查页表来完成，大大提升了效率，且只需为 Guest 维护一份 EPT 页表，减少内存的开销 缺点：两级页表查询，只能寄望于 TLB 命中 1.4 QEMU 的主要工作内存虚拟化的目的就是让虚拟机能够无缝的访问内存。有了 Intel EPT 的支持后，CPU 在 VMX non-root 状态时进行内存访问会再做一次 EPT 转换。在这个过程中，QEMU 会负责以下内容： 首先需要从自己的进程地址空间中申请内存用于 Guest 需要将上一步中申请到的内存的虚拟地址（HVA）和 Guest 的物理地址之间的映射关系传递给 KVM，即GPA-&gt;HVA 需要组织一系列的数据结构来管理虚拟内存空间，并在内存拓扑结构更改时将最新的内存信息同步至 KVM 中 1.5 QEMU 和 KVM 的工作分界QEMU 和 KVM 之间是通过 KVM 提供的ioctl()接口进行交互的。在内核的kvm_vm_ioctl()中，设置虚拟机内存的系统调用为KVM_SET_USER_MEMORY_REGION： static long kvm_vm_ioctl(struct file *filp, unsigned int ioctl, unsigned long arg) { /* ... */ case KVM_SET_USER_MEMORY_REGION: { // 在 KVM 中注册用户空间传入的内存信息 struct kvm_userspace_memory_region kvm_userspace_mem; r = -EFAULT; // 将传入的数据结构复制到内核空间 if (copy_from_user(&amp;kvm_userspace_mem, argp, sizeof kvm_userspace_mem)) goto out; // 实际进行处理的函数 r = kvm_vm_ioctl_set_memory_region(kvm, &amp;kvm_userspace_mem, 1); if (r) goto out; break; } /* ... */ } 可以看到这里需要传递的参数类型为kvm_userspace_memory_region： /* for KVM_SET_USER_MEMORY_REGION */ struct kvm_userspace_memory_region { __u32 slot; // slot 编号 __u32 flags; // 标志位，例如是否追踪脏页、是否可用等 __u64 guest_phys_addr; // Guest 物理地址，即 GPA __u64 memory_size; // 内存大小，单位 bytes __u64 userspace_addr; // 从 QEMU 进程地址空间中分配内存的起始地址，即 HVA }; KVM_SET_USER_MEMORY_REGION这个 ioctl 主要目的就是设置GPA-&gt;HVA的映射关系，KVM 会继续调用kvm_vm_ioctl_set_memory_region()，在内核空间维护并管理 Guest 的内存。 2. 相关数据结构2.1 AddressSpace2.1.1 结构体定义QEMU 用 AddressSpace 结构体表示 Guest 中 CPU/设备看到的内存，类似于物理机中地址空间的概念，但在这里表示的是 Guest 的一段地址空间，如内存地址空间address_space_memory、I/O 地址空间address_space_io，它在 QEMU 源码memory.c中定义： /* A system address space - I/O, memory, etc. */ struct AddressSpace { MemoryRegion *root; // 根级 MemoryRegion FlatView current_map; // 对应的平面展开视图 FlatView int ioeventfd_nb; MemoryRegionIoeventfd *ioeventfds; }; 每个 AddressSpace 一般包含一系列的 MemoryRegion：root指针指向根级 MemoryRegion，而root可能有自己的若干个 subregions，于是形成树状结构。这些 MemoryRegion 通过树连接起来，树的根即为 AddressSpace 的root域。 2.1.2 全局变量另外，QEMU 中有两个全局的静态 AddressSpace，在memory.c中定义： static AddressSpace address_space_memory; // 内存地址空间 static AddressSpace address_space_io; // I/O 地址空间 其root域分别指向之后会提到的两个 MemoryRegion 类型变量：system_memory、system_io。 2.2 MemoryRegion2.2.1 结构体定义MemoryRegion 表示在 Guest Memory Layout 中的一段内存区域，它是联系 GPA 和 RAMBlocks（描述真实内存）之间的桥梁，在memory.h中定义： struct MemoryRegion { /* All fields are private - violators will be prosecuted */ const MemoryRegionOps *ops; // 回调函数集合 void *opaque; MemoryRegion *parent; // 父 MemoryRegion 指针 Int128 size; // 该区域内存的大小 target_phys_addr_t addr; // 在 Address Space 中的地址，即 HVA void (*destructor)(MemoryRegion *mr); ram_addr_t ram_addr; // MemoryRegion 的起始地址，即 GPA bool subpage; bool terminates; bool readable; bool ram; // 是否表示 RAM bool readonly; /* For RAM regions */ bool enabled; // 是否已经通知 KVM 使用这段内存 bool rom_device; bool warning_printed; /* For reservations */ MemoryRegion *alias; // 是否为 MemoryRegion alias target_phys_addr_t alias_offset; // 若为 alias，在原 MemoryRegion 中的 offset unsigned priority; bool may_overlap; QTAILQ_HEAD(subregions, MemoryRegion) subregions; // 子区域链表头 QTAILQ_ENTRY(MemoryRegion) subregions_link; // 子区域链表节点 QTAILQ_HEAD(coalesced_ranges, CoalescedMemoryRange) coalesced; const char *name; // MemoryRegion 的名字，调试时使用 uint8_t dirty_log_mask; // 表示哪一种 dirty map 被使用，共分三种 unsigned ioeventfd_nb; MemoryRegionIoeventfd *ioeventfds; }; 2.2.2 全局变量在 QEMU 的exec.c中也定义了两个静态的 MemoryRegion 指针变量： static MemoryRegion *system_memory; // 内存 MemoryRegion，对应 address_space_memory static MemoryRegion *system_io; // I/O MemoryRegion，对应 address_space_io 与两个全局 AddressSpace 对应，即 AddressSpace 的root域指向这两个 MemoryRegion。 2.2.3 MemoryRegion 的类型MemoryRegion 有多种类型，可以表示一段 RAM、ROM、MMIO、alias。 若为 alias 则表示一个 MemoryRegion 的部分区域，例如 QEMU 会为pc.ram这个表示 RAM 的 MemoryRegion 添加两个 alias：ram-below-4g和ram-above-4g，之后会看到具体的代码实例。 另外，MemoryRegion 也可以表示一个 container，这就表示它只是其他若干个 MemoryRegion 的容器 那么要如何创建不同类型的 MemoryRegion 呢？在 QEMU 中实际上是通过调用不同的初始化函数区分的。根据不同的初始化函数及其功能，可以将 MemoryRegion 划分为以下三种类型： 根级 MemoryRegion：直接通过memory_region_init初始化，没有自己的内存，用于管理 subregion，例如system_memory： void memory_region_init(MemoryRegion *mr, const char *name, uint64_t size) { mr-&gt;ops = NULL; mr-&gt;parent = NULL; mr-&gt;size = int128_make64(size); if (size == UINT64_MAX) { mr-&gt;size = int128_2_64(); } mr-&gt;addr = 0; mr-&gt;subpage = false; mr-&gt;enabled = true; mr-&gt;terminates = false; // 非实体 MemoryRegion，搜索时会继续前往其 subregions mr-&gt;ram = false; // 根级 MemoryRegion 不分配内存 mr-&gt;readable = true; mr-&gt;readonly = false; mr-&gt;rom_device = false; mr-&gt;destructor = memory_region_destructor_none; mr-&gt;priority = 0; mr-&gt;may_overlap = false; mr-&gt;alias = NULL; QTAILQ_INIT(&amp;mr-&gt;subregions); memset(&amp;mr-&gt;subregions_link, 0, sizeof mr-&gt;subregions_link); QTAILQ_INIT(&amp;mr-&gt;coalesced); mr-&gt;name = g_strdup(name); mr-&gt;dirty_log_mask = 0; mr-&gt;ioeventfd_nb = 0; mr-&gt;ioeventfds = NULL; } 可以看到mr-&gt;addr被设置为 0，而mr-&gt;ram_addr则并没有初始化。 实体 MemoryRegion：通过memory_region_init_ram()初始化，有自己的内存（从 QEMU 进程地址空间中分配），大小为size，例如ram_memory、pci_memory： void *pc_memory_init(MemoryRegion *system_memory, const char *kernel_filename, const char *kernel_cmdline, const char *initrd_filename, ram_addr_t below_4g_mem_size, ram_addr_t above_4g_mem_size, MemoryRegion *rom_memory, MemoryRegion **ram_memory) { MemoryRegion *ram, *option_rom_mr; /* ...*/ /* Allocate RAM. We allocate it as a single memory region and use * aliases to address portions of it, mostly for backwards compatibility * with older qemus that used qemu_ram_alloc(). */ ram = g_malloc(sizeof(*ram)); // 调用 memory_region_init_ram 对 ram_memory 进行初始化 memory_region_init_ram(ram, &quot;pc.ram&quot;, below_4g_mem_size + above_4g_mem_size); vmstate_register_ram_global(ram); *ram_memory = ram; /* ... */ } void memory_region_init_ram(MemoryRegion *mr, const char *name, uint64_t size) { memory_region_init(mr, name, size); mr-&gt;ram = true; mr-&gt;terminates = true; mr-&gt;destructor = memory_region_destructor_ram; mr-&gt;ram_addr = qemu_ram_alloc(size, mr); } 可以看到这里是先调用了memory_region_init()，之后设置 RAM 属性，并继续调用qemu_ram_alloc()分配内存。 别名 MemoryRegion：通过memory_region_init_alias() 初始化，没有自己的内存，表示实体 MemoryRegion 的一部分。通过 alias 成员指向实体 MemoryRegion，alias_offset为在实体 MemoryRegion 中的偏移量，例如ram_below_4g、ram_above_4g： void *pc_memory_init(MemoryRegion *system_memory, const char *kernel_filename, const char *kernel_cmdline, const char *initrd_filename, ram_addr_t below_4g_mem_size, ram_addr_t above_4g_mem_size, MemoryRegion *rom_memory, MemoryRegion **ram_memory) { MemoryRegion *ram_below_4g, *ram_above_4g; /* ... */ ram_below_4g = g_malloc(sizeof(*ram_below_4g)); // 调用 memory_region_init_alias 对 ram_below_4g 进行初始化 memory_region_init_alias(ram_below_4g, &quot;ram-below-4g&quot;, ram, 0, below_4g_mem_size); /* ... */ } void memory_region_init_alias(MemoryRegion *mr, const char *name, MemoryRegion *orig, target_phys_addr_t offset, uint64_t size) { memory_region_init(mr, name, size); mr-&gt;alias = orig; // 指向实体 MemoryRegion mr-&gt;alias_offset = offset; } 2.3 RAMBlock2.3.1 结构体定义MemoryRegion 用来描述一段逻辑层面上的内存区域，而记录实际分配的内存地址信息的结构体则是 RAMBlock，在cpu-all.h中定义： typedef struct RAMBlock { struct MemoryRegion *mr; // 唯一对应的 MemoryRegion uint8_t *host; // RAMBlock 关联的内存，即 HVA ram_addr_t offset; // RAMBlock 在 VM 物理内存中的偏移量，即 GPA ram_addr_t length; // RAMBlock 的长度 uint32_t flags; char idstr[256]; // RAMBlock 的 id QLIST_ENTRY(RAMBlock) next; // 指向下一个 RAMBlock #if defined(__linux__) &amp;&amp; !defined(TARGET_S390X) int fd; #endif } RAMBlock; 可以看到在 RAMBlock 中host和offset域分别对应了 HVA 和 GPA，因此也可以说 RAMBlock 中存储了GPA-&gt;HVA的映射关系，另外每一个 RAMBlock 都会指向其所属的 MemoryRegion。 2.3.2 全局变量 ram_listQEMU 在cpu-all.h中定义了一个全局变量ram_list，以链表的形式维护了所有的 RAMBlock： typedef struct RAMList { uint8_t *phys_dirty; QLIST_HEAD(, RAMBlock) blocks; uint64_t dirty_pages; } RAMList; extern RAMList ram_list; 每一个新分配的 RAMBlock 都会被插入到ram_list的头部。如需查找地址所对应的 RAMBlock，则需要遍历ram_list，当目标地址落在当前 RAMBlock 的地址区间时，该 RAMBlock 即为查找目标。 2.3.3 AS、MR、RAMBlock 之间的关系AddressSpace、MemoryRegion、RAMBlock 之间的关系如下所示： 可以看到 AddressSpace 的root域指向根级 MemoryRegion，AddressSpace 是由root域指向的 MemoryRegion 及其子树共同表示的。MemoryRegion 作为一个逻辑层面的内存区域，还需借助分布在其中的 RAMBlock 来存储真实的地址映射关系。 下图是我根据自己的理解绘制的三者之间的关系图： 如图所示，以address_space_memory为例，其root域对应的 MemoryRegion 为system_memory。system_memory的 subregions 为两个 alias MemoryRegion：ram_below_4g、ram_above_4g，均指向pc.ram这个实体 MemoryRegion。pc.ram的内存实际上通过 RAMBlock 分配，其addr与ram_addr域分别对应了 RAMBlock 的 HVA、GPA。QEMU 从自己的进程地址空间中为该 RAMBlock 分配内存后，将其mr域指向pc.ram，至此就完成了 QEMU 侧的内存分配。 2.4 FlatViewAddressSpace 的root域及其子树共同构成了 Guest 的物理地址空间，但这些都是在 QEMU 侧定义的。要传入 KVM 进行设置时，复杂的树状结构是不利于内核进行处理的，因此需要将其转换为一个“平坦”的地址模型，也就是一个从零开始、只包含地址信息的数据结构，这在 QEMU 中通过 FlatView 来表示。每个 AddressSpace 都有一个与之对应的 FlatView 指针current_map，表示其对应的平面展开视图。 2.4.1 结构体定义FlatView 在memory.c中定义： /* Flattened global view of current active memory hierarchy. Kept in sorted * order. */ struct FlatView { FlatRange *ranges; // 对应的 FlatRange 数组 unsigned nr; // FlatRange 的数目 unsigned nr_allocated; // 当前数组的项数 }; 其中，ranges是一个数组，记录了 FlatView 下所有的 FlatRange。 2.4.2 FlatRange在 FlatView 中，FlatRange 表示在 FlatView 中的一段内存范围，同样在memory.c中定义： /* Range of memory in the global map. Addresses are absolute. */ struct FlatRange { MemoryRegion *mr; // 指向所属的 MemoryRegion target_phys_addr_t offset_in_region; // 在全局 MemoryRegion 中的 offset，对应 GPA AddrRange addr; // 代表的地址区间，对应 HVA uint8_t dirty_log_mask; bool readable; bool readonly; }; 每个 FlatRange 对应一段虚拟机物理地址区间，各个 FlatRange 不会重叠，按照地址的顺序保存在数组中，具体的地址范围由一个 AddrRange 结构来描述： /* * AddrRange 用于表示 FlatRange 的起始地址及大小 */ struct AddrRange { Int128 start; Int128 size; }; 2.5 MemoryRegionSection2.5.1 结构体定义在 QEMU 中，还有几个起到中介作用的结构体，MemoryRegionSection 就是其中之一。 之前介绍的 FlatRange 代表一个物理地址空间的片段，偏向于描述在 Host 侧即 AddressSpace 中的分布，而 MemoryRegionSection 则代表在 Guest 侧即 MemoryRegion 中的片段。MemoryRegionSection 在memory.h中定义： /** * MemoryRegionSection: describes a fragment of a #MemoryRegion * * @mr: the region, or %NULL if empty * @address_space: the address space the region is mapped in * @offset_within_region: the beginning of the section, relative to @mr&#39;s start * @size: the size of the section; will not exceed @mr&#39;s boundaries * @offset_within_address_space: the address of the first byte of the section * relative to the region&#39;s address space * @readonly: writes to this section are ignored */ struct MemoryRegionSection { MemoryRegion *mr; // 所属的 MemoryRegion MemoryRegion *address_space; // 关联的 AddressSpace target_phys_addr_t offset_within_region; // 在 MemoryRegion 内部的 offset uint64_t size; // Section 的大小 target_phys_addr_t offset_within_address_space; // 在 AddressSpace 内部的 offset bool readonly; // 是否为只读 }; offset_within_region：在所属 MemoryRegion 中的 offset。一个 AddressSpace 可能由多个 MemoryRegion 组成，因此该 offset 是局部的 offset_within_address_space：在所属 AddressSpace 中的 offset，它是全局的 2.5.2 和其他数据结构之间的关系 AddressSpace 的root指向对应的根级 MemoryRegion，current_map指向root通过generate_memory_topology()生成的 FlatView FlatView 中的ranges数组表示该 MemoryRegion 所表示的 Guest 地址区间，并按照地址的顺序进行排列 MemoryRegionSection 由ranges数组中的 FlatRange 对应生成，作为注册到 KVM 中的基本单位 2.6 KVM 相关QEMU 在用户空间申请内存后，需要将内存信息通过一系列系统调用传入内核空间的 KVM，由 KVM 侧进行管理，因此 QEMU 侧也定义了一些用于向 KVM 传递参数的结构体。 2.6.1 KVMSlot在kvm-all.c中定义，是 KVM 中内存管理的基本单位： typedef struct KVMSlot { target_phys_addr_t start_addr; // Guest 物理地址，GPA ram_addr_t memory_size; // 内存大小 void *ram; // QEMU 用户空间地址，HVA int slot; // Slot 编号 int flags; // 标志位，例如是否追踪脏页、是否可用等 } KVMSlot; KVMSlot 类似于内存插槽的概念，在 KVMState 的定义中可以看到，最多支持 32 个 KVMSlot： struct KVMState { KVMSlot slots[32]; // 最多支持 32 个 KVMSlot /* ... */ } KVMState *kvm_state; 2.6.2 kvm_userspace_memory_region调用ioctl(KVM_SET_USER_MEMORY_REGION)时需要向 KVM 传递的参数，在kvm.h中定义 /* for KVM_SET_USER_MEMORY_REGION */ struct kvm_userspace_memory_region { __u32 slot; // slot 编号 __u32 flags; // 标志位，例如是否追踪脏页、是否可用等 __u64 guest_phys_addr; // Guest 物理地址，GPA __u64 memory_size; // 内存大小，bytes __u64 userspace_addr; // 从 QEMU 进程空间分配的起始地址，HVA }; 2.7 MemoryListener2.7.1 结构体定义为了监控虚拟机的物理地址访问，对于每一个 AddressSpace，都会有一个 MemoryListener 与之对应。每当物理映射GPA-&gt;HVA发生改变时，就会回调这些函数。MemoryListener 是对一些事件的回调函数合集，在memory.h中定义： /** * MemoryListener: callbacks structure for updates to the physical memory map * * Allows a component to adjust to changes in the guest-visible memory map. * Use with memory_listener_register() and memory_listener_unregister(). */ struct MemoryListener { void (*begin)(MemoryListener *listener); void (*commit)(MemoryListener *listener); void (*region_add)(MemoryListener *listener, MemoryRegionSection *section); void (*region_del)(MemoryListener *listener, MemoryRegionSection *section); void (*region_nop)(MemoryListener *listener, MemoryRegionSection *section); void (*log_start)(MemoryListener *listener, MemoryRegionSection *section); void (*log_stop)(MemoryListener *listener, MemoryRegionSection *section); void (*log_sync)(MemoryListener *listener, MemoryRegionSection *section); void (*log_global_start)(MemoryListener *listener); void (*log_global_stop)(MemoryListener *listener); void (*eventfd_add)(MemoryListener *listener, MemoryRegionSection *section, bool match_data, uint64_t data, EventNotifier *e); void (*eventfd_del)(MemoryListener *listener, MemoryRegionSection *section, bool match_data, uint64_t data, EventNotifier *e); /* Lower = earlier (during add), later (during del) */ unsigned priority; MemoryRegion *address_space_filter; QTAILQ_ENTRY(MemoryListener) link; }; 2.7.2 全局变量 memory_listeners所有的 MemoryListener 都会挂在全局变量memory_listeners链表上，在memory.c中定义： static QTAILQ_HEAD(memory_listeners, MemoryListener) memory_listeners = QTAILQ_HEAD_INITIALIZER(memory_listeners); 在memory.c中枚举了 ListenerDireciton： enum ListenerDirection { Forward, Reverse }; 另外，system_memory、system_io这两个全局 MemoryRegion 分别注册了core_memory_listener和io_memory_listener，在exec.c中定义： // 对应 system_memory 这个 MemoryRegion static MemoryListener core_memory_listener = { .begin = core_begin, .commit = core_commit, .region_add = core_region_add, .region_del = core_region_del, .region_nop = core_region_nop, .log_start = core_log_start, .log_stop = core_log_stop, .log_sync = core_log_sync, .log_global_start = core_log_global_start, .log_global_stop = core_log_global_stop, .eventfd_add = core_eventfd_add, .eventfd_del = core_eventfd_del, .priority = 0, }; // 对应 system_io 这个 MemoryRegion static MemoryListener io_memory_listener = { .begin = io_begin, .commit = io_commit, .region_add = io_region_add, .region_del = io_region_del, .region_nop = io_region_nop, .log_start = io_log_start, .log_stop = io_log_stop, .log_sync = io_log_sync, .log_global_start = io_log_global_start, .log_global_stop = io_log_global_stop, .eventfd_add = io_eventfd_add, .eventfd_del = io_eventfd_del, .priority = 0, }; 除此之外，QEMU 还在全局注册了kvm_memory_listener，在kvm-all.c中定义，用于将 QEMU 侧内存拓扑结构的改动同步更新至 KVM 中： // 同时监听 system_memory、system_io static MemoryListener kvm_memory_listener = { .begin = kvm_begin, .commit = kvm_commit, .region_add = kvm_region_add, .region_del = kvm_region_del, .region_nop = kvm_region_nop, .log_start = kvm_log_start, .log_stop = kvm_log_stop, .log_sync = kvm_log_sync, .log_global_start = kvm_log_global_start, .log_global_stop = kvm_log_global_stop, .eventfd_add = kvm_eventfd_add, .eventfd_del = kvm_eventfd_del, .priority = 10, }; 2.8 重要数据结构总览2.8.1 数据结构及其含义总览 结构体名 定义 说明 AddressSpace memory.c VM 能看到的一段地址空间，偏向 Host 侧 MemoryRegion memory.h 地址空间中一段逻辑层面的内存区域，偏向 Guest 侧 RAMBlock cpu-all.h 记录实际分配的内存地址信息，存储了GPA-&gt;HVA的映射关系 FlatView memory.c MemoryRegion 对应的平面展开视图，包含一个 FlatRange 类型的 ranges 数组 FlatRange memory.c 对应一段虚拟机物理地址区间，各个 FlatRange 不会重叠，按照地址的顺序保存在数组中 MemoryRegionSection memory.h 表示 MemoryRegion 中的片段 MemoryListener memory.h 回调函数集合 KVMSlot kvm-all.c KVM 中内存管理的基本单位，表示一个内存插槽 kvm_userspace_memory_region kvm.h 调用ioctl(KVM_SET_USER_MEMORY_REGION)时需要向 KVM 传递的参数 2.8.2 全局变量总览 两个 static AddressSpace，在memory.c中定义： static AddressSpace address_space_memory; // 内存地址空间，对应 system_memory static AddressSpace address_space_io; // I/O 地址空间，对应 system_io 两个 static MemoryRegion 指针，在exec.c中定义： static MemoryRegion *system_memory; // 用于管理内存 subregion 的根级 MemoryRegion static MemoryRegion *system_io; // 用于管理 I/O subregion 的根级 MemoryRegion 一个 RAMList，在exec.c中定义： RAMList ram_list = { .blocks = QLIST_HEAD_INITIALIZER(ram_list.blocks) }; // 用于管理全局的 RAMBlock 一个 MemoryListener 全局链表，在memory.c中定义 static QTAILQ_HEAD(memory_listeners, MemoryListener) memory_listeners = QTAILQ_HEAD_INITIALIZER(memory_listeners); 三个 MemoryListener，在exec.c和kvm-all.c中定义： // 对应 system_memory 这个 MemoryRegion static MemoryListener core_memory_listener = { .begin = core_begin, .commit = core_commit, .region_add = core_region_add, .region_del = core_region_del, .region_nop = core_region_nop, .log_start = core_log_start, .log_stop = core_log_stop, .log_sync = core_log_sync, .log_global_start = core_log_global_start, .log_global_stop = core_log_global_stop, .eventfd_add = core_eventfd_add, .eventfd_del = core_eventfd_del, .priority = 0, }; // 对应 system_io 这个 MemoryRegion static MemoryListener io_memory_listener = { .begin = io_begin, .commit = io_commit, .region_add = io_region_add, .region_del = io_region_del, .region_nop = io_region_nop, .log_start = io_log_start, .log_stop = io_log_stop, .log_sync = io_log_sync, .log_global_start = io_log_global_start, .log_global_stop = io_log_global_stop, .eventfd_add = io_eventfd_add, .eventfd_del = io_eventfd_del, .priority = 0, }; // 在全局注册，同时监听 system_memory、system_io static MemoryListener kvm_memory_listener = { .begin = kvm_begin, .commit = kvm_commit, .region_add = kvm_region_add, .region_del = kvm_region_del, .region_nop = kvm_region_nop, .log_start = kvm_log_start, .log_stop = kvm_log_stop, .log_sync = kvm_log_sync, .log_global_start = kvm_log_global_start, .log_global_stop = kvm_log_global_stop, .eventfd_add = kvm_eventfd_add, .eventfd_del = kvm_eventfd_del, .priority = 10, }; 3. 具体实现机制QEMU 的内存申请流程大致可分为三个部分：回调函数的注册、AddressSpace 的初始化、实际内存的分配。下面将根据在vl.c的main()函数中的调用顺序分别介绍。 3.1 回调函数的注册 int main() └─ static int configure_accelerator() └─ int kvm_init() // 初始化 KVM ├─ int kvm_ioctl(KVM_CREATE_VM) // 创建 VM ├─ int kvm_arch_init() // 针对不同的架构进行初始化 └─ void memory_listener_register() // 注册 kvm_memory_listener └─ static void listener_add_address_space() // 调用 region_add 回调 └─ static void kvm_region_add() // region_add 对应的回调实现 └─ static void kvm_set_phys_mem() // 根据传入的 section 填充 KVMSlot └─ static int kvm_set_user_memory_region() └─ int ioctl(KVM_SET_USER_MEMORY_REGION) 进入configure_accelerator()后，QEMU 会先调用configure_accelerator()设置 KVM 的加速支持，之后进入kvm_init()。该函数主要完成对 KVM 的初始化，包括一些常规检查如 CPU 个数、KVM 版本等，之后通过kvm_ioctl(KVM_CREATE_VM)与内核交互，创建 KVM 虚拟机。在kvm_init()的最后，会调用memory_listener_register()注册kvm_memory_listener： int kvm_init(void) { /* ... */ s-&gt;vmfd = kvm_ioctl(s, KVM_CREATE_VM, 0); // 创建 VM /* ... */ ret = kvm_arch_init(s); // 针对不同的架构进行初始化 if (ret &lt; 0) { goto err; } /* ... */ memory_listener_register(&amp;kvm_memory_listener, NULL); // 注册回调函数 /* ... */ } 该注册函数本身并不复杂，结合备注来看： void memory_listener_register(MemoryListener *listener, MemoryRegion *filter) { MemoryListener *other = NULL; listener-&gt;address_space_filter = filter; /* 若 memory_listeners 为空或当前 listener 的优先级大于最后一个 listener 的优先级，则直接在末尾插入 */ if (QTAILQ_EMPTY(&amp;memory_listeners) || listener-&gt;priority &gt;= QTAILQ_LAST(&amp;memory_listeners, memory_listeners)-&gt;priority) { QTAILQ_INSERT_TAIL(&amp;memory_listeners, listener, link); } else { /* 遍历链表，按照优先级升序排列 */ QTAILQ_FOREACH(other, &amp;memory_listeners, link) { if (listener-&gt;priority &lt; other-&gt;priority) { break; } } /* 插入 listener */ QTAILQ_INSERT_BEFORE(other, listener, link); } /* 对于以下 AddressSpace，设置其对应的 listener */ listener_add_address_space(listener, &amp;address_space_memory); listener_add_address_space(listener, &amp;address_space_io); } 最后的listener_add_address_space()主要是将listener注册到其对应的 AddressSpace 上，并根据 AddressSpace 对应的 FlatRange 数组，生成 MemoryRegionSection，并注册到 KVM 中： static void listener_add_address_space(MemoryListener *listener, AddressSpace *as) { FlatRange *fr; /* 若非注册的 AddressSpace，直接返回 */ if (listener-&gt;address_space_filter &amp;&amp; listener-&gt;address_space_filter != as-&gt;root) { return; } /* 开启内存脏页记录 */ if (global_dirty_log) { listener-&gt;log_global_start(listener); } /* 遍历 AddressSpace 对应的 FlatRange 数组，并将其转换成 MemoryRegionSection */ FOR_EACH_FLAT_RANGE(fr, &amp;as-&gt;current_map) { MemoryRegionSection section = { .mr = fr-&gt;mr, .address_space = as-&gt;root, .offset_within_region = fr-&gt;offset_in_region, .size = int128_get64(fr-&gt;addr.size), .offset_within_address_space = int128_get64(fr-&gt;addr.start), .readonly = fr-&gt;readonly, }; /* 将 section 所代表的内存区域注册到 KVM 中 */ listener-&gt;region_add(listener, &amp;section); } } 由于此时 AddressSapce 尚未初始化，所以此处的循环为空，仅是在全局注册了kvm_memory_listener。最后调用了kvm_memory_listener-&gt;region_add()，对应的实现是kvm_region_add()，该函数最终会通过ioctl(KVM_SET_USER_MEMORY_REGION)，将 QEMU 侧申请的内存信息传入 KVM 进行注册，这里的流程会在下一部分进行分析。 3.2 AddressSpace 的初始化 int main() └─ void cpu_exec_init_all() ├─ static void memory_map_init() | ├─ void memory_region_init() // 初始化 system_memory/io 这两个全局 MemoryRegion | ├─ void set_system_memory_map() // address_space_memory-&gt;root = system_memory | | └─ static void memory_region_update_topology() // 为 MemoryRegion 生成 FlatView | | └─ static void address_space_update_topology() // as-&gt;current_map = new_view | | └─ static void address_space_update_topology_pass() | | └─ static void kvm_region_add() // region_add 对应的回调实现 | | └─ static void kvm_set_phys_mem() // 根据传入的 section 填充 KVMSlot | | └─ static int kvm_set_user_memory_region() | | └─ int ioctl(KVM_SET_USER_MEMORY_REGION) | | | └─ void memory_listener_register() // 注册对应的 MemoryListener | └─ static void listener_add_address_space() | └─ static void io_mem_init() └─ void memory_region_init_io() // ram/rom/unassigned/notdirty/subpage-ram/watch └─ void memory_region_init() 第一部分在全局注册了kvm_memory_listener，但由于 AddressSpace 尚未初始化，实际上并未向 KVM 中注册任何实际的内存信息。QEMU 在main()函数中会继续调用cpu_exec_init_all()对 AddressSpace 进行初始化，该函数实际上是对两个 init 函数的封装调用： void cpu_exec_init_all(void) { #if !defined(CONFIG_USER_ONLY) memory_map_init(); // 初始化两个全局 AddressSpace，以及对应的 MemoryRegion、FlatView io_mem_init(); // 初始化六个I/O MemoryRegion #endif } 先来看memory_map_init()，主要用来初始化两个全局的系统地址空间system_memory、system_io： static void memory_map_init(void) { system_memory = g_malloc(sizeof(*system_memory)); memory_region_init(system_memory, &quot;system&quot;, INT64_MAX); // 1. 初始化 system_memory set_system_memory_map(system_memory); // 2. 设置 address_space_memory 关联 system_memory 及其对应的 FlatView system_io = g_malloc(sizeof(*system_io)); memory_region_init(system_io, &quot;io&quot;, 65536); // 1. 初始化 system_io set_system_io_map(system_io); // 2. 设置 address_space_io 关联 system_io 及其对应的 FlatView memory_listener_register(&amp;core_memory_listener, system_memory); // 3. 注册 core_memory_listener memory_listener_register(&amp;io_memory_listener, system_io); // 3. 注册 io_memory_listener } 这样一来就完成了以下对应关系： AddressSpace address_space_memory address_space_io ↓ ↓ MemoryRegion system_memory system_io ↑ ↑ MemoryRegionListener core_memory_listener io_memory_listener AddressSpace 对应的 MemoryRegion 对应的 MemoryRegionListener address_space_memory system_memory core_memory_listener address_space_io system_io io_memory_listener memory_region_init主要是初始化system_memory的各个字段，这里比较重要的是set_system_memory_map()，先设置 AddressSpace 对应的 MemoryRegion，之后根据system_memory更新address_space_memory对应的 FlatView： void set_system_memory_map(MemoryRegion *mr) { address_space_memory.root = mr; // 将 address_space_memory 的 root 域指向 system_memory memory_region_update_topology(NULL); // 根据 system_memory 更新 address_space_memory 对应的 FlatView } 而memory_region_update_topology()则会继续调用address_space_update_topology()，生成 AddressSpace 对应的 FlatView 视图： static void memory_region_update_topology(MemoryRegion *mr) { // 此时仅在全局注册了 kvm_memory_listener，而 kvm_begin() 为空，无实际操作 MEMORY_LISTENER_CALL_GLOBAL(begin, Forward); if (address_space_memory.root) { // 更新 address_space_memory 的 FlatView address_space_update_topology(&amp;address_space_memory); } if (address_space_io.root) { // 更新 address_space_io 的 FlatView address_space_update_topology(&amp;address_space_io); } // 此时仅在全局注册了 kvm_memory_listener，而 kvm_commit() 为空，无实际操作 MEMORY_LISTENER_CALL_GLOBAL(commit, Forward); memory_region_update_pending = false; } address_space_update_topology()会先调用generate_memory_topology()生成system_memory更新后的视图new_view，再将address_space_memory的current_map指向这个new_view，最后销毁old_view： static void address_space_update_topology(AddressSpace *as) { FlatView old_view = as-&gt;current_map; FlatView new_view = generate_memory_topology(as-&gt;root); // 根据 system_memory 生成 new_view // 入参 adding 为 false 时将调用 kvm_region_del() address_space_update_topology_pass(as, old_view, new_view, false); // 入参 adding 为 true 时将调用 kvm_region_add() address_space_update_topology_pass(as, old_view, new_view, true); as-&gt;current_map = new_view; // 指向 new_view flatview_destroy(&amp;old_view); // 销毁 old_view address_space_update_ioeventfds(as); } 在address_space_update_topology_pass()的最后，会调用MEMORY_LISTENER_UPDATE_REGION这个宏，触发region_add对应的回调函数kvm_region_add()： static void address_space_update_topology_pass(AddressSpace *as, FlatView old_view, FlatView new_view, bool adding) { unsigned iold, inew; FlatRange *frold, *frnew; /* Generate a symmetric difference of the old and new memory maps. * Kill ranges in the old map, and instantiate ranges in the new map. */ /* ... */ } else { /* In new */ if (adding) { MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, region_add); } ++inew; } } } 这个宏在memory.c中定义，会将 FlatView 中的 FlatRange 转换为 MemoryRegionSection，作为入参传递给kvm_region_add()： #define MEMORY_LISTENER_UPDATE_REGION(fr, as, dir, callback) \\ MEMORY_LISTENER_CALL(callback, dir, (&amp;(MemoryRegionSection) { \\ .mr = (fr)-&gt;mr, \\ .address_space = (as)-&gt;root, \\ .offset_within_region = (fr)-&gt;offset_in_region, \\ .size = int128_get64((fr)-&gt;addr.size), \\ .offset_within_address_space = int128_get64((fr)-&gt;addr.start), \\ .readonly = (fr)-&gt;readonly, \\ })) 而kvm_region_add()实际上是对kvm_set_phys_mem()的封装调用。该函数比较复杂，会根据传入的section填充 KVMSlot，再传递给kvm_set_user_memory_region()： static int kvm_set_user_memory_region(KVMState *s, KVMSlot *slot) { struct kvm_userspace_memory_region mem; mem.slot = slot-&gt;slot; // 根据 KVMSlot 填充 kvm_userspace_memory_region mem.guest_phys_addr = slot-&gt;start_addr; mem.memory_size = slot-&gt;memory_size; mem.userspace_addr = (unsigned long)slot-&gt;ram; mem.flags = slot-&gt;flags; if (s-&gt;migration_log) { mem.flags |= KVM_MEM_LOG_DIRTY_PAGES; } return kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &amp;mem); } 可以看到这里又将 KVMSlot 转换为 kvm_userspace_memory_region，作为ioctl()的参数，交给内核中的 KVM 进行内存的注册。至此 QEMU 侧负责管理内存的数据结构均已完成初始化，可以参考下面的图片了解各数据结构之间的对应关系： 最后简单看下io_mem_init()，调用memory_region_init_io()对六个 I/O MemoryRegion 进行初始化： static void io_mem_init(void) { memory_region_init_io(&amp;io_mem_ram, &amp;error_mem_ops, NULL, &quot;ram&quot;, UINT64_MAX); memory_region_init_io(&amp;io_mem_rom, &amp;rom_mem_ops, NULL, &quot;rom&quot;, UINT64_MAX); memory_region_init_io(&amp;io_mem_unassigned, &amp;unassigned_mem_ops, NULL, &quot;unassigned&quot;, UINT64_MAX); memory_region_init_io(&amp;io_mem_notdirty, &amp;notdirty_mem_ops, NULL, &quot;notdirty&quot;, UINT64_MAX); memory_region_init_io(&amp;io_mem_subpage_ram, &amp;subpage_ram_ops, NULL, &quot;subpage-ram&quot;, UINT64_MAX); memory_region_init_io(&amp;io_mem_watch, &amp;watch_mem_ops, NULL, &quot;watch&quot;, UINT64_MAX); } io_mem_ram，名为 “ram” io_mem_rom，名为 “rom” io_mem_unassigned，名为 “unassigned” io_mem_notdirty，名为 “notdirty” io_mem_subpage_ram，名为 “subpage-ram” io_mem_warch，名为 “watch” 而memory_region_init_io()则会先调用memory_region_init()对上述六个 MemoryRegion 进行初始化，之后设置一些字段的值： void memory_region_init_io(MemoryRegion *mr, const MemoryRegionOps *ops, void *opaque, const char *name, uint64_t size) { memory_region_init(mr, name, size); mr-&gt;ops = ops; mr-&gt;opaque = opaque; mr-&gt;terminates = true; // 表示为实体类型的 MemoryRegion mr-&gt;destructor = memory_region_destructor_iomem; mr-&gt;ram_addr = ~(ram_addr_t)0; } 3.3 实际内存的分配 int main() └─ void machine-&gt;init(ram_size, ...) └─ static void pc_init_pci(ram_size, ...) // 初始化虚拟机 └─ static void pc_init1(system_memory, system_io, ram_size, ...) ├─ void memory_region_init(pci_memory, &quot;pci&quot;, ...) // pci_memory, rom_memory └─ void pc_memory_init() // 初始化内存，分配实际的物理内存地址 ├─ void memory_region_init_ram() // 创建 pc.ram, pc.rom 并分配内存 | ├─ void memory_region_init() | └─ ram_addr_t qemu_ram_alloc() | └─ ram_addr_t qemu_ram_alloc_from_ptr() | ├─ void vmstate_register_ram_global() // 将 MR 的 name 写入 RAMBlock 的 idstr | └─ void vmstate_register_ram() | └─ void qemu_ram_set_idstr() | ├─ void memory_region_init_alias() // 初始化 ram_below_4g, ram_above_4g └─ void memory_region_add_subregion() // 在 system_memory 中添加 subregions └─ static void memory_region_add_subregion_common() └─ static void memory_region_update_topology() // 为 MemoryRegion 生成 FlatView └─ static void address_space_update_topology() // as-&gt;current_map = new_view └─ static void address_space_update_topology_pass() └─ static void kvm_region_add() // region_add 对应的回调实现 └─ static void kvm_set_phys_mem() // 根据传入的 section 填充 KVMSlot └─ static int kvm_set_user_memory_region() └─ int ioctl(KVM_SET_USER_MEMORY_REGION) 之前的回调函数注册、AddressSpace 的初始化，实际上均没有对应的物理内存。顺着main()函数往下走，会来到pc_init_pci()这个函数。 函数pc_init_pci()负责在 QEMU 中初始化虚拟机，内存的虚拟化也是在这里完成的。调用machine-&gt;init()时传入了ram_size参数，表示申请内存的大小，一步步传递给了pc_init1()。 在pc_init1()中，先将ram_size分为above_4g_mem_size、below_4g_mem_size，之后调用pc_memory_init()对内存进行初始化： void *pc_memory_init(MemoryRegion *system_memory, const char *kernel_filename, const char *kernel_cmdline, const char *initrd_filename, ram_addr_t below_4g_mem_size, ram_addr_t above_4g_mem_size, MemoryRegion *rom_memory, MemoryRegion **ram_memory) { MemoryRegion *ram, *option_rom_mr; // 两个实体 MR: pc.ram, pc.rom MemoryRegion *ram_below_4g, *ram_above_4g; // 两个别名 MR: ram_below_4g, ram_above_4g /* Allocate RAM. We allocate it as a single memory region and use * aliases to address portions of it, mostly for backwards compatibility * with older qemus that used qemu_ram_alloc(). */ ram = g_malloc(sizeof(*ram)); // 创建 ram // 分配具体的内存（实际上会创建一个 RAMBlock 并将其 offset 值写入 ram.ram_addr，对应 GPA） memory_region_init_ram(ram, &quot;pc.ram&quot;, below_4g_mem_size + above_4g_mem_size); // 将 MR 的 name 写入 RAMBlock 的 idstr vmstate_register_ram_global(ram); *ram_memory = ram; // 创建 ram_below_4g 表示 4G 以下的内存 ram_below_4g = g_malloc(sizeof(*ram_below_4g)); memory_region_init_alias(ram_below_4g, &quot;ram-below-4g&quot;, ram, 0, below_4g_mem_size); // 将 ram_below_4g 挂在 system_memory 下 memory_region_add_subregion(system_memory, 0, ram_below_4g); if (above_4g_mem_size &gt; 0) { ram_above_4g = g_malloc(sizeof(*ram_above_4g)); memory_region_init_alias(ram_above_4g, &quot;ram-above-4g&quot;, ram, below_4g_mem_size, above_4g_mem_size); memory_region_add_subregion(system_memory, 0x100000000ULL, ram_above_4g); } /* ... */ } 这里的重点在于memory_region_init_ram()，它通过qemu_ram_alloc()获取ram这个 MemoryRegion 对应的 RAMBlock 的offset，并存入ram.ram_addr，这样就可以在ram_list中根据该字段查找 MR 对应的 RAMBlock： void memory_region_init_ram(MemoryRegion *mr, const char *name, uint64_t size) { memory_region_init(mr, name, size); // 填充字段，初始化默认值 mr-&gt;ram = true; // 表示为 RAM mr-&gt;terminates = true; // 表示为实体 MemoryRegion mr-&gt;destructor = memory_region_destructor_ram; mr-&gt;ram_addr = qemu_ram_alloc(size, mr); // 这里保存 RAMBlock 的 offset，即 GPA } 而qemu_ram_alloc()最终会调用qemu_ram_alloc_from_ptr()，创建一个对应大小 RAMBlock 并分配内存，返回对应的 GPA 地址存入mr-&gt;ram_addr中： ram_addr_t qemu_ram_alloc_from_ptr(ram_addr_t size, void *host, MemoryRegion *mr) { RAMBlock *new_block; // 创建一个 RAMBlock size = TARGET_PAGE_ALIGN(size); // 页对齐 new_block = g_malloc0(sizeof(*new_block)); // 初始化 new_block new_block-&gt;mr = mr; // 将 new_block-&gt; 指向入参的 MemoryRegion new_block-&gt;offset = find_ram_offset(size); // 从 ram_list 中的 RAMBlock 之间找到一段可以满足 size 需求的 gap，并返回起始地址的 offset，对应 GPA if (host) { // 新建的 RAMBlock host 字段为空，跳过 new_block-&gt;host = host; new_block-&gt;flags |= RAM_PREALLOC_MASK; } else { if (mem_path) { // 未指定 mem_path #if defined (__linux__) &amp;&amp; !defined(TARGET_S390X) new_block-&gt;host = file_ram_alloc(new_block, size, mem_path); if (!new_block-&gt;host) { new_block-&gt;host = qemu_vmalloc(size); qemu_madvise(new_block-&gt;host, size, QEMU_MADV_MERGEABLE); } #else fprintf(stderr, &quot;-mem-path option unsupported\\n&quot;); exit(1); #endif } else { if (xen_enabled()) { xen_ram_alloc(new_block-&gt;offset, size, mr); } else if (kvm_enabled()) { // 从这里继续 /* some s390/kvm configurations have special constraints */ new_block-&gt;host = kvm_vmalloc(size); // 实际上还是调用 qemu_vmalloc(size) } else { new_block-&gt;host = qemu_vmalloc(size); // 从 QEMU 的线性空间中分配 size 大小的内存，返回 HVA } qemu_madvise(new_block-&gt;host, size, QEMU_MADV_MERGEABLE); } } new_block-&gt;length = size; // 将 length 设置为 size QLIST_INSERT_HEAD(&amp;ram_list.blocks, new_block, next); // 将该 RAMBlock 插入 ram_list 头部 ram_list.phys_dirty = g_realloc(ram_list.phys_dirty, // 重新分配 ram_list.phys_dirty 的内存空间 last_ram_offset() &gt;&gt; TARGET_PAGE_BITS); memset(ram_list.phys_dirty + (new_block-&gt;offset &gt;&gt; TARGET_PAGE_BITS), 0, size &gt;&gt; TARGET_PAGE_BITS); cpu_physical_memory_set_dirty_range(new_block-&gt;offset, size, 0xff); // 对该 RAMBlock 对应的内存标记为 dirty qemu_ram_setup_dump(new_block-&gt;host, size); if (kvm_enabled()) kvm_setup_guest_memory(new_block-&gt;host, size); return new_block-&gt;offset; } 这样一来ram对应的 RAMBlock 中就分配好了 GPA 和 HVA，就可以将内存信息同步至 KVM 侧了。 最后回到pc_memory_init()中，在分配完实际内存后，会先调用memory_region_init_alias()初始化ram_below_4g、ram_above_4g这两个 alias，之后调用memory_region_add_subregion()将这两个 alias 指向ram这个实体 MemoryRegion。该函数最终会触发kvm_region_add()回调，将实际的内存信息传入 KVM 注册。该过程如下图所示，与之前分析的流程相同，此处不再赘述。 4. 总结一下4.1 QEMU 侧 创建一系列 MemoryRegion，分别表示 Guest 中的 RAM、ROM 等区域。MemoryRegion 之间通过 alias 或 subregions 的方式维护相互之间的关系，从而进一步细化区域的定义 对于一个实体 MemoryRegion（非 alias），在初始化内存的过程中 QEMU 会创建它所对应的 RAMBlock。该 RAMBlock 通过调用qemu_ram_alloc_from_ptr()从 QEMU 的进程地址空间中以 mmap 的方式分配内存，并负责维护该 MemoryRegion 对应内存的起始 GPA/HVA/size 等相关信息 AddressSpace 表示 Guest 的物理地址空间。如果 AddressSpace 中的 MemoryRegion 发生变化，则注册的 listener 会被触发，将所属的 MemoryRegion 树展开生成一维的 FlatView，比较 FlatRange 是否发生了变化。如果是则调用相应的方法对 MemoryRegionSection 进行检查，更新 QEMU 中的 KVMSlot，同时填充kvm_userspace_memory_region结构体，作为ioctl()的参数更新 KVM 中的kvm_memory_slot 4.2 KVM 侧 当 QEMU 通过ioctl()创建 vcpu 时，调用kvm_mmu_create()初始化 MMU 相关信息 当 KVM 要进入 Guest 前，vcpu_enter_guest()=&gt;kvm_mmu_reload()会将根级页表地址加载到 VMCS，让 Guest 使用该页表 当发生 EPT Violation 时，VM-EXIT 到 KVM 中。如果是缺页，则根据 GPA 算出 gfn，再根据 gfn 找到对应的 KVMSlot，从中得到对应的 HVA。然后根据 HVA 算出对应的 pfn，确保该 Page 位于内存中。填好缺失的页之后，需要更新 EPT，完善其中缺少的页表项，逐层补全页表 参考文章干货 【系列分享】QEMU 内存虚拟化源码分析 | 安全客 QEMU学习笔记——内存 | BinSite QEMU-KVM 内存虚拟化 1 | cnblogs QEMU-KVM 内存虚拟化 2 | cnblogs QEMU 中的内存管理 - 前进的code | cnblogs KVM 虚拟化原理探究（4）— 内存虚拟化 | cnblogs QEMU 内存管理之生成 FlatView 内存拓扑模型过程分析（基于QEMU 2.0.0）- eric_liufeng QEMU-KVM 内存虚拟化 | 王子阳 QEMU 对虚拟机的地址空间管理 - Jessica 要努力了 | cnblogs QEMU-KVM 部分流程/源代码分析（多图）| kk Blog QEMU 深入浅出: Guest物理内存管理 | IBM 中国 Linux 与虚拟化实验室 阿里云 Bozh 目录：KVM 虚拟化原理探究 —— 目录 | 博客园 KVM 虚拟化原理探究(1) —— Overview | 博客园 KVM 虚拟化原理探究(2) —— QEMU 启动过程 | 博客园 KVM 虚拟化原理探究(3) —— CPU 虚拟化 | 博客园 KVM 虚拟化原理探究(4) —— 内存虚拟化 | 博客园 KVM 虚拟化原理探究(5) —— 网络 I/O 虚拟化 | 博客园 KVM 虚拟化原理探究(6) —— 块设备 I/O 虚拟化 | 博客园 太初有道 目录：KVM 虚拟化技术 - 太初有道 | 博客园 intel EPT 机制详解 - 太初有道 | 博客园 KVM 中 EPT 逆向映射机制分析 - 太初有道 | 博客园 QEMU 进程页表和 EPT 的同步问题 - 太初有道 | 博客园 QEMU-KVM 内存虚拟化 1 - 太初有道 | 博客园 QEMU-KVM 内存虚拟化 2 - 太初有道 | 博客园 Linux 下的 KSM 内存共享机制分析 - 太初有道 | 博客园 KVM 中断虚拟化浅析 - 太初有道 | 博客园 KVM vCPU 线程调度问题的讨论 - 太初有道| 博客园 OenHanKVM 虚拟化 KVM 源代码分析 1: 基本工作原理 | OenHan KVM 源代码分析 2: 虚拟机的创建与运行 | OenHan KVM 源代码分析 3: CPU 虚拟化 | OenHan KVM 源代码分析 4: 内存虚拟化 | OenHan KVM 源代码分析 5: I/O 虚拟化之 PIO | OenHan QEMU 下的内存结构 MemoryRegion 和 AddressSpace | OenHan KVM CLOCK 时钟虚拟化源代码分析 | OenHan KVM MMU Page 释放机制 | OenHan 其他 TOPIC | OenHan CPU 亲和性的使用与机制 | OenHan CGROUP 源码分析 1: 基本概念与框架 | OenHan 从一次内存泄露看程序在内核中的执行过程 | OenHan Linux 缓存写回机制 | OenHan leoufung QEMU内存管理之生成 FlatView 内存拓扑模型过程分析（基于QEMU2.0.0）| CSDN QEMU 内存管理之 FlatView 模型（QEMU2.0.0）| CSDN kvm_mmu_get_page 函数解析 | CSDN tdp_page_fault 函数解析之 level, gfn 变量的含义 | CSDN QEMU 中通过 GPA 得到对应 HVA 的方法 | CSDN kvm_mmu_page 结构和用法解析（基于Kernel3.10.0）| CSDN 通过 KVM_SET_USER_MEMORY_REGION 操作虚拟机内存（Kernel 3.10.0 &amp; qemu 2.0.0）| CSDN QEMU 的 AddrRange 地址空间对象模型算法总结(QEMU2.0.0) | CSDN QEMU 内存管理之 FlatView 模型（QEMU2.0.0）| CSDN MemoryRegion 模型原理，以及同 FlatView 模型的关系(QEMU2.0.0) | CSDN 如何查看系统中都注册了哪些 MemoryRegion (QEMU2.0.0) | CSDN QEMU 中关于 CPU 初始化的重要函数调用栈 | CSDN 如何调试 QEMU | CSDN 单独编译 KVM 模块的方法(进行调试) | CSDN kvm 代码中 vcpu_vmx、vcpu、vmcs、cpu 的关系 | CSDN 论文 and PPT Fast Write Protection - 肖光荣 | PDF Nested paging hardware and software - KVM Forum 2018 | PDF Accelerating Two-Dimensional Page Walks for Virtualized Systems | PDF intel 白皮书 Intel 64 and IA-32 Architectures Software Developer’s Manual | PDF 5-Level Paging and 5-Level EPT | PDF Page Modification Logging for Virtual Machine Monitor White Paper | PDF Intel 64 架构 5 级分页和 5 级 EPT 白皮书 | 简书 EPT &amp; MMU EPT 缺页异常源码分析 | Benxi Liu VT-x/EPT 解读 | Benxi Liu 关于中断虚拟化 | Benxi Liu 梳理一下 EPT 表项的建立 | GeekBen KVM 地址翻译流程及 EPT 页表的建立过程 | CSDN tdp_page_fault 函数解析之 level，gfn 变量的含义 | CSDN EPT Page Fault Procedure KVM 中的 EPT Exception | Blogger KVM 内存访问采样（一）—— 扩展页表 EPT 的结构 | 周语馨 KVM 的 EPT 机制 | 博客园 EPT page fault procedure | KVM Mailing List 科普 VT、EPT | 简书 Memory | KVM Documents mmu.txt | KVM KVM MMU EPT 内存管理 | CSDN qemu-kvm 内存虚拟化 - ept | CSDN KVM MMU EPT 内存管理 | 学佳园 Patchwork常用网站 KVM development | Patchwork QEMU patches | Patchwork Bootlin - Elixir Cross Reference | 在线阅读 Kernel、QEMU 源码 rpmfind | 用来找 rpm 包 kernel-3.10.0-957.el7 RPM for x86_64 | rpmfind KVM: x86: implement ring-based dirty memory tracking | kvm.git 肖光荣 Fast Write Protect-v1 [0/7] KVM: MMU: fast write protect | Patchwork [1/7] KVM: MMU: correct the behavior of mmu_spte_update_no_track | Patchwork [2/7] KVM: MMU: introduce possible_writable_spte_bitmap | Patchwork [3/7] KVM: MMU: introduce kvm_mmu_write_protect_all_pages | Patchwork [4/7] KVM: MMU: enable KVM_WRITE_PROTECT_ALL_MEM | Patchwork [5/7] KVM: MMU: allow dirty log without write protect | Patchwork [6/7] KVM: MMU: clarify fast_pf_fix_direct_spte | Patchwork [7/7] KVM: MMU: stop using mmu_spte_get_lockless under mmu-lock | Patchwork 肖光荣 Fast Write Protect-v2 [v2,0/7] KVM: MMU: fast write protect | Patchwork | Patchwork [v2,1/7] KVM: MMU: correct the behavior of mmu_spte_update_no_track | Patchwork [v2,2/7] KVM: MMU: introduce possible_writable_spte_bitmap | Patchwork [v2,3/7] KVM: MMU: introduce kvm_mmu_write_protect_all_pages | Patchwork [v2,4/7] KVM: MMU: enable KVM_WRITE_PROTECT_ALL_MEM | Patchwork [v2,5/7] KVM: MMU: allow dirty log without write protect | Patchwork [v2,6/7] KVM: MMU: clarify fast_pf_fix_direct_spte | Patchwork [v2,7/7] KVM: MMU: stop using mmu_spte_get_lockless under mmu-lock | Patchwork Mailing List [PATCH v2 0/7] KVM: MMU: fast write protect | LKML Re: [Qemu-devel] [PATCH 0/7] KVM: MMU: fast write protect | gnu.org patch 教程 如何给 Linux 内核打补丁 | 一根稻草 diff 和 patch 的入门（及 Windows 下的用法）| orzfly.com 补丁(patch)的制作与应用 | Linux-Wiki.cn Linux 内核补丁与 patch/diff 使用详解 | CSDN 升级内核 Linux kernel 内核升级和降级的方法实践 | Hello Dog Linux 内核版本介绍与查询 | Jason Website 内存虚拟化基础地址空间 操作系统 内存地址（逻辑地址、线性地址、物理地址）概念 | CSDN 物理地址、虚拟地址（线性地址）、逻辑地址以及MMU的知识 | CSDN PCIe 的内存地址空间、I/O 地址空间和配置地址空间 | CSDN Linux 线性地址，逻辑地址和虚拟地址的关系？| 知乎 Linux 中的物理地址、虚拟地址、总线地址的区别 | CSDN 物理地址和总线地址的区别 | CSDN mmap 认真分析 mmap：是什么 为什么 怎么用 | cnblogs QEMU 部分 【干货！】【系列分享】QEMU内存虚拟化源码分析 | 安全客 QEMU-KVM 内存虚拟化 | 王子阳 QEMU 学习笔记 —— 内存 | BinSite QEMU 中的内存管理 - 前进的code| cnblogs QEMU 对虚拟机的地址空间管理 - Jessica 要努力了 | cnblogs QEMU 内存管理之生成 FlatView 内存拓扑模型过程分析（基于 QEMU 2.0.0）| leoufung Qemu 内存管理代码分析 1：qemu (tag: v3.0.0-rc1) 命令行配置 guest ram 及 machine_class_init 的 QOM 调用 | CSDN Qemu 内存管理主要结构体分析 2：MemoryRegion/AddressSpace/FlatView | CSDN Qemu 内存管理代码分析 3：guest ram 的初始化及分配 | CSDN qemu-kvm 部分流程/源代码分析（多图）| kk Blog QEMU深入浅出: guest物理内存管理 | IBM 中国 Linux 与虚拟化实验室 QEMU 对虚机的地址空间管理 | 阿里云栖社区 QEMU 内存管理 | 腾讯云+社区 QEMU 中的内存管理介绍 | CSDN KVM 部分 KVM 初始化过程 | liujunming.top KVM 内核模块重要的数据结构 | liujunming.top KVM 内存虚拟化及其实现 | IBM Developer CPU 体系架构 - MMU | NieNet TLB 和 MMU 的区别 | 博客园 MMU 和 Cache 详解（TLB 机制）| CSDN x86 虚拟化概述 | BinSite 其他 KVM，QEMU 核心分析 | 博客园 内存虚拟化到底是咋整的？- 腾讯云 TStack | 腾讯云+社区 从kvm场景下guest访问的内存被swap出去之后说起 | kernelnote linux 下 cpu load 和 cpu 使用率的关系 | kernelnote 关于linux下进程栈的研究 | kernelnote 虚拟化环境中的hypercall介绍 | kernelnote linux ksm 内存 merge机制研究 | kernelnote KVM 虚拟化之 VM Exit/Entry | Min’s Blog QEMU Internals: How guest physical RAM works | Stefan Hajnoczi kvm: virtual x86 mmu setup | Davidlohr Bueso GDB 调试 QEMU 源码记录 - 太初有道 | cnblogs SIG@QEMU-KVM - kernel-dev-environment | Github 向大家汇报，我们连续第二年登上KVM全球开源贡献榜 | 腾讯开源 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"}]},{"title":"Linux 下使用 Perf 分析系统性能","slug":"perf-quick-guides","date":"2019-07-07T09:46:39.000Z","updated":"2019-09-01T13:04:11.607Z","comments":true,"path":"2019/07/07/perf-quick-guides/","link":"","permalink":"https://abelsu7.top/2019/07/07/perf-quick-guides/","excerpt":"Perf 使用速查","text":"Perf 使用速查 更新中… 记得更新：linux 终端报 Message from syslogd | 51CTO 不错的文章 性能压测过程中关于 CPU 使用率的思考 | WalkerTalking 性能分析利器之 perf 浅析 | WalkerTalking 内核符号表 Linux 内核符号表 kallsyms 简介 | 阿里云栖社区 Linux 内核符号表 kallsyms | CSDN 常用工具 Linux 性能监控、测试、优化工具 | vpsee Linux Performance | Brendan Gregg 火焰图 FlameGraph 参见 perf+火焰图分析程序性能 | 博客园 # 1. Ctrl-C 结束执行后，生成采样数据 perf.data &gt; perf record -g -e cpu-cycles -p $(pidof qemu-system-x86_64) # 2. 使用 perf script 对 perf.data 进行解析 &gt; perf script -i perf.data &amp;&gt; perf.unfold # 3. 将 perf.unfold 中的符号进行折叠 &gt; ./stackcollapse-perf.pl perf.unfold &amp;&gt; perf.folded # 4. 最后生成 SVG 火焰图 &gt; ./flamegraph.pl perf.folded &gt; perf.svg 参考文章 电子书：《Linux Perf Master》- RiboseYim | 知乎 The Linux Perf Master | GitBook How to analyze your system with perf and Python | opensource.com Linux 效能分析工具: Perf | 成大資工 Wiki 2. 程序调试 | Linux Tools Quick Tutorial 5. pstack 跟踪进程栈 | Linux Tools Quick Tutorial perf-tools | Bolog Linux 性能诊断 perf 使用指南 | 阿里云栖社区 Linux perf sched Summary | Oliver Yang Linux 性能优化 9：KVM 环境 | 知乎 了解 Linux Perf 报告输出 运维利器万能的 strace | 运维生存时间 Perf 命令 | 云网牛站 系统级性能分析工具 perf 的介绍与使用 | 博客园 brendangregg/FlameGraph | Github perf+火焰图分析程序性能 | 博客园 Linux下的内核测试工具 —— perf使用简介 | 阿里云栖社区 KVM 分析工具 | hanbaoying objdump 反汇编用法示例 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux Shell 编程速查Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Perf","slug":"Perf","permalink":"https://abelsu7.top/tags/Perf/"},{"name":"性能分析","slug":"性能分析","permalink":"https://abelsu7.top/tags/性能分析/"}]},{"title":"Shell 输入/输出重定向：1>/dev/null、2>&1","slug":"shell-io-redirection","date":"2019-07-07T09:28:30.000Z","updated":"2019-09-01T13:04:11.671Z","comments":true,"path":"2019/07/07/shell-io-redirection/","link":"","permalink":"https://abelsu7.top/2019/07/07/shell-io-redirection/","excerpt":"理解 Shell 命令中 1&gt;/dev/null、2&gt;&amp;1 的含义","text":"理解 Shell 命令中 1&gt;/dev/null、2&gt;&amp;1 的含义 更新中… 参考文章 Shell 输入/输出重定向 | 菜鸟教程 Linux 输入输出重定向, &amp;&gt;file, 2&gt;&amp;1, 1&gt;&amp;2 等 | 隔夜黄莺 Yanbin Blog shell 重定向输出(1&gt;&amp;2 2&gt;&amp;1 &amp;&gt;file &gt;&amp;file) | 简书 Linux Shell 1&gt;/dev/null 2&gt;&amp;1 含义 | CSDN Shell重定向 ＆&gt;file、2&gt;&amp;1、1&gt;&amp;2 、/dev/null的区别 | CSDN 如何理解 Linux shell中“2&gt;&amp;1”？| 编程珠玑 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令Linux 终端修改 ls 命令目录显示颜色Fluent Terminal：Windows 下的炫酷终端Windows 10 终端 PowerShell 外观美化Go执行shell命令之copy命令Go执行shell命令之copy命令","categories":[{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/categories/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"}]},{"title":"QEMU-KVM 热迁移：Live Migration","slug":"qemu-kvm-live-migration","date":"2019-07-07T07:29:55.000Z","updated":"2019-10-31T08:15:29.454Z","comments":true,"path":"2019/07/07/qemu-kvm-live-migration/","link":"","permalink":"https://abelsu7.top/2019/07/07/qemu-kvm-live-migration/","excerpt":"QEMU-KVM 热迁移原理及相关源码分析","text":"QEMU-KVM 热迁移原理及相关源码分析 // TODO: To be updated… OenHan 的文章列表KVM 虚拟化 KVM源代码分析1: 基本工作原理 | OenHan KVM源代码分析2: 虚拟机的创建与运行 | OenHan KVM源代码分析3: CPU虚拟化 | OenHan KVM源代码分析4: 内存虚拟化 | OenHan KVM源代码分析5: IO虚拟化之PIO | OenHan KVMCLOCK时钟虚拟化源代码分析 | OenHan KVM MMU Page 释放机制 | OenHan 其他 TOPIC | OenHan CPU 亲和性的使用与机制 | OenHan CGROUP 源码分析 1: 基本概念与框架 | OenHan 从一次内存泄露看程序在内核中的执行过程 | OenHan LINUX 缓存写回机制 | OenHan KVM 迁移原理简介 VM 热迁移详解 | Blog Cshuo 虚拟机迁移技术漫谈 - 第一部分 | IBM Developer kernel 3.10 代码分析—KVM相关—虚拟机创建 | ChinaUnix Migration | KVM Docs Live Migration | Wikipedia Live Migrating QEMU-KVM Virtual Machines | Red Hat Developer 迁移算法 Features/PostCopyLiveMigration | QEMU KVM 的预拷贝在线迁移过程 | CSDN Post-copy live migration in QEMU | Zurich University Libvirt Live Migration 与 Pre-Copy 实现原理 | CSDN 相关论文 Live migration of virtual machines | ACM Post-copy live migration of virtual machines | ACM Better Live Migration - 腾讯云肖光荣 | PDF Live Migration: Even faster, now with a dedicated thread! - redhat | KVM Forum 2012 Real-time KVM from the ground up - redhat | LinuxCon NA 2016 iMIG: Toward an Adaptive Live Migration Method for KVM Virtual Machines | PDF Comparative Study of Live Virtual Machine Migration Techniques in Cloud | PDF KVM Live Migration Optimization | PDF PPT Comparative Study of Live Virtual Machine Migration Techniques in Cloud | PDF KVM Live Migration Optimization | PDF Enhanced Live Migration For Intensive Memory Loads | LinuxCon Japan 2015 Extending KVM with new Intel Virtualization technology | Kvm Forum 2008 QEMU Coroutines, Exposed | Red Hat QEMU 迁移源码分析 qemu-kvm-1.1.0 源码中关于迁移的代码分析 | CSDN qemu-kvm 部分流程/源代码分析（很详细的流程图） | CSDN qemu 热迁移简介 | 不忘初心，方得始终 QEMU 迁移代码分析 | 随便写写 KVM/QEMU 2.3.0 虚拟机动态迁移分析（一）| CSDN QEMU MONITOR SAVEVM LOADVM 源代码分析 | OenHan 走读 qemu 代码热迁移流程 | 任思绪在这里飞 KVM 迁移中脏页位图机制源码分析 | CSDN QEMU 迁移实践 通过qemu monitor 来测试 qemu live migration (1) | CSDN/yadeihuiyin 通过qemu monitor 来测试 qemu live migration (2) | CSDN/yadeihuiyin 通过qemu monitor 来测试 qemu live migration (3) | CSDN/yadeihuiyin KVM 介绍（8）：使用 libvirt 迁移 QEMU/KVM 虚机和 Nova 虚机 | 世民谈云计算 KVM 虚拟机静态和动态迁移 | CSDN QEMU 热迁移优化 qemu live migration 优化 1（compress and xbzrle）| CSDN/yadeihuiyin qemu live migration 优化 2（post-copy and x-multifd）| CSDN/yadeihuiyin qemu live migration 优化 3（ auto-converge）| CSDN/yadeihuiyin QEMU-KVM 中的多线程压缩迁移技术 - leoufung | CSDN 操作系统相关资料 Computer Science from the Bottom Up x86 架构操作系统内核的实现 | hurley25 计算机是如何启动的？| 阮一峰 调试 Debug Features/Migration/Troubleshooting | QEMU Wiki Documentation/Debugging | QEMU gdb Debugger Tutorial 使用 gdb debug libvirt 心得 | CSDN/yadeihuiyin VMs go to 100% CPU after live migration from Trusty to Bionic | Ubuntu qemu package 100% CPU utilisation and hang after virsh migrate | Unix &amp; Linux Complete Live Migration of VMs with High Load | Server24 qemu-kvm stuck at 100% cpu after live migration with spice,then guest time goes very fast | Red Hat Bugzilla 压测工具 lookbusy - a synthetic load generator CPU Steal time KVM 下 STEAL_TIME 源代码分析 | OenHan 理解 CPU steal time | CSDN 谁偷走了我的云主机 CPU 时间：理解 CPU Steal Time | 知乎 理解 CPU steal time | 博客园 CPU到底在忙啥？CPU利用率的正确计算方法 | 搜狐科技 Understanding CPU Steal Time - when should you be worried? Are We Stealing from You? Understanding CPU Steal Time in the Cloud CPU State CPU C-States 省电模式 | 新浪博客 CPU 的运行环、特权级与保护 | CSDN VMCS VMX(2) — VMCS理解 - 河马虚拟化 | 知乎 如何阅读内核源码 Bootlin - 在线阅读内核源码 | Elixir Cross Referencer 如何阅读 Linux 内核源码 | 知乎 Linux 内核源码阅读（一）从何处阅读源码 | CSDN 献给新手，如何阅读 Linux 源码(转) | CSDN KVM 关于 Fast Write Protect 的 Patch [PATCH 0/7] KVM: MMU: fast write protect | LKML [5/7] KVM: MMU: allow dirty log without write protect | Patchwork - QEMU Development dirty pages 脏页同步 qemu/kvm dirty pages tracking in migration | 不忘初心，方得始终 KVM 同步脏页位图到 QEMU | tobyjiang KVM 异常处理流程源码简要分析 - Mr_buffoon | CSDN KVM 迁移中脏页位图机制源码分析 - Mr_buffoon | CSDN 参考文章 Libvirt支持的三种CPU模式与热迁移(by Joshua) Libvirt支持的三种CPU模式与热迁移(by Joshua) | CSDN 虚拟化在线迁移优化实践（二）：KVM虚拟化跨机迁移优化指南 | UCloud 云计算 Linux KVM 在线迁移实战 | Cloud Atlas huataihuang/Cloud Atlas Draft | GitBook huataihuang/Cloud Atlas Draft | Github 热迁移、RTC 计时与安全加固…腾讯云 KVM 性能优化实践验谈 | InfoQ 热迁移、RTC 计时与安全增强…腾讯云 KVM 性能优化实践经验谈 | 腾讯云+社区 内存管理之：页和页框&amp;地址变换结构 | CSDN KVM 虚拟迁移 | ICode9 浅析 QEMU 热迁移特性 - Multifd | 滴滴云 QEMU 中 Bitmap 的应用 | 滴滴云 美团云“零感知”在线迁移解决方案 | 驱动中国 docs: Fix generating qemu-doc.html with texinfo 5 | QEMU Development Errors in makefile for qemu 0.14.1 in ubuntu 15.04 64 bit | StackOverflow Windows 虚拟机对应的 QEMU 进程 CPU 占有率 116% | 代码天地 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"},{"name":"热迁移","slug":"热迁移","permalink":"https://abelsu7.top/tags/热迁移/"}]},{"title":"Fluent Terminal：Windows 下的炫酷终端","slug":"windows-fluent-terminal","date":"2019-07-03T03:43:40.000Z","updated":"2019-09-01T13:04:11.778Z","comments":true,"path":"2019/07/03/windows-fluent-terminal/","link":"","permalink":"https://abelsu7.top/2019/07/03/windows-fluent-terminal/","excerpt":"A Terminal Emulator based on UWP and web technologies.","text":"A Terminal Emulator based on UWP and web technologies. 1. Fluent Terminal 简介 支持PowerShell、CMD、WSL或其他自定义终端 Built-in support for SSH 多标签、多窗口 便捷的主题与外观配置 支持导入/导出主题 支持导入iTerm主题 全屏模式 Ctrl-F搜索 支持快捷键编辑 支持配置shell profiles 2. 安装 Fluent Terminal 注：需要更新至Windows 10 Fall Creators Update参考 How to install(as an end-user) 首先安装 Chocolatey，以管理员身份运行cmd.exe，运行以下命令： @&quot;%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe&quot; -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command &quot;iex ((New-Object System.Net.WebClient).DownloadString(&#39;https://chocolatey.org/install.ps1&#39;))&quot; &amp;&amp; SET &quot;PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin&quot; 安装完成后，使用choco -v命令验证Chocolatey是否已正确安装： PS C:\\Users\\abel1&gt; choco -v 0.10.15 PS C:\\Users\\abel1&gt; choco list -l Chocolatey v0.10.15 chocolatey 0.10.15 fluent-terminal 0.4.1.0 PowerShell 5.1.14409.20180811 3 packages installed. 之后使用choco安装fluent-terminal： PS C:\\Users\\abel1&gt; choco install fluent-terminal 3. 常用快捷键 Function Key Tab 向前 Ctrl-Tab Tab 向后 Ctrl-Shift-Tab 新建 Tab Ctrl-T 选择 Profile 新建 Tab Ctrl-Shift-T 更改 Tab 标题 Ctrl-Shift-R 关闭 Tab Ctrl-W 新建 Window Ctrl-N 选择 Profile 新建 Window Ctrl-Shift-N 打开 Settings Ctrl-, 复制 Ctrl-Shift-C 粘贴 Ctrl-Shift-V 搜索 Ctrl-F 全屏 Alt-Enter 全选 Ctrl-A 快速切换 Tab Ctrl-1~9 4. 效果图 参考文章 felixse/FluentTerminal | Github screenFetch - The Bash Screenshot Information Tool | Github Chocolatey - The package manager for Windows 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 终端修改 ls 命令目录显示颜色Shell 输入/输出重定向：1>/dev/null、2>&1Windows 10 终端 PowerShell 外观美化几款监控 CPU 温度的软件推荐Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"},{"name":"Fluent Terminal","slug":"Fluent-Terminal","permalink":"https://abelsu7.top/tags/Fluent-Terminal/"},{"name":"PowerShell","slug":"PowerShell","permalink":"https://abelsu7.top/tags/PowerShell/"}]},{"title":"Chrome 插件 Vimium：键盘党的胜利","slug":"chrome-extension-vimium","date":"2019-06-13T14:22:21.000Z","updated":"2019-09-01T13:04:11.035Z","comments":true,"path":"2019/06/13/chrome-extension-vimium/","link":"","permalink":"https://abelsu7.top/2019/06/13/chrome-extension-vimium/","excerpt":"插件地址：Vimium | Chrome Web Store","text":"插件地址：Vimium | Chrome Web Store 1. 常用快捷键 查看帮助按? 2. 页面导航2.1 滚屏/翻页 Vimium Function Chrome j 向下滚动 ↓ k 向上滚动 ↑ h 向左滚动 ← l 向右滚动 → d 向下翻页 PageDown u 向上翻页 PageUp 2.2 Home/End Vimium Function Chrome gg 前往页面顶部 Ctrl+Home G 前往页面底部 Ctrl+End 2.3 刷新/查看源码 Vimium Function Chrome r 刷新页面 Ctrl+R gs 查看页面源码 Ctrl+U 2.4 URL 复制粘贴 Vimium Function yy 复制当前页面地址 yf 复制某一链接地址 p 在当前标签页中打开复制的 URL P 在新标签页中打开复制的 URL i 进入 insert mode，使用网站默认的快捷键 2.5 打开链接/书签/历史 Vimium Function f 在当前标签页打开链接 F 在新标签页打开链接 o 在当前标签页打开 URL/书签/历史 O 在新标签页打开 URL/书签/历史 T 搜索已打开的标签页 b 在当前标签页打开书签 B 在新标签页打开书签 2.6 切换 Frame Vimium Function gf 切换 Frame 3. 查找 Vimium Function Chrome / 进入 find mode Ctrl+F n 下一个匹配 Enter N 上一个匹配 Shift+Enter 4. 前进后退 Vimium Function Chrome H 后退 Alt ← L 前进 Alt → 5. 标签页 Vimium Function Chrome K，gt 前往右侧 Tab Ctrl+PageDown J，gT 前往左侧 Tab Ctrl+PageUp g0 第一个 Tab Ctrl+1 g$ 最后一个 Tab t 新建 Tab Ctrl+T yt 在新 Tab 中打开当前 Tab Alt+P 固定当前 Tab Alt+M 静音当前 Tab x 关闭当前 Tab Ctrl+W X 重新打开关闭的 Tab Ctrl+Shift+T 参考文章 让你用 Chrome 上网快到想哭：Vimium | 少数派 15 分钟入门 Chrome 神器 Vimium | 简书 vimium | Github Vimium | Chrome Web Store Vimium 下的 insert mode 有什么用？怎么用？| 知乎 🚩推荐阅读（由hexo文章推荐插件驱动）Oh My Zsh/NeoVim/Tmux 打造终端 IDEVim 入坑不完全指北","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"https://abelsu7.top/tags/Chrome/"},{"name":"Vimium","slug":"Vimium","permalink":"https://abelsu7.top/tags/Vimium/"},{"name":"Vim","slug":"Vim","permalink":"https://abelsu7.top/tags/Vim/"}]},{"title":"Windows 10 终端 PowerShell 外观美化","slug":"windows-powershell-beautify","date":"2019-06-13T12:21:30.000Z","updated":"2019-09-16T14:51:07.808Z","comments":true,"path":"2019/06/13/windows-powershell-beautify/","link":"","permalink":"https://abelsu7.top/2019/06/13/windows-powershell-beautify/","excerpt":"摘自 告别 Windows 终端的难看难用，从改造 PowerShell 的外观开始 | 少数派","text":"摘自 告别 Windows 终端的难看难用，从改造 PowerShell 的外观开始 | 少数派 待更新… 配置文件路径： C:\\Users\\abelsu7\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 主要看这两篇： 将美化进行到底，把 PowerShell 做成 oh-my-zsh 的样子 | walterlv 吕毅 PowerShell 美化：oh my posh | Flymia 参考文章 告别 Windows 终端的难看难用，从改造 PowerShell 的外观开始 | 少数派 5 个 PowerShell 主题，让你的 Windows 终端更好看 | 少数派 为什么 Windows 的终端（如命令提示符、PowerShell）都这么丑？| 知乎 将美化进行到底，把 PowerShell 做成 oh-my-zsh 的样子 | walterlv 吕毅 PowerShell 美化：oh my posh | Flymia oh-my-posh | Github Sarasa Gothic / 更纱黑体 | Github FluentTerminal | Github Chocolatey | The package manager for Windows 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 终端修改 ls 命令目录显示颜色Shell 输入/输出重定向：1>/dev/null、2>&1Fluent Terminal：Windows 下的炫酷终端几款监控 CPU 温度的软件推荐Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"},{"name":"PowerShell","slug":"PowerShell","permalink":"https://abelsu7.top/tags/PowerShell/"},{"name":"oh-my-posh","slug":"oh-my-posh","permalink":"https://abelsu7.top/tags/oh-my-posh/"}]},{"title":"Linux Shell 编程速查","slug":"linux-shell-examples","date":"2019-06-10T07:16:16.000Z","updated":"2019-09-01T13:04:11.508Z","comments":true,"path":"2019/06/10/linux-shell-examples/","link":"","permalink":"https://abelsu7.top/2019/06/10/linux-shell-examples/","excerpt":"摘自 这些必备的 Linux shell知识你都掌握了吗 | Linux 学习","text":"摘自 这些必备的 Linux shell知识你都掌握了吗 | Linux 学习 1. 入参和默认变量/root/sh-utils/test.sh para1 para2 para3 $0 $1 $2 $3 脚本名 第一个参数 第三个参数 $0：执行的脚本名 $1：第一个参数 $2：第二个参数 $#：脚本后面传入的参数个数 $@：所有参数，并且可以被遍历 $*：所有参数，不加引号时与$@相同，具体区别请移步 参考文章 $?：上一条命令的退出状态 两个$：当前脚本的进程 ID 2. 变量使用=给变量赋值： para1=&quot;hello world&quot; # 字符串直接赋给变量 para1 注意：=两边不能有空格，等号右边有空格的字符串也必须用引号括起来 使用unset取消变量： unset para1 使用变量时，需要在变量前添加$，或者变量名两边添加{}： #!/bin/bash para1=&quot;hello world&quot; echo &quot;para1 is $para1&quot; echo &quot;para1 is ${para1}!&quot; ------ para1 is hello world para1 is hello world! 3. 命令执行#!/bin/bash # save command output into var hostname=`hostname` echo $hostname # call command in string echo &quot;Current path is $(pwd)&quot; # use double (()) to calculate an expression echo &quot;36+52=$((36+52))&quot; # command as a string kernel=&quot;uname -r&quot; echo &quot;kernel is $($kernel)&quot; # several commands as a string cmd=&quot;ls;pwd&quot; echo &quot;$(eval $cmd)&quot; ------ centos-2 Current path is /root/GithubProjects/sh-utils 36+52=88 kernel is 3.10.0-862.14.4.el7.x86_64 24-bit-color.sh docker-k8s-images.sh export-http-proxy.sh get-wechat-cover.sh ssr.sh start-goland.sh test.sh tmux-tools /root/GithubProjects/sh-utils 4. 条件分支if 语句一般来说，如果命令成功执行，则其返回值为0，因此可通过下面的方式判断上一条命令的执行结果： if [ $? -eq 0 ] then echo &quot;success&quot; elif [ $? -eq 1 ] then echo &quot;failed,code is 1&quot; else echo &quot;other code&quot; fi case 语句case语句的使用方法如下： name=&quot;aa&quot; name=&quot;aa&quot; case $name in &quot;aa&quot;) echo &quot;name is $name&quot; ;; &quot;&quot;) echo &quot;name is empty&quot; ;; &quot;bb&quot;) echo &quot;name is $name&quot; ;; *) echo &quot;other name&quot; ;; esac 需要注意以下几点： []前面要有空格，里面是逻辑表达式 if elif后面要跟then，之后才是要执行的语句 如果想打印上一条命令的执行结果，最好的做法是将$?赋给一个变量，因为一旦执行了一条命令，$?的值就可能会变 case语句的每个分支最后以两个;;结尾，最后是esac 使用多个条件有两种写法： if [ 10 -gt 5 -o 10 -gt 4 ];then echo &quot;10&gt;5 or 10&gt;4&quot; fi # 或者 if [ 10 -gt 5 ] || [ 10 -gt 4 ];then echo &quot;10&gt;5 or 10&gt;4&quot; fi -a，同&amp;&amp;，表示与 -o，同||，表示或 !，表示非 整数判断 -eq：两数是否相等 -ne：两数是否不等 -gt：前者是否大于后者 -lt：前者是否小于后者 -ge：前者是否大于等于后者 -le：前者是否小于等于后者 文件目录判断 -f $filename：是否为文件 -e $filename：是否存在 -d $filename：是否为目录 -s $filename：文件存在且不为空 ! -s $filename：文件是否为空 5. 循环for in遍历输出脚本的参数： # 遍历输出脚本的参数 for i in $@; do echo $i done 还可以指定循环变量范围： for i in {1..5}; do echo &quot;Welcome $i&quot; done 在此基础上指定循环步长： for i in {5..15..3}; do echo &quot;number is $i&quot; done for dofor ((i = 0 ; i &lt; 10 ; i++)); do echo $i done while dowhile [ &quot;$ans&quot; != &quot;yes&quot; ] do read -p &quot;please input yes to exit loop: &quot; ans done until doans=&quot;yes&quot; until [ &quot;$ans&quot; != &quot;yes&quot; ] do read -p &quot;please input yes to continue loop: &quot; ans done 6. 函数函数定义如下： myfunc() { echo &quot;Hello! $1&quot; } 或者： function myfunc() { echo &quot;Hello! $1&quot; } 函数调用： para1=&quot;abelsu7&quot; myfunc $para1 7. 返回值通常函数的return返回值只支持0-255，因此想要获得其他形式的返回值，可以通过下面的方式： function myfunc() { local myresult=&quot;some value&quot; echo $myresult } val=$(myfunc) # val 的值为 some value 通过return的方式适用于判断函数的执行是否成功： function myfunc() { # do something return 0 } if myfunc;then echo &quot;success&quot; else echo &quot;failed&quot; fi 8. 注释#!/bin/bash # 这是单行注释 : &lt;&lt; ! 注释 1 注释 2 注释 3 ! : &#39; 注释 1 注释 2 注释 3 &#39; : &lt;&lt; EOF 注释 1 注释 2 注释 3 EOF : &lt;&lt; 字符 # 数字或者字符均可 注释 1 注释 2 注释 3 字符 # 要与之前的字符相同 9. 日志保存脚本执行后免不了要记录日志，常用的方法是重定向。 方式一，将标准输出保存到文件中，并在控制台打印标准错误： ./test.sh &gt; log.dat 方式二，将标准输出和标准错误都保存到日志文件中： ./test.sh &gt; log.dat 2&gt;&amp;1 方式三，保存日志文件的同时，也输出到控制台： ./test.sh |tee log.dat 10. 脚本执行./test.sh # 最常见的执行方式 sh test.sh # 在子进程中执行 sh -x test.sh # 会在终端打印执行的命令，适合调试 source test.sh # 在父进程中执行 . test.sh # 不需要赋予执行权限，临时执行 11. 脚本退出码很多时候我们需要获取脚本的执行结果，即退出状态。通常0表示执行成功，而非0表示执行失败。 为了获得退出码，我们需要使用exit，例如： #!/bin/bash function myfun() { if [ $# -lt 2 ] then echo &quot;para num error&quot; exit 1 fi echo &quot;ok&quot; exit 2 } if [ $# -lt 1 ] then echo &quot;para num error&quot; exit 1 fi returnVal=`myfun aa` echo &quot;end shell&quot; exit 0 这里需要注意的是，使用： returnVal=`myfun aa` 这样的语句来执行函数，即使函数里面有exit，它也不会退出脚本执行，而只是会退出该函数。这是因为exit是退出当前进程，而这种方式执行函数，相当于fork了一个子进程，因此不会退出当前脚本。 所以无论你的函数参数是什么，最后都会打印： ./test.sh;echo $? 0 参考文章 这些必备的 Linux Shell 知识你都掌握了吗 | Linux 学习 如何理解 Linux shell中“2&gt;&amp;1”？| 编程珠玑 Shell $* 和 $@ 的区别 | C 语言中文网 Shell $* 与 $@ 的区别 | 博客园 linux bash shell 中，单引号、 双引号，反引号（``）的区别及各种括号的区别 | CSDN 【Shell】单行注释和多行注释 | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/categories/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"}]},{"title":"VS Code 配置 Go 开发环境","slug":"go-in-vscode","date":"2019-06-10T03:45:03.000Z","updated":"2019-09-01T13:04:11.254Z","comments":true,"path":"2019/06/10/go-in-vscode/","link":"","permalink":"https://abelsu7.top/2019/06/10/go-in-vscode/","excerpt":"参见 Go in Visual Studio Code | VS Code","text":"参见 Go in Visual Studio Code | VS Code 自动补全 VS Code 中的代码自动补全和自动导入包 | 茶歇驿站 VS Code 的 golang 开发配置之代码提示 | 博客园 stamblerre/gocode | Github GOPATH GOPATH in the VS Code Go extension | Github/vscode-go 参考文章 Go in Visual Studio Code | VS Code GOPATH in the VS Code Go extension | Github/vscode-go VS Code 中的代码自动补全和自动导入包 | 茶歇驿站 VS Code 的 golang 开发配置之代码提示 | 博客园 stamblerre/gocode | Github 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://abelsu7.top/tags/VS-Code/"}]},{"title":"几款监控 CPU 温度的软件推荐","slug":"tools-for-monitor-cpu-temp","date":"2019-06-10T03:06:25.000Z","updated":"2019-09-01T13:04:11.708Z","comments":true,"path":"2019/06/10/tools-for-monitor-cpu-temp/","link":"","permalink":"https://abelsu7.top/2019/06/10/tools-for-monitor-cpu-temp/","excerpt":"摘自 How to Monitor Your Computer’s CPU Temperature | How-To Geek","text":"摘自 How to Monitor Your Computer’s CPU Temperature | How-To Geek 1. Core Temp 传送门 Core Temp Core Temp 2. HWMonitor 传送门 HWMonitor HWMonitor 3. Linux lm_sensors：sensors命令 xsensors s-tui 参考文章 How to Monitor Your Computer’s CPU Temperature | How-To Geek Core Temp HWMonitor 🚩推荐阅读（由hexo文章推荐插件驱动）Fluent Terminal：Windows 下的炫酷终端Windows 10 终端 PowerShell 外观美化Windows 10 彻底删除已配对的蓝牙设备开源下载工具aria2使用教程Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"}]},{"title":"Go Modules 配置 GOPROXY","slug":"go-module-using-goproxy-io","date":"2019-06-06T08:12:06.000Z","updated":"2019-11-01T07:55:14.996Z","comments":true,"path":"2019/06/06/go-module-using-goproxy-io/","link":"","permalink":"https://abelsu7.top/2019/06/06/go-module-using-goproxy-io/","excerpt":"goproxy.io is a global proxy for Go Modules.","text":"goproxy.io is a global proxy for Go Modules. 1. Linux/MacOS# Enable the go modules feature export GO111MODULE=on # Set the GOPROXY environment variable export GOPROXY=https://goproxy.io 2. Windows# Enable the go modules feature $env:GO111MODULE=&quot;on&quot; # Set the GOPROXY environment variable $env:GOPROXY=&quot;https://goproxy.io&quot; 3. go 1.13+go env -w GOPROXY=https://goproxy.io,direct # Set environment variable allow bypassing the proxy for selected modules go env -w GOPRIVATE=*.corp.example.com 参考文章goproxy goproxy.io goproxy.cn Go Mod Using Go Modules | The Go Blog Migrating to Go Modules | The Go Blog 拜拜了，GOPATH 君！新版本 Golang 的包管理入门教程 | 知乎 Go module 机制下升级 major 版本号的实践 | TonyBai VSCode 配置 Go 环境及 Go mod 使用 | YSICING go mod 使用 | 掘金 VSCode 配置 Go 环境及 Go mod 使用 | 方缘之道 开始使用 Go Module - isLishude | 知乎 Go Modules 详解 | 后端进阶 Go Modules 不完全教程 | Golang 成神之路 Go Modules 不完全教程 - Golang Inside | 知乎专栏 Go Module 使用实践及问题解决 | banyu 【干货】Go Modules 内部分享 | Xuanwo’s Blog 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Go Modules","slug":"Go-Modules","permalink":"https://abelsu7.top/tags/Go-Modules/"},{"name":"GOPROXY","slug":"GOPROXY","permalink":"https://abelsu7.top/tags/GOPROXY/"}]},{"title":"Golang ORM 框架：GORM","slug":"gorm-notes","date":"2019-06-05T01:36:50.000Z","updated":"2019-10-31T10:08:26.827Z","comments":true,"path":"2019/06/05/gorm-notes/","link":"","permalink":"https://abelsu7.top/2019/06/05/gorm-notes/","excerpt":"GORM is a fantastic ORM library for Golang.","text":"GORM is a fantastic ORM library for Golang. // TODO: To be updated… 目录1. 快速开始1.1 GORM 概述 全功能 ORM（几乎） 关联（包含一个/包含多个/属于/多对多/多态） Callbacks（在创建/保存/更新/删除/查找之前或之后） 预加载 事务 复合主键 SQL Builder 数据库自动迁移 自定义日志 可扩展性，可基于 GORM 回调编写插件 每个功能都有测试 开发人员友好 1.2 安装&gt; go get -u github.com/jinzhu/gorm 1.3 快速体验以MySQL为例： package main import ( &quot;fmt&quot; &quot;github.com/jinzhu/gorm&quot; _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot; ) type Product struct { gorm.Model Code string Price uint } func main() { // 初始化 MySQL 连接 config := fmt.Sprintf(&quot;%s:%s@tcp(%s)/%s?charset=utf8&amp;parseTime=%t&amp;loc=%s&quot;, &quot;your_username&quot;, &quot;your_password&quot;, &quot;host:port&quot;, &quot;database&quot;, true, &quot;Local&quot;) db, err := gorm.Open(&quot;mysql&quot;, config) if err != nil { panic(&quot;Failed to connect database&quot;) } defer db.Close() // Migrate the schema db.AutoMigrate(&amp;Product{}) // 创建 db.Create(&amp;Product{ Code: &quot;L1212&quot;, Price: 1000, }) // 读取 var product Product db.First(&amp;product, 1) // 查询 ID 为 1 的 Product db.First(&amp;product, &quot;code = ?&quot;, &quot;L1212&quot;) // 查询 code 为 L1212 的 Product // 更新 - 更新 product 的 price 为 2000 db.Model(&amp;product).Update(&quot;price&quot;, 2000) // 删除 - 删除 product db.Delete(&amp;product) } 2. 数据库2.1 连接数据库首先需要导入目标数据库的驱动程序。例如： import _ &quot;github.com/go-sql-driver/mysql&quot; 为了方便记住导入路径，GORM包装了一些驱动： import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot; // import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot; // import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot; // import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot; MySQL注意：为了处理time.Time，需要包括parseTime作为参数。更多支持的参数 import ( &quot;github.com/jinzhu/gorm&quot; _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot; ) func main() { db, err := gorm.Open(&quot;mysql&quot;, &quot;user:password@/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local&quot;) defer db.Close() } 也可以参照之前的形式来写： // 初始化 MySQL 连接 config := fmt.Sprintf(&quot;%s:%s@tcp(%s)/%s?charset=utf8&amp;parseTime=%t&amp;loc=%s&quot;, &quot;your_username&quot;, &quot;your_password&quot;, &quot;host:port&quot;, &quot;database&quot;, true, &quot;Local&quot;) db, err := gorm.Open(&quot;mysql&quot;, config) if err != nil { panic(&quot;Failed to connect database&quot;) } defer db.Close() PostgreSQLimport ( &quot;github.com/jinzhu/gorm&quot; _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot; ) func main() { db, err := gorm.Open(&quot;postgres&quot;, &quot;host=myhost user=gorm dbname=gorm sslmode=disable password=mypassword&quot;) defer db.Close() } SQLite3import ( &quot;github.com/jinzhu/gorm&quot; _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot; ) func main() { db, err := gorm.Open(&quot;sqlite3&quot;, &quot;/tmp/gorm.db&quot;) defer db.Close() } 2.2 迁移 Migrate自动迁移（Auto Migrate）模式将自动保持更新到最新。 注意：自动迁移仅仅会创建表以及缺少的列和索引，并不会改变现有列的类型或删除未使用的列，以保护数据 db.AutoMigrate(&amp;User{}) db.AutoMigrate(&amp;User{}, &amp;Product{}, &amp;Order{}) // 创建表时添加表后缀 db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Product{}) 2.3 检查表是否存在// 检查模型`User`对应的表是否存在 db.HasTable(&amp;User{}) // 检查表`users`是否存在 db.HasTable(&quot;users&quot;) 2.4 创建表// 为模型`User`创建表 db.CreateTable(&amp;User{}) // 创建表`users`时将&quot;ENGINE=InnoDB&quot;附加到SQL语句 db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).CreateTable(&amp;User{}) 2.5 删除表// 删除模型`User`的表 db.DropTable(&amp;User{}) // 删除表`users` db.DropTable(&quot;users&quot;) // 删除模型`User`的表和表`products` db.DropTableIfExists(&amp;User{}, &quot;products&quot;) 2.6 修改列// 修改模型`User`的description列的数据类型为`text` db.Model(&amp;User{}).ModifyColumn(&quot;description&quot;, &quot;text&quot;) 2.7 删除列// 删除模型`User`的description列 db.Model(&amp;User{}).DropColumn(&quot;description&quot;) 2.8 添加外键// 添加外键 // 1st param : 外键字段 // 2nd param : 外键表(字段) // 3rd param : ONDELETE // 4th param : ONUPDATE db.Model(&amp;Product{}).AddForeignKey(&quot;city_id&quot;, &quot;cities(id)&quot;, &quot;RESTRICT&quot;, &quot;RESTRICT&quot;) 2.9 索引// 为`name`列添加索引`idx_user_name` db.Model(&amp;User{}).AddIndex(&quot;idx_user_name&quot;, &quot;name&quot;) // 为`name`, `age`列添加索引`idx_user_name_age` db.Model(&amp;User{}).AddIndex(&quot;idx_user_name_age&quot;, &quot;name&quot;, &quot;age&quot;) // 添加唯一索引 db.Model(&amp;User{}).AddUniqueIndex(&quot;idx_user_name&quot;, &quot;name&quot;) // 为多列添加唯一索引 db.Model(&amp;User{}).AddUniqueIndex(&quot;idx_user_name_age&quot;, &quot;name&quot;, &quot;age&quot;) // 删除索引 db.Model(&amp;User{}).RemoveIndex(&quot;idx_user_name&quot;) 3. 模型3.1 模型定义package model import ( &quot;database/sql&quot; &quot;time&quot; &quot;github.com/jinzhu/gorm&quot; ) type User struct { gorm.Model Birthday time.Time Age int Name string `gorm:&quot;size:255&quot;` // string 长度默认为 255 Num int `gorm:&quot;AUTO_INCREMENT&quot;` // 自增 CreditCard CreditCard // One-To-One (拥有一个 - CreditCard 表的 UserID 作外键) Emails []Email // One-To-Many (拥有多个 - Email 表的 UserID 作外键) BillingAddress Address // One-To-One (属于 - 本表的 BillingAddressID 作外键) BillingAddressID sql.NullInt64 ShippingAddress Address // One-To-One (属于 - 本表的 ShippingAddressID 作外键) ShippingAddressId int IgnoreMe int `gorm:&quot;-&quot;` // 忽略这个字段 Languages []Language `gorm:&quot;many2many:user_languages；&quot;` // Many-To-Many , `user_languages` 是连接表 } type Email struct { ID int UserID int `gorm:&quot;index&quot;` // 外键 (属于), tag `index` 是为该列创建索引 Email string `gorm:&quot;type:varchar(100);unique_index&quot;` // `type` 设置 sql 类型，`unique_index` 为该列设置唯一索引 Subscribed bool } type Address struct { ID int Address1 string `gorm:&quot;not null;unique&quot;` // 设置该字段非空且唯一 Address2 string `gorm:&quot;type:varchar(100);unique&quot;` Post sql.NullString `gorm:&quot;not null&quot;` } type Language struct { ID int Name string `gorm:&quot;index:idx_name_code&quot;` // 创建索引并命名，如果找到其他相同名称的索引则创建组合索引 Code string `gorm:&quot;index:idx_name_code&quot;` // `unique_index` also works } type CreditCard struct { gorm.Model UserID uint Number string } 3.2 约定gorm.Model 结构体基本模型定义gorm.Model，包括字段ID、CreatedAt、UpdatedAt、DeletedAt。 gorm.Model在gorm目录下的model.go中定义： // Model base model definition, including fields `ID`, `CreatedAt`, `UpdatedAt`, `DeletedAt`, which could be embedded in your models // type User struct { // gorm.Model // } type Model struct { ID uint `gorm:&quot;primary_key&quot;` CreatedAt time.Time UpdatedAt time.Time DeletedAt *time.Time `sql:&quot;index&quot;` } 可以将它嵌入你的模型，或者只写需要的字段： // 添加字段 `ID`，`CreatedAt`，`UpdatedAt`，`DeletedAt` type User struct { gorm.Model Name string } // 只需要字段 `ID`，`CreatedAt` type User struct { ID uint CreatedAt time.Time Name string } 表名是结构体名的复数type User struct {} // 默认表名是 `users` // 设置 User 的表名为 `profiles` func (User) TableName() string { return &quot;profiles&quot; } func (u User) TableName() string { if u.Role == &quot;admin&quot; { return &quot;admin_users&quot; } else { return &quot;users&quot; } } // 全局禁用表名负数 db.SingularTable(true) // 如果设置为 true,`User` 的默认表名为 `user`，使用 `TableName` 设置的表名不受影响 更改默认表名可以通过定义DefaultTableNameHandler对默认表名应用任何规则： gorm.DefaultTableNameHandler = func (db *gorm.DB, defaultTableName string) string { return &quot;prefix_&quot; + defaultTableName; } 列名是字段名的蛇形小写type User struct { ID uint // 列名为 `id` Name string // 列名为 `name` Birthday time.Time // 列名为 `birthday` CreatedAt time.Time // 列名为 `created_at` } // 重设列名 type Animal struct { AnimalID int64 `gorm:&quot;column:beast_id&quot;` // 设置列名为 `beast_id` Birthday time.Time `gorm:&quot;column:day_of_the_beast&quot;` // 设置列名为 `day_of_the_beast` Age int64 `gorm:&quot;column:age_of_the_beast&quot;` // 设置列名为 `age_of_the_beast` } 字段 ID 为默认主键type User struct { ID uint // 字段 `ID` 为默认主键 Name string } // 使用 tag `primary_key` 来设置主键 type Animal struct { AnimalID int64 `gorm:&quot;primary_key&quot;` // 设置 AnimalID 为主键 Name string Age int64 } 字段 CreatedAt 存储创建时间创建具有CreatedAt字段的记录将被设置为当前时间： db.Create(&amp;user) // 将会设置 `CreatedAt` 为当前时间 // 使用 `Update` 来更改它的值 db.Model(&amp;user).Update(&quot;created_at&quot;, time.Now()) 字段 UpdatedAt 存储修改时间保存具有UpdatedAt字段的记录将被设置为当前时间： db.Save(&amp;user) // 将会设置 `UpdatedAt` 为当前时间 db.Model(&amp;user).Update(&quot;name&quot;, &quot;jinzhu&quot;) // 将会设置 `UpdatedAt` 为当前时间 字段 DeletedAt 用于存储删除时间 删除具有DeletedAt字段的记录时，记录本身不会从数据库中删除，只是将字段DeletedAt设置为当前时间，并且该记录在查询时无法被找到，即软删除。 3.3 关联Belongs To A belongs to association sets up a one-to-one connection with another model, such that each instance of the declaring model “belongs to” one instance of the other model. 例如，如果您的应用程序包含用户和配置文件，并且可以将每个配置文件分配给一个用户： type User struct { gorm.Model Name string } // `Profile` belongs to `User`, `UserID` is the foreign key type Profile struct { gorm.Model UserID int User User Name string } 4. Code Snippets// Enable Logger, show detailed log db.LogMode(true) // Disable Logger, don&#39;t show any log db.LogMode(false) // Debug a single operation, show detailed log for this operation db.Debug().Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).First(&amp;User{}) 5. 高级用法 参见 1.6. 高级用法 · GORM 中文文档 5.1 错误处理执行任何操作后，如果发生任何错误，GORM 会将其设置为*DB的Error字段： if err := db.Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).First(&amp;user).Error; err != nil { // 错误处理... } // 如果有多个错误发生，用`GetErrors`获取所有的错误，它返回`[]error` db.First(&amp;user).Limit(10).Find(&amp;users).GetErrors() // 检查是否返回 RecordNotFound 错误 db.Where(&quot;name = ?&quot;, &quot;hello world&quot;).First(&amp;user).RecordNotFound() if db.Model(&amp;user).Related(&amp;credit_card).RecordNotFound() { // 没有信用卡被发现处理... } 5.2 事务要在事务中执行一组操作，一般流程如下： // 开始事务 tx := db.Begin() // 在事务中做一些数据库操作（从这一点使用&#39;tx&#39;，而不是&#39;db&#39;） tx.Create(...) // ... // 发生错误时回滚事务 tx.Rollback() // 或提交事务 tx.Commit() 一个具体的例子： func CreateAnimals(db *gorm.DB) err { tx := db.Begin() // 注意，一旦你在一个事务中，使用tx作为数据库句柄 if err := tx.Create(&amp;Animal{Name: &quot;Giraffe&quot;}).Error; err != nil { tx.Rollback() return err } if err := tx.Create(&amp;Animal{Name: &quot;Lion&quot;}).Error; err != nil { tx.Rollback() return err } tx.Commit() return nil } 5.3 SQL 构建执行原生 SQLdb.Exec(&quot;DROP TABLE users;&quot;) db.Exec(&quot;UPDATE orders SET shipped_at=? WHERE id IN (?)&quot;, time.Now, []int64{11,22,33}) // Scan type Result struct { Name string Age int } var result Result db.Raw(&quot;SELECT name, age FROM users WHERE name = ?&quot;, 3).Scan(&amp;result) sql.Row &amp; sql.Rows获取查询结果为*sql.Row或*sql.Rows： row := db.Table(&quot;users&quot;).Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).Select(&quot;name, age&quot;).Row() // (*sql.Row) row.Scan(&amp;name, &amp;age) rows, err := db.Model(&amp;User{}).Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).Select(&quot;name, age, email&quot;).Rows() // (*sql.Rows, error) defer rows.Close() for rows.Next() { ... rows.Scan(&amp;name, &amp;age, &amp;email) ... } // Raw SQL rows, err := db.Raw(&quot;select name, age, email from users where name = ?&quot;, &quot;jinzhu&quot;).Rows() // (*sql.Rows, error) defer rows.Close() for rows.Next() { ... rows.Scan(&amp;name, &amp;age, &amp;email) ... } 迭代中使用 sql.Rows 的 Scanrows, err := db.Model(&amp;User{}).Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).Select(&quot;name, age, email&quot;).Rows() // (*sql.Rows, error) defer rows.Close() for rows.Next() { var user User db.ScanRows(rows, &amp;user) // do something } 5.4 通用数据库接口 sql.DB从*gorm.DB连接获取通用数据库接口*sql.DB： // 获取通用数据库对象`*sql.DB`以使用其函数 db.DB() // Ping db.DB().Ping() 设置连接池： db.DB().SetMaxIdleConns(10) db.DB().SetMaxOpenConns(100) 5.5 复合主键将多个字段设置为主键以启用复合主键： type Product struct { ID string `gorm:&quot;primary_key&quot;` LanguageCode string `gorm:&quot;primary_key&quot;` } 5.6 日志Gorm 有内置的日志记录器支持，默认情况下，它会打印发生的错误： // 启用Logger，显示详细日志 db.LogMode(true) // 禁用日志记录器，不显示任何日志 db.LogMode(false) // 调试单个操作，显示此操作的详细日志 db.Debug().Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).First(&amp;User{}) 也可以自定义Logger： db.SetLogger(gorm.Logger{revel.TRACE}) db.SetLogger(log.New(os.Stdout, &quot;\\r\\n&quot;, 0)) 参见： Logger | GORM 文档 自定义 Logger - GORM 中文文档 | LearnKu // TODO: To be updated… 参考文章 gorm.io GORM Guides | gorm.io GORM Guides 中文版 | gorm.io GoDoc | Search for Go Packages GORM 中文文档 | LearnKu GORM 中文文档 | GitBook 逻辑数据库设计 - 多态关联 | 博客园 Logger | GORM 文档 自定义 Logger - GORM 中文文档 | LearnKu 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"数据库","slug":"数据库","permalink":"https://abelsu7.top/tags/数据库/"},{"name":"GORM","slug":"GORM","permalink":"https://abelsu7.top/tags/GORM/"},{"name":"SQL","slug":"SQL","permalink":"https://abelsu7.top/tags/SQL/"}]},{"title":"QEMU 3.1.0 源码学习","slug":"qemu-src-notes","date":"2019-06-04T12:39:44.000Z","updated":"2019-09-01T13:04:11.627Z","comments":true,"path":"2019/06/04/qemu-src-notes/","link":"","permalink":"https://abelsu7.top/2019/06/04/qemu-src-notes/","excerpt":"QEMU 3.1.0 源码学习，更新中…","text":"QEMU 3.1.0 源码学习，更新中… To be updated… 目录 目录 1. QEMU 迁移 1.1 Migration 1.2 Transports 1.3 Common infrastructure 1.4 Saving the state of one device 2. QEMU Detailed Study 2.1 源码基本结构 2.2 main 流程分析 参考文章 1. QEMU 迁移 摘自qemu-3.1.0/docs/devel/migration.rst 1.1 MigrationQEMU 中关于保存/恢复正在运行客户机的状态的代码，有两个相对应的操作： Saving the state Restoring a guest 因此，QEMU 需要在目的宿主机上以相同的参数启动客户机，并且客户机所拥有的设备需要与迁移前保存时所拥有的设备保持一致。 当我们可以保存/恢复客户机之后，还需要另一项功能，即迁移Migration： 迁移意味着源宿主机上运行的 QEMU 可以被迁移至目标宿主机继续运行 而 KVM 虚拟机的迁移又可分为以下两种： 静态迁移static migration，又称冷迁移cold migration 动态迁移live migration，又称热迁移hot migration 其中动态迁移值得更多关注，因为运行中的客户机有很多的状态（例如RAM），而动态迁移可以保证客户机在保持运行的情况下，将这些状态一并迁移至目标宿主机。 当然，客户机并不是真的一直处于运行态。当客户机所有的相关数据都已迁移至目标宿主机后，源宿主机上的客户机就会停止运行。而在目标宿主机上的客户机重新运行之前，还会有一段停机时间service down-time，通常情况下为几百毫秒以内。 1.2 Transports迁移的数据流一般都是字节流byte stream，可以通过常见的协议进行传递： tcp migration：使用 TCP 套接字TCP Sockets完成迁移 unix migration：使用 UNIX 套接字UNIX Sockets完成迁移 exec migration：使用进程的标准输入/输出stdin/stdout完成迁移 fd migration：使用传递给 QEMU 的文件描述符fd完成迁移，并且 QEMU 不需要关心这个fd是如何打开的 In addition, support is included for migration using RDMA, which transports the page data using RDMA, where the hardware takes care of transporting the pages, and the load on the CPU is much lower. While the internals of RDMA migration are a bit different, this isn’t really visible outside the RAM migration code. 所有的迁移协议使用相同的infrastructure来保存/恢复虚拟机的设备。 1.3 Common infrastructure持有迁移数据流的文件、套接字sockets、文件描述符fd都抽象在migration/qemu-file.h中的QEMUFile结构体中。 结构体QEMUFile在qemu-file.c中的定义如下： #define IOV_MAX 1024 /* 定义在 include/qemu/osdep.h 中 */ ... #define IO_BUF_SIZE 32768 #define MAX_IOV_SIZE MIN(IOV_MAX, 64) struct QEMUFile { const QEMUFileOps *ops; const QEMUFileHooks *hooks; void *opaque; int64_t bytes_xfer; int64_t xfer_limit; int64_t pos; /* start of buffer when writing, end of buffer when reading */ int buf_index; int buf_size; /* 0 when writing */ uint8_t buf[IO_BUF_SIZE]; DECLARE_BITMAP(may_free, MAX_IOV_SIZE); struct iovec iov[MAX_IOV_SIZE]; unsigned int iovcnt; int last_error; }; 结构体QIOChannel在include/io/channel.h中的定义如下： /** * QIOChannel: * * The QIOChannel defines the core API for a generic I/O channel * class hierarchy. It is inspired by GIOChannel, but has the * following differences * * - Use QOM to properly support arbitrary subclassing * - Support use of iovecs for efficient I/O with multiple blocks * - None of the character set translation, binary data exclusively * - Direct support for QEMU Error object reporting * - File descriptor passing * * This base class is abstract so cannot be instantiated. There * will be subclasses for dealing with sockets, files, and higher * level protocols such as TLS, WebSocket, etc. */ struct QIOChannel { Object parent; unsigned int features; /* bitmask of QIOChannelFeatures */ char *name; AioContext *ctx; Coroutine *read_coroutine; Coroutine *write_coroutine; #ifdef _WIN32 HANDLE event; /* For use with GSource on Win32 */ #endif }; 大多数情况下，QEMUFile都和QIOChannel的subtype相互关联，例如QIOChannelTLS、QIOChannelFile、QIOChannelSocket 1.4 Saving the state of one device对于大多数的设备，只需要调用一次common infrastructure即可，这些被称为non-iterative devices。这些设备的数据在precopy migration预拷贝迁移阶段的最后被传送，此时虚拟机的 CPU 处于暂停状态。 而对于iterative devices，包含的数据量很大，例如内存RAM或large tables。 General advice for device developers 略 VMState大部分的设备数据可以使用include/migration/vmstate.h中的VMSTATE宏定义来描述。 结构体VMStateDescription在include/migration/vmstate.h中定义如下： struct VMStateDescription { const char *name; int unmigratable; int version_id; int minimum_version_id; int minimum_version_id_old; MigrationPriority priority; LoadStateHandler *load_state_old; int (*pre_load)(void *opaque); int (*post_load)(void *opaque, int version_id); int (*pre_save)(void *opaque); bool (*needed)(void *opaque); const VMStateField *fields; const VMStateDescription **subsections; }; 而在hw/input/pckbd.c中，vmstate_kdb定义如下： static const VMStateDescription vmstate_kbd = { .name = &quot;pckbd&quot;, .version_id = 3, .minimum_version_id = 3, .post_load = kbd_post_load, .fields = (VMStateField[]) { VMSTATE_UINT8(write_cmd, KBDState), VMSTATE_UINT8(status, KBDState), VMSTATE_UINT8(mode, KBDState), VMSTATE_UINT8(pending, KBDState), VMSTATE_END_OF_LIST() }, .subsections = (const VMStateDescription*[]) { &amp;vmstate_kbd_outport, NULL } }; Legacy way与VMState相对应的是 QEMU 早期的实现方式：每个被迁移的设备需要注册两个函数，一个用来保存状态，另一个用来恢复状态。 函数register_savevm_live在migration/savevm.c中的定义如下： /* TODO: Individual devices generally have very little idea about the rest of the system, so instance_id should be removed/replaced. Meanwhile pass -1 as instance_id if you do not already have a clearly distinguishing id for all instances of your device class. */ int register_savevm_live(DeviceState *dev, const char *idstr, int instance_id, int version_id, SaveVMHandlers *ops, void *opaque) { SaveStateEntry *se; se = g_new0(SaveStateEntry, 1); se-&gt;version_id = version_id; se-&gt;section_id = savevm_state.global_section_id++; se-&gt;ops = ops; se-&gt;opaque = opaque; se-&gt;vmsd = NULL; /* if this is a live_savem then set is_ram */ if (ops-&gt;save_setup != NULL) { se-&gt;is_ram = 1; } if (dev) { char *id = qdev_get_dev_path(dev); if (id) { if (snprintf(se-&gt;idstr, sizeof(se-&gt;idstr), &quot;%s/&quot;, id) &gt;= sizeof(se-&gt;idstr)) { error_report(&quot;Path too long for VMState (%s)&quot;, id); g_free(id); g_free(se); return -1; } g_free(id); se-&gt;compat = g_new0(CompatEntry, 1); pstrcpy(se-&gt;compat-&gt;idstr, sizeof(se-&gt;compat-&gt;idstr), idstr); se-&gt;compat-&gt;instance_id = instance_id == -1 ? calculate_compat_instance_id(idstr) : instance_id; instance_id = -1; } } pstrcat(se-&gt;idstr, sizeof(se-&gt;idstr), idstr); if (instance_id == -1) { se-&gt;instance_id = calculate_new_instance_id(se-&gt;idstr); } else { se-&gt;instance_id = instance_id; } assert(!se-&gt;compat || se-&gt;instance_id == 0); savevm_state_handler_insert(se); return 0; } 而ops是一个指向SaveVMHanlers的指针对象，结构体SaveVMHandlers在include/migration/register.h中的定义如下： typedef struct SaveVMHandlers { /* This runs inside the iothread lock. */ SaveStateHandler *save_state; void (*save_cleanup)(void *opaque); int (*save_live_complete_postcopy)(QEMUFile *f, void *opaque); int (*save_live_complete_precopy)(QEMUFile *f, void *opaque); /* This runs both outside and inside the iothread lock. */ bool (*is_active)(void *opaque); bool (*has_postcopy)(void *opaque); /* is_active_iterate * If it is not NULL then qemu_savevm_state_iterate will skip iteration if * it returns false. For example, it is needed for only-postcopy-states, * which needs to be handled by qemu_savevm_state_setup and * qemu_savevm_state_pending, but do not need iterations until not in * postcopy stage. */ bool (*is_active_iterate)(void *opaque); /* This runs outside the iothread lock in the migration case, and * within the lock in the savevm case. The callback had better only * use data that is local to the migration thread or protected * by other locks. */ int (*save_live_iterate)(QEMUFile *f, void *opaque); /* This runs outside the iothread lock! */ int (*save_setup)(QEMUFile *f, void *opaque); void (*save_live_pending)(QEMUFile *f, void *opaque, uint64_t threshold_size, uint64_t *res_precopy_only, uint64_t *res_compatible, uint64_t *res_postcopy_only); /* Note for save_live_pending: * - res_precopy_only is for data which must be migrated in precopy phase * or in stopped state, in other words - before target vm start * - res_compatible is for data which may be migrated in any phase * - res_postcopy_only is for data which must be migrated in postcopy phase * or in stopped state, in other words - after source vm stop * * Sum of res_postcopy_only, res_compatible and res_postcopy_only is the * whole amount of pending data. */ LoadStateHandler *load_state; int (*load_setup)(QEMUFile *f, void *opaque); int (*load_cleanup)(void *opaque); /* Called when postcopy migration wants to resume from failure */ int (*resume_prepare)(MigrationState *s, void *opaque); } SaveVMHandlers; 可以看到有以下两个指针对象： typedef struct SaveVMHandlers { /* This runs inside the iothread lock. */ SaveStateHandler *save_state; ... LoadStateHandler *load_state; ... } SaveVMHandlers; 而在include/qemu/typedefs.h中： typedef void SaveStateHandler(QEMUFile *f, void *opaque); typedef int LoadStateHandler(QEMUFile *f, void *opaque, int version_id); 值得注意的是：load_state需要接收version_id作为参数，以便确认正在接收的状态数据的格式。而save_state不需要version_id参数，因为它总是会保存最新的状态 QEMU 之后应该会逐渐用VMState的方式来替代现有的VMState macros： Note that because the VMState macros still save the data in a raw format, in many cases it’s possible to replace legacy code with a carefully constructed VMState description that matches the byte layout of the existing code. 未完待续… 2. QEMU Detailed Study 摘自 QEMU Detailed Study | PDF 先看一张图： QEMU 作为设备模拟器，可以模拟多种处理器架构。其中，待模拟的架构称为Target，而 QEMU 运行的系统环境称为Host。 QEMU 中有一个模块叫做Tiny Code Generator，简称TCG，负责将Target Code动态的翻译为Host Code，也即TCG Target。 因此我们也可以将在模拟处理器上运行的代码 (OS + UserTools) 称为Guest Code。QEMU 的作用就是将Guest Code提取出来，并将其转换为Host Specific Code。 2.1 源码基本结构启动过程QEMU 的启动过程涉及以下几个重要的源文件： vl.c cpus.c exec.c cpu-exec.c 在vl.c中定义了启动入口main函数，负责根据传入的参数例如RAM、CPU、devices来建立虚拟机的运行环境。CPU 的执行也是从此处开始的。 硬件设备的模拟所有与虚拟硬件设备相关的代码都在hw/目录下。 Guest (Target) 定义在target/目录下： &gt; pwd /kvm/qemu-src/qemu-3.1.0/target &gt; ll total 28K drwxr-xr-x 2 ibm ibm 269 Dec 12 2018 alpha drwxr-xr-x 2 ibm ibm 4.0K Dec 12 2018 arm drwxr-xr-x 2 ibm ibm 296 Dec 12 2018 cris drwxr-xr-x 2 ibm ibm 214 Dec 12 2018 hppa drwxr-xr-x 3 ibm ibm 4.0K Dec 12 2018 i386 drwxr-xr-x 2 ibm ibm 219 Dec 12 2018 lm32 drwxr-xr-x 2 ibm ibm 299 Dec 12 2018 m68k drwxr-xr-x 2 ibm ibm 210 Dec 12 2018 microblaze drwxr-xr-x 2 ibm ibm 4.0K Dec 12 2018 mips drwxr-xr-x 2 ibm ibm 164 Dec 12 2018 moxie drwxr-xr-x 2 ibm ibm 166 Dec 12 2018 nios2 drwxr-xr-x 2 ibm ibm 319 Dec 12 2018 openrisc drwxr-xr-x 3 ibm ibm 4.0K Dec 12 2018 ppc drwxr-xr-x 2 ibm ibm 243 Dec 12 2018 riscv drwxr-xr-x 2 ibm ibm 4.0K Dec 12 2018 s390x drwxr-xr-x 2 ibm ibm 192 Dec 12 2018 sh4 drwxr-xr-x 2 ibm ibm 4.0K Dec 12 2018 sparc drwxr-xr-x 2 ibm ibm 168 Dec 12 2018 tilegx drwxr-xr-x 2 ibm ibm 223 Dec 12 2018 tricore drwxr-xr-x 2 ibm ibm 179 Dec 12 2018 unicore32 drwxr-xr-x 8 ibm ibm 4.0K Dec 12 2018 xtensa Host (TCG) 定义在tcg目录下： &gt; pwd /kvm/qemu-src/qemu-3.1.0/tcg &gt; ll total 576K drwxr-xr-x 2 ibm ibm 74 Dec 12 2018 aarch64 drwxr-xr-x 2 ibm ibm 50 Dec 12 2018 arm drwxr-xr-x 2 ibm ibm 74 Dec 12 2018 i386 -rw-r--r-- 1 ibm ibm 146 Dec 12 2018 LICENSE drwxr-xr-x 2 ibm ibm 50 Dec 12 2018 mips -rw-r--r-- 1 ibm ibm 48K Dec 12 2018 optimize.c drwxr-xr-x 2 ibm ibm 50 Dec 12 2018 ppc -rw-r--r-- 1 ibm ibm 22K Dec 12 2018 README drwxr-xr-x 2 ibm ibm 50 Dec 12 2018 s390 drwxr-xr-x 2 ibm ibm 50 Dec 12 2018 sparc -rw-r--r-- 1 ibm ibm 122K Dec 12 2018 tcg.c -rw-r--r-- 1 ibm ibm 1.6K Dec 12 2018 tcg-common.c -rw-r--r-- 1 ibm ibm 1.8K Dec 12 2018 tcg-gvec-desc.h -rw-r--r-- 1 ibm ibm 47K Dec 12 2018 tcg.h -rw-r--r-- 1 ibm ibm 3.0K Dec 12 2018 tcg-ldst.inc.c -rw-r--r-- 1 ibm ibm 2.0K Dec 12 2018 tcg-mo.h -rw-r--r-- 1 ibm ibm 94K Dec 12 2018 tcg-op.c -rw-r--r-- 1 ibm ibm 11K Dec 12 2018 tcg-opc.h -rw-r--r-- 1 ibm ibm 72K Dec 12 2018 tcg-op-gvec.c -rw-r--r-- 1 ibm ibm 15K Dec 12 2018 tcg-op-gvec.h -rw-r--r-- 1 ibm ibm 49K Dec 12 2018 tcg-op.h -rw-r--r-- 1 ibm ibm 11K Dec 12 2018 tcg-op-vec.c -rw-r--r-- 1 ibm ibm 5.2K Dec 12 2018 tcg-pool.inc.c drwxr-xr-x 2 ibm ibm 64 Dec 12 2018 tci -rw-r--r-- 1 ibm ibm 39K Dec 12 2018 tci.c -rw-r--r-- 1 ibm ibm 394 Dec 12 2018 TODO 总结一下 /vl.c：包含了main函数，负责启动虚拟机、运行 vCPU。main_loop()也存在于此文件中，虚拟机的转换是在这个循环中进行调用的 /target/i386/translate.c：负责提取Guest Code并将其转换为平台无关的TCG ops。转换过程中的单位元是一个TB即Translation Block，只有当一个TB的转换执行结束后，才会轮到下一个TB。这里是 TCG 的前端 /tcg/tcg.c：TCG 的主要实现代码，这里是 TCG 的后端 /tcg/i386/tcg-target.inc.c：将TCG ops转换为Host Code /accel/tcg/cpu-exec.c：函数int cpu_exec(CPUState *cpu)会调用函数tb_find()在 Code Buffer 中查找下一个 TB，这里的 TB 指的是已经翻译成 Host 相关指令的 TB。如果找到了，就会调用cpu_loop_exec_tb()来在 Host 上执行 QEMU 的作用就是，提取Guest Code，并将其转换为Host Code 整个转换过程由两部分组成： 第一步由前端完成，Target Code的代码块TB被转换成TCG-ops（独立于机器的中间代码） 第二步由后端完成，利用 Host 架构对应的TCG，把由TB生成的TCP-ops转换成Host Code 2.2 main 流程分析main(…)定义在/vl.c中，函数原型如下： int main(int argc, char **argv, char **envp); 入口main函数，解析传入 QEMU 的命令行参数，并以此初始化 VM，例如内存大小、磁盘大小、启动盘等。 3. QEMU 2.12.1 热迁移 部分内容参考 Living Migrating QEMU-KVM Virtual Machines | Red Hat Developer 3.1 热迁移的用法QEMU/KVM 在早期版本中就引入了热迁移的支持。一般来说，热迁移需要迁移的src和dst可以同时访问虚拟机镜像。一个简单的例子，在同一台 Host 上将QEMU VM迁移至另一台QEMU VM。 首先在src启动一台虚拟机vm1： qemu-system-x86_64 --accel kvm -m 2G -smp 2 -hda fedora30.qcow2 之后在dst以相同的启动命令运行另一台虚拟机vm2，指定相同的镜像文件，并添加-incoming参数： qemu-system-x86_64 --accel kvm -m 2G -smp 2 -hda fedora30.qcow2 -incoming tcp:0:6666 在vm1中的QEMU monitor中输入以下命令： migrate tcp:localhost:6666 大概十几秒之后可以看到vm2以vm1暂停之前的状态继续运行，迁移成功。 3.2 热迁移的基本原理 现在来看迁移过程中涉及到的具体数据。首先我们需要迁移一些Guest的运行现状——内存区域，QEMU 将其视为the entire Guest。不需要翻译任何关于内存区域的内容，这部分会被迁移代码当作一个黑盒Opaque，只需将这些内容从src发送到dst。这个区域在上图中被标记为灰色 之后就是左边的区域，表示Devices即设备状态，这部分对Guest来说是可见的，也即 QEMU 内部的状态（因为这些设备由 QEMU 进行模拟并提供给Guest），因此 QEMU 使用自己的协议发送这部分数据，其中包含了所有对Guest可见的设备状态 最后就是右边的部分，QEMU 本身的状态也即Host上的 QEMU 进程状态（例如通过-smp指定的 CPU 核数、-m指定的内存大小等），这部分由 Host 内核中的 KVM 模块提供，因此迁移过程不涉及这部分状态，但需要在迁移之前确保在src和dst上这部分状态保持一致，一般以相同的 QEMU 命令行参数启动 QEMU 即可实现 3.3 热迁移的前提条件迁移的src和dst需要满足以下前提条件才可实现热迁移： 使用共享存储存储镜像文件，例如NFS 主机时间同步（很重要），可通过NTP实现 主机的网络配置必须一致 主机的CPU 类型必须一致 VM 的machine type（当进行跨 QEMU 版本的热迁移时很重要）、RAM大小 3.4 热迁移的主要阶段热迁移主要有以下三个阶段 Stage 1：将Guest的所有RAM标记为dirty Stage 2：持续迭代的将所有dirty RAM page发送至dst，直到达到一定的终止条件 Stage 3：停止src上的Guest，继续传送剩余的dirty RAM page以及device state 阶段一、二对应上图中的灰色区域，阶段三对应灰色区域和左边的区域 可以看到热迁移大部分的工作都是在进行RAM传输，尤其是dirty page的传输，所以很多对于热迁移的优化也是针对RAM传输进行优化。 注：dirty page指的是在迁移过程中产生变化的memory page，内存迁移是先把没有变化的内存传输过去，然后逐渐减小dirty page的大小，最后有短暂的downtime，把剩下的dirty page一并传输过去 之后就可以在dst上继续运行 QEMU 程序了。 注意：当从阶段二向阶段三过渡时，要做一个很重要的决策，即Guest会在阶段三暂停运行，所以在第三阶段要尽可能少的迁移页面，以减少停机时间 3.5 发送端源码分析先来看在QEMU Monitor输入migrate命令后，经过的一些函数： 注意：除了hmp.c在根目录之外，其他源文件均在migration目录下 void hmp_migrate() /* hmp.c */ -&gt; void qmp_migrate() /* migration.c */ -&gt; void tcp_start_outgoing_migration() /* socket.c */ -&gt; static void socket_start_outgoing_migration() /* socket.c */ -&gt; static void socket_outgoing_migration() /* socket.c */ -&gt; void migration_channel_connect() /* channel.c */ -&gt; QEMUFile *qemu_fopen_channel_output() /* qemu-file-channel.c */ -&gt; void migrate_fd_connect() /* migration.c */ -&gt; static void *migration_thread() /* migration.c */ 在hmp-commands.hx中可以看到migrate命令对应的入口函数为hmp_migrate： ETEXI { .name = &quot;migrate&quot;, .args_type = &quot;detach:-d,blk:-b,inc:-i,resume:-r,uri:s&quot;, .params = &quot;[-d] [-b] [-i] [-r] uri&quot;, .help = &quot;migrate to URI (using -d to not wait for completion)&quot; &quot;\\n\\t\\t\\t -b for migration without shared storage with&quot; &quot; full copy of disk\\n\\t\\t\\t -i for migration without &quot; &quot;shared storage with incremental copy of disk &quot; &quot;(base image shared between src and destination)&quot; &quot;\\n\\t\\t\\t -r to resume a paused migration&quot;, .cmd = hmp_migrate, }, STEXI @item migrate [-d] [-b] [-i] @var{uri} @findex migrate Migrate to @var{uri} (using -d to not wait for completion). -b for migration with full copy of disk -i for migration with incremental copy of disk (base image is shared) ETEXI 函数hmp_migrate在hmp.c中定义： void hmp_migrate(Monitor *mon, const QDict *qdict) { /* 省略部分代码 */ qmp_migrate(uri, !!blk, blk, !!inc, inc, false, false, &amp;err); if (err) { hmp_handle_error(mon, &amp;err); return; } /* 省略部分代码 */ } 进行迁移逻辑处理的函数跳转到了qmp_migrate，在migration.c中定义： void qmp_migrate(const char *uri, bool has_blk, bool blk, bool has_inc, bool inc, bool has_detach, bool detach, Error **errp) { Error *local_err = NULL; MigrationState *s = migrate_get_current(); const char *p; if (migration_is_setup_or_active(s-&gt;state) || s-&gt;state == MIGRATION_STATUS_CANCELLING || s-&gt;state == MIGRATION_STATUS_COLO) { error_setg(errp, QERR_MIGRATION_ACTIVE); return; } if (runstate_check(RUN_STATE_INMIGRATE)) { error_setg(errp, &quot;Guest is waiting for an incoming migration&quot;); return; } if (migration_is_blocked(errp)) { return; } /* 省略部分代码 */ migrate_init(s); if (strstart(uri, &quot;tcp:&quot;, &amp;p)) { tcp_start_outgoing_migration(s, p, &amp;local_err); #ifdef CONFIG_RDMA } else if (strstart(uri, &quot;rdma:&quot;, &amp;p)) { rdma_start_outgoing_migration(s, p, &amp;local_err); #endif } else if (strstart(uri, &quot;exec:&quot;, &amp;p)) { exec_start_outgoing_migration(s, p, &amp;local_err); } else if (strstart(uri, &quot;unix:&quot;, &amp;p)) { unix_start_outgoing_migration(s, p, &amp;local_err); } else if (strstart(uri, &quot;fd:&quot;, &amp;p)) { fd_start_outgoing_migration(s, p, &amp;local_err); } else { error_setg(errp, QERR_INVALID_PARAMETER_VALUE, &quot;uri&quot;, &quot;a valid migration protocol&quot;); migrate_set_state(&amp;s-&gt;state, MIGRATION_STATUS_SETUP, MIGRATION_STATUS_FAILED); block_cleanup_parameters(s); return; } if (local_err) { migrate_fd_error(s, local_err); error_propagate(errp, local_err); return; } } 简单说下这个函数：首先通过migrate_get_current()获取当前的MigrationState指针对象，之后检查当前是否已经有迁移进程存在。之后下面的语句： if (migration_is_blocked(errp)) { return; } ... /* migration.c 中定义 */ bool migration_is_blocked(Error **errp) { if (qemu_savevm_state_blocked(errp)) { return true; } if (migration_blockers) { error_propagate(errp, error_copy(migration_blockers-&gt;data)); return true; } return false; } 这里通过qemu_savevm_state_blocked()来判断当前虚拟机状态适不适合进行迁移。 最后直接来说上面函数调用栈最下面的migrate_fd_connect()，通过qemu_thread_create调用migration_thread在src上创建一个迁移线程： void migrate_fd_connect(MigrationState *s, Error *error_in) { /* 省略之前的语句 */ qemu_thread_create(&amp;s-&gt;thread, &quot;live_migration&quot;, migration_thread, s, QEMU_THREAD_JOINABLE); s-&gt;migration_thread_running = true; } 而migration_thread同样在migration.c中定义： /* * Master migration thread on the source VM. * It drives the migration and pumps the data down the outgoing channel. */ static void *migration_thread(void *opaque) { /* 省略部分代码 */ /* 对应 Stage 1 */ qemu_savevm_state_setup(s-&gt;to_dst_file); /* 省略部分代码 */ while (s-&gt;state == MIGRATION_STATUS_ACTIVE || s-&gt;state == MIGRATION_STATUS_POSTCOPY_ACTIVE) { int64_t current_time; if (!qemu_file_rate_limit(s-&gt;to_dst_file)) { /* 对应 Stage 2 */ MigIterateState iter_state = migration_iteration_run(s); if (iter_state == MIG_ITERATE_SKIP) { continue; } else if (iter_state == MIG_ITERATE_BREAK) { break; } } if (qemu_file_get_error(s-&gt;to_dst_file)) { if (migration_is_setup_or_active(s-&gt;state)) { migrate_set_state(&amp;s-&gt;state, s-&gt;state, MIGRATION_STATUS_FAILED); } trace_migration_thread_file_err(); break; } current_time = qemu_clock_get_ms(QEMU_CLOCK_REALTIME); migration_update_counters(s, current_time); if (qemu_file_rate_limit(s-&gt;to_dst_file)) { /* usleep expects microseconds */ g_usleep((s-&gt;iteration_start_time + BUFFER_DELAY - current_time) * 1000); } } trace_migration_thread_after_loop(); /* 对应 Stage 3 */ migration_iteration_finish(s); rcu_unregister_thread(); return NULL; } migration_thread主要就是用来完成热迁移的三个步骤。 首先来看第一个步骤，qemu_savevm_state_setup将标记所有的RAM为dirty： void qemu_savevm_state_setup() /* savevm.c */ -&gt; SaveVMHandlers.save_setup /* block-dirty-bitmap.c */ -&gt; static int dirty_bitmap_save_setup() /* block-dirty-bitmap.c */ -&gt; static int init_dirty_bitmap_migration() /* block-dirty-bitmap.c */ -&gt; static void send_bitmap_start() /* block-dirty-bitmap.c */ -&gt; static void qemu_put_bitmap_flags() /* block-dirty-bitmap.c */ 未完待续… 4. KVM Migration 文档 参考 Migration | KVM 迁移简介KVM 目前支持savevm/loadvm即快照、静态迁移、动态迁移，可通过快捷键Ctrl+Alt+2调出qemu-monitor，并在其中通过migrate相关命令进行迁移操作。迁移成功完成后，VM 就可以在目标主机上继续运行。 注意：支持在AMD和Intel主机之间进行迁移。通常情况下，64 位的 VM 仅可以被迁移至 64 位的 Host 运行，而 32 位的 VM 则可以迁移至 32 位或 64 位的 Host 未完待续… 参考文章 QEMU QEMU Wiki KVM kvm/kvm.git KVM Documents Virt Tools | Blogging about open source virtualization Migration | KVM QEMU Detailed Study | PDF QEMU vl.c 源码学习 | CSDN QEMU 参数解析 | CSDN qemu-kvm 部分流程/源代码分析 | CSDN qemu 学习（一）———— qemu 整体流程解读 | CSDN qemu 学习（二）———— qemu 中对处理器大小端的设置 | CSDN qemu 学习（三）———— qemu 中反汇编操作解析 | CSDN QEMU 源码架构 | ChinaUnix QEMU 源码分析系列(二) | ChinaUnix QEMU-KVM 虚机动态迁移原理 | 51CTO 虚拟化在线迁移优化实践（一）：KVM虚拟化跨机迁移原理 - UCloud 云计算 | 知乎 QEMU 热迁移简介 | 不忘初心，方得始终 Live Migrating QEMU-KVM Virtual Machines | Red Hat Developer 虚拟机迁移之热迁移(live_migrate) | 随便写写 上面文章博主关于虚拟化的文章列表 | 随便写写 KVM 虚拟机静态和动态迁移 | bbsmax 虚拟机活迁移揭秘 | 博客园 qemu-kvm-1.1.0 源码中关于迁移的代码分析 | CSDN QEMU 源码分析系列（一）| CSDN qemu-kvm 虚拟机 live 迁移源代码解读 | CSDN QEMU live migration 代码简单剖析 | CSDN qemu-kvm savevm/loadvm 流程 | CSDN KVM/QEMU 2.3.0 虚拟机动态迁移分析（一）| CSDN KVM/QEMU 2.3.0 虚拟机动态迁移分析（二）| CSDN KVM/QEMU 2.3.0 虚拟机动态迁移分析（三）| CSDN Qemu-KVM 虚拟机初始化及创建过程源码简要分析（一）| CSDN Qemu-KVM 虚拟机初始化及创建过程源码简要分析（二）| CSDN qemu-kvm 虚拟机live迁移源代码解读 | CSDN 北方南方的文章列表 | CSDN qemu 迁移代码分析 | 随便写写 QEMU live migration 代码简单剖析 | ChinaUnix qemu-kvm 虚拟机 live 迁移源代码解读 | ChinaUnix qemu-kvm 磁盘读写的缓冲(cache)的五种模式 | jusonalien 关于追踪 qemu 源码函数路径的一个方法 | jusonalien QEMU main 流程分析 | CSDN QEMU 翻译块（TB）分析 | CSDN 我见过最全的剖析 QEMU 原理的文章 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"},{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/tags/云计算/"}]},{"title":"SQL 必知必会","slug":"sql-notes","date":"2019-05-31T01:57:58.000Z","updated":"2019-09-01T13:04:11.691Z","comments":true,"path":"2019/05/31/sql-notes/","link":"","permalink":"https://abelsu7.top/2019/05/31/sql-notes/","excerpt":"摘自 《SQL 必知必会》","text":"摘自 《SQL 必知必会》 1. 了解 SQL1.1 数据库基础 数据库database：保存有组织的数据的容器。数据库软件通常称为数据库管理系统DBMS 数据库是通过DBMS创建和操纵的容器 表table：某种特定类型数据的结构化清单 模式schema：用来描述数据在表中如何存储，包含存储什么样的数据，数据如何分解，各部分信息如何命名等信息 模式可以用来描述数据库中特定的表，也可以用来描述整个数据库（和其中表的关系） 列column：表中的一个字段。表由列组成，列存储表中的某部分信息 数据类型datatype：定义了列可以存储那些数据种类 行row：表中的一个记录。表中的数据是按行存储的，每条记录存储在自己的行内 也可称为数据库记录record 主键primary key：一列（或一组列），其值能够唯一标识表中每一行 表中的任何列只要满足以下条件，都可以作为主键： 任意一行的主键值唯一 主键列不允许NULL值 主键列中的值不允许修改或更新 主键值不能重用，即被删除行的主键值不能赋给以后的新行 1.2 什么是 SQLSQL 即结构化查询语言（Structured Query Language）。与常见的过程式编程语言相比，SQL 更加类似于一种声明式语言。 标准 SQL 由 ANSI 标准委员会管理，从而称为ANSI SQL。所有主要的 DBMS ，即使有自己的扩展，也都支持ANSI SQL。 各个 DBMS 关于 SQL 的实现有自己的名称，例如 Oracle 的PL/SQL、微软的Transact-SQL等 1.3 注释风格SQL 支持以下三种注释风格： # 注释 SELECT * FROM mytable; -- 注释 /* 注释 1 注释 2 */ 1.4 样例数据库 摘自 Sams Teach Yourself SQL in 10 Minutes (Fourth Edition) | Ben Forta 创建数据库首先创建数据库： CREATE DATABASE sql_10mins; USE sql_10mins; 之后创建以下五张样例表： Vendors 表Vendors表存储供应商信息，每个供应商有唯一的vendor_id作为主键，用于匹配产品与供应商： -- -------------------- -- Create Vendors table -- -------------------- CREATE TABLE Vendors ( vend_id char(10) NOT NULL, -- 供应商 ID，主键 vend_name char(50) NOT NULL, -- 供应商名 vend_address char(50) NULL, -- 供应商地址 vend_city char(50) NULL, -- 供应商所在城市 vend_state char(5) NULL, -- 供应商所在州 vend_zip char(10) NULL, -- 供应商邮编 vend_country char(50) NULL -- 供应商所在国家 ); Products 表Products表包含产品目录，每行一个产品。每个产品有唯一的prod_id作为主键，并借助vend_id作为外键与Vendors表相关联： -- --------------------- -- Create Products table -- --------------------- CREATE TABLE Products ( prod_id char(10) NOT NULL, -- 产品 ID，主键 vend_id char(10) NOT NULL, -- 供应商 ID 外键 prod_name char(255) NOT NULL, -- 产品名 prod_price decimal(8, 2) NOT NULL, -- 产品价格 prod_desc text NULL -- 产品描述 ); Customers 表Customers表存储所有顾客信息。每个顾客有唯一的cust_id作为主键： -- ---------------------- -- Create Customers table -- ---------------------- CREATE TABLE Customers ( cust_id char(10) NOT NULL, -- 顾客 ID，主键 cust_name char(50) NOT NULL, -- 顾客名 cust_address char(50) NULL, -- 顾客地址 cust_city char(50) NULL, -- 顾客所在城市 cust_state char(5) NULL, -- 顾客所在州 cust_zip char(10) NULL, -- 顾客邮编 cust_country char(50) NULL, -- 顾客所在国家 cust_contact char(50) NULL, -- 顾客联系名 cust_email char(255) NULL -- 顾客邮件地址 ); Orders 表Orders表存储顾客订单，每个订单有唯一的编号order_num作为主键，按cust_id作为外键关联到Customers表的相应顾客： -- ------------------- -- Create Orders table -- ------------------- CREATE TABLE Orders ( order_num int NOT NULL, -- 订单号，主键 order_date datetime NOT NULL, -- 订单日期 cust_id char(10) NOT NULL -- 订单顾客 ID，外键 ); OrderItems 表OrderItems表存储每个订单中的实际物品，每个订单的每个物品一行。对于Orders表的每一行，在OrderItems表中有一行或多行。 每个OrderItem由订单号order_num加订单物品号order_item作为唯一标识的主键，并用order_num作为外键关联到Orders表。另外，prod_id列也作为外键关联到Products表： -- ----------------------- -- Create OrderItems table -- ----------------------- CREATE TABLE OrderItems ( order_num int NOT NULL, -- 订单号，主键，外键 order_item int NOT NULL, -- 订单物品号 prod_id char(10) NOT NULL, -- 产品 ID，外键 quantity int NOT NULL, -- 物品数量 item_price decimal(8, 2) NOT NULL -- 物品价格 ); 添加主键和外键刚才只是创建了五张表及其各个字段，现在添加主键： -- ------------------- -- Define primary keys -- ------------------- ALTER TABLE Customers ADD PRIMARY KEY (cust_id); ALTER TABLE OrderItems ADD PRIMARY KEY (order_num, order_item); ALTER TABLE Orders ADD PRIMARY KEY (order_num); ALTER TABLE Products ADD PRIMARY KEY (prod_id); ALTER TABLE Vendors ADD PRIMARY KEY (vend_id); 之后添加外键： -- ------------------- -- Define foreign keys -- ------------------- ALTER TABLE OrderItems ADD CONSTRAINT FK_OrderItems_Orders FOREIGN KEY (order_num) REFERENCES Orders (order_num); ALTER TABLE OrderItems ADD CONSTRAINT FK_OrderItems_Products FOREIGN KEY (prod_id) REFERENCES Products (prod_id); ALTER TABLE Orders ADD CONSTRAINT FK_Orders_Customers FOREIGN KEY (cust_id) REFERENCES Customers (cust_id); ALTER TABLE Products ADD CONSTRAINT FK_Products_Vendors FOREIGN KEY (vend_id) REFERENCES Vendors (vend_id); ER 图样例数据库sql_10mins的ER 图如下所示： 插入样例数据Customers表： -- ------------------------ -- Populate Customers table -- ------------------------ INSERT INTO Customers(cust_id, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country, cust_contact, cust_email) VALUES(&#39;1000000001&#39;, &#39;Village Toys&#39;, &#39;200 Maple Lane&#39;, &#39;Detroit&#39;, &#39;MI&#39;, &#39;44444&#39;, &#39;USA&#39;, &#39;John Smith&#39;, &#39;sales@villagetoys.com&#39;); INSERT INTO Customers(cust_id, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country, cust_contact) VALUES(&#39;1000000002&#39;, &#39;Kids Place&#39;, &#39;333 South Lake Drive&#39;, &#39;Columbus&#39;, &#39;OH&#39;, &#39;43333&#39;, &#39;USA&#39;, &#39;Michelle Green&#39;); INSERT INTO Customers(cust_id, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country, cust_contact, cust_email) VALUES(&#39;1000000003&#39;, &#39;Fun4All&#39;, &#39;1 Sunny Place&#39;, &#39;Muncie&#39;, &#39;IN&#39;, &#39;42222&#39;, &#39;USA&#39;, &#39;Jim Jones&#39;, &#39;jjones@fun4all.com&#39;); INSERT INTO Customers(cust_id, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country, cust_contact, cust_email) VALUES(&#39;1000000004&#39;, &#39;Fun4All&#39;, &#39;829 Riverside Drive&#39;, &#39;Phoenix&#39;, &#39;AZ&#39;, &#39;88888&#39;, &#39;USA&#39;, &#39;Denise L. Stephens&#39;, &#39;dstephens@fun4all.com&#39;); INSERT INTO Customers(cust_id, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country, cust_contact) VALUES(&#39;1000000005&#39;, &#39;The Toy Store&#39;, &#39;4545 53rd Street&#39;, &#39;Chicago&#39;, &#39;IL&#39;, &#39;54545&#39;, &#39;USA&#39;, &#39;Kim Howard&#39;); Vendors表： -- ---------------------- -- Populate Vendors table -- ---------------------- INSERT INTO Vendors(vend_id, vend_name, vend_address, vend_city, vend_state, vend_zip, vend_country) VALUES(&#39;BRS01&#39;,&#39;Bears R Us&#39;,&#39;123 Main Street&#39;,&#39;Bear Town&#39;,&#39;MI&#39;,&#39;44444&#39;, &#39;USA&#39;); INSERT INTO Vendors(vend_id, vend_name, vend_address, vend_city, vend_state, vend_zip, vend_country) VALUES(&#39;BRE02&#39;,&#39;Bear Emporium&#39;,&#39;500 Park Street&#39;,&#39;Anytown&#39;,&#39;OH&#39;,&#39;44333&#39;, &#39;USA&#39;); INSERT INTO Vendors(vend_id, vend_name, vend_address, vend_city, vend_state, vend_zip, vend_country) VALUES(&#39;DLL01&#39;,&#39;Doll House Inc.&#39;,&#39;555 High Street&#39;,&#39;Dollsville&#39;,&#39;CA&#39;,&#39;99999&#39;, &#39;USA&#39;); INSERT INTO Vendors(vend_id, vend_name, vend_address, vend_city, vend_state, vend_zip, vend_country) VALUES(&#39;FRB01&#39;,&#39;Furball Inc.&#39;,&#39;1000 5th Avenue&#39;,&#39;New York&#39;,&#39;NY&#39;,&#39;11111&#39;, &#39;USA&#39;); INSERT INTO Vendors(vend_id, vend_name, vend_address, vend_city, vend_state, vend_zip, vend_country) VALUES(&#39;FNG01&#39;,&#39;Fun and Games&#39;,&#39;42 Galaxy Road&#39;,&#39;London&#39;, NULL,&#39;N16 6PS&#39;, &#39;England&#39;); INSERT INTO Vendors(vend_id, vend_name, vend_address, vend_city, vend_state, vend_zip, vend_country) VALUES(&#39;JTS01&#39;,&#39;Jouets et ours&#39;,&#39;1 Rue Amusement&#39;,&#39;Paris&#39;, NULL,&#39;45678&#39;, &#39;France&#39;); Products表： -- ----------------------- -- Populate Products table -- ----------------------- INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;BR01&#39;, &#39;BRS01&#39;, &#39;8 inch teddy bear&#39;, 5.99, &#39;8 inch teddy bear, comes with cap and jacket&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;BR02&#39;, &#39;BRS01&#39;, &#39;12 inch teddy bear&#39;, 8.99, &#39;12 inch teddy bear, comes with cap and jacket&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;BR03&#39;, &#39;BRS01&#39;, &#39;18 inch teddy bear&#39;, 11.99, &#39;18 inch teddy bear, comes with cap and jacket&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;BNBG01&#39;, &#39;DLL01&#39;, &#39;Fish bean bag toy&#39;, 3.49, &#39;Fish bean bag toy, complete with bean bag worms with which to feed it&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;BNBG02&#39;, &#39;DLL01&#39;, &#39;Bird bean bag toy&#39;, 3.49, &#39;Bird bean bag toy, eggs are not included&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;BNBG03&#39;, &#39;DLL01&#39;, &#39;Rabbit bean bag toy&#39;, 3.49, &#39;Rabbit bean bag toy, comes with bean bag carrots&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;RGAN01&#39;, &#39;DLL01&#39;, &#39;Raggedy Ann&#39;, 4.99, &#39;18 inch Raggedy Ann doll&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;RYL01&#39;, &#39;FNG01&#39;, &#39;King doll&#39;, 9.49, &#39;12 inch king doll with royal garments and crown&#39;); INSERT INTO Products (prod_id, vend_id, prod_name, prod_price, prod_desc) VALUES (&#39;RYL02&#39;, &#39;FNG01&#39;, &#39;Queen doll&#39;, 9.49, &#39;12 inch queen doll with royal garments and crown&#39;); Orders表： -- --------------------- -- Populate Orders table -- --------------------- INSERT INTO Orders (order_num, order_date, cust_id) VALUES (20005, &#39;2012-05-01&#39;, &#39;1000000001&#39;); INSERT INTO Orders (order_num, order_date, cust_id) VALUES (20006, &#39;2012-01-12&#39;, &#39;1000000003&#39;); INSERT INTO Orders (order_num, order_date, cust_id) VALUES (20007, &#39;2012-01-30&#39;, &#39;1000000004&#39;); INSERT INTO Orders (order_num, order_date, cust_id) VALUES (20008, &#39;2012-02-03&#39;, &#39;1000000005&#39;); INSERT INTO Orders (order_num, order_date, cust_id) VALUES (20009, &#39;2012-02-08&#39;, &#39;1000000001&#39;); OrderItems表： -- ------------------------- -- Populate OrderItems table -- ------------------------- INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20005, 1, &#39;BR01&#39;, 100, 5.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20005, 2, &#39;BR03&#39;, 100, 10.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20006, 1, &#39;BR01&#39;, 20, 5.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20006, 2, &#39;BR02&#39;, 10, 8.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20006, 3, &#39;BR03&#39;, 10, 11.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20007, 1, &#39;BR03&#39;, 50, 11.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20007, 2, &#39;BNBG01&#39;, 100, 2.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20007, 3, &#39;BNBG02&#39;, 100, 2.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20007, 4, &#39;BNBG03&#39;, 100, 2.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20007, 5, &#39;RGAN01&#39;, 50, 4.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20008, 1, &#39;RGAN01&#39;, 5, 4.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20008, 2, &#39;BR03&#39;, 5, 11.99); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20008, 3, &#39;BNBG01&#39;, 10, 3.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20008, 4, &#39;BNBG02&#39;, 10, 3.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20008, 5, &#39;BNBG03&#39;, 10, 3.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20009, 1, &#39;BNBG01&#39;, 250, 2.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20009, 2, &#39;BNBG02&#39;, 250, 2.49); INSERT INTO OrderItems (order_num, order_item, prod_id, quantity, item_price) VALUES (20009, 3, &#39;BNBG03&#39;, 250, 2.49); 检查数据Vendors表： mysql&gt; describe Vendors; +--------------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +--------------+----------+------+-----+---------+-------+ | vend_id | char(10) | NO | PRI | NULL | | | vend_name | char(50) | NO | | NULL | | | vend_address | char(50) | YES | | NULL | | | vend_city | char(50) | YES | | NULL | | | vend_state | char(5) | YES | | NULL | | | vend_zip | char(10) | YES | | NULL | | | vend_country | char(50) | YES | | NULL | | +--------------+----------+------+-----+---------+-------+ 7 rows in set (0.00 sec) mysql&gt; select * from Vendors; +---------+-----------------+-----------------+------------+------------+----------+--------------+ | vend_id | vend_name | vend_address | vend_city | vend_state | vend_zip | vend_country | +---------+-----------------+-----------------+------------+------------+----------+--------------+ | BRE02 | Bear Emporium | 500 Park Street | Anytown | OH | 44333 | USA | | BRS01 | Bears R Us | 123 Main Street | Bear Town | MI | 44444 | USA | | DLL01 | Doll House Inc. | 555 High Street | Dollsville | CA | 99999 | USA | | FNG01 | Fun and Games | 42 Galaxy Road | London | NULL | N16 6PS | England | | FRB01 | Furball Inc. | 1000 5th Avenue | New York | NY | 11111 | USA | | JTS01 | Jouets et ours | 1 Rue Amusement | Paris | NULL | 45678 | France | +---------+-----------------+-----------------+------------+------------+----------+--------------+ 6 rows in set (0.00 sec) Products表： mysql&gt; describe Products; +------------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------+------+-----+---------+-------+ | prod_id | char(10) | NO | PRI | NULL | | | vend_id | char(10) | NO | MUL | NULL | | | prod_name | char(255) | NO | | NULL | | | prod_price | decimal(8,2) | NO | | NULL | | | prod_desc | text | YES | | NULL | | +------------+--------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) mysql&gt; select * from Products; +---------+---------+---------------------+------------+-----------------------------------------------------------------------+ | prod_id | vend_id | prod_name | prod_price | prod_desc | +---------+---------+---------------------+------------+-----------------------------------------------------------------------+ | BNBG01 | DLL01 | Fish bean bag toy | 3.49 | Fish bean bag toy, complete with bean bag worms with which to feed it | | BNBG02 | DLL01 | Bird bean bag toy | 3.49 | Bird bean bag toy, eggs are not included | | BNBG03 | DLL01 | Rabbit bean bag toy | 3.49 | Rabbit bean bag toy, comes with bean bag carrots | | BR01 | BRS01 | 8 inch teddy bear | 5.99 | 8 inch teddy bear, comes with cap and jacket | | BR02 | BRS01 | 12 inch teddy bear | 8.99 | 12 inch teddy bear, comes with cap and jacket | | BR03 | BRS01 | 18 inch teddy bear | 11.99 | 18 inch teddy bear, comes with cap and jacket | | RGAN01 | DLL01 | Raggedy Ann | 4.99 | 18 inch Raggedy Ann doll | | RYL01 | FNG01 | King doll | 9.49 | 12 inch king doll with royal garments and crown | | RYL02 | FNG01 | Queen doll | 9.49 | 12 inch queen doll with royal garments and crown | +---------+---------+---------------------+------------+-----------------------------------------------------------------------+ 9 rows in set (0.00 sec) Customers表： mysql&gt; describe Customers; +--------------+-----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +--------------+-----------+------+-----+---------+-------+ | cust_id | char(10) | NO | PRI | NULL | | | cust_name | char(50) | NO | | NULL | | | cust_address | char(50) | YES | | NULL | | | cust_city | char(50) | YES | | NULL | | | cust_state | char(5) | YES | | NULL | | | cust_zip | char(10) | YES | | NULL | | | cust_country | char(50) | YES | | NULL | | | cust_contact | char(50) | YES | | NULL | | | cust_email | char(255) | YES | | NULL | | +--------------+-----------+------+-----+---------+-------+ 9 rows in set (0.00 sec) mysql&gt; select * from Customers; +------------+---------------+----------------------+-----------+------------+----------+--------------+--------------------+-----------------------+ | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email | +------------+---------------+----------------------+-----------+------------+----------+--------------+--------------------+-----------------------+ | 1000000001 | Village Toys | 200 Maple Lane | Detroit | MI | 44444 | USA | John Smith | sales@villagetoys.com | | 1000000002 | Kids Place | 333 South Lake Drive | Columbus | OH | 43333 | USA | Michelle Green | NULL | | 1000000003 | Fun4All | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | jjones@fun4all.com | | 1000000004 | Fun4All | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Denise L. Stephens | dstephens@fun4all.com | | 1000000005 | The Toy Store | 4545 53rd Street | Chicago | IL | 54545 | USA | Kim Howard | NULL | +------------+---------------+----------------------+-----------+------------+----------+--------------+--------------------+-----------------------+ 5 rows in set (0.00 sec) Orders表： mysql&gt; describe Orders; +------------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+----------+------+-----+---------+-------+ | order_num | int(11) | NO | PRI | NULL | | | order_date | datetime | NO | | NULL | | | cust_id | char(10) | NO | MUL | NULL | | +------------+----------+------+-----+---------+-------+ 3 rows in set (0.00 sec) mysql&gt; select * from Orders; +-----------+---------------------+------------+ | order_num | order_date | cust_id | +-----------+---------------------+------------+ | 20005 | 2012-05-01 00:00:00 | 1000000001 | | 20006 | 2012-01-12 00:00:00 | 1000000003 | | 20007 | 2012-01-30 00:00:00 | 1000000004 | | 20008 | 2012-02-03 00:00:00 | 1000000005 | | 20009 | 2012-02-08 00:00:00 | 1000000001 | +-----------+---------------------+------------+ 5 rows in set (0.00 sec) OrderItems表： mysql&gt; describe OrderItems; +------------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------+------+-----+---------+-------+ | order_num | int(11) | NO | PRI | NULL | | | order_item | int(11) | NO | PRI | NULL | | | prod_id | char(10) | NO | MUL | NULL | | | quantity | int(11) | NO | | NULL | | | item_price | decimal(8,2) | NO | | NULL | | +------------+--------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) mysql&gt; select * from OrderItems; +-----------+------------+---------+----------+------------+ | order_num | order_item | prod_id | quantity | item_price | +-----------+------------+---------+----------+------------+ | 20005 | 1 | BR01 | 100 | 5.49 | | 20005 | 2 | BR03 | 100 | 10.99 | | 20006 | 1 | BR01 | 20 | 5.99 | | 20006 | 2 | BR02 | 10 | 8.99 | | 20006 | 3 | BR03 | 10 | 11.99 | | 20007 | 1 | BR03 | 50 | 11.49 | | 20007 | 2 | BNBG01 | 100 | 2.99 | | 20007 | 3 | BNBG02 | 100 | 2.99 | | 20007 | 4 | BNBG03 | 100 | 2.99 | | 20007 | 5 | RGAN01 | 50 | 4.49 | | 20008 | 1 | RGAN01 | 5 | 4.99 | | 20008 | 2 | BR03 | 5 | 11.99 | | 20008 | 3 | BNBG01 | 10 | 3.49 | | 20008 | 4 | BNBG02 | 10 | 3.49 | | 20008 | 5 | BNBG03 | 10 | 3.49 | | 20009 | 1 | BNBG01 | 250 | 2.49 | | 20009 | 2 | BNBG02 | 250 | 2.49 | | 20009 | 3 | BNBG03 | 250 | 2.49 | +-----------+------------+---------+----------+------------+ 18 rows in set (0.00 sec) 2. 检索数据2.1 SELECT# 检索单个列 SELECT prod_name FROM Products; # 检索多个列 SELECT prod_id, prod_name, prod_price FROM Products; # 检索所有列 SELECT * FROM Products; 2.2 DISTINCT mysql&gt; SELECT vend_id -&gt; FROM Products; +---------+ | vend_id | +---------+ | BRS01 | | BRS01 | | BRS01 | | DLL01 | | DLL01 | | DLL01 | | DLL01 | | FNG01 | | FNG01 | +---------+ 9 rows in set (0.00 sec) mysql&gt; SELECT DISTINCT vend_id -&gt; FROM Products; +---------+ | vend_id | +---------+ | BRS01 | | DLL01 | | FNG01 | +---------+ 3 rows in set (0.00 sec) 2.3 LIMIT/OFFSETmysql&gt; SELECT prod_name -&gt; FROM Products; +---------------------+ | prod_name | +---------------------+ | Fish bean bag toy | | Bird bean bag toy | | Rabbit bean bag toy | | 8 inch teddy bear | | 12 inch teddy bear | | 18 inch teddy bear | | Raggedy Ann | | King doll | | Queen doll | +---------------------+ # 返回前 5 行 mysql&gt; SELECT prod_name -&gt; FROM Products -&gt; LIMIT 5; +---------------------+ | prod_name | +---------------------+ | Fish bean bag toy | | Bird bean bag toy | | Rabbit bean bag toy | | 8 inch teddy bear | | 12 inch teddy bear | +---------------------+ # 返回从第 3 行 (1+2) 开始，不超过 4 行的数据 mysql&gt; SELECT prod_name -&gt; FROM Products -&gt; LIMIT 4 OFFSET 2; +---------------------+ | prod_name | +---------------------+ | Rabbit bean bag toy | | 8 inch teddy bear | | 12 inch teddy bear | | 18 inch teddy bear | +---------------------+ # 返回第 3~6 行 mysql&gt; SELECT prod_name -&gt; FROM Products -&gt; LIMIT 2, 4; +---------------------+ | prod_name | +---------------------+ | Rabbit bean bag toy | | 8 inch teddy bear | | 12 inch teddy bear | | 18 inch teddy bear | +---------------------+ 4 rows in set (0.00 sec) 3. 排序检索数据3.1 ORDER BY 注意：确保ORDER BY是SELECT语句中最后一条子句，否则会报错 # 通过选择的列进行排序 SELECT prod_name FROM Products ORDER BY prod_name; # 通过非选择列进行排序 SELECT prod_name FROM Products ORDER BY prod_id; # 按多个列排序 SELECT prod_id, prod_price, prod_name FROM Products ORDER BY prod_price, prod_name; -- 或者 ORDER BY 2, 3; 3.2 DESC/ASC 默认升序ASC，使用DESC关键字降序排序 SELECT prod_id, prod_price, prod_name FROM Products ORDER BY prod_price DESC, prod_name; 4. 过滤数据4.1 WHEREmysql&gt; SELECT prod_name, prod_price -&gt; FROM Products -&gt; WHERE prod_price = 3.49 -&gt; ORDER BY prod_name; +---------------------+------------+ | prod_name | prod_price | +---------------------+------------+ | Bird bean bag toy | 3.49 | | Fish bean bag toy | 3.49 | | Rabbit bean bag toy | 3.49 | +---------------------+------------+ 4.2 WHERE 子句操作符 操作符 说明 = 等于 &lt;&gt; 不等于 != 不等于 &lt; 小于 &lt;= 小于等于 !&lt; 不小于 &gt; 大于 &gt;= 大于等于 !&gt; 不大于 BETWEEN 在两个值之间 IS NULL 为 NULL 值 # 范围值检查 SELECT prod_name, prod_price FROM Products WHERE prod_price BETWEEN 5 AND 10; # 空值检查 SELECT cust_name FROM Customers WHERE cust_email IS NULL; 5. 高级数据过滤5.1 ANDSELECT prod_id, prod_price, prod_name FROM Products WHERE vend_id = &#39;DLL01&#39; AND prod_price &lt;= 4; 5.2 OR事实上，许多 DBMS 在OR WHERE子句的第一个条件得到满足的情况下，就不再计算第二个条件了： SELECT prod_name, prod_price FROM Products WHERE vend_id = &#39;DLL01&#39; OR vend_id = &#39;BRS01&#39;; 5.3 AND 和 OR 的优先级在 SQL 中，AND的优先级比OR高，因此尽量使用圆括号明确分组操作符： SELECT prod_name, prod_price FROM Products WHERE (vend_id = &#39;DLL01&#39; OR vend_id = &#39;BRS01&#39;) AND prod_price &gt;= 10; 5.4 ININ操作符用来指定条件范围： SELECT prod_name, prod_price FROM Products WHERE vend_id IN (&#39;DLL01&#39;, &#39;BRS01&#39;) ORDER BY prod_name; 5.5 NOTNOT关键字用来在WHERE子句中否定其后条件： SELECT prod_name FROM Products WHERE NOT vend_id = &#39;DLL01&#39; ORDER BY prod_name; 这与使用&lt;&gt;操作符效果相同： SELECT prod_name FROM Products WHERE vend_id &lt;&gt; &#39;DLL01&#39; ORDER BY prod_name; MariaDB 支持使用NOT否定IN、BETWEEN、EXISTS子句。大多数 DBMS 允许使用NOT否定任何条件 6. 使用通配符进行过滤 关于MySQL中通配符和正则表达式的使用，参见 MySQL-通配符与正则表达式的使用 | CSDN 6.1 百分号（%）通配符最常用的通配符是百分号%。在搜索串中，%表示任意字符出现任意次数： SELECT prod_id, prod_name FROM Products WHERE prod_name LIKE &#39;%bean bag%&#39;; 注意：通配符%不会匹配NULL 6.2 下划线（_）通配符下划线_只匹配单个字符，而不是多个字符： SELECT prod_id, prod_name FROM Products WHERE prod_name LIKE &#39;__ inch teddy bear&#39;; ------ +---------+--------------------+ | prod_id | prod_name | +---------+--------------------+ | BR02 | 12 inch teddy bear | | BR03 | 18 inch teddy bear | +---------+--------------------+ 6.3 方括号（[]）通配符 注意：仅在Access及SQL Server中有效 方括号通配符[]用来指定一个字符集，它会匹配指定位置上的一个字符： SELECT cust_contact FROM Customers WHERE cust_contact LIKE &#39;[JM]%&#39; ORDER BY cust_contact; 使用前缀字符^表示否定： SELECT cust_contact FROM Customers WHERE cust_contact LIKE &#39;[^JM]%&#39; ORDER BY cust_contact; 更新中… 参考文章 《SQL 必知必会》 Sams Teach Yourself SQL in 10 Minutes (Fourth Edition) | Ben Forta MySQL-通配符与正则表达式的使用 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）Golang ORM 框架：GORMLeetcode 题解 in Golang（不定期更新）数据库系统原理笔记《数据库系统概论》学习笔记之关系数据库《数据库系统概论》学习笔记之绪论","categories":[{"name":"数据库","slug":"数据库","permalink":"https://abelsu7.top/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://abelsu7.top/tags/数据库/"},{"name":"SQL","slug":"SQL","permalink":"https://abelsu7.top/tags/SQL/"}]},{"title":"《KVM 实战》笔记 2：KVM 管理工具","slug":"kvm-in-action-2","date":"2019-05-30T03:11:46.000Z","updated":"2019-09-01T13:04:11.429Z","comments":true,"path":"2019/05/30/kvm-in-action-2/","link":"","permalink":"https://abelsu7.top/2019/05/30/kvm-in-action-2/","excerpt":"摘自 《KVM实战：原理、进阶与性能调优》 《KVM实战：原理、进阶与性能调优》","text":"摘自 《KVM实战：原理、进阶与性能调优》 《KVM实战：原理、进阶与性能调优》 目录1. libvirt1.1 libvirt 简介什么是 libvirtlibvirt 是目前使用最为广泛的对 KVM 虚拟机进行管理的工具和 API，主要作为连接底层 Hypervisor 和上层应用程序的一个中间适配层。 libvirt 支持多种 Hypervisor 主要模块libvirt 主要包含三个模块： 守护进程libvirtd：接收并处理 API 请求 API 库：可基于此 API 开发管理工具，例如virt-manager virsh是经常会使用到的 KVM 命令行管理工具 层次结构 libvirt 的层次结构 libvirt 总体上可分为三个层次： 公共接口层（Public API Layer） 驱动接口层（Driver API Layer） 驱动实现层（Driver Implementation Layer） 重要概念另外，在libvirt 中涉及到以下几个重要概念： 节点Node：是一个物理机器，上面可能运行着多个虚拟客户机。Hypervisor和Domain都运行在节点上 Hypervisor：也称虚拟机监控器（VMM），如 KVM、Xen、VMWare、Hyper-V 等，是虚拟化中的一个底层软件层，它可以虚拟化一个节点使其运行多个虚拟客户机 域Domain：是在Hypervisor上运行的一个客户机操作系统实例。域也被称为实例（instance）、客户机操作系统（Guest OS）或虚拟机（VM），它们都是同一个概念 管理功能libvirt 的管理功能主要包含以下五个部分： 域的管理：包括对节点上的域的各个生命周期的管理，如启动、停止、暂停、保存、恢复和动态迁移，以及对多种设备类型的热拔插操作 远程节点的管理：只要物理节点上运行了libvirtd守护进程，远程的管理程序就可以连接到该节点进行管理操作。libvirt 支持多种网络远程传输类型，如 SSH、TCP 套接字、Unix domain socket、TLS 的加密传输等。例如，可通过virsh -c qemu+ssh://root@example.com/system连接到example.com上，从而管理其上的域 存储的管理：任何运行了libvirtd守护进程的主机，都可以通过 libvirt 来管理不同类型的存储，如创建不同格式的客户机镜像、挂载 NFS、查看现有的 LVM 卷组、创建新的 LVM 卷组和逻辑卷、对磁盘设备分区、挂载 iSCSI 共享存储、使用 Ceph 系统支持的 RBD 远程存储等 网络的管理：列出现有的网络接口、配置网络接口、创建虚拟网络接口、桥接、VLAN 管理、NAT 网络设置、为客户机分配虚拟网络等 提供一个稳定、可靠、高效的 API，以便可以完成前面的四个管理功能 1.2 libvirt 的安装与配置安装 libvirt在CentOS 7.5中，部分 libvirt 相关的包如下所示： &gt; yum install libvirt &gt; rpm -qa | grep libvirt libvirt-daemon-driver-network-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-mpath-4.5.0-10.el7_6.6.x86_64 libvirt-libs-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-config-network-4.5.0-10.el7_6.6.x86_64 libvirt-python-4.5.0-1.el7.x86_64 libvirt-daemon-driver-storage-rbd-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-kvm-4.5.0-10.el7_6.6.x86_64 libvirt-gconfig-1.0.0-1.el7.x86_64 libvirt-bash-completion-4.5.0-10.el7_6.6.x86_64 libvirt-glib-1.0.0-1.el7.x86_64 libvirt-daemon-driver-secret-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-lxc-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-nwfilter-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-gluster-4.5.0-10.el7_6.6.x86_64 libvirt-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-iscsi-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-interface-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-config-nwfilter-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-scsi-4.5.0-10.el7_6.6.x86_64 libvirt-devel-4.5.0-10.el7_6.6.x86_64 libvirt-client-4.5.0-10.el7_6.6.x86_64 libvirt-gobject-1.0.0-1.el7.x86_64 libvirt-daemon-driver-nodedev-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-qemu-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-disk-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-core-4.5.0-10.el7_6.6.x86_64 libvirt-daemon-driver-storage-logical-4.5.0-10.el7_6.6.x86_64 libvirt 的配置文件首先查看libvirtd的使用说明： &gt; libvirtd --help Usage: libvirtd [options] Options: -h | --help Display program help: -v | --verbose Verbose messages. -d | --daemon Run as a daemon &amp; write PID file. -l | --listen Listen for TCP/IP connections. -t | --timeout &lt;secs&gt; Exit after timeout period. -f | --config &lt;file&gt; Configuration file. -V | --version Display version information. -p | --pid-file &lt;file&gt; Change name of PID file. libvirt management daemon: Default paths: Configuration file (unless overridden by -f): /etc/libvirt/libvirtd.conf Sockets: /var/run/libvirt/libvirt-sock /var/run/libvirt/libvirt-sock-ro TLS: CA certificate: /etc/pki/CA/cacert.pem Server certificate: /etc/pki/libvirt/servercert.pem Server private key: /etc/pki/libvirt/private/serverkey.pem PID file (unless overridden by -p): /var/run/libvirtd.pid 以CentOS 7.5为例，libvirt 的相关配置文件都在/etc/libvirt/目录中： /etc/libvirt &gt; ls -hl total 80K -rw-r--r-- 1 root root 450 Mar 14 18:25 libvirt-admin.conf -rw-r--r-- 1 root root 547 Mar 14 18:25 libvirt.conf -rw-r--r-- 1 root root 17K Mar 14 18:25 libvirtd.conf -rw-r--r-- 1 root root 1.2K Mar 14 18:25 lxc.conf drwx------. 2 root root 4.0K Apr 24 16:29 nwfilter drwx------. 3 root root 55 May 30 11:18 qemu -rw-r--r-- 1 root root 30K Mar 14 18:25 qemu.conf -rw-r--r-- 1 root root 2.2K Mar 14 18:25 qemu-lockd.conf drwx------. 2 root root 6 Nov 13 2018 secrets drwxr-xr-x 3 root root 116 Apr 25 09:22 storage -rw-r--r-- 1 root root 3.2K Mar 14 18:25 virtlockd.conf -rw-r--r-- 1 root root 3.2K Mar 14 18:25 virtlogd.conf /etc/libvirt &gt; cd qemu /etc/libvirt/qemu &gt; ls -hl total 16K drwx------. 3 root root 42 Apr 25 10:23 networks -rw------- 1 root root 4.1K May 30 11:18 win10.xml -rw------- 1 root root 4.5K Apr 25 10:21 win7.xml 其中几个重要的配置文件和目录介绍如下： (1) /etc/libvirt/libvirt.conflibvirt.conf文件用于配置本地默认的URI连接以及一些常用libvirt远程连接的别名： # # This can be used to setup URI aliases for frequently # used connection URIs. Aliases may contain only the # characters a-Z, 0-9, _, -. # # Following the &#39;=&#39; may be any valid libvirt connection # URI, including arbitrary parameters #uri_aliases = [ # &quot;hail=qemu+ssh://root@hail.cloud.example.com/system&quot;, # &quot;sleet=qemu+ssh://root@sleet.cloud.example.com/system&quot;, #] # # These can be used in cases when no URI is supplied by the application # (@uri_default also prevents probing of the hypervisor driver). # #uri_default = &quot;qemu:///system&quot; uri_aliases = [ &quot;abelsu7-ubuntu=qemu+ssh://root@abelsu7-ubuntu/system&quot;, &quot;centos-1=qemu+ssh://root@centos-1/system&quot; ] 配置别名后，即可使用abelsu7-ubuntu来替代qemu+ssh://root@abelsu7-ubuntu/system远程的libvirt连接： &gt; systemctl reload libvirtd # 重启 libvirtd &gt; virsh -c abelsu7-ubuntu # 使用别名连接至远程 libvirt Welcome to virsh, the virtualization interactive terminal. Type: &#39;help&#39; for help with commands &#39;quit&#39; to quit virsh # hostname abelsu7-ubuntu virsh # 当然在代码中也可以使用这个别名，例如以下 Go 代码： package main import ( libvirt &quot;github.com/libvirt/libvirt-go&quot; ) func main() { // conn, err := libvirt.NewConnect(&quot;qemu+ssh://root@abelsu7-ubuntu/system&quot;) conn, err := libvirt.NewConnect(&quot;abelsu7-ubuntu&quot;) ... ... } (2) /etc/libvirt/libvirtd.conflibvirtd.conf是 libvirt 的守护进程libvirtd的配置文件，被修改后需要让 libvirtd 重新加载配置文件或重启 libvirtd 才会生效。 在libvirtd.conf中配置了libvirtd启动时的许多设置，包括是否建立 TCP、UNIX domain socket 等连接方式及其最大连接数，以及这些连接的认证机制，设置libvirtd的日志级别等 例如修改libvirtd.conf中的以下配置： listen_tls = 0 # 关闭 TLS 安全认证的连接（默认是打开的） listen_tcp = 1 # 打开 TCP 连接（默认是关闭的） tcp_port = &quot;16666&quot; # 设置 TCP 监听的端口 unix_sock_dir = &quot;/var/run/libvirt&quot; # 设置 UNIX domain socket 的保存目录 auth_tcp = &quot;none&quot; # TCP 连接不使用认证授权方式 要让 TCP、TLS 等连接生效，需要在启动libvirtd时加上--listen参数 修改完成后，使用systemctl命令重启libvirtd服务： > systemctl daemon-reload > systemctl restart libvirtd > systemctl status libvirtd ● libvirtd.service - Virtualization daemon Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2019-06-03 11:08:57 CST; 8s ago Docs: man:libvirtd(8) https://libvirt.org Main PID: 12192 (libvirtd) Tasks: 19 (limit: 32768) Memory: 13.6M CGroup: /system.slice/libvirtd.service ├─ 1827 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper ├─ 1828 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper └─12192 /usr/sbin/libvirtd --listen Jun 03 11:08:57 centos-2 systemd[1]: Starting Virtualization daemon... Jun 03 11:08:57 centos-2 systemd[1]: Started Virtualization daemon. Jun 03 11:08:57 centos-2 dnsmasq[1827]: read /etc/hosts - 5 addresses Jun 03 11:08:57 centos-2 dnsmasq[1827]: read /var/lib/libvirt/dnsmasq/default.addnhosts - 0 addresses Jun 03 11:08:57 centos-2 dnsmasq-dhcp[1827]: read /var/lib/libvirt/dnsmasq/default.hostsfile 可以看到libvirtd的启动命令已经添加了--listen参数。测试一下 TCP 连接是否可用： > virsh -c qemu+tcp://localhost:16666/system Welcome to virsh, the virtualization interactive terminal. Type: 'help' for help with commands 'quit' to quit virsh # exit > ll /var/run/libvirt/ total 0 drwxr-xr-x 2 root root 100 Jun 3 11:08 network srwx------ 1 root root 0 Jun 3 11:08 libvirt-admin-sock srwxrwxrwx 1 root root 0 Jun 3 11:08 libvirt-sock srwxrwxrwx 1 root root 0 Jun 3 11:08 libvirt-sock-ro drwxr-xr-x 2 root root 40 May 30 11:32 qemu srw-rw-rw- 1 root root 0 May 30 11:19 virtlogd-admin-sock drwxr-xr-x 2 root root 40 May 29 09:47 lxc drwxr-xr-x 2 root root 40 May 29 09:47 hostdevmgr drwx------ 2 root root 40 May 29 09:47 nwfilter-binding drwxr-xr-x 2 root root 40 May 29 09:47 storage srw-rw-rw- 1 root root 0 May 29 09:47 virtlockd-sock srw-rw-rw- 1 root root 0 May 29 09:47 virtlogd-sock (3) /etc/libvirt/qemu.confqemu.conf是 libvirt 对 QEMU 的驱动配置文件，包括 VNC、SPICE 等，以及连接它们时采用的权限认证方式的配置，也包括内存大页、SELinux、Cgroups 等相关配置。 (4) /etc/libvirt/qemu 目录在qemu目录下存放的是使用 QEMU 驱动的域的配置文件，查看qemu目录如下： &gt; ls -l total 16 drwx------. 3 root root 42 Apr 25 10:23 networks -rw------- 1 root root 4165 May 30 11:18 win10.xml -rw------- 1 root root 4560 Apr 25 10:21 win7.xml 其中包括了两个域的 XML 配置文件（win10.xml和win7.xml），这是使用virt-manager工具创建的两个域，默认会将其保存到/etc/libvirt/qemu/目录下。 另一个networks目录则保存了创建一个域时默认使用的网络配置。 libvirtd 的使用libvirtd是虚拟化管理系统中服务端的守护进程。要想让某个节点能够利用 libvirt 进行管理，就需要在这个节点上运行libvirtd守护进程，以便让其他上层管理工具可以连接到该节点。 在RHEL 7.3和CentOS 7.5中，libvirtd是作为一个服务配置在系统中的： &gt; systemctl list-unit-files | grep libvirtd libvirtd.service enabled &gt; systemctl is-enabled libvirtd enabled &gt; systemctl is-active libvirtd active &gt; systemctl status libvirtd ● libvirtd.service - Virtualization daemon Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2019-06-03 11:08:57 CST; 22h ago Docs: man:libvirtd(8) https://libvirt.org Main PID: 12192 (libvirtd) Tasks: 20 (limit: 32768) Memory: 23.2M CGroup: /system.slice/libvirtd.service ├─ 1827 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper ├─ 1828 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper └─12192 /usr/sbin/libvirtd --listen Jun 03 17:19:33 centos-2 libvirtd[12192]: 2019-06-03 09:19:33.679+0000: 12195: warning : qemuProcessVerifyHypervFeatures:3936 : host doesn&#39;t support hyper...d&#39; feature Jun 03 17:19:33 centos-2 libvirtd[12192]: 2019-06-03 09:19:33.679+0000: 12195: warning : qemuProcessVerifyHypervFeatures:3936 : host doesn&#39;t support hyper...c&#39; feature Jun 03 17:19:33 centos-2 libvirtd[12192]: 2019-06-03 09:19:33.679+0000: 12195: warning : qemuProcessVerifyHypervFeatures:3936 : host doesn&#39;t support hyper...s&#39; feature Jun 03 17:20:41 centos-2 dnsmasq-dhcp[1827]: DHCPDISCOVER(virbr0) 192.168.122.176 52:54:00:b1:88:3b Jun 03 17:20:41 centos-2 dnsmasq-dhcp[1827]: DHCPOFFER(virbr0) 192.168.122.176 52:54:00:b1:88:3b Jun 03 17:20:41 centos-2 dnsmasq-dhcp[1827]: DHCPREQUEST(virbr0) 192.168.122.176 52:54:00:b1:88:3b Jun 03 17:20:41 centos-2 dnsmasq-dhcp[1827]: DHCPACK(virbr0) 192.168.122.176 52:54:00:b1:88:3b DESKTOP-RKPPR8A Jun 03 17:20:46 centos-2 dnsmasq-dhcp[1827]: DHCPREQUEST(virbr0) 192.168.122.176 52:54:00:b1:88:3b Jun 03 17:20:46 centos-2 dnsmasq-dhcp[1827]: DHCPACK(virbr0) 192.168.122.176 52:54:00:b1:88:3b DESKTOP-RKPPR8A Jun 03 17:31:35 centos-2 libvirtd[12192]: 2019-06-03 09:31:35.081+0000: 12192: error : qemuMonitorIO:718 : internal error: End of file from qemu monitor Hint: Some lines were ellipsized, use -l to show in full. 默认情况下，libvirt 监听一个本地的 Unix domain socket，而没有监听基于网络的 TCP/IP socket，需要使用-l或者--listen的命令行参数来开启对libvirtd.conf配置文件中TCP/IP socket的监听 libvirtd守护进程的启动或停止，并不会直接影响正在运行中的客户机 libvirtd在启动或重启完成时，只要客户机的 XML 配置文件是存在的，libvirtd就会自动加载这些客户机的配置，获取它们的信息 如果客户机没有基于libvirt格式的 XML 文件来运行（例如直接通过qemu命令行启动的客户机），libvirtd就不会自动发现它们 libvirtd 常用的命令行参数libvirtd常用的命令行参数如下： -d或--daemon：作为守护进程在后台运行 -f或--config FILE：指定配置文件为FILE，默认为/etc/libvirt/libvirtd.conf -l或--listen：监听配置文件中的 TCP Socket -p或--pid-file FILE：将libvirtd进程的 PID 写入FILE文件中，默认为/var/run/libvirtd.pid -t或--timeout SECONDS：设置超时时间为SECONDS秒 -v或--verbose：调整日志级别为Verbose -V或--version：版本号 &gt; libvirtd --help Usage: libvirtd [options] Options: -h | --help Display program help: -v | --verbose Verbose messages. -d | --daemon Run as a daemon &amp; write PID file. -l | --listen Listen for TCP/IP connections. -t | --timeout &lt;secs&gt; Exit after timeout period. -f | --config &lt;file&gt; Configuration file. -V | --version Display version information. -p | --pid-file &lt;file&gt; Change name of PID file. libvirt management daemon: Default paths: Configuration file (unless overridden by -f): /etc/libvirt/libvirtd.conf Sockets: /var/run/libvirt/libvirt-sock /var/run/libvirt/libvirt-sock-ro TLS: CA certificate: /etc/pki/CA/cacert.pem Server certificate: /etc/pki/libvirt/servercert.pem Server private key: /etc/pki/libvirt/private/serverkey.pem PID file (unless overridden by -p): /var/run/libvirtd.pid 1.3 域的 XML 配置文件配置文件格式示例在 libvirt 中，客户机（即域）的配置是采用 XML 格式来描述的。例如下面是我使用virt-manager创建的客户机配置文件fedora-30.xml： &lt;!-- WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE OVERWRITTEN AND LOST. Changes to this xml configuration should be made using: virsh edit fedora-30 or other application using the libvirt API. --&gt; &lt;domain type=&#39;kvm&#39;&gt; &lt;name&gt;fedora-30&lt;/name&gt; &lt;uuid&gt;70b8f58a-1589-4b83-bfd1-90dfd0cc8a56&lt;/uuid&gt; &lt;memory unit=&#39;KiB&#39;&gt;16777216&lt;/memory&gt; &lt;currentMemory unit=&#39;KiB&#39;&gt;16777216&lt;/currentMemory&gt; &lt;vcpu placement=&#39;static&#39;&gt;4&lt;/vcpu&gt; &lt;os&gt; &lt;type arch=&#39;x86_64&#39; machine=&#39;pc-i440fx-2.11&#39;&gt;hvm&lt;/type&gt; &lt;boot dev=&#39;hd&#39;/&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;vmport state=&#39;off&#39;/&gt; &lt;/features&gt; &lt;cpu mode=&#39;host-model&#39; check=&#39;partial&#39;&gt; &lt;model fallback=&#39;allow&#39;/&gt; &lt;/cpu&gt; &lt;clock offset=&#39;utc&#39;&gt; &lt;timer name=&#39;rtc&#39; tickpolicy=&#39;catchup&#39;/&gt; &lt;timer name=&#39;pit&#39; tickpolicy=&#39;delay&#39;/&gt; &lt;timer name=&#39;hpet&#39; present=&#39;no&#39;/&gt; &lt;/clock&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;destroy&lt;/on_crash&gt; &lt;pm&gt; &lt;suspend-to-mem enabled=&#39;no&#39;/&gt; &lt;suspend-to-disk enabled=&#39;no&#39;/&gt; &lt;/pm&gt; &lt;devices&gt; &lt;emulator&gt;/usr/bin/kvm-spice&lt;/emulator&gt; &lt;disk type=&#39;file&#39; device=&#39;disk&#39;&gt; &lt;driver name=&#39;qemu&#39; type=&#39;qcow2&#39;/&gt; &lt;source file=&#39;/var/lib/libvirt/images/generic.qcow2&#39;/&gt; &lt;target dev=&#39;hda&#39; bus=&#39;ide&#39;/&gt; &lt;address type=&#39;drive&#39; controller=&#39;0&#39; bus=&#39;0&#39; target=&#39;0&#39; unit=&#39;0&#39;/&gt; &lt;/disk&gt; &lt;disk type=&#39;file&#39; device=&#39;cdrom&#39;&gt; &lt;driver name=&#39;qemu&#39; type=&#39;raw&#39;/&gt; &lt;target dev=&#39;hdb&#39; bus=&#39;ide&#39;/&gt; &lt;readonly/&gt; &lt;address type=&#39;drive&#39; controller=&#39;0&#39; bus=&#39;0&#39; target=&#39;0&#39; unit=&#39;1&#39;/&gt; &lt;/disk&gt; &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-ehci1&#39;&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x7&#39;/&gt; &lt;/controller&gt; &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci1&#39;&gt; &lt;master startport=&#39;0&#39;/&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x0&#39; multifunction=&#39;on&#39;/&gt; &lt;/controller&gt; &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci2&#39;&gt; &lt;master startport=&#39;2&#39;/&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x1&#39;/&gt; &lt;/controller&gt; &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci3&#39;&gt; &lt;master startport=&#39;4&#39;/&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x2&#39;/&gt; &lt;/controller&gt; &lt;controller type=&#39;pci&#39; index=&#39;0&#39; model=&#39;pci-root&#39;/&gt; &lt;controller type=&#39;ide&#39; index=&#39;0&#39;&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x01&#39; function=&#39;0x1&#39;/&gt; &lt;/controller&gt; &lt;controller type=&#39;virtio-serial&#39; index=&#39;0&#39;&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x06&#39; function=&#39;0x0&#39;/&gt; &lt;/controller&gt; &lt;interface type=&#39;network&#39;&gt; &lt;mac address=&#39;52:54:00:36:59:c3&#39;/&gt; &lt;source network=&#39;default&#39;/&gt; &lt;model type=&#39;rtl8139&#39;/&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x03&#39; function=&#39;0x0&#39;/&gt; &lt;/interface&gt; &lt;serial type=&#39;pty&#39;&gt; &lt;target type=&#39;isa-serial&#39; port=&#39;0&#39;&gt; &lt;model name=&#39;isa-serial&#39;/&gt; &lt;/target&gt; &lt;/serial&gt; &lt;console type=&#39;pty&#39;&gt; &lt;target type=&#39;serial&#39; port=&#39;0&#39;/&gt; &lt;/console&gt; &lt;channel type=&#39;spicevmc&#39;&gt; &lt;target type=&#39;virtio&#39; name=&#39;com.redhat.spice.0&#39;/&gt; &lt;address type=&#39;virtio-serial&#39; controller=&#39;0&#39; bus=&#39;0&#39; port=&#39;1&#39;/&gt; &lt;/channel&gt; &lt;input type=&#39;mouse&#39; bus=&#39;ps2&#39;/&gt; &lt;input type=&#39;keyboard&#39; bus=&#39;ps2&#39;/&gt; &lt;graphics type=&#39;spice&#39; autoport=&#39;yes&#39; listen=&#39;0.0.0.0&#39;&gt; &lt;listen type=&#39;address&#39; address=&#39;0.0.0.0&#39;/&gt; &lt;image compression=&#39;off&#39;/&gt; &lt;/graphics&gt; &lt;sound model=&#39;ich6&#39;&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x04&#39; function=&#39;0x0&#39;/&gt; &lt;/sound&gt; &lt;video&gt; &lt;model type=&#39;qxl&#39; ram=&#39;65536&#39; vram=&#39;65536&#39; vgamem=&#39;16384&#39; heads=&#39;1&#39; primary=&#39;yes&#39;/&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x02&#39; function=&#39;0x0&#39;/&gt; &lt;/video&gt; &lt;redirdev bus=&#39;usb&#39; type=&#39;spicevmc&#39;&gt; &lt;address type=&#39;usb&#39; bus=&#39;0&#39; port=&#39;1&#39;/&gt; &lt;/redirdev&gt; &lt;redirdev bus=&#39;usb&#39; type=&#39;spicevmc&#39;&gt; &lt;address type=&#39;usb&#39; bus=&#39;0&#39; port=&#39;2&#39;/&gt; &lt;/redirdev&gt; &lt;memballoon model=&#39;virtio&#39;&gt; &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x07&#39; function=&#39;0x0&#39;/&gt; &lt;/memballoon&gt; &lt;/devices&gt; &lt;/domain&gt; 如需编辑fedora-30.xml，请使用virsh edit fedora-30命令 在该域的 XML 文件中，所有的有效配置都在&lt;domain&gt;和&lt;/domain&gt;标签之间，这表明该配置文件是一个域的配置。 通过 libvirt 启动客户机，经过文件解析和命令参数的转换，最终也会调用qemu命令行工具来实际完成客户机的创建。该命令行参数非常详尽冗长，通过ps命令查询到的创建命令如下： &gt; ps -ef | grep qemu | grep fedora-30 libvirt+ 20817 1 0 10:23 ? 00:02:39 qemu-system-x86_64 -enable-kvm -name guest=fedora-30,debug-threads=on -S -object secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-35-fedora-30/master-key.aes -machine pc-i440fx-2.11,accel=kvm,usb=off,vmport=off,dump-guest-core=off -cpu Skylake-Client-IBRS,ss=on,vmx=on,hypervisor=on,tsc_adjust=on,clflushopt=on,ssbd=on,xsaves=on,pdpe1gb=on -m 16384 -realtime mlock=off -smp 4,sockets=4,cores=1,threads=1 -uuid 70b8f58a-1589-4b83-bfd1-90dfd0cc8a56 -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/domain-35-fedora-30/monitor.sock,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=delay -no-hpet -no-shutdown -global PIIX4_PM.disable_s3=1 -global PIIX4_PM.disable_s4=1 -boot strict=on -device ich9-usb-ehci1,id=usb,bus=pci.0,addr=0x5.0x7 -device ich9-usb-uhci1,masterbus=usb.0,firstport=0,bus=pci.0,multifunction=on,addr=0x5 -device ich9-usb-uhci2,masterbus=usb.0,firstport=2,bus=pci.0,addr=0x5.0x1 -device ich9-usb-uhci3,masterbus=usb.0,firstport=4,bus=pci.0,addr=0x5.0x2 -device virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6 -drive file=/var/lib/libvirt/images/generic.qcow2,format=qcow2,if=none,id=drive-ide0-0-0 -device ide-hd,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive if=none,id=drive-ide0-0-1,readonly=on -device ide-cd,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=27,id=hostnet0 -device rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:36:59:c3,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -chardev spicevmc,id=charchannel0,name=vdagent -device virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=com.redhat.spice.0 -spice port=5900,addr=0.0.0.0,disable-ticketing,image-compression=off,seamless-migration=on -device qxl-vga,id=video0,ram_size=67108864,vram_size=67108864,vram64_size_mb=0,vgamem_mb=16,max_outputs=1,bus=pci.0,addr=0x2 -device intel-hda,id=sound0,bus=pci.0,addr=0x4 -device hda-duplex,id=sound0-codec0,bus=sound0.0,cad=0 -chardev spicevmc,id=charredir0,name=usbredir -device usb-redir,chardev=charredir0,id=redir0,bus=usb.0,port=1 -chardev spicevmc,id=charredir1,name=usbredir -device usb-redir,chardev=charredir1,id=redir1,bus=usb.0,port=2 -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x7 -msg timestamp=on CPU、内存、启动顺序等基本配置关于 CPU 的配置如下： &lt;vcpu placement=&#39;static&#39;&gt;4&lt;/vcpu&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;/features&gt; &lt;cpu mode=&#39;custom&#39; match=&#39;exact&#39;&gt; &lt;model fallback=&#39;allow&#39;&gt;Haswell-noTSX&lt;/model&gt; &lt;/cpu&gt; 关于内存的配置如下： &lt;domain&gt; ... &lt;memory unit=&#39;KiB&#39;&gt;16777216&lt;/memory&gt; &lt;currentMemory unit=&#39;KiB&#39;&gt;16777216&lt;/currentMemory&gt; ... &lt;/domain&gt; 关于客户机类型和启动顺序配置如下： &lt;os&gt; &lt;type arch=&#39;x86_64&#39; machine=&#39;pc-i440fx-2.11&#39;&gt;hvm&lt;/type&gt; &lt;boot dev=&#39;hd&#39;/&gt; &lt;boot dev=&#39;cdrom&#39;/&gt; &lt;/os&gt; 网络的配置更新中… 参考文章 《KVM实战：原理、进阶与性能调优》 libvirt XML Format | libvirt QEMU 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"libvirt","slug":"libvirt","permalink":"https://abelsu7.top/tags/libvirt/"},{"name":"virsh","slug":"virsh","permalink":"https://abelsu7.top/tags/virsh/"},{"name":"virt-manager","slug":"virt-manager","permalink":"https://abelsu7.top/tags/virt-manager/"}]},{"title":"Python 速查","slug":"python-quick-reference","date":"2019-05-29T07:38:02.000Z","updated":"2019-09-01T13:04:11.612Z","comments":true,"path":"2019/05/29/python-quick-reference/","link":"","permalink":"https://abelsu7.top/2019/05/29/python-quick-reference/","excerpt":"C++ 基础速查笔记，摘自 《Python 编程快速上手》","text":"C++ 基础速查笔记，摘自 《Python 编程快速上手》 目录1. Python 基础1.1 数学操作符 操作符 操作 例子 求值 ** 指数 2 ** 3 8 % 取模 22 % 8 6 // 整除 22 // 8 2 / 除法 22 / 8 2.75 * 乘法 3 * 5 15 - 减法 5 - 2 3 + 加法 2 + 2 4 1.2 数据类型 数据类型 例子 整型 int 86 浮点型 float 3.14159 字符串 str &#39;Abel Su&#39; 1.3 字符串连接和复制&gt;&gt;&gt; &#39;Abel&#39; + &#39;Su&#39; &#39;AbelSu&#39; &gt;&gt;&gt; &#39;abel&#39; * 5 &#39;abelabelabelabelabel&#39; 1.4 在变量中保存值&gt;&gt;&gt; name = &#39;Abel&#39; &gt;&gt;&gt; name &#39;Abel&#39; &gt;&gt;&gt; name = &#39;Yuki&#39; &#39;Yuki&#39; 1.5 变量名 只能是一个词 只能包含字母、数字、下划线 不能以数字开头 1.6 常用函数#!/usr/local/bin/python3 print(&#39;Hello Python!&#39;) print(&quot;What&#39;s your name?&quot;) # waiting for input name = input() print(&#39;The length of your name is: &#39; + str(len(name))) print()：打印 input()：读取输入 len()：返回长度 str()：转换为字符串 int()：截断取整 float()：转换为浮点数 2. 控制流2.1 布尔值首字母大写： True False 2.2 操作符# 比较操作符 == != &lt; &gt; &lt;= &gt;= # 布尔操作符 and or not 2.3 if / else / elif#!/usr/local/bin/python3 if name == &#39;Alice&#39;: print(&#39;Hi, Alice.&#39;) elif age &lt; 12: print(&#39;You are not Alice, kiddo.&#39;) elif age &gt; 2000: print(&#39;Unlike you, Alice is not an undead, immortal vampire.&#39;) elif age &gt; 100: print(&#39;You are not Alice, grannie.&#39;) else: print(&#39;You are neither Alice nor a little kid&#39;) 2.4 while / break / continue#!/usr/local/bin/python3 name = &#39;&#39; while name != &#39;your name&#39;: print(&#39;Please type your name&#39;) name = input() print(&#39;Thank you!&#39;) 也可以用break跳出当前循环： #!/usr/local/bin/python3 name = &#39;&#39; while True: print(&#39;Please type your name&#39;) name = input() if name == &#39;your name&#39;: break print(&#39;Thank you!&#39;) 还可以用continue跳过之后的语句，进入下一次循环： #!/usr/local/bin/python3 while True: print(&#39;Who are you?&#39;) name = input() if name != &#39;Joe&#39;: continue print(&#39;Hello, Joe. What is the password?&#39;) password = input() if password == &#39;swordfish&#39;: break print(&#39;Access granted.&#39;) 2.5 for / range range()的三个参数分别为：起始、停止、步长 #!/usr/local/bin/python3 for i in range(0, 10, 2): print(i) 2.6 import / from import#!/usr/local/bin/python3 import random for i in range(5): print(random.randint(1, 10)) 或者使用from import语句，此时调用randint函数不需要random.前缀： #!/usr/local/bin/python3 from random import * for i in range(5): print(randint(1, 10)) 2.7 sys.exit()调用sys.exit()函数，可以让程序提前终止： #!/usr/local/bin/python3 import sys while True: print(&#39;Type exit to exit&#39;) response = input() if response == &#39;exit&#39;: sys.exit() print(&#39;You typed &#39; + response + &#39;.&#39;) 3. 函数3.1 def 语句和参数#!/usr/local/bin/python3 def hello(name): print(&#39;Hello &#39; + name) hello(&#39;Alice&#39;) hello(&#39;Bob&#39;) 3.2 return 语句和返回值#!/usr/local/bin/python3 import random def getAnswer(answerNumber): if answerNumber == 1: return &#39;It is certain&#39; elif answerNumber == 2: return &#39;It is decidedly so&#39; elif answerNumber == 3: return &#39;Yes&#39; elif answerNumber == 4: return &#39;Reply hazy try again&#39; elif answerNumber == 5: return &#39;Ask again later&#39; elif answerNumber == 6: return &#39;Concentrate and ask again&#39; elif answerNumber == 7: return &#39;My reply is no&#39; elif answerNumber == 8: return &#39;Outlook not so good&#39; elif answerNumber == 9: return &#39;Very doubtful&#39; r = random.randint(1, 9) fortune = getAnswer(r) print(fortune) 3.3 None 值None值是NoneType数据类型的唯一值。 对于所有没有return语句的函数定义，Python 都会在末尾加上return None 如果return语句不带返回值，也会默认返回None 这类似于while或for循环隐式的以continue语句结尾 &gt;&gt;&gt; spam = print(&#39;Hello&#39;) Hello &gt;&gt;&gt; None == spam True 3.4 print() 和关键字参数print()函数默认在行末打印换行，可以设置end关键字参数替换行末的换行符： &gt;&gt;&gt; print(&#39;Hello&#39;, end=&#39; &#39;) Hello &gt;&gt;&gt; 如果向print()传入多个字符串值，则该函数会自动的用一个空格来分隔它们： &gt;&gt;&gt; print(&#39;Arsenal&#39;, &#39;Chelsea&#39;, &#39;Liverpool&#39;) Arsenal Chelsea Liverpool 传入sep关键字参数，替换默认的分隔字符串： &gt;&gt;&gt; print(&#39;Arsenal&#39;, &#39;Chelsea&#39;, &#39;Liverpool&#39;, sep=&#39;,&#39;) Arsenal,Chelsea,Liverpool 3.5 global 语句如果需要在一个函数内修改全局变量，则使用global语句： #!/usr/local/bin/python3 def spam(): global eggs eggs = &#39;spam&#39; eggs = &#39;global&#39; spam() print(eggs) 3.6 异常处理#!/usr/local/bin/python3 def spam(divideBy): try: return 42 / divideBy except ZeroDivisionError: print(&#39;Error: Invalid argument&#39;) print(spam(2)) print(spam(12)) print(spam(0)) print(spam(1)) ------ 21.0 3.5 Error: Invalid argument None 42.0 4. 列表5. 字典和结构化数据6. 字符串操作更新中… 参考文章 《Python 编程快速上手》 🚩推荐阅读（由hexo文章推荐插件驱动）C++ 速查使用 pingtop 同时 ping 多台服务器Leetcode 118. 杨辉三角Java 语言推荐书单使用virtualenv创建隔离环境奇异值分解的原理与使用","categories":[{"name":"Python","slug":"Python","permalink":"https://abelsu7.top/categories/Python/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://abelsu7.top/tags/编程/"},{"name":"学习","slug":"学习","permalink":"https://abelsu7.top/tags/学习/"},{"name":"Python","slug":"Python","permalink":"https://abelsu7.top/tags/Python/"}]},{"title":"C++ 速查","slug":"cpp-quick-reference","date":"2019-05-24T03:39:13.000Z","updated":"2019-09-01T13:04:11.105Z","comments":true,"path":"2019/05/24/cpp-quick-reference/","link":"","permalink":"https://abelsu7.top/2019/05/24/cpp-quick-reference/","excerpt":"C++ 基础速查笔记","text":"C++ 基础速查笔记 更新中… 目录1. 绪论 C++ 最初由 Bjarne Stroustroup 于1979年在贝尔实验室开发 C++ 是一种面向对象的语言，实现了继承、封装、多态等概念 1998年，第一个 C++ 标准获得了 ISO 标准委员会的批准，俗称C++98 C++11、C++14、C++17 #include &lt;iostream&gt; int main() { std::cout&lt;&lt; &quot;Hello World!&quot; &lt;&lt; std::endl; return 0; } 2. C++ 程序结构 #include：预处理器编译指令，在编译前运行 &lt; &gt;：包含标准头文件 &quot; &quot;：包含自定义头文件 main()：程序的主体 std::count：命名空间，即namespace C++ 区分大小写 注释会被编译器忽略 int main(int argc, char* argv[]) 3. 变量与常量3.1 变量变量名规范 变量名可包含数字、字母、下划线 但不能以数字开头 变量名不能是保留的关键字 可在同一行初始化多个相同类型的变量 int first = 0, second = 0, third = 0; 命名约定 变量名小写字母开头 函数名等其他元素大写字母开头 驼峰命名法 常用变量类型 C++14新增了用&#39;表示的组块分隔符chunking separator，可以提高数字的可读性 int totalCash = 0; bool isLampOn = false; char userInput = &#39;Y&#39;; short int gradesInMath = -5; int moneyInBank = -7&#39;0000; long populationChange = -8&#39;5000; long long countryGDPChange = -700&#39;0000; unsigned short int numColorsInRainbow = 7; unsigned int unmEggsInBasket = 24; unsigned long numCarsInNewYork = 70&#39;0000; unsigned long long countryMedicareExpense = 7&#39;0000&#39;0000; float pi = 3.14; double morePrecisePi = 22.0 / 7; sizeof 确定变量长度cout &lt;&lt; &quot;Size of an int: &quot; &lt;&lt; sizeof(int); 列表初始化/缩窄转换C++11引入了列表初始化来禁止缩窄转换： int largeNum = 700&#39;0000; short smallNum{largeNum}; auto 自动推断C++11或更高版本可不显式指定变量的类型，而使用关键字auto： auto coinFlippedHeads = true; 注意：如果将变量类型声明为auto，但不对其进行初始化，将出现编译错误 typedef 定义变量类型使用关键字typedef定义变量类型： typedef unsigned int STRICTLY_POSITIVE_INTEGER; STRICTLY_POSITIVE_INTEGER numEggsInBasket = 4532; 3.2 常量在C++中，常量可以是： 字面常量 使用关键字const声明的常量 使用关键字constexpr声明的表达式（C++11新增） 使用关键字enum声明的枚举常量 使用关键字#define定义的常量（已废弃） 字面常量字面常量可以是任何类型。从C++14开始，还可以使用二进制字面常量： int someNumber = 10; int someNumber = 012; // 八进制 int someNumber = 0b1010; // 二进制 const 定义常量使用关键字const定义常量，常量定义后不可修改： const double pi = 22.0 / 7; constexpr 定义常量表达式常量表达式提供了编译阶段优化的可能性。 只要编译器能够从常量表达式计算出常量，就会在编译阶段将其替换为常量，避免了在代码运行时进行计算。 const double GetPi() { return 22.0 / 7; } const double TwicePi() { return 2 * GetPi(); } enum 枚举可使用关键字enum声明枚举，枚举由一组称为枚举量emumerator的常量组成： enum RainbowColors { Violet, // 0 Indigo, // 1 Blue, // 2 Green = 4, // 4, 显式初始化 Yellow, // 5 Orange = 1, // 1, 显式初始化 Red // 2 }; 编译器将枚举量转换为整数，每个枚举量都比前一个大1 如果没有指定起始值，编译器默认起始值为0 可以通过显式初始化为每个枚举量指定值 4. 数组与字符串4.1 静态数组静态数组的长度在编译阶段就已确定，因此其占据的内存也是固定的。 编译器为静态数组预留的内存量为sizeof(element-type)*length const int ARRAY_LENGTH = 5; int myNumbers[ARRAY_LENGTH] = {34, 21, -56, 5002, 1314}; int myNumbers[ARRAY_LENGTH] = {}; // {0, 0, 0, 0, 0} int myNumbers[ARRAY_LENGTH] = {34, 21}; // {34, 21, 0, 0, 0,} 4.2 多维数组int solarPanels[2][3] = {{0, 1, 2}, {3, 4, 5}}; 4.3 动态数组 需要包含头文件#include &lt;vector&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; int main() { vector&lt;int&gt; dynArray(3); // dynamic array of int dynArray[0] = 365; dynArray[1] = -421; dynArray[2] = 789; cout &lt;&lt; &quot;Number of integers in array: &quot; &lt;&lt; dynArray.size() &lt;&lt; endl; cout &lt;&lt; &quot;Enter another element to insert: &quot;; int newValue = 0; cin &gt;&gt; newValue; dynArray.push_back(newValue); cout &lt;&lt; &quot;Number of integers in array: &quot; &lt;&lt; dynArray.size() &lt;&lt; endl; cout &lt;&lt; &quot;Last element in array: &quot;; cout &lt;&lt; dynArray[dynArray.size() - 1] &lt;&lt; endl; return 0; } ------ Number of integers in array: 3 Enter another element to insert: 4 Number of integers in array: 4 Last element in array: 4 4.4 C 风格字符串 最后一个字符为空字符\\0，即终止空字符 数组中间插入\\0不会改变数组的长度，只会导致字符串处理到这个位置结束 #include &lt;iostream&gt; using namespace std; int main() { char sayHello[] = {&#39;H&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39;\\0&#39;}; cout &lt;&lt; sayHello &lt;&lt; endl; cout &lt;&lt; &quot;Size of sayHello: &quot; &lt;&lt; sizeof(sayHello); return 0; } ------ Hello Size of sayHello: 6 4.5 C++ 字符串 std::string不同于字符数组（C 风格字符串实现），std::string是动态的，在需要存储更多数据时其容量会增大。 #include &lt;iostream&gt; #include &lt;string&gt; using namespace std; int main() { string greetStr(&quot;Hello std::string!&quot;); cout &lt;&lt; greetStr &lt;&lt; endl; cout &lt;&lt; &quot;Enter a line of text:&quot; &lt;&lt; endl; string firstLine; getline(cin, firstLine); cout &lt;&lt; &quot;Enter another:&quot; &lt;&lt; endl; string secondLine; getline(cin, secondLine); cout &lt;&lt; &quot;Result of concatenation:&quot; &lt;&lt; endl; string concatStr = firstLine + &quot; &quot; + secondLine; cout &lt;&lt; concatStr &lt;&lt; endl; cout &lt;&lt; &quot;Copy of concatenated string:&quot; &lt;&lt; endl; string aCopy; aCopy = concatStr; cout &lt;&lt; aCopy &lt;&lt; endl; cout &lt;&lt; &quot;Length of concat string: &quot; &lt;&lt; concatStr.length() &lt;&lt; endl; return 0; } ------ Hello std::string! Enter a line of text: this is the first line Enter another: this is the second line Result of concatenation: this is the first line this is the second line Copy of concatenated string: this is the first line this is the second line Length of concat string: 46 5. 语句与运算符5.1 语句当编译器注意到有两个相邻的字符串字面量后，会将其拼接成一个： cout &lt;&lt; &quot;The first line of content&quot; &quot;The second line of content&quot; &quot;The third line of content&quot; &lt;&lt; endl; 5.2 前缀/后缀运算符 后缀运算符num1++先将右值赋给左值，再将右值递增或递减 前缀运算符++num1先将右值递增或递减，再将结果赋给左值 理论上，++startValue优于startValue++，因为使用后缀运算符时，编译器需要临时存储初始值，以防需要将其赋给其他变量 int num1 = 101; int num2 = num1++; // num1 = 102, num2 = 101 int num3 = ++num1; // num1 = 103, num3 = 103 5.3 逻辑运算符 NOT：! AND：&amp;&amp; OR：|| 5.4 位运算符 NOT：~ AND：&amp; OR：| XOR：^ 左移：&lt;&lt;，相当于乘以2^n 右移：&gt;&gt;，相当于除以2^n 6. 控制程序流程6.1 if elseif (condition) { do something... } else { do something else... } 6.2 switch caseswitch (expression) { case /* constant-expression */: /* code */ break; default: break; } 6.3 三目运算符int max = (num1 &gt; num2) ? num1 : num2; 6.4 whilewhile (/* condition */) { /* code */ } 6.5 do whiledo { /* code */ } while (/* condition */); 6.6 forfor (size_t i = 0; i &lt; count; i++) { /* code */ } 6.7 for rangefor (VarType varName : sequence) { do something... } 可以使用关键字auto自动推断变量的类型： for (auto anElement : elements) 6.8 continue 和 break continue：跳转到循环开头，跳过本次循环之后的代码，进入下一次循环 break：退出循环块，结束当前循环 7. 函数7.1 函数原型与函数定义 函数原型：指出了函数的名称、接受的参数列表以及返回值的类型 函数定义：也即函数的实现代码 #include &lt;iostream&gt; using namespace std; const double Pi = 3.14159265; // Function Declarations (Prototypes) double Area(double radius); double Circumference(double radius); int main(int argc, char const *argv[]) { cout &lt;&lt; &quot;Enter radius: &quot;; double radius = 0; cin &gt;&gt; radius; // Call function &quot;Area&quot; cout &lt;&lt; &quot;Area is: &quot; &lt;&lt; Area(radius) &lt;&lt; endl; // Call function &quot;Circumference&quot; cout &lt;&lt; &quot;Circumference is: &quot; &lt;&lt; Circumference(radius) &lt;&lt; endl; return 0; } // Function definitions (Implementations) double Area(double radius) { return Pi * radius * radius; } double Circumference(double radius) { return 2 * Pi * radius; } ------ Enter radius: 10 Area is: 314.159 Circumference is: 62.8319 在函数原型中可以添加函数参数的默认值： double Area(double radius, double Pi = 3.14); 7.2 函数重载// for circle double Area(double radius) { return Pi * radius * radius; } // overloaded for cylinder double Area(double radius, double height) { // reuse the area of circle return 2 * Area(radius) + 2 * Pi * radius * height; } 7.3 按引用传递参数当希望函数修改的变量在其外部中也可用时，可将形参的类型声明为引用： #include &lt;iostream&gt; using namespace std; const double Pi = 3.14159265; // output parameter result by reference void Area(double radius, double &amp;result) { result = Pi * radius * radius; } int main(int argc, char const *argv[]) { cout &lt;&lt; &quot;Enter radius: &quot;; double radius = 0; cin &gt;&gt; radius; double areaFetched = 0; Area(radius, areaFetched); cout &lt;&lt; &quot;The area is: &quot; &lt;&lt; areaFetched &lt;&lt; endl; return 0; } ------ Enter radius: 10 The area is: 314.159 7.4 函数调用函数调用意味着： 微处理器跳转到属于被调用函数的下一条指令处执行，对应CALL指令 执行完函数的指令后，将返回最初离开的地方，对应RET语句 inline 内联函数常规函数调用被转换为CALL指令，这会导致栈操作、微处理器跳转到函数处执行等。但如果函数非常简单： double GetPi() { return 3.14159; } 相对于实际执行GetPi()的时间，执行函数调用的开销可能非常高。使用关键字inline可以让函数在被调用时就地展开： inline double GetPi() { return 3.14159; } 仅当函数非常简单，需要降低开销时，才应使用inline关键字 auto 自动推断返回类型从C++14起，auto也适用于函数返回类型的自动推断： auto Area(double radius) { return Pi * radius * radius; } lambda 函数语法如下，后续会详细介绍： [optional parameters](parameter list){ statements; } 8. 指针和引用8.1 什么是指针 指针是存储内存地址的变量 指针包含的值被解读为内存地址 内存单元地址通常使用十六进制表示，如0x60fe80 使用引用运算符&amp;获取变量的地址 使用解除引用运算符*访问指针指向的数据 32位系统，指针变量为4字节，64位系统为8字节 #include &lt;iostream&gt; using namespace std; int main(int argc, char const *argv[]) { int dogsAge = 30; cout &lt;&lt; &quot;Initialize dogsAge = &quot; &lt;&lt; dogsAge &lt;&lt; endl; int *pointsToAnAge = &amp;dogsAge; cout &lt;&lt; &quot;pointsToAnAge points to dogsAge&quot; &lt;&lt; endl; cout &lt;&lt; &quot;Enter an age for your dog: &quot;; // store input at the memory pointed to by pointsToAnAge cin &gt;&gt; *pointsToAnAge; // Displaying the address where age is stored cout &lt;&lt; &quot;Integer stored at &quot; &lt;&lt; hex &lt;&lt; pointsToAnAge &lt;&lt; endl; cout &lt;&lt; &quot;Integer dogsAge = &quot; &lt;&lt; dec &lt;&lt; dogsAge &lt;&lt; endl; return 0; } ------ Initialize dogsAge = 30 pointsToAnAge points to dogsAge Enter an age for your dog: 14 Integer stored at 0x60fe88 Integer dogsAge = 14 8.2 动态内存分配new 和 delete 运算符使用new来分配新的内存块，最终都需使用对应的delete进行释放： int *pNum = new int; // get a pointer to an integer int *pNums = new int[10]; // pointer to a block of 10 integers delete pNum; delete[] pNums; 对于使用new[...]分配的内存块，需要使用delete[]进行释放 不再使用分配的内存后，如果不释放它们，这些内存仍被预留并分配给应用程序，这将减少系统内存量，甚至降低应用程序的执行速度，即内存泄露。 #include &lt;iostream&gt; using namespace std; int main(int argc, char const *argv[]) { // Request for memory space for an int int *pointsToAnAge = new int; // Use the allocated memory to store a number cout &lt;&lt; &quot;Enter your dog&#39;s age: &quot;; cin &gt;&gt; *pointsToAnAge; // Use indirection operator* to access value cout &lt;&lt; &quot;Age &quot; &lt;&lt; *pointsToAnAge &lt;&lt; &quot; is stored at &quot; &lt;&lt; hex &lt;&lt; pointsToAnAge &lt;&lt; endl; // Release memory delete pointsToAnAge; return 0; } ------ Enter your dog&#39;s age: 14 Age 14 is stored at 0xf518c0 而对于使用new[...]分配的内存，应使用delete[]来释放： int *myNumbers = new int[numEntries]; ... // de-allocate before existing delete[] myNumbers; 指针递增或递减将指针递增或递减时，其包含的地址将增加或减少sizeof(Type)。 例如声明了如下指针： Type *pType = Address; 则执行++pType后，pType将指向Address + sizeof(Type)。 将++用于该指针，相当于告诉编译器，希望它指向下一个int #include &lt;iostream&gt; using namespace std; int main(int argc, char const *argv[]) { cout &lt;&lt; &quot;How many integers you wish to enter? &quot;; int numEntries = 0; cin &gt;&gt; numEntries; int *pointsToInts = new int[numEntries]; cout &lt;&lt; &quot;Allocated for &quot; &lt;&lt; numEntries &lt;&lt; &quot; integers&quot; &lt;&lt; endl; for (int counter = 0; counter &lt; numEntries; ++counter) { cout &lt;&lt; &quot;Enter number &quot; &lt;&lt; counter &lt;&lt; &quot;: &quot;; cin &gt;&gt; *(pointsToInts + counter); } cout &lt;&lt; &quot;Displaying all numbers entered: &quot; &lt;&lt; endl; for (int counter = 0; counter &lt; numEntries; ++counter) { cout &lt;&lt; *(pointsToInts++) &lt;&lt; &quot; &quot;; } cout &lt;&lt; endl; // return pointer to initial position pointsToInts -= numEntries; cout &lt;&lt; *pointsToInts; // done with using memory? release delete[] pointsToInts; return 0; } ------ How many integers you wish to enter? 5 Allocated for 5 integers Enter number 0: 10 Enter number 1: 29 Enter number 2: 35 Enter number 3: -3 Enter number 4: 918 Displaying all numbers entered: 10 29 35 -3 918 10 将关键字 const 用于指针🚩推荐阅读（由hexo文章推荐插件驱动）Python 速查Java 语言推荐书单C 语言推荐书单程序员学习之路技术博客的重要性技术博客的重要性","categories":[{"name":"C/C++","slug":"C-C","permalink":"https://abelsu7.top/categories/C-C/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://abelsu7.top/tags/编程/"},{"name":"学习","slug":"学习","permalink":"https://abelsu7.top/tags/学习/"},{"name":"CPP","slug":"CPP","permalink":"https://abelsu7.top/tags/CPP/"}]},{"title":"配置终端代理解决 go get 命令国内无法使用","slug":"go-get-using-proxy","date":"2019-05-22T07:04:24.000Z","updated":"2019-10-27T07:57:42.535Z","comments":true,"path":"2019/05/22/go-get-using-proxy/","link":"","permalink":"https://abelsu7.top/2019/05/22/go-get-using-proxy/","excerpt":"注：Golang 从1.13开始默认使用Go Mod，请切换至Go Mod并配置goproxy","text":"注：Golang 从1.13开始默认使用Go Mod，请切换至Go Mod并配置goproxy 问题描述国内使用go get命令时，Google 相关的域名例如golang.org经常被墙。 方法 1：使用 Gopm 注：Gopm 目前已停止维护 使用gopm get命令替代go get： &gt; go get -u github.com/gpmgo/gopm &gt; gopm NAME: Gopm - Go Package Manager USAGE: Gopm [global options] command [command options] [arguments...] VERSION: 0.8.8.0307 Beta COMMANDS: list list all dependencies of current project gen generate a gopmfile for current Go project get fetch remote package(s) and dependencies bin download and link dependencies and build binary config configure gopm settings run link dependencies and go run test link dependencies and go test build link dependencies and go build install link dependencies and go install clean clean all temporary files update check and update gopm resources including itself help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --noterm, -n disable color output --strict, -s strict mode --debug, -d debug mode --help, -h show help --version, -v print the version 方法 2：install from Github 参见 解决 VS Code 中 golang.org 被墙导致的 Go 插件安装失败问题 方法 3：配置终端代理阅读get.go源码会发现，go get命令通过git clone命令将远程仓库的代码拉取到本地。 根据官方 golang/go - GoGetProxyConfig | Github 的说明，需要设置git的代理： &gt; git config [--global] http.proxy http://proxy.example.com:port 然而并没有起作用。。 我在Linux和Windows的机器上都开启了Shadowsocks代理，本地端口为1080 搜索了一圈之后发现，需要设置http_proxy和https_proxy这两个环境变量。 for Linux我在CentOS 7.5的机器上已经使用ProxyChains-NG作为终端命令的代理程序，这样可以很方便的在需要代理的时候在命令前加上pc前缀（之前设置了alias pc=&#39;proxychains4&#39;）。 而添加http_proxy环境变量后，所有终端命令的 HTTP 连接都会走代理，这并非我所期望的。因此不能直接在~/.zshrc中添加环境变量。 我的解决方案是：将设置http_proxy与https_proxy环境变量的export命令单独写在 Shell 脚本中，需要走代理时直接source即可。 首先以下内容另存为export-http-proxy.sh： #!/bin/bash export http_proxy=socks5://127.0.0.1:1080 # 代理地址 export https_proxy=$http_proxy export | grep http 之后添加执行权限 &gt; chmod +x export-http-proxy.sh 最后 &gt; source export-http-proxy.sh http_proxy=socks5://127.0.0.1:1080 https_proxy=socks5://127.0.0.1:1080 这样就可以直接go get被墙的包了。 for WindowsWindows 就非常简单了，直接设置以下环境变量： http_proxy socks5://127.0.0.1:1080 # 代理地址 https_proxy socks5://127.0.0.1:1080 要想临时添加代理，只需将以下内容保存为http-proxy.bat，需要时执行即可： set http_proxy=socks5://127.0.0.1:1080 set https_proxy=%http_proxy% 参考文章 Gopm Registry Gopm | Github golang/go - GoGetProxyConfig | Github go get 使用代理 | CSDN go get 命令被墙问题 | CSDN 解决go get timeout | CSDN Golang 依赖包下载时候代理设置 | CSDN go get 设置代理 | CSDN go get 命令被墙问题 | CSDN 国内的 go get 问题的解决 | CSDN go get 国内解决办法汇总 | CSDN 让 go get 显示进度 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Git","slug":"Git","permalink":"https://abelsu7.top/tags/Git/"},{"name":"代理","slug":"代理","permalink":"https://abelsu7.top/tags/代理/"}]},{"title":"本周文章汇总","slug":"temp-notes","date":"2019-05-22T02:38:45.000Z","updated":"2019-09-01T13:04:11.695Z","comments":true,"path":"2019/05/22/temp-notes/","link":"","permalink":"https://abelsu7.top/2019/05/22/temp-notes/","excerpt":"众所周知，技术文章越读越多，永远没个完","text":"众所周知，技术文章越读越多，永远没个完 虚拟化 Vagrant Chef Linux 运维 Linux运维常见故障及处理的 32 个锦囊妙计 | 民工哥技术之路 Go 语言 spf13/viper | Go configuration with fangs 深度揭秘 Go 语言之 map | 码农桃花源 常用软件 最佳常用电脑检测软件 | 黎小白 后台面经 后台开发/基础架构方向 学习路线 | 写的很不错！ 团队协作 Trello 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"写作","slug":"写作","permalink":"https://abelsu7.top/categories/写作/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://abelsu7.top/tags/运维/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"监控工具","slug":"监控工具","permalink":"https://abelsu7.top/tags/监控工具/"}]},{"title":"解决 Ubuntu apt-get install 错误：未满足的依赖关系","slug":"ubuntu-aptitude","date":"2019-05-21T08:52:52.000Z","updated":"2019-09-01T13:04:11.752Z","comments":true,"path":"2019/05/21/ubuntu-aptitude/","link":"","permalink":"https://abelsu7.top/2019/05/21/ubuntu-aptitude/","excerpt":"升级一时爽，一直升级一直爽","text":"升级一时爽，一直升级一直爽 1. 问题原因 安装的软件依赖于某一软件的旧版本，但是系统中已经安装了所依赖软件的新版本 要装A，依赖于B，但是已经安装的C也依赖于B，且A和C依赖的B版本不一致 2. 更新软件源&gt; apt-get update &gt; apt-get -f install # 即 --fix-broken，会针对当前不满足的依赖关系，下载正确版本的依赖库 &gt; apt-get install [YOUR_PACKAGE_NAME] 3. 使用 aptitude&gt; apt show aptitude # 或 apt-cache show aptitude Package: aptitude Version: 0.8.10-6ubuntu1 Priority: optional Section: admin Origin: Ubuntu Maintainer: Ubuntu Developers &lt;ubuntu-devel-discuss@lists.ubuntu.com&gt; Original-Maintainer: Aptitude Development Team &lt;aptitude-devel@lists.alioth.debian.org&gt; Bugs: https://bugs.launchpad.net/ubuntu/+filebug Installed-Size: 4,414 kB Depends: aptitude-common (= 0.8.10-6ubuntu1), libapt-pkg5.0 (&gt;= 1.1), libboost-filesystem1.65.1, libboost-iostreams1.65.1, libboost-system1.65.1, libc6 (&gt;= 2.14), libcwidget3v5, libgcc1 (&gt;= 1:3.0), libncursesw5 (&gt;= 6), libsigc++-2.0-0v5 (&gt;= 2.8.0), libsqlite3-0 (&gt;= 3.6.5), libstdc++6 (&gt;= 5.2), libtinfo5 (&gt;= 6), libxapian30 Recommends: libparse-debianchangelog-perl, sensible-utils Suggests: aptitude-doc-en | aptitude-doc, apt-xapian-index, debtags, tasksel Homepage: https://aptitude.alioth.debian.org/ Supported: 5y Download-Size: 1,269 kB APT-Manual-Installed: yes APT-Sources: http://cn.archive.ubuntu.com/ubuntu bionic/main amd64 Packages Description: 基于终端的软件包管理器 aptitude 是一个功能丰富的包管理器，包括：使用类似 mutt 的语法灵活地 检索软件包，类似 dselect 的持续用户操作，获取并显示大多数软件包的 Debian changelog 的功能，一个类似 apt-get 的命令行模式。 . aptitude 还是个 Y2K 兼容，轻便，自清洁以及友好的程序 &gt; apt install aptitude 运行后，不接受未安装方案，选择降级方案： &gt; aptitude install [YOUR_PACKAGE_NAME] 4. apt 与 apt-get 之间的区别apt命令的引入就是为了解决命令过于分散的问题，它包括了apt-get命令出现以来使用最广泛的功能选项，以及apt-cache和apt-config命令中很少用到的功能。 简单来说就是：apt = apt-get、apt-cache、apt-config中最常用命令选项的集合 &gt; apt list --insalled &gt; apt list --upgradable &gt; apt search htop &gt; apt show htop 可以使用apt替换部分apt-get命令： apt 命令 取代的命令 命令的功能 apt install apt-get install 安装软件包 apt remove apt-get remove 移除软件包 apt purge apt-get purge 移除软件包及配置文件 apt update apt-get update 刷新数据库索引 apt upgrade apt-get upgrade 升级所有可升级的软件包 apt autoremove apt-get autoremove 自动删除不需要的包 apt full-upgrade apt-get dist-upgrade 升级软件包时自动处理依赖关系 apt search apt-cache search 搜索软件包 apt show apt-cache show 显示软件包详情 另外还有一些apt自己的命令： 新的 apt 命令 命令的功能 apt list 根据条件列出软件包（已安装、可升级等） apt edit-sources 编辑源列表 apt list --installed apt list --upgradeable apt list --all-versions 参考文章 Ubuntu 安装软件时：有未能满足的依赖关系 | CSDN Ubuntu 16.04 在使用 apt-get install命令时出现：下列软件包有未满足的依赖关系错误 | CSDN Aptitude | Debian Wiki Linux 中 apt 与 apt-get 命令的区别与解释 | 系统极客 Ubuntu (Debian) 的 aptitude 与 apt-get 的区别和联系 | 博客园 dpkg、apt-get、aptitude 三种方式的区别及命令格式 | CSDN Fedora 及 Ubuntu 深度比较 | Linux 公社 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSUbuntu 18.04 配置阿里云 OPSX APT 安装源Ubuntu 18.04 安装 Nvidia 显卡驱动Linux 下 Yum、APT 禁用指定软件包更新虚拟机 VMware 中安装 Ubuntu 操作系统虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Apt","slug":"Apt","permalink":"https://abelsu7.top/tags/Apt/"},{"name":"Aptitude","slug":"Aptitude","permalink":"https://abelsu7.top/tags/Aptitude/"}]},{"title":"Oh My Zsh/NeoVim/Tmux 打造终端 IDE","slug":"terminal-ide-using-zsh-nvim-tmux","date":"2019-05-21T03:26:02.000Z","updated":"2019-11-10T09:07:44.453Z","comments":true,"path":"2019/05/21/terminal-ide-using-zsh-nvim-tmux/","link":"","permalink":"https://abelsu7.top/2019/05/21/terminal-ide-using-zsh-nvim-tmux/","excerpt":"The only thing you need is just a termimal.","text":"The only thing you need is just a termimal. 待更新… (立了好多 Flag 溜了溜了 Leader 键：&lt;Space&gt; &lt;Space&gt;+1/2/3...：切换 Tab Ctrl+W Vim 教程 谁说 Vim 不是 IDE（一）| 池建强 谁说 Vim 不是 IDE（二）| 池建强 谁说 Vim 不是 IDE（三）| 池建强 谁说 Vim 不是 IDE（四）| 池建强 Vim 练级手册 Vim 修行之路 | Harttle Land 游戏：VIM 大冒险 | 酷壳 CoolShell OpenVim | 交互式学习 Vim 从「什么是Vim」开始、その一 | 知乎 从「什么是Vim」开始、その二 | 知乎 Vim 从入门到精通 - wsdjeg | Github Vim 入门教程 | 伯乐在线 VimGolf | Vim 趣题 VIM 快捷键大全 | 风笑痴 配置 VIM 的 Go 语言开发环境 | 无闻 有哪些编程必备的 Vim 配置？| 知乎 Vim 切换 tab 标签快捷键 | CSDN Vim 学习笔记 多标签页（Tabs）| 知乎 Vim(2):多标签切换|窗口拆分 | fxs_2008 的专栏 Vim 多文件编辑：缓冲区 | Harttle Land Vim 进阶技巧 - 刘志龙 | IMWeb 前端博客 在 VIM 下写 C++ 能有多爽？| Harttle Land 给程序员的 VIM 速查卡 | 酷壳 CoolShell 主流文本编辑器学习曲线 | 酷壳 CoolShell 简明 VIM 练级攻略 | 酷壳 CoolShell Vim 快捷键 Vim 使用 map 自定义快捷键 | CSDN NeoVim NeoVim 初体验 | GQQNBIG 的专栏 安装使用配置 NeoVim | 简书 安装使用配置 NeoVim - 配置 | 简书 安装使用配置 Neovim | 冻皮博客 安装使用配置 Neovim - 配置 | 冻皮博客 如何安装 NeoVim 和使用 vim-plug 安装相关插件？| 腾讯云+社区 用 NeoVim 取代 Vim | Harries Blog SpaceVim SpaceVim 官网 SpaceVim | Github Emacs 著名 Emacs 用户列表 | Wenshan’s Blog Tmux 优雅地使用命令行：Tmux 终端复用 | Harttle Land Tmux 使用介绍 | Verne in Github CentOS 下 tmux 打造完美终端管理工具 | 51CTO CentOS Tmux 安装与配置 | CSDN 使用 Tmux 改进终端体验 | 徐至强 Tmux 入门指南 | 腾讯云+社区 True Color 相关 为 vim + tmux 开启真彩色(true color) | 三点水 Adding 24-bit TrueColor RGB escape sequences to tmux 24-bit-color.sh | Github Terminal Colors | Github 让 Tmux 支持 True Color | CSDN 开发工具 Vim 在 bash 中的显示与 tmux 中的显示不同 | CSDN vim配色主题在tmux中显示异常解决方案（macOS+iterm2+zsh）| CSDN tmux 与 vim 冲突问题的解决方法 | CSDN 使用 tmux 时 vim 主题（theme）失效的解决 | CSDN Vim 插件 Vim Awesome Vim Scripts | Vim 官网插件的镜像 spf13-vim Vim 的插件 | Medium.com vim-go | Github Vim 插件之 MRU mru.vim | Github startify.vim | Github ctrlp.vim | Github skywind3000/asyncrun.vim | Github powerline | Github VIM 插件: AIRLINE[状态栏增强] | WKLKEN BUILDING vim-airline | Github Vim 插件 vim-airline 状态栏增强显示 | 温欣爸比 Vim-airline 插件安装配置 | CSDN VIM 配置:vim-airline 插件安装 | CSDN vim-vice - Dark and vibrant colorscheme for vim | Github Tmux 插件 tmux-powerline | Github tmux-onedark-theme | Github tmux-colors-solarized | Github dotfiles 收集 int32bit/dotfiles - vim/zsh/git/tmux dotfiles | Github ourvim - jusonalien| Github TimothyYe/mydotfiles | Github amix/vimrc | Github wsdjeg/DotFiles | Github barretlee/autoconfig-mac-vimrc | Github TimothyYe 的程序员内功系列 程序员内功系列 - 序篇 | iTimothy 程序员内功系列 - iTerm 与 Zsh 篇 | iTimothy 程序员内功系列 - Tmux 篇 | iTimothy 程序员内功系列 - Vim 篇 | iTimothy 程序员内功系列 - 常用命令行工具篇 | iTimothy 参考文章 Oh My Zsh Neovim NeoVim 科普，21 世纪的 Vim | 知乎 tpm - Tmux Plugin Manager | Github Tmux Better Mouse Mode | Github mydotfiles - TimothyYe | Github Tmux 配置使用 | Kompass k-vim - wklken | Github myrc - laixintao | Github tmux 2.9 配置变更 | Xuanwo’s Blog 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 终端修改 ls 命令目录显示颜色Shell 输入/输出重定向：1>/dev/null、2>&1Fluent Terminal：Windows 下的炫酷终端Chrome 插件 Vimium：键盘党的胜利zsh安装配置zsh安装配置","categories":[{"name":"Vim","slug":"Vim","permalink":"https://abelsu7.top/categories/Vim/"}],"tags":[{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"zsh","slug":"zsh","permalink":"https://abelsu7.top/tags/zsh/"},{"name":"Vim","slug":"Vim","permalink":"https://abelsu7.top/tags/Vim/"},{"name":"NeoVim","slug":"NeoVim","permalink":"https://abelsu7.top/tags/NeoVim/"},{"name":"tmux","slug":"tmux","permalink":"https://abelsu7.top/tags/tmux/"}]},{"title":"RSSHub + Awesome TTRSS 搭建 RSS 阅读器","slug":"rsshub-and-ttrss","date":"2019-05-21T02:58:51.000Z","updated":"2019-09-01T13:04:11.666Z","comments":true,"path":"2019/05/21/rsshub-and-ttrss/","link":"","permalink":"https://abelsu7.top/2019/05/21/rsshub-and-ttrss/","excerpt":"摘自 通过 RSSHub 订阅不支持 RSS 的网站 | 少数派","text":"摘自 通过 RSSHub 订阅不支持 RSS 的网站 | 少数派 待更新… (立了好多 Flag 溜了溜了 参考文章 RSSHub Awesome TTRSS Awesome TTRSS | Github Feed43 Ionreader 向开源致敬：RSSHub - 万物皆可 RSS | Henry’s blog 通过 RSSHub 订阅不支持 RSS 的网站 | 少数派 一切只为给你更好的阅读体验，老牌 RSS 阅读器 Reeder 更新 4.0 | 少数派 对比过多款 RSS 阅读工具之后，lire 成为了我的最佳选择 | 少数派 利用 Feed43，将任意网页制作成 RSS 订阅源 | 少数派 利用 Feed43，将任意网页制作成 RSS 订阅源配合inoreader | 简书 🚩推荐阅读（由hexo文章推荐插件驱动）Hexo 博客安装 RSS 插件","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"RSS","slug":"RSS","permalink":"https://abelsu7.top/tags/RSS/"},{"name":"RSSHub","slug":"RSSHub","permalink":"https://abelsu7.top/tags/RSSHub/"}]},{"title":"Linux 终端常用快捷键","slug":"terminal-hot-keys","date":"2019-05-20T06:48:46.000Z","updated":"2019-09-01T13:04:11.699Z","comments":true,"path":"2019/05/20/terminal-hot-keys/","link":"","permalink":"https://abelsu7.top/2019/05/20/terminal-hot-keys/","excerpt":"Terminal 快捷键速查","text":"Terminal 快捷键速查 以下组合键不区分大小写 1. 光标、行编辑 快捷键 功能 Alt+F 光标向前移动一个单词 Alt+B 光标向后移动一个单词 Ctrl+F 光标向前移动一格 Ctrl+B 光标向后移动一格 Ctrl+A 光标移动到行首 Ctrl+E 光标移动至行尾 Ctrl+C 另起新行 Ctrl+U 清空当前行 Ctrl+D 删除当前字符 Ctrl+L 清屏 Esc+W 删除光标之前的所有字符 Ctrl+K 删除从光标到行尾的左右字符 Ctrl+Y 粘贴刚才删除的字符 Ctrl+(X U) 撤销刚才的操作 2. 历史命令 快捷键 功能 !! 上一条命令 !pre 执行以pre为开头的最新命令 !n 执行历史 Alt+&lt; 历史第一项 Alt+&gt; 历史最后一项，即当前输入的命令 Ctrl+R 查询历史 Ctrl+G 从历史搜索模式退出 3. 窗口、标签 快捷键 功能 Ctrl+Shift+T 新建标签页 Ctrl+Shift+W 关闭标签页 Ctrl+PageUp 前一标签页 Ctrl+PageDown 后一标签页 Ctrl+Shift+PageUp 标签页左移 Ctrl+Shift+PageDown 标签页右移 Alt+2 切换到标签 2 Ctrl+Shift+N 新建窗口 Ctrl+Shift+Q 关闭终端 4. GNOME 桌面快捷键 快捷键 功能 Alt+F1 打开主菜单 Alt+F2 运行命令 Alt+F10 窗口最大化 5. 文件管理器 快捷键 功能 Ctrl+H 显示隐藏文件 Ctrl+T 新建标签 Ctrl+W 关闭标签 参考文章 Linux 下不得不说的那些快捷键 | freestar’s blog Bash Shell 常用快捷键 | hokein’s Wiki Ubuntu 终端快捷方式汇总 | 博客园 让你提升命令行效率的 Bash 快捷键 | LinuxToy 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"快捷键","slug":"快捷键","permalink":"https://abelsu7.top/tags/快捷键/"}]},{"title":"使用 imagemagick 转换图片格式","slug":"convert-picture-using-imagemagick","date":"2019-05-20T02:59:25.000Z","updated":"2019-09-01T13:04:11.054Z","comments":true,"path":"2019/05/20/convert-picture-using-imagemagick/","link":"","permalink":"https://abelsu7.top/2019/05/20/convert-picture-using-imagemagick/","excerpt":"摘自 转换图片格式 | Verne in Github","text":"摘自 转换图片格式 | Verne in Github 1. 安装 ImageMagick&gt; yum info imagemagick Installed Packages Name : ImageMagick Arch : x86_64 Version : 6.7.8.9 Release : 16.el7_6 Size : 7.6 M Repo : installed From repo : updates Summary : An X application for displaying and manipulating images URL : http://www.imagemagick.org/ License : ImageMagick Description : ImageMagick is an image display and manipulation tool for the X : Window System. ImageMagick can read and write JPEG, TIFF, PNM, GIF, : and Photo CD image formats. It can resize, rotate, sharpen, color : reduce, or add special effects to an image, and when finished you can : either save the completed work in the original format or a different : one. ImageMagick also includes command line programs for creating : animated or transparent .gifs, creating composite images, creating : thumbnail images, and more. : : ImageMagick is one of your choices if you need a program to manipulate : and display images. If you want to develop your own applications : which use ImageMagick code or APIs, you need to install : ImageMagick-devel as well. &gt; yum info imagemagick-devel Available Packages Name : ImageMagick-devel Arch : i686 Version : 6.7.8.9 Release : 16.el7_6 Size : 100 k Repo : updates/7/x86_64 Summary : Library links and header files for ImageMagick app development URL : http://www.imagemagick.org/ License : ImageMagick Description : ImageMagick-devel contains the library links and header files you&#39;ll : need to develop ImageMagick applications. ImageMagick is an image : manipulation program. : : If you want to create applications that will use ImageMagick code or : APIs, you need to install ImageMagick-devel as well as ImageMagick. : You do not need to install it if you just want to use ImageMagick, : however. &gt; yum install imagemagick imagemagick-devel 2. 查看使用手册&gt; man imagemagick # 查看使用手册 NAME ImageMagick - is a free software suite for the creation, modification and display of bitmap images. SYNOPSIS convert input-file [options] output-file OVERVIEW convert identify mogrify composite montage compare stream display animate import clojure &gt; man convert # 查看各命令对应的使用手册 2. 检查图片格式&gt; identify bg.jpg bg.jpg JPEG 1900x870 1900x870+0+0 8-bit DirectClass 104KB 0.000u 0:00.009 3. 转换格式&gt; convert bg.jpg bg.png 4. 批量转换&gt; mogrify -format png ~/.Wallpapers/*.jpg 参考文章 转换图片格式 | Verne in Github","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"ImageMagick","slug":"ImageMagick","permalink":"https://abelsu7.top/tags/ImageMagick/"},{"name":"格式转换","slug":"格式转换","permalink":"https://abelsu7.top/tags/格式转换/"}]},{"title":"reveal.js + Markdown 制作 PPT","slug":"reveal-js-with-markdown","date":"2019-05-10T07:51:20.000Z","updated":"2019-10-23T13:50:51.823Z","comments":true,"path":"2019/05/10/reveal-js-with-markdown/","link":"","permalink":"https://abelsu7.top/2019/05/10/reveal-js-with-markdown/","excerpt":"摘自 reveal.js | Github","text":"摘自 reveal.js | Github 1. 快速开始 需要 Node.js 版本在4.0.0以上 &gt; git clone https://github.com/hakimel/reveal.js.git &gt; cd reveal.js reveal.js &gt; npm install # 安装依赖 安装puppeteer@1.12.2时报错： &gt; puppeteer@1.12.2 install C:\\Users\\abel1\\GithubProjects\\reveal.js\\node_modules\\puppeteer &gt; node install.js ERROR: Failed to download Chromium r624492! Set &quot;PUPPETEER_SKIP_CHROMIUM_DOWNLOAD&quot; env variable to skip download. 参见 ERROR: Failed to download Chromium | 简书，使用淘宝的npm源： &gt; npm config set puppeteer_download_host=https://npm.taobao.org/mirrors &gt; npm i puppeteer 或者使用淘宝的 cnpm，自动使用国内源： &gt; npm install -g cnpm --registry=https://registry.npm.taobao.org &gt; cnpm i puppeteer 启动Server： &gt; cnpm start 再次报错，这次是node-sass： &gt; reveal.js@3.8.0 start C:\\Users\\abel1\\GithubProjects\\reveal.js &gt; grunt serve Loading &quot;Gruntfile.js&quot; tasks...ERROR &gt;&gt; Error: ENOENT: no such file or directory, scandir &#39;C:\\Users\\abel1\\GithubProjects\\reveal.js\\node_modules\\node-sass\\vendor&#39; 重新构建node-sass： &gt; cnpm rebuild node-sass 再次启动Server，成功： $ cnpm start &gt; reveal.js@3.8.0 start C:\\Users\\abel1\\GithubProjects\\reveal.js &gt; grunt serve Running &quot;connect:server&quot; (connect) task Started connect web server on http://localhost:8000 Running &quot;watch&quot; task 未完待续… 参考文章 reveal.js 官网 reveal.js | Github Markdown - reveal.js | Github ERROR: Failed to download Chromium | 简书 淘宝 NPM 镜像 | cnpm Mirrors | cnpm mdp - 终端下基于 Markdown 的 PPT 展示工具 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 present 展示 PPTHexo写作笔记Markdown 工具推荐","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"PPT","slug":"PPT","permalink":"https://abelsu7.top/tags/PPT/"},{"name":"reveal.js","slug":"reveal-js","permalink":"https://abelsu7.top/tags/reveal-js/"},{"name":"Markdown","slug":"Markdown","permalink":"https://abelsu7.top/tags/Markdown/"}]},{"title":"Linux 定时任务与 crontab 简介","slug":"crontab-intro","date":"2019-05-08T02:38:31.000Z","updated":"2019-09-01T13:04:11.107Z","comments":true,"path":"2019/05/08/crontab-intro/","link":"","permalink":"https://abelsu7.top/2019/05/08/crontab-intro/","excerpt":"摘自 A Beginners Guide To Cron Jobs | OSTechNix","text":"摘自 A Beginners Guide To Cron Jobs | OSTechNix 1. 基本格式Minute(0-59) Hour(0-24) Day_of_month(1-31) Month(1-12) Day_of_week(0-6) Command_to_execute 待更新… 参考文章 A Beginners Guide To Cron Jobs | OSTechNix crontab guru Crontab Generator Cronitor.io 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"https://abelsu7.top/tags/crontab/"}]},{"title":"使用 pingtop 同时 ping 多台服务器","slug":"ping-multiple-server-using-pingtop","date":"2019-05-07T07:23:39.000Z","updated":"2019-09-01T13:04:11.609Z","comments":true,"path":"2019/05/07/ping-multiple-server-using-pingtop/","link":"","permalink":"https://abelsu7.top/2019/05/07/ping-multiple-server-using-pingtop/","excerpt":"摘自 Ping Multiple Servers And Show The Output In Top-like Text UI | OSTechNix","text":"摘自 Ping Multiple Servers And Show The Output In Top-like Text UI | OSTechNix 1. 安装 pingtop使用pip安装pingtop，确保已经在系统中安装过Python 3.7.x以及pip： &gt; pip3 search pingtop pingtop (0.2.8) - Ping multiple servers and show the result in a top like terminal UI. INSTALLED: 0.2.8 (latest) &gt; pip3 install pingtop 2. 使用 pingtop&gt; pingtop abelsu7.top github.com 使用 pingtop 同时 ping 多台服务器 参考文章 Ping Multiple Servers And Show The Output In Top-like Text UI | OSTechNix ping 多台服务器并在类似 top 的界面中显示 | Linux 中国 Some Alternatives To ‘top’ Command line Utility You Might Want To Know | OSTechNix How To Ping Multiple Hosts At Once In Linux | OSTechNix pingtop | Github 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能使用virtualenv创建隔离环境奇异值分解的原理与使用","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Python","slug":"Python","permalink":"https://abelsu7.top/tags/Python/"},{"name":"pingtop","slug":"pingtop","permalink":"https://abelsu7.top/tags/pingtop/"}]},{"title":"Go 语言 CSP 并发模型编程实例","slug":"go-csp-example","date":"2019-05-06T13:54:48.000Z","updated":"2019-09-01T13:04:11.250Z","comments":true,"path":"2019/05/06/go-csp-example/","link":"","permalink":"https://abelsu7.top/2019/05/06/go-csp-example/","excerpt":"摘自 从并发模型看 Go 的语言设计 | 腾讯技术工程，更新中…","text":"摘自 从并发模型看 Go 的语言设计 | 腾讯技术工程，更新中… Go 语言中channel的&lt;-：左读右写 1. 阶乘计算package main import &quot;fmt&quot; const limit = 5 func main() { fact := MakeFactFunc() for i := 0; i &lt; limit; i++ { fmt.Println(fact(i)) } } // 阶乘计算的实体 func FactCalc(in &lt;-chan int, out chan&lt;- int) { var subIn, subOut chan int for { n := &lt;-in if n == 0 { out &lt;- 1 } else { if subIn == nil { subIn, subOut = make(chan int), make(chan int) go FactCalc(subIn, subOut) } subIn &lt;- n - 1 r := &lt;-subOut out &lt;- n * r } } } // 包装一个阶乘计算函数 func MakeFactFunc() func(int) int { in, out := make(chan int), make(chan int) go FactCalc(in, out) return func(x int) int { in &lt;- x return &lt;-out } } ------ 1 1 2 6 24 Process finished with exit code 0 2. 筛法求素数package main import &quot;fmt&quot; func main() { primes := make(chan int) go PrimeSieve(primes) for i := 0; i &lt; 5; i++ { fmt.Println(&lt;-primes) } } func Counter(out chan&lt;- int) { for i := 2; ; i++ { out &lt;- i } } func PrimeFilter(prime int, in &lt;-chan int, out chan&lt;- int) { for { i := &lt;-in if i%prime != 0 { out &lt;- i } } } func PrimeSieve(out chan&lt;- int) { c := make(chan int) go Counter(c) for { prime := &lt;-c out &lt;- prime newC := make(chan int) go PrimeFilter(prime, c, newC) c = newC } } ------ 2 3 5 7 11 Process finished with exit code 0 3. 信号量4. 一个简单的服务模板参考文章 从并发模型看 Go 的语言设计 | 腾讯技术工程 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"并发","slug":"并发","permalink":"https://abelsu7.top/tags/并发/"}]},{"title":"Fedora 30 显示桌面图标","slug":"fedora-gnome-desktop-icon","date":"2019-05-05T09:46:49.000Z","updated":"2019-09-01T13:04:11.235Z","comments":true,"path":"2019/05/05/fedora-gnome-desktop-icon/","link":"","permalink":"https://abelsu7.top/2019/05/05/fedora-gnome-desktop-icon/","excerpt":"摘自 解决 fedora 28 桌面图标问题 | cnblog","text":"摘自 解决 fedora 28 桌面图标问题 | cnblog 问题描述在 Fedora 30 中，Gnome Desktop 默认是没有桌面图标的，只会显示背景，然而这样并不是很方便，我们可以根据需要手动开启桌面图标。 解决办法1. 安装 nemo&gt; dnf info nemo Available Packages Name : nemo Version : 4.0.6 Release : 2.fc30 Architecture : i686 Size : 1.5 M Source : nemo-4.0.6-2.fc30.src.rpm Repository : fedora Summary : File manager for Cinnamon URL : https://github.com/linuxmint/nemo License : GPLv2+ and LGPLv2+ Description : Nemo is the file manager and graphical shell for the Cinnamon desktop : that makes it easy to manage your files and the rest of your system. : It allows to browse directories on local and remote filesystems, preview : files and launch applications associated with them. : It is also responsible for handling the icons on the Cinnamon desktop. &gt; dnf install nemo 2. 创建自启动文件创建~/.config/autostart/nemo-autostart-with-gnome.desktop，并在文件中保存以下内容： &gt; vim ~/.config/autostart/nemo-autostart-with-gnome.desktop [Desktop Entry] Type=Application Name=Nemo Comment=Start Nemo desktop at log in Exec=nemo-desktop OnlyShowIn=GNOME; AutostartCondition=GSettings org.nemo.desktop show-desktop-icons X-GNOME-AutoRestart=true NoDisplay=true 3. 注销后重新登录此时已经配置完成，这时只需要注销后重新登录，或者直接按Alt+F2，并输入nemo-desktop，就可以看到熟悉的图标出现在桌面上： 4. 解决桌面图标无法移动这时虽然桌面已经出现了图标，但是无法进行拖拽移动等操作，需要在终端内输入如下命令： &gt; gsettings set org.nemo.desktop use-desktop-grid false 5. Gtk-WARNING **: cannot open display: :0.0例如以abelsu用户的身份登录系统，之后在终端执行sudo su切换至root用户后，在终端启动应用会报该错误。 切换回abelsu用户，执行如下命令即可解决： &gt; xhost + access control disabled, clients can connect from any host sudo gedit 错误：Gtk-WARNING **: cannot open display: :0.0 | Linux 公社 完美解决xhost +报错： unable to open display “” | 漏洞人生 DISPLAY 变量和 xhost | ITeye 参考文章 解决 fedora 28 桌面图标问题 | cnblog Changes to Files in GNOME 3.28 | Fedora Magazine Remove desktop support - Alternative solution | Gnome GitLab Fedora 27 Gnome | Gnome-Look.org Fedora 27 Workstation配置改造全记录+常用软件推荐和安装 | 知乎","categories":[{"name":"Fedora","slug":"Fedora","permalink":"https://abelsu7.top/categories/Fedora/"}],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://abelsu7.top/tags/Fedora/"},{"name":"Gnome","slug":"Gnome","permalink":"https://abelsu7.top/tags/Gnome/"}]},{"title":"Windows 10 彻底删除已配对的蓝牙设备","slug":"win10-completely-remove-bluetooth-device","date":"2019-04-30T08:18:06.000Z","updated":"2019-09-01T13:04:11.773Z","comments":true,"path":"2019/04/30/win10-completely-remove-bluetooth-device/","link":"","permalink":"https://abelsu7.top/2019/04/30/win10-completely-remove-bluetooth-device/","excerpt":"ikbc DC-87 终于重新用蓝牙连上 XPS-13 了，我先去哭会儿！QAQ","text":"ikbc DC-87 终于重新用蓝牙连上 XPS-13 了，我先去哭会儿！QAQ 1. 啥问题 系统环境Windows 10-1803 去年用 ikbc DC-87 的蓝牙模式连接到我的 XPS 13 上，后来有一天突然就不能正常使用了。 尝试了先在系统设置中删除设备，打算再重新配对，然而 Amazing 的是，删除设备之后，HM KB3这个蓝牙设备又很快出现在列表中，并显示已配对(╯‵□′)╯︵┻━┻： 删除设备 HM KB3 后，又会自动显示「已配对」 然而设备无法删除就不能被识别为待配对的新设备，这样一来就没办法重新配对。。 科学上网 Google 了一圈，重启、飞行模式、卸载设备、升级蓝牙驱动统统试过，全都不管用。。 那叫一个心塞啊，只好先用有线模式连着，凑合过吧，还能离咋的。。 2. 那咋整本来最近都忘了这个事儿，今天突发奇想再次搜索一下，发现了这篇救命博客： Win10 彻底删除蓝牙设备 | CSDN 这位 CSDN 博主也是看到一篇国外友人的文章，想必大家都是有缘人： How to completely remove a Bluetooth device from Win 10? | Windows Ten Forums 简单来说，彻底删除冥顽不化的蓝牙设备，总共分以下几步： 下载 Bluetooth Command Line Tools，一路按默认选项完成安装 打开cmd或powershell，命令行输入btpair -u，回车执行并等待一小会儿，这将取消所有蓝牙设备的配对 将你冥顽不化的蓝牙设备设置为配对状态，再次尝试配对，你就会惊奇的发现—— Bingo！配对成功 骂微软，感谢博主，然后哭一会儿 参考文章 Win10 彻底删除蓝牙设备 | CSDN 已配对蓝牙设备无法删除 | Microsoft Community How to completely remove a Bluetooth device from Win 10? | Windows Ten Forums Bluetooth Command Line Tools 🚩推荐阅读（由hexo文章推荐插件驱动）Fluent Terminal：Windows 下的炫酷终端Windows 10 终端 PowerShell 外观美化几款监控 CPU 温度的软件推荐开源下载工具aria2使用教程Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"},{"name":"蓝牙","slug":"蓝牙","permalink":"https://abelsu7.top/tags/蓝牙/"}]},{"title":"Ubuntu 18.04 配置阿里云 OPSX APT 安装源","slug":"ubuntu-1804-add-opsx-apt-source","date":"2019-04-29T15:01:01.000Z","updated":"2019-09-01T13:04:11.748Z","comments":true,"path":"2019/04/29/ubuntu-1804-add-opsx-apt-source/","link":"","permalink":"https://abelsu7.top/2019/04/29/ubuntu-1804-add-opsx-apt-source/","excerpt":"摘自 ubuntu 18.04 (bionic) 配置 opsx 安装源 | OPSX","text":"摘自 ubuntu 18.04 (bionic) 配置 opsx 安装源 | OPSX 1. 创建 OPSX 安装源配置文件&gt; sudo vim /etc/apt/sources.list.d/aliyun.list 2. 添加源地址deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 3. 更新本地源列表sudo apt-get update 参考文章 OPSX | 阿里巴巴开源镜像站 ubuntu 18.04 (bionic) 配置 opsx 安装源 | OPSX Ubuntu安装软件时：有未能满足的依赖关系 | CSDN Ubuntu 16.04 在使用 apt-get install 命令时出现：下列软件包有未满足的依赖关系错误 | CSDN How to List Installed Packages on Ubuntu | Linuxize 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Apt","slug":"Apt","permalink":"https://abelsu7.top/tags/Apt/"}]},{"title":"Ubuntu 18.04 安装 Nvidia 显卡驱动","slug":"ubuntu-1804-install-nvidia-driver","date":"2019-04-29T02:00:44.000Z","updated":"2019-09-01T13:04:11.750Z","comments":true,"path":"2019/04/29/ubuntu-1804-install-nvidia-driver/","link":"","permalink":"https://abelsu7.top/2019/04/29/ubuntu-1804-install-nvidia-driver/","excerpt":"编译新版本内核时nvidia.ko总是报错，卸载原驱动340.107，安装新驱动","text":"编译新版本内核时nvidia.ko总是报错，卸载原驱动340.107，安装新驱动 To be updated… 参考文章 Ubuntu 18.04 安装 Nvidia 显卡驱动 | 慢半拍 Ubuntu 安装 Nvidia 驱动一直遇到 pre-install scipt failed 错误 | CSDN Ubuntu 18.04 NVIDIA驱动安装总结 | CSDN How to install the NVIDIA drivers on Ubuntu 18.04 Bionic Beaver Linux | LinuxConfig.org Ubuntu 18.04 安装 NVIDIA 显卡驱动 | 知乎 安装 Cuda 8.0 中所遇到的问题-解决办法 | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Nvidia","slug":"Nvidia","permalink":"https://abelsu7.top/tags/Nvidia/"}]},{"title":"解决 CentOS 7 tracker CPU 占用率 100%","slug":"centos7-tracker-hight-cpu-percent","date":"2019-04-28T07:49:44.000Z","updated":"2019-09-01T13:04:11.030Z","comments":true,"path":"2019/04/28/centos7-tracker-hight-cpu-percent/","link":"","permalink":"https://abelsu7.top/2019/04/28/centos7-tracker-hight-cpu-percent/","excerpt":"记一次莫名其妙的 CPU 100% Bug 排查","text":"记一次莫名其妙的 CPU 100% Bug 排查 问题描述 系统环境CentOS 7.5.1804 tracker-extract CPU 占用率 100% 用htop查看系统负载，发现其中一个 CPU 长时间处于100%状态，排查后发现罪魁祸首就是/usr/libexec/tracker-extract这个进程。 直接kill或kill -9后，进程tracker-extract会自动重启，并再次达到CPU 100%。 &gt; yum info tracker Installed Packages Name : tracker Arch : x86_64 Version : 1.10.5 Release : 6.el7 Size : 5.6 M Repo : installed From repo : anaconda Summary : Desktop-neutral search tool and indexer URL : https://wiki.gnome.org/Projects/Tracker License : GPLv2+ Description : Tracker is a powerful desktop-neutral first class object database, : tag/metadata database, search tool and indexer. : : It consists of a common object database that allows entities to have an : almost infinite number of properties, metadata (both embedded/harvested as : well as user definable), a comprehensive database of keywords/tags and : links to other entities. : : It provides additional features for file based objects including context : linking and audit trails for a file object. : : It has the ability to index, store, harvest metadata. retrieve and search : all types of files and other first class objects tracker-extract属于tracker包，主要用于桌面索引，下面介绍几种解决办法。 1. 卸载 tracker（不推荐）最直接的办法，卸载tracker包，不过会同时卸载nautilus、gnome-classic-session等相关依赖包，不推荐这种方法。 &gt; yum info tracker Installed Packages Name : tracker Arch : x86_64 Version : 1.10.5 Release : 6.el7 Size : 5.6 M Repo : installed From repo : anaconda Summary : Desktop-neutral search tool and indexer URL : https://wiki.gnome.org/Projects/Tracker License : GPLv2+ Description : Tracker is a powerful desktop-neutral first class object database, : tag/metadata database, search tool and indexer. : : It consists of a common object database that allows entities to have an : almost infinite number of properties, metadata (both embedded/harvested as : well as user definable), a comprehensive database of keywords/tags and : links to other entities. : : It provides additional features for file based objects including context : linking and audit trails for a file object. : : It has the ability to index, store, harvest metadata. retrieve and search : all types of files and other first class objects &gt; yum remove tracker Dependencies Resolved ================================================================================= Package Arch Version Repository Size ================================================================================= Removing: tracker x86_64 1.10.5-6.el7 @anaconda 5.6 M Removing for dependencies: brasero x86_64 3.12.1-2.el7 @anaconda 11 M brasero-nautilus x86_64 3.12.1-2.el7 @anaconda 47 k evince-nautilus x86_64 3.22.1-7.el7 @anaconda 19 k gnome-boxes x86_64 3.22.4-4.el7 @anaconda 5.0 M gnome-classic-session noarch 3.26.2-3.el7 @anaconda 199 k grilo-plugins x86_64 0.3.4-3.el7 @anaconda 2.1 M nautilus x86_64 3.22.3-5.el7 @anaconda 15 M totem x86_64 1:3.22.1-1.el7 @anaconda 6.3 M totem-nautilus x86_64 1:3.22.1-1.el7 @anaconda 36 k tracker-preferences x86_64 1.10.5-6.el7 @base 248 k Transaction Summary ================================================================================= Remove 1 Package (+10 Dependent packages) Installed size: 45 M Is this ok [y/N]: n 2. tracker daemon -k（暂时性）暂时性的方法，调用tracker daemon -k杀死所有tracker相关进程： &gt; tracker usage: tracker [--version] [--help] &lt;command&gt; [&lt;args&gt;] Available tracker commands are: daemon Start, stop, pause and list processes responsible for indexing content extract Extract information from a file info Show information known about local files or items indexed index Backup, restore, import and (re)index by MIME type or file name reset Reset or remove index and revert configurations to defaults search Search for content indexed or show content by type sparql Query and update the index using SPARQL or search, list and tree the ontology sql Query the database at the lowest level using SQL status Show the indexing progress, content statistics and index state tag Create, list or delete tags for indexed content See &#39;tracker help &lt;command&gt;&#39; to read about a specific subcommand. &gt; tracker daemon -k all Found 10 PIDs… Killed process 2390 - &#39;tracker-miner-user-guides&#39; Killed process 2395 - &#39;tracker-store&#39; Killed process 2656 - &#39;tracker-miner-apps&#39; Killed process 2705 - &#39;tracker-miner-fs&#39; Killed process 2952 - &#39;tracker-miner-user-guides&#39; Killed process 2962 - &#39;tracker-extract&#39; Killed process 2963 - &#39;tracker-miner-apps&#39; Killed process 2964 - &#39;tracker-miner-fs&#39; Killed process 2987 - &#39;tracker-store&#39; Killed process 13666 - &#39;tracker-extract&#39; 可通过tracker daemon -s重新启动tracker相关进程 3. 禁用 tracker 的 autostart在/etc/xdg/autostart/tracker*.desktop文件的末尾添加以下内容： Hidden=true 注销后重新登录生效。 4. 安装 tracker-preferences&gt; yum info tracker-preferences Available Packages Name : tracker-preferences Arch : x86_64 Version : 1.10.5 Release : 6.el7 Size : 58 k Repo : base/7/x86_64 Summary : Tracker preferences URL : https://wiki.gnome.org/Projects/Tracker License : GPLv2+ Description : Graphical frontend to tracker configuration. &gt; yum install tracker-preferences tracker-preferences 打勾的选项全部取消，注销后重新登录生效。 参考文章 tracker-extract high cpu usage | StackExchange tracker-extract process with 100% cpu usage | CentOS [Solved] How to disable tracker-store processes that eat 100% CPU | openSUSE Forum Ubuntu Gnome 14.04 tracker-extract 占用内存太高 | CSDN 解决 Linux 中 tracker 大量占用 CPU 的问题 | Linux 公社 Ubuntu 16.04 莫名其妙占用 CPU 的 tracker | Paulus.Chen 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"}]},{"title":"Linux 设置多台主机 SSH 免密登录","slug":"setup-remote-ssh-login","date":"2019-04-28T03:25:45.000Z","updated":"2019-09-01T13:04:11.668Z","comments":true,"path":"2019/04/28/setup-remote-ssh-login/","link":"","permalink":"https://abelsu7.top/2019/04/28/setup-remote-ssh-login/","excerpt":"摘自 How to Setup Passwordless SSH Login | Linuxize","text":"摘自 How to Setup Passwordless SSH Login | Linuxize 1. 查看已有密钥&gt; ls -l ~/.ssh/ total 12 -rw------- 1 root root 1679 Apr 11 10:11 id_rsa -rw-r--r-- 1 root root 398 Apr 11 10:11 id_rsa.pub -rw-r--r--. 1 root root 1736 Apr 11 10:21 known_hosts 若可看到id_rsa、id_rsa.pub存在，则说明该机器上之前已经生成了 SSH 密钥，可以选择继续使用该密钥或重新生成新密钥。 2. 重新生成密钥若选择重新生成密钥，则先备份旧密钥（如有需要），再使用以下命令： &gt; ssh-keygen -t rsa -b 4096 -C &quot;your_email@domain.com&quot; 之后连按 4 次回车，表示采用默认设置，生成密钥： 连按 4 次回车，生成密钥文件 最后确认已经生成密钥文件id_rsa、id_rsa.pub： &gt; ls ~/.ssh/id_* /root/.ssh/id_rsa /root/.ssh/id_rsa.pub 3. 将公钥复制到其他主机使用ssh-copy-id命令将本机的公钥复制到指定主机的authorized_keys文件中： &gt; ssh-copy-id remote_username@server_ip_address 例如现在我有三台 Linux 主机，均已生成 SSH 密钥，主机名如下所示： abelsu7-ubuntu centos-1 centos-2 以abelsu7-ubuntu为例，执行以下命令： &gt; ssh-copy-id root@centos-1 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot; /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@centos-1 password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &#39;root@centos-1&#39;&quot; and check to make sure that only the key(s) you wanted were added. &gt; ssh-copy-id root@centos-2 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot; /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@centos-2 password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &#39;root@centos-2&#39;&quot; and check to make sure that only the key(s) you wanted were added. 之后就可以在abelsu7-ubuntu上直接通过 SSH 免密登录centos-1、centos-2： &gt; ssh root@centos-1 &gt; ssh root@centos-2 在其他两台主机centos-1、centos-2上重复以上操作，即可在三台 Linux 主机上互相 SSH 免密登录 另外，如果ssh-copy-id不可用，则可使用以下命令作为替代： &gt; cat ~/.ssh/id_rsa.pub | ssh remote_username@server_ip_address &quot;mkdir -p ~/.ssh &amp;&amp; cat &gt;&gt; ~/.ssh/authorized_keys&quot; 4. 禁用 SSH 密码登录（可选） 关于sshd_config的更多配置，可参考 Using the SSH Config File | Linuxize 若要禁用 SSH 密码登录，则需修改sshd_config配置文件： &gt; sudo vim /etc/ssh/sshd_config ... # 修改如下 PasswordAuthentication no ChallengeResponseAuthentication no UsePAM no ... &gt; sudo systemctl restart sshd # 重启服务后生效 参考文章 How to Set Up SSH Keys on CentOS 7 | Linuxize How to Setup Passwordless SSH Login | Linuxize Using the SSH Config File | Linuxize How to Change the SSH Port in Linux | Linuxize CentOS 7 如何实现免密登录（三个及三个以上机器）| CSDN SSH 相关文章收集 4 Ways to Speed Up SSH Connections in Linux | TecMint ssh-chat – Make Group/Private Chat with Other Linux Users Over SSH | TecMint 高级 SSH 速查表 | Linux 中国 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://abelsu7.top/tags/SSH/"}]},{"title":"Linux 下使用 df 命令查看磁盘使用情况","slug":"linux-df-command","date":"2019-04-18T13:46:25.000Z","updated":"2019-09-01T13:04:11.496Z","comments":true,"path":"2019/04/18/linux-df-command/","link":"","permalink":"https://abelsu7.top/2019/04/18/linux-df-command/","excerpt":"译自 How to Check Disk Space in Linux Using the df Command，补充整理来源于网络","text":"译自 How to Check Disk Space in Linux Using the df Command，补充整理来源于网络 1. 查看已挂载的所有文件系统&gt; df Filesystem 1K-blocks Used Available Use% Mounted on udev 948204 0 948204 0% /dev tmpfs 193132 19896 173236 11% /run /dev/vda1 51474044 2331696 46520964 5% / tmpfs 965652 24 965628 1% /dev/shm tmpfs 5120 0 5120 0% /run/lock tmpfs 965652 0 965652 0% /sys/fs/cgroup tmpfs 100 0 100 0% /run/lxcfs/controllers tmpfs 193132 0 193132 0% /run/user/0 指定挂载路径/： &gt; df / Filesystem 1K-blocks Used Available Use% Mounted on /dev/vda1 51474044 2332576 46520084 5% / 2. 以 K、M、G 为单位显示大小&gt; df -h Filesystem Size Used Avail Use% Mounted on udev 926M 0 926M 0% /dev tmpfs 189M 20M 170M 11% /run /dev/vda1 50G 2.3G 45G 5% / tmpfs 944M 24K 943M 1% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 944M 0 944M 0% /sys/fs/cgroup tmpfs 100K 0 100K 0% /run/lxcfs/controllers tmpfs 189M 0 189M 0% /run/user/0 3. 显示文件系统类型&gt; df -hT Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 926M 0 926M 0% /dev tmpfs tmpfs 189M 20M 170M 11% /run /dev/vda1 ext3 50G 2.3G 45G 5% / tmpfs tmpfs 944M 24K 943M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs tmpfs 944M 0 944M 0% /sys/fs/cgroup tmpfs tmpfs 100K 0 100K 0% /run/lxcfs/controllers tmpfs tmpfs 189M 0 189M 0% /run/user/0 指定文件系统类型ext3： &gt; df -t ext3 Filesystem 1K-blocks Used Available Use% Mounted on /dev/vda1 51474044 2332712 46519948 5% / &gt; df -x ext3 # 除 ext3 以外的其他类型 Filesystem 1K-blocks Used Available Use% Mounted on udev 948204 0 948204 0% /dev tmpfs 193132 19896 173236 11% /run tmpfs 965652 24 965628 1% /dev/shm tmpfs 5120 0 5120 0% /run/lock tmpfs 965652 0 965652 0% /sys/fs/cgroup tmpfs 100 0 100 0% /run/lxcfs/controllers tmpfs 193132 0 193132 0% /run/user/0 4. 显示 Inode 使用情况&gt; df -ih / Filesystem Inodes IUsed IFree IUse% Mounted on /dev/vda1 3.2M 93K 3.1M 3% / 5. 格式化输出还可以在df命令中指定打印的字段，可以添加--output[=FIELD_LIST]选项，FIELD_LIST中各个字段用,隔开： source：文件系统源地址 fstype：文件系统类型 itotal：文件系统的 inodes 总量 iused：已使用的 inodes iavail：可使用的 inodes ipcent：已使用的 inodes 百分比 size：磁盘空间总量 used：已使用的磁盘空间大小 avail：可用的磁盘空间大小 pcent：已使用的磁盘空间百分比 file：命令行中指定的文件名 target：文件系统挂载点 &gt; df -h -t tmpfs --output=source,size,pcent,target Filesystem Size Use% Mounted on tmpfs 189M 11% /run tmpfs 944M 1% /dev/shm tmpfs 5.0M 0% /run/lock tmpfs 944M 0% /sys/fs/cgroup tmpfs 100K 0% /run/lxcfs/controllers tmpfs 189M 0% /run/user/0 参考文章 How to Check Disk Space in Linux Using the df Command 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"}]},{"title":"Vim 入坑不完全指北","slug":"vim-quick-guide","date":"2019-04-18T12:53:20.000Z","updated":"2019-09-01T13:04:11.762Z","comments":true,"path":"2019/04/18/vim-quick-guide/","link":"","permalink":"https://abelsu7.top/2019/04/18/vim-quick-guide/","excerpt":"一入 Vim 深似海，从此 IDE 是路人","text":"一入 Vim 深似海，从此 IDE 是路人 更新中… 目录 目录 1. 基本操作 移动光标 文件保存与退出 删除字符 插入字符 行末添加新字符 2. 删除/撤销 d 命令及其参数 w/e 移动光标 dd 删除整行 Undo/Redo 3. 插入/替换/编辑 p 命令 r 命令 c 命令 4. 定位/搜索替换/括号匹配 快速定位 搜索 替换 括号匹配 5. 运行终端命令/保存至文件 运行终端命令 保存至文件 保存选中内容 插入文件内容 6. 新行插入/连续替换/复制粘贴/搜索选项 o 命令 a 命令 R 命令 复制/粘贴 设置搜索选项 7. 获取帮助/自动补全 获取帮助 自动补全 参考文章 1. 基本操作移动光标 ^ k Hint: The h key is at the left and moves left. &lt; h l &gt; The l key is at the right and moves right. j The j key looks like a down arrow. v 文件保存与退出 待补充 :w :wq :q! :qa 删除字符 x：删除光标选中的字符 插入字符 i：进入编辑模式 行末添加新字符 A：可在当前光标行末添加新字符 2. 删除/撤销d 命令及其参数Many commands that change text are made from an operator and a motion. The format for a delete command with the d delete operator is as follows: d motion Where: d - is the delete operator. motion - is what the operator will operate on (listed below). A short list of motions: w - until the start of the next word, EXCLUDING its first character. e - to the end of the current word, INCLUDING the last character. $ - to the end of the line, INCLUDING the last character. dw：删除光标后的单词，光标停留在下一个单词的开头 de：删除光标后的单词，光标停留在下一个单词开头的前一个字符 d$：删除至行末 w/e 移动光标 w：移动至下一个单词的开头，可与数字连用，例如2w会移动至后数第二个单词的开头 e：移动至下一个单词的末尾，可与数字连用，例如3e会移动至后数第三个单词的末尾 0：移动至光标所在行的开头（类似Home） d2w：删除光标后数的两个单词，光标停留在第三个单词的首字符 d2e：删除光标后数的两个单词，光标停留在第三个单词首字符的前一个字符 dd 删除整行 dd：删除当前行 2dd：删除包括当前行之后的 2 行 Undo/Redo u：撤销最近的一次更改 U：撤销整行的更改 Ctrl+R：Redo 3. 插入/替换/编辑p 命令 p：将上一次删除的内容插入到光标之后 r 命令 r：替换光标选中的字符 c 命令与d命令类似，满足以下格式： &gt; c [number] motion ce：编辑光标之后的单词直至其末尾 c2e：编辑光标之后的 2 个单词直至其末尾 c$：编辑光标至行末的内容 4. 定位/搜索替换/括号匹配快速定位 Ctrl+G：显示当前位置及行号 G：移动至文件末尾 gg：移动至文件开头 313 G：移动至第313行 搜索 /pattern：向后查找包含pattern的字符串 ?pattern：向前查找包含pattern的字符串 n：下一个匹配 N：上一个匹配 Ctrl+O：跳转至光标上一次所在位置 Ctrl+I：跳转至光标下一次所在位置 替换 :s/old/new：将该行第一个出现的old替换为new :s/old/new/g：将该行所有出现的old替换为new :#,#s/old/new/g：将两行之间所有出现的old替换为new :%s/old/new/g：将文件中所有出现的old替换为new :%s/old/new/g：查找文件中所有出现的old，并提示用户是否用new进行替换 括号匹配 %：查找与光标后最近的左括号(、[、{匹配的右括号 5. 运行终端命令/保存至文件运行终端命令 :!command：例如:!pwd将打印当前工作目录路径 保存至文件 :w FILENAME：将更改保存至FILENAME 保存选中内容 首先在起始行按下v进入可视化选择模式 移动光标，选中想要保存的内容 之后按下:，屏幕下方会出现:&#39;&lt;,&#39;&gt; 输入w TEST，即屏幕下方显示:&#39;&lt;,&#39;&gt;w TEST，将选中内容保存至TEST 插入文件内容 :r TEST：在光标后插入文件TEST的内容 :r !pwd：在光标后插入pwd命令输出的内容 6. 新行插入/连续替换/复制粘贴/搜索选项o 命令 :o：在光标下方插入新行，并进入编辑模式 :O：在光标上方插入新行，并进入编辑模式 a 命令 :a：在当前光标之后插入新内容，并进入编辑模式 R 命令 :R：进入编辑模式，并用输入的字符替换当前光标选中的字符 复制/粘贴 y：复制选中内容 y2w：复制光标之后的两个单词 p：在光标之后粘贴内容 设置搜索选项 :set ic：Ignore Case，忽略大小写 :set noic：开启大小写 :set hls：Highlight Search，高亮搜索 :nohlsearch：取消当前的高亮，可简写为:nohl或:noh :set is：Increasing Search，递进搜索 :set nois：取消递进搜索 7. 获取帮助/自动补全获取帮助 :help：打开帮助文档 自动补全 Ctrl+D：显示所有匹配开头的命令 Tab：自动补全至下一项 8. .vimrc 设置快捷键Ctrl+S 保存 参考 Vim 实现 Ctrl+S 为保存快捷键 | 博客园 在~/.vimrc中加入以下内容： 我用的是nvim，所以配置文件在~/.config/nvim/目录下 &quot; 快捷键设置 nmap &lt;F2&gt; :NERDTreeToggle&lt;cr&gt; nmap &lt;F3&gt; :TagbarToggle&lt;cr&gt; nmap &lt;F6&gt; :GoFmt&lt;cr&gt; nmap &lt;C-s&gt; :w&lt;cr&gt; 参考文章 Learning Vim: What I Wish I Knew | Hacker Noon Introduction To Vim Customization | Linode The Ultimate vimrc | Github Vim Dracula Theme | Github Vundle.vim | Github lexVim - lexkong | Github 138 条 Vim 命令、操作、快捷键全集 | 马哥 Linux 运维 练了一年再来总结的 vim 使用技巧 | CU 技术社区 哈哈：180万程序员不知如何退出Vim编辑器 | 实验楼 精通 VIM ，此文就够了 | zempty 笔记 超酷的 Vim 搜索技巧 | Linux 中国 Vim 系列教程 | 卡瓦邦噶 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Vim","slug":"Vim","permalink":"https://abelsu7.top/categories/Vim/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"Vim","slug":"Vim","permalink":"https://abelsu7.top/tags/Vim/"}]},{"title":"Linux 下使用 du 命令查看目录占用空间大小","slug":"linux-du-command","date":"2019-04-17T08:31:37.000Z","updated":"2019-09-01T13:04:11.498Z","comments":true,"path":"2019/04/17/linux-du-command/","link":"","permalink":"https://abelsu7.top/2019/04/17/linux-du-command/","excerpt":"译自 How to Get the Size of a Directory in Linux，补充整理来源于网络","text":"译自 How to Get the Size of a Directory in Linux，补充整理来源于网络 1. du 命令简介du命令为disk usage的缩写，是一个计算磁盘上目录或文件占用空间的工具，它可以用来显示文件系统上的目录、单个/多个文件所占用的磁盘空间。 这与df命令有所不同，df命令用来显示每个文件系统的磁盘使用量以及可用量的信息 2. 查看目录占用空间总大小&gt; du -csh /var /kvm 5.3G /var 7.5G /kvm 13G total 参数释义： -c、--total：最后打印所有参数目录的空间占用大小总和 -s、--summarize：仅打印各参数目录的空间占用大小总和，不打印其子目录 -h、--human-readable：以K、M、G为单位显示空间占用大小 3. 查看一级子目录占用空间大小&gt; du -shc /var/* 0 /var/account 0 /var/adm 2.0G /var/cache 0 /var/crash 8.0K /var/db 0 /var/empty 0 /var/games 0 /var/gopher 0 /var/kerberos 3.1G /var/lib 0 /var/local 0 /var/lock 180M /var/log 0 /var/mail 0 /var/nis 0 /var/opt 0 /var/preserve 0 /var/run 45M /var/spool 0 /var/target 32K /var/tmp 0 /var/yp 5.3G total 或者： &gt; du -h --max-depth=1 /var 32K /var/tmp 3.1G /var/lib 180M /var/log 0 /var/adm 2.0G /var/cache 8.0K /var/db 0 /var/empty 0 /var/games 0 /var/gopher 0 /var/local 0 /var/nis 0 /var/opt 0 /var/preserve 45M /var/spool 0 /var/yp 0 /var/kerberos 0 /var/crash 0 /var/target 0 /var/account 5.3G /var 4. 查看目录使用空间大小添加--apparent-size参数： &gt; du -sh /var 5.3G /var &gt; du -sh --apparent-size /var 5.2G /var du命令还可以通过管道与其他命令结合使用，例如以下命令将打印/var目录下占用空间最大的前 5 个目录： &gt; du -h /var/ | sort -rh | head -5 5.3G /var/ 3.1G /var/lib 2.8G /var/lib/docker/overlay2 2.8G /var/lib/docker 2.0G /var/cache/yum/x86_64/7 参考文章 How to Get the Size of a Directory in Linux du 命令 | dslztx Ext文件系统中，文件的“占用大小”和“使用大小” | dslztx Linux 的 du 命令 | 51CTO 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"}]},{"title":"浅谈 CI/CD：持续集成、持续交付","slug":"ci-cd-intro","date":"2019-04-17T07:05:48.000Z","updated":"2019-09-01T13:04:11.040Z","comments":true,"path":"2019/04/17/ci-cd-intro/","link":"","permalink":"https://abelsu7.top/2019/04/17/ci-cd-intro/","excerpt":"文章内容收集整理于网络，详见参考文章","text":"文章内容收集整理于网络，详见参考文章 To be updated 参考文章 什么是 CI/CD？| Linux 中国 什么是 CI/CD？| RedHat DevOps 借助 Ansible 实现持续集成和交付 | RedHat 如何理解持续集成、持续交付、持续部署？| CSDN 一文帮你秒懂CI, CD AND CD | 知乎 如何理解持续集成、持续交付、持续部署？| 知乎 The Product Managers’ Guide to Continuous Delivery and DevOps | mind the Product 一张图带你了解持续交付和 DevOps 的前世今生 - 乔梁 | GitChat 持续集成是什么？| 阮一峰 什么是持续集成（CI）/持续部署（CD）？| 知乎 CI/CD Hello World in OpenShift | 陈沙克日志 🚩推荐阅读（由hexo文章推荐插件驱动）应用程序发布与部署中的几个小TipsDevOps团队结构类型汇总","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://abelsu7.top/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://abelsu7.top/tags/DevOps/"},{"name":"持续集成","slug":"持续集成","permalink":"https://abelsu7.top/tags/持续集成/"},{"name":"持续交付","slug":"持续交付","permalink":"https://abelsu7.top/tags/持续交付/"}]},{"title":"CentOS 7 安装配置 VNC","slug":"centos7-install-and-configure-vnc","date":"2019-04-16T13:03:25.000Z","updated":"2019-09-01T13:04:11.007Z","comments":true,"path":"2019/04/16/centos7-install-and-configure-vnc/","link":"","permalink":"https://abelsu7.top/2019/04/16/centos7-install-and-configure-vnc/","excerpt":"一文搞定 CentOS 7 VNC 配置","text":"一文搞定 CentOS 7 VNC 配置 1. 安装 TigerVNC&gt; yum install tigervnc-server 2. 设置登录密码切换至通过 VNC 连接的用户，并使用vncpasswd命令设置密码，长度至少为 6 位： > su - your_user # If you want to configure VNC server to run under this user directly from CLI without switching users from GUI > vncpasswd 3. 添加 systemd 配置文件&gt; cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service &gt; vim /etc/systemd/system/vncserver@:1.service 编辑配置文件/etc/systemd/system/vncserver@:1.service，注意修改高亮部分： [Unit] Description=Remote desktop service (VNC) After=syslog.target network.target [Service] Type=forking ExecStartPre=/bin/sh -c '/usr/bin/vncserver -kill %i > /dev/null 2>&1 || :' ExecStart=/sbin/runuser -l my_user -c \"/usr/bin/vncserver %i -geometry 1280x1024\" PIDFile=/home/my_user/.vnc/%H%i.pid ExecStop=/bin/sh -c '/usr/bin/vncserver -kill %i > /dev/null 2>&1 || :' [Install] WantedBy=multi-user.target 4. 启用服务并设置开机启动&gt; systemctl daemon-reload &gt; systemctl start vncserver@:1 &gt; systemctl status vncserver@:1 &gt; systemctl enable vncserver@:1 使用以下命令查看服务状态： &gt; systemctl status vncserver@:1.service # 或 &gt; service vncserver@:1 status 可以看到vncserver已正常启动： vncserver@:1.service 正常启动 5. 查看端口使用情况&gt; ss -tulpn | grep vnc tcp LISTEN 0 5 *:5901 *:* users:((&quot;Xvnc&quot;,pid=1356,fd=9)) tcp LISTEN 0 128 *:6001 *:* users:((&quot;Xvnc&quot;,pid=1356,fd=6)) tcp LISTEN 0 5 :::5901 :::* users:((&quot;Xvnc&quot;,pid=1356,fd=10)) tcp LISTEN 0 128 :::6001 :::* users:((&quot;Xvnc&quot;,pid=1356,fd=5)) 或者： &gt; vncserver -list TigerVNC server sessions: X DISPLAY # PROCESS ID :1 1344 :2 4112 6. 防火墙放行端口&gt; firewall-cmd --add-port=5901/tcp &gt; firewall-cmd --add-port=5901/tcp --permanent 7. 死机重启后服务启动失败的解决办法 系统死机重启后，服务启动失败 手动启动 vncserver 提示端口已被占用 ~/.vnc 目录下残留 centos-1:5.pid 该目录下文件未被清除 手动清除残余文件后，重新启动服务： &gt; rm ~/.vnc/*.pid &gt; rm -rf /tmp/.X11-unix &gt; service vncserver@:1 start 可以看到服务已正常启动： 参考文章 How to Install and Configure VNC Server in CentOS 7 | TecMint How to Install and Configure VNC on CentOS 7 | Linuxize 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"VNC","slug":"VNC","permalink":"https://abelsu7.top/tags/VNC/"}]},{"title":"《KVM 实战》笔记 1：构建 KVM 环境","slug":"kvm-in-action-1","date":"2019-04-16T12:50:59.000Z","updated":"2019-09-01T13:04:11.424Z","comments":true,"path":"2019/04/16/kvm-in-action-1/","link":"","permalink":"https://abelsu7.top/2019/04/16/kvm-in-action-1/","excerpt":"摘自 《KVM实战：原理、进阶与性能调优》 《KVM实战：原理、进阶与性能调优》","text":"摘自 《KVM实战：原理、进阶与性能调优》 《KVM实战：原理、进阶与性能调优》 目录 目录 1. 硬件系统的配置 1.1 BIOS 开启 VT/VT-d 1.2 重启后查看 CPU 特性标志 2. 安装宿主机操作系统 3. 编译和安装 KVM 3.1 下载 KVM 源代码 3.2 配置 KVM 3.3 编译 KVM 3.4 安装 KVM 3.5 安装后的检查 4. 编译和安装 QEMU 4.1 下载 QEMU 源代码 4.2 配置和编译 QEMU 4.3 安装 QEMU 5. 安装客户机 参考文章 1. 硬件系统的配置KVM 从诞生之初就需要硬件虚拟化扩展的支持，其最初的开发是基于x86和x86-64处理器架构上的 Linux 系统进行的。 目前，KVM 被移植到多种不同处理器架构上，但在x86-64架构上的支持是最完善的。 本文默认基于x86-64的 Linux 系统进行相关操作 在x86-64架构的处理器中，KVM 需要的硬件虚拟化扩展分别为： Intel VT AMD-V 1.1 BIOS 开启 VT/VT-d 需要 CPU 在硬件上支持 VT 技术 在 BIOS 中启用VT即Intel(R) Virtualization Technology 在 BIOS 中启用VT-d即Intel(R) VT for Directed I/O 1.2 重启后查看 CPU 特性标志设置好VT和VT-d的相关选项，保存 BIOS 设置并退出，系统重启后生效。 可通过检查/proc/cpuinfo文件中的 CPU 特性标志（flags）来查看 CPU 目前是否支持硬件虚拟化： Intel CPU 支持虚拟化的标志为vmxAMD CPU 支持虚拟化的标志为svm &gt; grep -E &quot;vmx|svm&quot; /proc/cpuinfo flags : ... vmx ... ... 2. 安装宿主机操作系统 CentOS 7 安装时不需要选择Virtualization Host，因为后续会自行编译 KVM 及 QEMU 源码 CentOS 7 推荐选择Server with GUI、GNOME Desktop以及Development Tools 本文实验环境：OSUbuntu 18.04 LTS，CPUi7-6700 * 8，内存32G 3. 编译和安装 KVM3.1 下载 KVM 源代码&gt; git clone git://git.kernel.org/pub/scm/virt/kvm/kvm.git # or &gt; git clone https://git.kernel.org/pub/scm/virt/kvm/kvm.git 内核版本：本文使用的是kvm.git的4.21.1版本，编译后显示的内核版本为4.20.0-rc6源码地址： index: kvm/kvm.git。 3.2 配置 KVMKVM 是作为 Linux 内核中的一个 module 而存在的，而kvm.git是一个包含了最新的 KVM 模块开发中代码的完整的 Linux 内核源码仓库。它的配置方式与普通的 Linux 内核配置完全一样，只是需要注意将 KVM 相关的配置选择为编译进内核或者编译为模块。 make 常用命令在kvm.git目录下，运行make help查看关于如何配置和编译 kernel 的帮助说明： &gt; make help Cleaning targets: clean - Remove most generated files but keep the config and enough build support to build external modules mrproper - Remove all generated files + config + various backup files distclean - mrproper + remove editor backup and patch files Configuration targets: config - Update current config utilising a line-oriented program nconfig - Update current config utilising a ncurses menu based program menuconfig - Update current config utilising a menu based program xconfig - Update current config utilising a Qt based front-end gconfig - Update current config utilising a GTK+ based front-end oldconfig - Update current config utilising a provided .config as base localmodconfig - Update current config disabling modules not loaded localyesconfig - Update current config converting local mods to core defconfig - New config with default from ARCH supplied defconfig savedefconfig - Save current config as ./defconfig (minimal config) allnoconfig - New config where all options are answered with no allyesconfig - New config where all options are accepted with yes allmodconfig - New config selecting modules when possible alldefconfig - New config with all symbols set to default randconfig - New config with random answer to all options listnewconfig - List new options olddefconfig - Same as oldconfig but sets new symbols to their default value without prompting kvmconfig - Enable additional options for kvm guest kernel support xenconfig - Enable additional options for xen dom0 and guest kernel support tinyconfig - Configure the tiniest possible kernel testconfig - Run Kconfig unit tests (requires python3 and pytest) Other generic targets: all - Build all targets marked with [*] * vmlinux - Build the bare kernel * modules - Build all modules modules_install - Install all modules to INSTALL_MOD_PATH (default: /) dir/ - Build all files in dir and below dir/file.[ois] - Build specified target only dir/file.ll - Build the LLVM assembly file (requires compiler support for LLVM assembly generation) dir/file.lst - Build specified mixed source/assembly target only (requires a recent binutils and recent build (System.map)) dir/file.ko - Build module including final link modules_prepare - Set up for building external modules tags/TAGS - Generate tags file for editors cscope - Generate cscope index gtags - Generate GNU GLOBAL index kernelrelease - Output the release version string (use with make -s) kernelversion - Output the version stored in Makefile (use with make -s) image_name - Output the image name (use with make -s) headers_install - Install sanitised kernel headers to INSTALL_HDR_PATH (default: ./usr) Static analysers: checkstack - Generate a list of stack hogs namespacecheck - Name space analysis on compiled kernel versioncheck - Sanity check on version.h usage includecheck - Check for duplicate included header files export_report - List the usages of all exported symbols headers_check - Sanity check on exported headers headerdep - Detect inclusion cycles in headers coccicheck - Check with Coccinelle Kernel selftest: kselftest - Build and run kernel selftest (run as root) Build, install, and boot kernel before running kselftest on it kselftest-clean - Remove all generated kselftest files kselftest-merge - Merge all the config dependencies of kselftest to existing .config. Userspace tools targets: use &quot;make tools/help&quot; or &quot;cd tools; make help&quot; Kernel packaging: rpm-pkg - Build both source and binary RPM kernel packages binrpm-pkg - Build only the binary kernel RPM package deb-pkg - Build both source and binary deb kernel packages bindeb-pkg - Build only the binary kernel deb package snap-pkg - Build only the binary kernel snap package (will connect to external hosts) tar-pkg - Build the kernel as an uncompressed tarball targz-pkg - Build the kernel as a gzip compressed tarball tarbz2-pkg - Build the kernel as a bzip2 compressed tarball tarxz-pkg - Build the kernel as a xz compressed tarball perf-tar-src-pkg - Build perf-4.20.0-rc6.tar source tarball perf-targz-src-pkg - Build perf-4.20.0-rc6.tar.gz source tarball perf-tarbz2-src-pkg - Build perf-4.20.0-rc6.tar.bz2 source tarball perf-tarxz-src-pkg - Build perf-4.20.0-rc6.tar.xz source tarball Documentation targets: Linux kernel internal documentation in different formats from ReST: htmldocs - HTML latexdocs - LaTeX pdfdocs - PDF epubdocs - EPUB xmldocs - XML linkcheckdocs - check for broken external links (will connect to external hosts) refcheckdocs - check for references to non-existing files under Documentation cleandocs - clean all generated files make SPHINXDIRS=&quot;s1 s2&quot; [target] Generate only docs of folder s1, s2 valid values for SPHINXDIRS are: driver-api networking input core-api userspace-api media gpu process sound crypto vm maintainer sh dev-tools doc-guide filesystems kernel-hacking admin-guide make SPHINX_CONF={conf-file} [target] use *additional* sphinx-build configuration. This is e.g. useful to build with nit-picking config. Default location for the generated documents is Documentation/output Architecture specific targets (x86): * bzImage - Compressed kernel image (arch/x86/boot/bzImage) install - Install kernel using (your) ~/bin/installkernel or (distribution) /sbin/installkernel or install to $(INSTALL_PATH) and run lilo fdimage - Create 1.4MB boot floppy image (arch/x86/boot/fdimage) fdimage144 - Create 1.4MB boot floppy image (arch/x86/boot/fdimage) fdimage288 - Create 2.8MB boot floppy image (arch/x86/boot/fdimage) isoimage - Create a boot CD-ROM image (arch/x86/boot/image.iso) bzdisk/fdimage*/isoimage also accept: FDARGS=&quot;...&quot; arguments for the booted kernel FDINITRD=file initrd for the booted kernel i386_defconfig - Build for i386 x86_64_defconfig - Build for x86_64 make V=0|1 [targets] 0 =&gt; quiet build (default), 1 =&gt; verbose build make V=2 [targets] 2 =&gt; give reason for rebuild of target make O=dir [targets] Locate all output files in &quot;dir&quot;, including .config make C=1 [targets] Check re-compiled c source with $CHECK (sparse by default) make C=2 [targets] Force check of all c source with $CHECK make RECORDMCOUNT_WARN=1 [targets] Warn about ignored mcount sections make W=n [targets] Enable extra gcc checks, n=1,2,3 where 1: warnings which may be relevant and do not occur too often 2: warnings which occur quite often but may still be relevant 3: more obscure warnings, can most likely be ignored Multiple levels can be combined with W=12 or W=123 Execute &quot;make&quot; or &quot;make all&quot; to build all targets marked with [*] For further info see the ./README file 对 KVM 进行内核配置常用的一些配置命令如下： make config：基于文本的最为传统也是最为枯燥的一种配置方式，适用于任何情况 make oldconfig：在现有的内核设置文件基础上建立一个新的设置文件，只会向用户提供有关新内核特性的问题 make silentoldconfig：和上面的make oldconfig一样，只是额外会静默更新选项的依赖关系 make olddefconfig：和上面的make silentoldconfig一样，但不需要手动交互，而是对新选项以其默认值配置 make menuconfig：基于终端的一种配置方式，提供了文本模式的图形用户界面，用户可以通过移动光标来浏览所支持的各种特性，要求系统中安装ncurses库 make xconfig：基于 X Window 的一种配置方式，只能在 X Server 上运行 X 桌面应用程序时使用，并且依赖于 QT 库 make gconfig：与make xconfig类似，不同的是它依赖于 GTK 库 makedefconfig：按照内核代码中提供的默认配置文件对内核进行配置。例如在Intel x86_64平台上，默认配置为arch/x86/configs/x86_64_defconfig，生成.config文件可以用作初始化配置，然后再使用make menuconfig进行定制化配置 make allmodconfig：尽可能多的使用y输入设置内核选项值，生成的配置中包含了全部的内核特性 make allnoconfig：除必需的选项外，其他选项一律不选（常用于嵌入式系统的编译） make allmodconfig：尽可能多的使用m输入设置内核选项值来生成配置文件 make localmodconfig：会执行lsmod命令查看当前系统中加载了哪些模块，并最终将原来的.config中不需要的模块去掉 make olddefconfig为了确保生成的.config文件生成的 Kernel 是实际可以工作的（直接make defconfig生成的.config文件编译出来的 Kernel 常常是不能工作的），最佳实践是以你当前使用的 config 为基础，将它复制到当前编译目录下，重命名为.config，然后再通过make olddefconfig更新补充这个设置文件： &gt; cp /boot/config-3.10.0-862.14.4.el7.x86_64 .config cp: overwrite ‘.config’? y &gt; make olddefconfig HOSTCC scripts/basic/fixdep HOSTCC scripts/kconfig/conf.o HOSTCC scripts/kconfig/confdata.o HOSTCC scripts/kconfig/expr.o LEX scripts/kconfig/lexer.lex.c YACC scripts/kconfig/parser.tab.h HOSTCC scripts/kconfig/lexer.lex.o YACC scripts/kconfig/parser.tab.c HOSTCC scripts/kconfig/parser.tab.o HOSTCC scripts/kconfig/preprocess.o HOSTCC scripts/kconfig/symbol.o HOSTLD scripts/kconfig/conf scripts/kconfig/conf --olddefconfig Kconfig .config:676:warning: symbol value &#39;m&#39; invalid for CPU_FREQ_STAT .config:755:warning: symbol value &#39;m&#39; invalid for HOTPLUG_PCI_SHPC .config:918:warning: symbol value &#39;m&#39; invalid for NF_CT_PROTO_GRE .config:946:warning: symbol value &#39;m&#39; invalid for NF_NAT_REDIRECT .config:949:warning: symbol value &#39;m&#39; invalid for NF_TABLES_INET .config:1111:warning: symbol value &#39;m&#39; invalid for NF_TABLES_IPV4 .config:1115:warning: symbol value &#39;m&#39; invalid for NF_TABLES_ARP .config:1156:warning: symbol value &#39;m&#39; invalid for NF_TABLES_IPV6 .config:1188:warning: symbol value &#39;m&#39; invalid for NF_TABLES_BRIDGE .config:1532:warning: symbol value &#39;m&#39; invalid for NET_DEVLINK .config:2958:warning: symbol value &#39;m&#39; invalid for HW_RANDOM_TPM .config:3554:warning: symbol value &#39;m&#39; invalid for LIRC .config:4104:warning: symbol value &#39;m&#39; invalid for HSA_AMD .config:4460:warning: symbol value &#39;m&#39; invalid for SND_X86 # # configuration written to .config # &gt; cat .config | grep KVM CONFIG_KVM_GUEST=y CONFIG_KVM_DEBUG_FS=y CONFIG_HAVE_KVM=y CONFIG_HAVE_KVM_IRQCHIP=y CONFIG_HAVE_KVM_IRQFD=y CONFIG_HAVE_KVM_IRQ_ROUTING=y CONFIG_HAVE_KVM_EVENTFD=y CONFIG_KVM_MMIO=y CONFIG_KVM_ASYNC_PF=y CONFIG_HAVE_KVM_MSI=y CONFIG_HAVE_KVM_CPU_RELAX_INTERCEPT=y CONFIG_KVM_VFIO=y CONFIG_KVM_GENERIC_DIRTYLOG_READ_PROTECT=y CONFIG_KVM_COMPAT=y CONFIG_HAVE_KVM_IRQ_BYPASS=y CONFIG_KVM=m CONFIG_KVM_INTEL=m CONFIG_KVM_AMD=m CONFIG_KVM_AMD_SEV=y CONFIG_KVM_MMU_AUDIT=y CONFIG_PTP_1588_CLOCK_KVM=m CONFIG_DRM_I915_GVT_KVMGT=m make menuconfig之后使用make menuconfig进行定制化配置，首先需要安装以下依赖项： &gt; yum install -y ncurses-devel flex bison 之后启动make menuconfig： &gt; make menuconfig HOSTCC scripts/kconfig/mconf.o HOSTCC scripts/kconfig/lxdialog/checklist.o HOSTCC scripts/kconfig/lxdialog/inputbox.o HOSTCC scripts/kconfig/lxdialog/menubox.o HOSTCC scripts/kconfig/lxdialog/textbox.o HOSTCC scripts/kconfig/lxdialog/util.o HOSTCC scripts/kconfig/lxdialog/yesno.o HOSTLD scripts/kconfig/mconf scripts/kconfig/mconf Kconfig *** End of the configuration. *** Execute &#39;make&#39; to start the build or try &#39;make help&#39;. make menuconfig 命令的选择界面 Virtualization 中的配置选项 修改完成后保存Save并退出Exit，可以看到.config中CONFIG_KVM_AMD已被修改： &gt; cat .config | grep KVM CONFIG_KVM_GUEST=y CONFIG_KVM_DEBUG_FS=y CONFIG_HAVE_KVM=y CONFIG_HAVE_KVM_IRQCHIP=y CONFIG_HAVE_KVM_IRQFD=y CONFIG_HAVE_KVM_IRQ_ROUTING=y CONFIG_HAVE_KVM_EVENTFD=y CONFIG_KVM_MMIO=y CONFIG_KVM_ASYNC_PF=y CONFIG_HAVE_KVM_MSI=y CONFIG_HAVE_KVM_CPU_RELAX_INTERCEPT=y CONFIG_KVM_VFIO=y CONFIG_KVM_GENERIC_DIRTYLOG_READ_PROTECT=y CONFIG_KVM_COMPAT=y CONFIG_HAVE_KVM_IRQ_BYPASS=y CONFIG_KVM=m CONFIG_KVM_INTEL=m # CONFIG_KVM_AMD is not set CONFIG_KVM_MMU_AUDIT=y CONFIG_PTP_1588_CLOCK_KVM=m CONFIG_DRM_I915_GVT_KVMGT=m 3.3 编译 KVM在对 KVM 源代码进行配置之后，编译 KVM 就比较容易了。它的编译过程就是一个普通的 Linux 内核编译过程，包括以下三个步骤： 编译 kernel 编译 bzImage 编译 内核模块 modules 编译 kernel&gt; make vmlinux -j 10 error: Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel &gt; yum install -y elfutils-libelf-devel &gt; make vmlinux -j 10 # 此处省略部分编译时的输出信息 GEN .version CHK include/generated/compile.h UPD include/generated/compile.h CC init/version.o AR init/built-in.a LD vmlinux.o MODPOST vmlinux.o KSYM .tmp_kallsyms1.o KSYM .tmp_kallsyms2.o LD vmlinux # 这里就是编译、链接后生成的启动所需的 Linux Kernel 文件 SORTEX vmlinux SYSMAP System.map 其中，编译命令中的-j参数不是必需的，他是允许 make 工具用多任务（job）来进行编译。例如上面的-j 10，表示 make 工具最多可以创建 20 个 GCC 进程，同时来进行编译任务。 在一个比较空闲的系统上，-j参数的推荐值大约为 2 倍于系统上的 CPU core。 如果-j后面不跟数字，则 make 会根据现在系统中的 CPU core 的数量自动安排任务数，通常比 core 的数量略多一点 编译完成后，可看到当前目录下生成了我们所需的vmlinux内核文件： &gt; ls -hl vmlinux -rwxr-xr-x 1 root root 446M Apr 21 18:14 vmlinux 编译 bzImage&gt; make bzImage CALL scripts/checksyscalls.sh CALL scripts/atomic/check-atomics.sh DESCEND objtool CHK include/generated/compile.h HOSTCC arch/x86/tools/insn_decoder_test HOSTCC arch/x86/tools/insn_sanity TEST posttest arch/x86/tools/insn_decoder_test: success: Decoded and checked 6299855 instructions TEST posttest arch/x86/tools/insn_sanity: Success: decoded and checked 1000000 random instructions with 0 errors (seed:0x7ffcb19) CC arch/x86/boot/a20.o AS arch/x86/boot/bioscall.o CC arch/x86/boot/cmdline.o AS arch/x86/boot/copy.o HOSTCC arch/x86/boot/mkcpustr CPUSTR arch/x86/boot/cpustr.h CC arch/x86/boot/cpu.o CC arch/x86/boot/cpuflags.o CC arch/x86/boot/cpucheck.o CC arch/x86/boot/early_serial_console.o CC arch/x86/boot/edd.o LDS arch/x86/boot/compressed/vmlinux.lds AS arch/x86/boot/compressed/head_64.o VOFFSET arch/x86/boot/compressed/../voffset.h CC arch/x86/boot/compressed/misc.o CC arch/x86/boot/compressed/string.o CC arch/x86/boot/compressed/cmdline.o CC arch/x86/boot/compressed/error.o OBJCOPY arch/x86/boot/compressed/vmlinux.bin RELOCS arch/x86/boot/compressed/vmlinux.relocs GZIP arch/x86/boot/compressed/vmlinux.bin.gz HOSTCC arch/x86/boot/compressed/mkpiggy MKPIGGY arch/x86/boot/compressed/piggy.S AS arch/x86/boot/compressed/piggy.o CC arch/x86/boot/compressed/cpuflags.o CC arch/x86/boot/compressed/early_serial_console.o CC arch/x86/boot/compressed/kaslr.o CC arch/x86/boot/compressed/kaslr_64.o AS arch/x86/boot/compressed/mem_encrypt.o CC arch/x86/boot/compressed/pgtable_64.o CC arch/x86/boot/compressed/acpi.o CC arch/x86/boot/compressed/eboot.o AS arch/x86/boot/compressed/efi_stub_64.o AS arch/x86/boot/compressed/efi_thunk_64.o LD arch/x86/boot/compressed/vmlinux ZOFFSET arch/x86/boot/zoffset.h AS arch/x86/boot/header.o CC arch/x86/boot/main.o CC arch/x86/boot/memory.o CC arch/x86/boot/pm.o AS arch/x86/boot/pmjump.o CC arch/x86/boot/printf.o CC arch/x86/boot/regs.o CC arch/x86/boot/string.o CC arch/x86/boot/tty.o CC arch/x86/boot/video.o CC arch/x86/boot/video-mode.o CC arch/x86/boot/version.o CC arch/x86/boot/video-vga.o CC arch/x86/boot/video-vesa.o CC arch/x86/boot/video-bios.o LD arch/x86/boot/setup.elf OBJCOPY arch/x86/boot/setup.bin OBJCOPY arch/x86/boot/vmlinux.bin HOSTCC arch/x86/boot/tools/build BUILD arch/x86/boot/bzImage Setup is 17340 bytes (padded to 17408 bytes). System is 7661 kB CRC 93bcb672 Kernel: arch/x86/boot/bzImage is ready (#2) 可以看到arch/x86/boot/bzImage已经生成： &gt; ls -hl arch/x86/boot/bzImage -rw-r--r-- 1 root root 7.5M Apr 21 19:03 arch/x86/boot/bzImage &gt; ls -hl arch/x86_64/boot/bzImage lrwxrwxrwx 1 root root 22 Apr 21 19:03 arch/x86_64/boot/bzImage -&gt; ../../x86/boot/bzImage 编译 module编译 Kernel 和 bzImage 之后编译内核的模块： &gt; make modules -j 10 # 此处省略部分编译时的输出信息 LD [M] sound/soc/snd-soc-acpi.ko LD [M] sound/soc/snd-soc-core.ko LD [M] sound/soundcore.ko LD [M] sound/synth/emux/snd-emux-synth.ko LD [M] sound/synth/snd-util-mem.ko LD [M] sound/usb/6fire/snd-usb-6fire.ko LD [M] sound/usb/bcd2000/snd-bcd2000.ko LD [M] sound/usb/caiaq/snd-usb-caiaq.ko LD [M] sound/usb/hiface/snd-usb-hiface.ko LD [M] sound/usb/line6/snd-usb-line6.ko LD [M] sound/usb/line6/snd-usb-pod.ko LD [M] sound/usb/line6/snd-usb-podhd.ko LD [M] sound/usb/line6/snd-usb-toneport.ko LD [M] sound/usb/line6/snd-usb-variax.ko LD [M] sound/usb/misc/snd-ua101.ko LD [M] sound/usb/snd-usb-audio.ko LD [M] sound/usb/snd-usbmidi-lib.ko LD [M] sound/usb/usx2y/snd-usb-us122l.ko LD [M] sound/usb/usx2y/snd-usb-usx2y.ko LD [M] sound/x86/snd-hdmi-lpe-audio.ko LD [M] virt/lib/irqbypass.ko 3.4 安装 KVMKVM 的安装包括两个步骤： 安装 module 安装 kernel 与 initramfs 安装 module通过make modules_install命令可以将编译好的 module 安装到相应的目录中： &gt; make modules_install # 此处省略部分编译时的输出信息 INSTALL sound/usb/snd-usbmidi-lib.ko INSTALL sound/usb/usx2y/snd-usb-us122l.ko INSTALL sound/usb/usx2y/snd-usb-usx2y.ko INSTALL sound/x86/snd-hdmi-lpe-audio.ko INSTALL virt/lib/irqbypass.ko DEPMOD 4.20.0-rc6 默认情况下，module 会被安装到/lib/modules/$kernel_version/kernel目录中 安装完成后可以查看对应的安装路径，且kvm.ko、kvm-intel.ko两个模块也已经安装： &gt; ls -hl /lib/modules/4.20.0-rc6/kernel total 16K drwxr-xr-x 3 root root 17 Apr 23 16:35 arch drwxr-xr-x 3 root root 4.0K Apr 23 16:35 crypto drwxr-xr-x 68 root root 4.0K Apr 23 16:36 drivers drwxr-xr-x 25 root root 4.0K Apr 23 16:36 fs drwxr-xr-x 3 root root 19 Apr 23 16:36 kernel drwxr-xr-x 5 root root 207 Apr 23 16:36 lib drwxr-xr-x 2 root root 32 Apr 23 16:36 mm drwxr-xr-x 35 root root 4.0K Apr 23 16:37 net drwxr-xr-x 12 root root 167 Apr 23 16:37 sound drwxr-xr-x 3 root root 17 Apr 23 16:37 virt &gt; ls -hl /lib/modules/4.20.0-rc6/kernel/arch/x86/kvm total 15M -rw-r--r-- 1 root root 3.6M Apr 23 16:35 kvm-intel.ko -rw-r--r-- 1 root root 11M Apr 23 16:35 kvm.ko 安装 kernel 和 initramfs通过make install命令安装 kernel 和 initramfs，命令行输出如下： &gt; make install sh ./arch/x86/boot/install.sh 4.20.0-rc6 arch/x86/boot/bzImage \\ System.map &quot;/boot&quot; &gt; ls -hl /boot -t total 300M -rw------- 1 root root 108M Apr 23 21:37 initramfs-4.20.0-rc6.img lrwxrwxrwx 1 root root 27 Apr 23 21:34 System.map -&gt; /boot/System.map-4.20.0-rc6 lrwxrwxrwx 1 root root 24 Apr 23 21:34 vmlinuz -&gt; /boot/vmlinuz-4.20.0-rc6 -rw-r--r-- 1 root root 3.5M Apr 23 21:34 System.map-4.20.0-rc6 -rw-r--r-- 1 root root 7.5M Apr 23 21:34 vmlinuz-4.20.0-rc6 drwx------. 2 root root 21 Jan 9 16:48 grub2 drwxr-xr-x. 2 root root 27 Nov 13 11:28 grub drwx------ 3 root root 16K Jan 1 1970 efi 可以看到在/boot目录下生成了内核文件vmlinuz和initramfs等内核启动所需的文件。 另外在运行make install之后，/boot/efi/EFI/centos/grub.cfg配置文件中也自动添加了一个 grub 选项，如下所示： 注：在下面的menuentry中还配置了KVMGT的相关选项，之后会另写一篇文章加以说明 menuentry &#39;Ubuntu，Linux 4.20.0-rc6 KVMGT&#39; --class kvmgt --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option&#39;gnulinux-4.20.0-rc6-advanced-26d36e85-367a-4200-87fb-0505c5837078&#39; { recordfail load_video gfxmode $linux_gfx_mode insmod gzio if [ x$grub_platform = xxen ]; then insmod xzio; insmod lzopio; fi insmod part_gpt insmod ext2 set root=&#39;hd0,gpt8&#39; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,gpt8 --hint-efi=hd0,gpt8 --hint-baremetal=ahci0,gpt8 26d36e85-367a-4200-87fb-0505c5837078 else search --no-floppy --fs-uuid --set=root 26d36e85-367a-4200-87fb-0505c5837078 fi echo &#39;载入 Linux 4.20.0-rc6 ...&#39; linux /boot/vmlinuz-4.20.0-rc6 root=UUID=26d36e85-367a-4200-87fb-0505c5837078 ro quiet splash $vt_handoff ignore_loglevel log_buf_len=128M console=ttyS0,115200,8n1 i915.enable_gvt=1 kvm.ignore_msrs=1 intel_iommu=on drm.debug=0 echo &#39;载入初始化内存盘...&#39; initrd /boot/initrd.img-4.20.0-rc6 } 联想扬天 T4900 开机进入 BIOS 快捷键 F12 检查grub.cfg配置无误后，重新启动系统，选择刚才为 KVM 而编译、安装的内核启动。 3.5 安装后的检查进入系统后，使用uname -r查看内核版本： &gt; uname -r 4.20.0-rc6 通常情况下，系统启动时已经默认加载了kvm和kvm_intel这两个模块，如果没有加载，则需要手动使用modprobe命令依次加载这两个模块： &gt; modprobe kvm &gt; modprobe kvm_intel &gt; lsmod | grep kvm kvm_intel 245760 0 kvmgt 28672 1 mdev 24576 2 kvmgt,vfio_mdev vfio 32768 3 kvmgt,vfio_mdev,vfio_iommu_type1 kvm 634880 2 kvmgt,kvm_intel irqbypass 16384 1 kvm 确认 KVM 相关模块加载成功后，检查/dev/kvm文件是否存在： &gt; ls -l /dev/kvm crw-rw---- 1 root kvm 10, 232 Apr 29 09:36 /dev/kvm /dev/kvm是 KVM 内核模块提供给用户空间 QEMU 程序使用的一个控制接口，提供了Guest OS运行所需要的模拟和实际的硬件设备环境。 crw-rw----以c为开头，表示/dev/kvm是一个字符设备 4. 编译和安装 QEMU除了在内核空间的kvm.ko模块之外，在用户空间还需要 QEMU 来模拟 VM 所需要的 I/O 设备，并启动客户机进程。 在早期版本中，支持 KVM 的qemu-kvm是由 kernel 社区维护的专门用于 KVM 虚拟化的 QEMU 分支。2012 年末，这个分支并入了主流的 QEMU 仓库，从此就不再需要特殊的qemu-kvm，而只需在通用的 QEMU 命令后添加--enable-kvm选项，即可创建 KVM Guest。 4.1 下载 QEMU 源代码直接下载源代码归档包： ~ &gt; wget https://download.qemu.org/qemu-4.0.0.tar.xz ~ &gt; tar -xvJf qemu-4.0.0.tar.xz ~ &gt; cd qemu-4.0.0 qemu-4.0.0 &gt; ls accel capstone device_tree.c hmp-commands.hx MAINTAINERS pc-bios qemu-keymap.c qtest.c tpm.c arch_init.c Changelog disas hmp-commands-info.hx Makefile po qemu-nbd.c README trace audio chardev disas.c hmp.h Makefile.objs python qemu-nbd.texi replay trace-events authz CODING_STYLE dma-helpers.c hw Makefile.target qapi qemu.nsi replication.c ui backends config.log docs include memory.c qdev-monitor.c qemu-options.h replication.h util balloon.c config-temp dtc io memory_ldst.inc.c qemu-bridge-helper.c qemu-options.hx roms VERSION block configure dump.c ioport.c memory_mapping.c qemu-deprecated.texi qemu-options-wrapper.h rules.mak version.rc block.c contrib exec.c iothread.c migration qemu-doc.texi qemu-option-trace.texi scripts vl.c blockdev.c COPYING fpu job.c module-common.c qemu-edid.c qemu.sasl scsi win_dump.c blockdev-nbd.c COPYING.LIB fsdev job-qmp.c monitor.c qemu-ga.texi qemu-seccomp.c slirp win_dump.h blockjob.c cpus.c gdbstub.c Kconfig.host nbd qemu-img.c qemu-tech.texi stubs bootdevice.c cpus-common.c gdb-xml libdecnumber net qemu-img-cmds.hx qga target bsd-user crypto gitdm.config LICENSE numa.c qemu-img.texi qmp.c tcg bt-host.c default-configs HACKING linux-headers os-posix.c qemu-io.c qobject tests bt-vhci.c device-hotplug.c hmp.c linux-user os-win32.c qemu-io-cmds.c qom thunk.c qemu-4.0.0 &gt; cat VERSION 4.0.0 或者使用 Git 拉取 QEMU 源代码： ~ &gt; git clone https://git.qemu.org/git/qemu.git ~ &gt; cd qemu qemu &gt; git submodule init qemu &gt; git submodule update --recursive 4.2 配置和编译 QEMU配置 QEMU 本文使用的 QEMU 版本为4.0.50 首先运行./configure --help查看配置 QEMU 的选项及帮助信息： qemu-4.0.50 > ./configure --help Usage: configure [options] Options: [defaults in brackets after descriptions] Standard options: --help print this message --prefix=PREFIX install in PREFIX [/usr/local] --interp-prefix=PREFIX where to find shared libraries, etc. use %M for cpu name [/usr/gnemul/qemu-%M] --target-list=LIST set target list (default: build everything) Available targets: aarch64-softmmu alpha-softmmu arm-softmmu cris-softmmu hppa-softmmu i386-softmmu lm32-softmmu m68k-softmmu microblaze-softmmu microblazeel-softmmu mips-softmmu mips64-softmmu mips64el-softmmu mipsel-softmmu moxie-softmmu nios2-softmmu or1k-softmmu ppc-softmmu ppc64-softmmu riscv32-softmmu riscv64-softmmu s390x-softmmu sh4-softmmu sh4eb-softmmu sparc-softmmu sparc64-softmmu tricore-softmmu unicore32-softmmu x86_64-softmmu xtensa-softmmu xtensaeb-softmmu aarch64-linux-user aarch64_be-linux-user alpha-linux-user arm-linux-user armeb-linux-user cris-linux-user hppa-linux-user i386-linux-user m68k-linux-user microblaze-linux-user microblazeel-linux-user mips-linux-user mips64-linux-user mips64el-linux-user mipsel-linux-user mipsn32-linux-user mipsn32el-linux-user nios2-linux-user or1k-linux-user ppc-linux-user ppc64-linux-user ppc64abi32-linux-user ppc64le-linux-user riscv32-linux-user riscv64-linux-user s390x-linux-user sh4-linux-user sh4eb-linux-user sparc-linux-user sparc32plus-linux-user sparc64-linux-user tilegx-linux-user x86_64-linux-user xtensa-linux-user xtensaeb-linux-user --target-list-exclude=LIST exclude a set of targets from the default target-list Advanced options (experts only): --source-path=PATH path of source code [/kvm/qemu_src/qemu-4.0.0] --cross-prefix=PREFIX use PREFIX for compile tools [] --cc=CC use C compiler CC [cc] --iasl=IASL use ACPI compiler IASL [iasl] --host-cc=CC use C compiler CC [cc] for code run at build time --cxx=CXX use C++ compiler CXX [c++] --objcc=OBJCC use Objective-C compiler OBJCC [cc] --extra-cflags=CFLAGS append extra C compiler flags QEMU_CFLAGS --extra-cxxflags=CXXFLAGS append extra C++ compiler flags QEMU_CXXFLAGS --extra-ldflags=LDFLAGS append extra linker flags LDFLAGS --cross-cc-ARCH=CC use compiler when building ARCH guest test cases --cross-cc-flags-ARCH= use compiler flags when building ARCH guest tests --make=MAKE use specified make [make] --install=INSTALL use specified install [install] --python=PYTHON use specified python [python] --smbd=SMBD use specified smbd [/usr/sbin/smbd] --with-git=GIT use specified git [git] --static enable static build [no] --mandir=PATH install man pages in PATH --datadir=PATH install firmware in PATH/qemu --docdir=PATH install documentation in PATH/qemu --bindir=PATH install binaries in PATH --libdir=PATH install libraries in PATH --libexecdir=PATH install helper binaries in PATH --sysconfdir=PATH install config in PATH/qemu --localstatedir=PATH install local state in PATH (set at runtime on win32) --firmwarepath=PATH search PATH for firmware files --with-confsuffix=SUFFIX suffix for QEMU data inside datadir/libdir/sysconfdir [/qemu] --with-pkgversion=VERS use specified string as sub-version of the package --enable-debug enable common debug build options --enable-sanitizers enable default sanitizers --disable-strip disable stripping binaries --disable-werror disable compilation abort on warning --disable-stack-protector disable compiler-provided stack protection --audio-drv-list=LIST set audio drivers list: Available drivers: oss alsa sdl pa --block-drv-whitelist=L Same as --block-drv-rw-whitelist=L --block-drv-rw-whitelist=L set block driver read-write whitelist (affects only QEMU, not qemu-img) --block-drv-ro-whitelist=L set block driver read-only whitelist (affects only QEMU, not qemu-img) --enable-trace-backends=B Set trace backend Available backends: dtrace ftrace log simple syslog ust --with-trace-file=NAME Full PATH,NAME of file to store traces Default:trace- --disable-slirp disable SLIRP userspace network connectivity --enable-tcg-interpreter enable TCG with bytecode interpreter (TCI) --enable-malloc-trim enable libc malloc_trim() for memory optimization --oss-lib path to OSS library --cpu=CPU Build for host CPU [x86_64] --with-coroutine=BACKEND coroutine backend. Supported options: ucontext, sigaltstack, windows --enable-gcov enable test coverage analysis with gcov --gcov=GCOV use specified gcov [gcov] --disable-blobs disable installing provided firmware blobs --with-vss-sdk=SDK-path enable Windows VSS support in QEMU Guest Agent --with-win-sdk=SDK-path path to Windows Platform SDK (to build VSS .tlb) --tls-priority default TLS protocol/cipher priority string --enable-gprof QEMU profiling with gprof --enable-profiler profiler support --enable-debug-stack-usage track the maximum stack usage of stacks created by qemu_alloc_stack Optional features, enabled with --enable-FEATURE and disabled with --disable-FEATURE, default is enabled if available: system all system emulation targets user supported user emulation targets linux-user all linux usermode emulation targets bsd-user all BSD usermode emulation targets docs build documentation guest-agent build the QEMU Guest Agent guest-agent-msi build guest agent Windows MSI installation package pie Position Independent Executables modules modules support debug-tcg TCG debugging (default is disabled) debug-info debugging information sparse sparse checker gnutls GNUTLS cryptography support nettle nettle cryptography support gcrypt libgcrypt cryptography support auth-pam PAM access control sdl SDL UI sdl_image SDL Image support for icons gtk gtk UI vte vte support for the gtk UI curses curses UI iconv font glyph conversion support vnc VNC UI support vnc-sasl SASL encryption for VNC server vnc-jpeg JPEG lossy compression for VNC server vnc-png PNG compression for VNC server cocoa Cocoa UI (Mac OS X only) virtfs VirtFS mpath Multipath persistent reservation passthrough xen xen backend driver support xen-pci-passthrough PCI passthrough support for Xen brlapi BrlAPI (Braile) curl curl connectivity membarrier membarrier system call (for Linux 4.14+ or Windows) fdt fdt device tree bluez bluez stack connectivity kvm KVM acceleration support hax HAX acceleration support hvf Hypervisor.framework acceleration support whpx Windows Hypervisor Platform acceleration support rdma Enable RDMA-based migration pvrdma Enable PVRDMA support vde support for vde network netmap support for netmap network linux-aio Linux AIO support cap-ng libcap-ng support attr attr and xattr support vhost-net vhost-net kernel acceleration support vhost-vsock virtio sockets device support vhost-scsi vhost-scsi kernel target support vhost-crypto vhost-user-crypto backend support vhost-kernel vhost kernel backend support vhost-user vhost-user backend support spice spice rbd rados block device (rbd) libiscsi iscsi support libnfs nfs support smartcard smartcard support (libcacard) libusb libusb (for usb passthrough) live-block-migration Block migration in the main migration stream usb-redir usb network redirection support lzo support of lzo compression library snappy support of snappy compression library bzip2 support of bzip2 compression library (for reading bzip2-compressed dmg images) lzfse support of lzfse compression library (for reading lzfse-compressed dmg images) seccomp seccomp support coroutine-pool coroutine freelist (better performance) glusterfs GlusterFS backend tpm TPM support libssh2 ssh block device support numa libnuma support libxml2 for Parallels image format tcmalloc tcmalloc support jemalloc jemalloc support avx2 AVX2 optimization support replication replication support opengl opengl support virglrenderer virgl rendering support xfsctl xfsctl support qom-cast-debug cast debugging support tools build qemu-io, qemu-nbd and qemu-img tools vxhs Veritas HyperScale vDisk backend support bochs bochs image format support cloop cloop image format support dmg dmg image format support qcow1 qcow v1 image format support vdi vdi image format support vvfat vvfat image format support qed qed image format support parallels parallels image format support sheepdog sheepdog block driver support crypto-afalg Linux AF_ALG crypto backend driver capstone capstone disassembler support debug-mutex mutex debugging support libpmem libpmem support NOTE: The object files are built at the place where configure is launched 根据实际需求启用或禁用相关配置项，配置命令如下： ./configure --prefix=/usr \\ --enable-kvm \\ --enable-libusb \\ --enable-usb-redir \\ --enable-debug \\ --enable-debug-info \\ --enable-curl \\ --enable-sdl \\ --enable-vhost-net \\ --enable-spice \\ --enable-vnc \\ --enable-opengl \\ --enable-gtk \\ --target-list=x86_64-softmmu 可能需要根据提示信息安装相应的依赖包，参见 3.3.1 Build Qemu for KVMGT | gvt-linux CentOS 7 的 yum 包： yum install SDL2-devel libcurl-devel Ubuntu 18.04 的 apt 包： apt-get install libsdl2-dev libcurl4-openssl-dev libusbredirhost-dev 若相关依赖均已安装，则可成功配置，终端输出如下所示： Install prefix /usr BIOS directory /usr/share/qemu firmware path /usr/share/qemu-firmware binary directory /usr/bin library directory /usr/lib module directory /usr/lib/qemu libexec directory /usr/libexec include directory /usr/include config directory /usr/etc local state directory /usr/var Manual directory /usr/share/man ELF interp prefix /usr/gnemul/qemu-%M Source path /kvm/qemu_src/qemu-4.0.50 GIT binary git GIT submodules ui/keycodemapdb tests/fp/berkeley-testfloat-3 tests/fp/berkeley-softfloat-3 dtc capstone C compiler cc Host C compiler cc C++ compiler c++ Objective-C compiler cc ARFLAGS rv CFLAGS -g QEMU_CFLAGS -I/usr/include/pixman-1 -I$(SRC_PATH)/dtc/libfdt -Werror -pthread -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -fPIE -DPIE -m64 -mcx16 -D_GNU_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -Wstrict-prototypes -Wredundant-decls -Wall -Wundef -Wwrite-strings -Wmissing-prototypes -fno-strict-aliasing -fno-common -fwrapv -std=gnu99 -Wexpansion-to-defined -Wendif-labels -Wno-shift-negative-value -Wno-missing-include-dirs -Wempty-body -Wnested-externs -Wformat-security -Wformat-y2k -Winit-self -Wignored-qualifiers -Wold-style-declaration -Wold-style-definition -Wtype-limits -fstack-protector-strong -I/usr/include/libpng16 -I/usr/include/spice-server -I/usr/include/spice-1 -I$(SRC_PATH)/capstone/include LDFLAGS -Wl,--warn-common -Wl,-z,relro -Wl,-z,now -pie -m64 -g QEMU_LDFLAGS -L$(BUILD_DIR)/dtc/libfdt make make install install python python -B (2.7.15rc1) slirp support internal smbd /usr/sbin/smbd module support no host CPU x86_64 host big endian no target list x86_64-softmmu gprof enabled no sparse enabled no strip binaries no profiler no static build no SDL support yes (2.0.8) SDL image support no GTK support yes (3.22.30) GTK GL support yes VTE support no TLS priority NORMAL GNUTLS support no libgcrypt no nettle no libtasn1 no PAM no iconv support yes curses support no virgl support no curl support yes mingw32 support no Audio drivers pa oss Block whitelist (rw) Block whitelist (ro) VirtFS support no Multipath support no VNC support yes VNC SASL support no VNC JPEG support no VNC PNG support yes xen support no brlapi support no bluez support no Documentation no PIE yes vde support no netmap support no Linux AIO support yes ATTR/XATTR support yes Install blobs yes KVM support yes HAX support no HVF support no WHPX support no TCG support yes TCG debug enabled yes TCG interpreter no malloc trim support yes RDMA support no PVRDMA support no fdt support git membarrier no preadv support yes fdatasync yes madvise yes posix_madvise yes posix_memalign yes libcap-ng support no vhost-net support yes vhost-crypto support yes vhost-scsi support yes vhost-vsock support yes vhost-user support yes Trace backends log spice support yes (0.12.13/0.14.0) rbd support no xfsctl support no smartcard support no libusb yes usb net redir yes OpenGL support yes OpenGL dmabufs yes libiscsi support no libnfs support no build guest agent yes QGA VSS support no QGA w32 disk info no QGA MSI support no seccomp support no coroutine backend ucontext coroutine pool yes debug stack usage no mutex debugging yes crypto afalg no GlusterFS support no gcov gcov gcov enabled no TPM support yes libssh2 support no TPM passthrough TPM emulator QOM debugging yes Live block migration yes lzo support no snappy support no bzip2 support no lzfse support no NUMA host support no libxml2 yes tcmalloc support no jemalloc support no avx2 optimization yes replication support yes VxHS block device no bochs support yes cloop support yes dmg support yes qcow v1 support yes vdi support yes vvfat support yes qed support yes parallels support yes sheepdog support yes capstone git docker yes libpmem support no libudev yes default devices yes NOTE: cross-compilers enabled: &#39;cc&#39; 在配置完以后，当前目录qemu-4.0.50下会生成config-host.mak和config.status文件： config-host.mak：可查看上述./configure之后的配置结果，会在后续make中被引用 config.status：便于后续要重新configure时，只要执行./config.status，就可以恢复上一次的配置 编译 QEMU经过配置之后，编译就很简单了，直接执行make命令： qemu-4.0.50 &gt; make -j 16 qemu-4.0.50 &gt; cd x86_64-softmmu x86_64-softmmu &gt; ls accel config-devices.mak cpus.d dump.o gdbstub.o hmp-commands-info.h memory.d monitor.d qemu-system-x86_64 trace arch_init.d config-devices.mak.old cpus.o exec.d gdbstub-xml.c hw memory_mapping.d monitor.o qtest.d win_dump.d arch_init.o config-target.h disas.d exec.o gdbstub-xml.d ioport.d memory_mapping.o numa.d qtest.o win_dump.o balloon.d config-target.h-timestamp disas.o fpu gdbstub-xml.o ioport.o memory.o numa.o target balloon.o config-target.mak dump.d gdbstub.d hmp-commands.h Makefile migration qapi tcg x86_64-softmmu &gt; ./qemu-system-x86_64 --version QEMU emulator version 4.0.50 (v4.0.0-142-ge0fb2c3d89-dirty) Copyright (c) 2003-2019 Fabrice Bellard and the QEMU Project developers 为了支持KVMGT，还需单独编译seabios，之后会在out目录下生成bios.bin文件： qemu-4.0.50 > cd roms/seabios seabios > make -j 16 seabios > ls ./out asm-offsets.h bios.bin.prep ccode16.o.tmp.c code16.o code32seg.d include rom32seg.strip.o romlayout.d scripts vgasrc autoconf.h bios.bin.raw ccode32flat.d code16.o.objdump code32seg.o rom16.o romlayout16.lds romlayout.o src autoversion.h ccode16.d ccode32flat.o code32flat.o code32seg.o.objdump rom16.strip.o romlayout32flat.lds rom.o version.d bios.bin ccode16.o ccode32flat.o.tmp.c code32flat.o.objdump code32seg.o.tmp.c rom32seg.o romlayout32seg.lds rom.o.objdump version.o 4.3 安装 QEMU编译完成后，运行make install命令即可安装 QEMU： qemu-4.0.50 &gt; make install qemu-4.0.50 &gt; ls /usr/share/qemu acpi-dsdt.aml edk2-x86_64-code.fd init ppc_rom.bin qemu-icon.bmp trace-events bamboo.dtb edk2-x86_64-secure-code.fd keymaps pvh.bin qemu_logo_no_text.svg trace-events-all bios-256k.bin efi-e1000e.rom kvmvapic.bin pxe-e1000.rom QEMU,tcx.bin u-boot.e500 bios.bin efi-e1000.rom linuxboot.bin pxe-eepro100.rom QEMU,VGA.bin u-boot-sam460-20100605.bin canyonlands.dtb efi-eepro100.rom linuxboot_dma.bin pxe-ne2k_isa.rom qemu_vga.ndrv vgabios.bin edk2-aarch64-code.fd efi-ne2k_pci.rom multiboot.bin pxe-ne2k_pci.rom s390-ccw.img vgabios-bochs-display.bin edk2-arm-code.fd efi-pcnet.rom openbios-ppc pxe-pcnet32.rom s390-netboot.img vgabios-cirrus.bin edk2-arm-vars.fd efi-rtl8139.rom openbios-sparc32 pxe-pcnet.rom s390-zipl.rom vgabios-qxl.bin edk2-i386-code.fd efi-virtio.rom openbios-sparc64 pxe-rtl8139.rom sgabios.bin vgabios-ramfb.bin edk2-i386-secure-code.fd efi-vmxnet3.rom palcode-clipper pxe-virtio.rom skiboot.lid vgabios-stdvga.bin edk2-i386-vars.fd firmware petalogix-ml605.dtb q35-acpi-dsdt.aml slof.bin vgabios-virtio.bin edk2-licenses.txt hppa-firmware.img petalogix-s3adsp1800.dtb QEMU,cgthree.bin spapr-rtas.bin vgabios-vmware.bin qemu-4.0.50 &gt; ls /usr/share/qemu/firmware 50-edk2-i386-secure.json 50-edk2-x86_64-secure.json 60-edk2-aarch64.json 60-edk2-arm.json 60-edk2-i386.json 60-edk2-x86_64.json qemu-4.0.50 &gt; ls /usr/share/qemu/keymaps ar common da de-ch en-us et fo fr-be fr-ch hu it lt mk nl no pt ru sv tr bepo cz de en-gb es fi fr fr-ca hr is ja lv modifiers nl-be pl pt-br sl th 另外还需将编译后的bios.bin拷贝至/usr/bin目录： qemu-4.0.50 &gt; cp roms/seabios/out/bios.bin /usr/bin/bios.bin QEMU 的安装过程主要有以下几个任务： 创建 QEMU 的一些目录 复制一些配置文件到相应的目录下 复制一些固件文件（如sgabios.bin、kvmvapic.bin）到目录下，以便 QEMU 命令行启动时可以找到对应的固件供客户机使用 复制keymaps到相应的目录下，以便在客户机中支持各种所需的键盘类型 复制qemu-system-x86_64、qemu-img等可执行程序到对应的目录下 &gt; ls /usr/share/qemu acpi-dsdt.aml edk2-x86_64-code.fd init ppc_rom.bin qemu-icon.bmp trace-events bamboo.dtb edk2-x86_64-secure-code.fd keymaps pvh.bin qemu_logo_no_text.svg trace-events-all bios-256k.bin efi-e1000e.rom kvmvapic.bin pxe-e1000.rom QEMU,tcx.bin u-boot.e500 bios.bin efi-e1000.rom linuxboot.bin pxe-eepro100.rom QEMU,VGA.bin u-boot-sam460-20100605.bin canyonlands.dtb efi-eepro100.rom linuxboot_dma.bin pxe-ne2k_isa.rom qemu_vga.ndrv vgabios.bin edk2-aarch64-code.fd efi-ne2k_pci.rom multiboot.bin pxe-ne2k_pci.rom s390-ccw.img vgabios-bochs-display.bin edk2-arm-code.fd efi-pcnet.rom openbios-ppc pxe-pcnet32.rom s390-netboot.img vgabios-cirrus.bin edk2-arm-vars.fd efi-rtl8139.rom openbios-sparc32 pxe-pcnet.rom s390-zipl.rom vgabios-qxl.bin edk2-i386-code.fd efi-virtio.rom openbios-sparc64 pxe-rtl8139.rom sgabios.bin vgabios-ramfb.bin edk2-i386-secure-code.fd efi-vmxnet3.rom palcode-clipper pxe-virtio.rom skiboot.lid vgabios-stdvga.bin edk2-i386-vars.fd firmware petalogix-ml605.dtb q35-acpi-dsdt.aml slof.bin vgabios-virtio.bin edk2-licenses.txt hppa-firmware.img petalogix-s3adsp1800.dtb QEMU,cgthree.bin spapr-rtas.bin vgabios-vmware.bin &gt; ls /usr/share/qemu/keymaps ar common da de-ch en-us et fo fr-be fr-ch hu it lt mk nl no pt ru sv tr bepo cz de en-gb es fi fr fr-ca hr is ja lv modifiers nl-be pl pt-br sl th 由于 QEMU 是用户空间的程序，所以安装之后不需要重启系统，直接使用qemu-system-x86_64、qemu-img这样的命令行工具就可以了 5. 安装客户机安装客户机前，需要先创建一个镜像文件来存储客户机中的系统和文件: &gt; qemu-img create -f raw fedora30.raw 20G # 指定为 raw 格式 Formatting &#39;fedora30.raw&#39;, fmt=raw size=21474836480 &gt; qemu-img info fedora30.raw image: fedora30.raw file format: raw virtual size: 20G (21474836480 bytes) disk size: 0 可以看到目前fedora30.raw并不占用任何磁盘空间，这是因为qemu-img默认的方式是按需分配，镜像文件的大小会随着实际的使用而增大。 可在qemu-img命令中添加-o preallocation=full选项，使得镜像在创建时分配全部的空间，不过这样的话格式化过程就会比较耗时： &gt; qemu-img create -f raw fedora30-full.raw 10G -o preallocation=full Formatting &#39;fedora30-full.raw&#39;, fmt=raw size=10737418240 preallocation=&#39;full&#39; &gt; qemu-img info fedora30-full.raw image: fedora30-full.raw file format: raw virtual size: 10G (10737418240 bytes) disk size: 10G 最后即可使用以下命令启动 KVM 客户机，并安装系统： &gt; qemu-system-x86_64 -accel kvm \\ -m 2G -smp 2 -boot once=d \\ -cdrom /kvm/iso/Fedora-Server-dvd-x86_64-30-1.2.iso \\ -drive file=/kvm/image/fedora30.raw,format=raw 参考文章 《KVM实战：原理、进阶与性能调优》 KVM QEMU kvm.git | Kernel.org GVTg_Setup_Guide | gvt-linux 虚拟化文档 | Coding-Notes 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述迁移 VMware 虚拟机到 KVM微星B350M 虚拟化开启 AMD-V","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"},{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/tags/云计算/"}]},{"title":"CentOS 7 安装配置 oh-my-zsh","slug":"centos7-install-ohmyzsh","date":"2019-04-11T09:05:05.000Z","updated":"2019-09-01T13:04:11.017Z","comments":true,"path":"2019/04/11/centos7-install-ohmyzsh/","link":"","permalink":"https://abelsu7.top/2019/04/11/centos7-install-ohmyzsh/","excerpt":"Your terminal never felt this good before.","text":"Your terminal never felt this good before. 1. 查看已有终端&gt; cat /etc/shells /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh /usr/bin/tmux &gt; chsh -l /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh /usr/bin/tmux &gt; echo $SHELL /bin/bash 可以看到 CentOS 7 的默认终端是/bin/bash。 2. 安装 zsh&gt; yum info zsh Available Packages Name : zsh Arch : x86_64 Version : 5.0.2 Release : 31.el7 Size : 2.4 M Repo : base/7/x86_64 Summary : Powerful interactive shell URL : http://zsh.sourceforge.net/ License : MIT Description : The zsh shell is a command interpreter usable as an interactive : login shell and as a shell script command processor. Zsh resembles : the ksh shell (the Korn shell), but includes many enhancements. : Zsh supports command line editing, built-in spelling correction, : programmable command completion, shell functions (with : autoloading), a history mechanism, and more. &gt; yum install -y zsh &gt; cat /etc/shells /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh /usr/bin/tmux /bin/zsh 3. 切换默认 Shell 为 zsh 请在root用户下切换 Shell &gt; chsh -s /bin/zsh Changing shell for root. Shell changed. 提示终端切换完成，但还需重启方能生效。之后继续安装oh-my-zsh。 4. 安装 oh-my-zshVia curlsh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; Via wgetsh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 提示oh-my-zsh安装成功： __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \\/ __ \\ / __ `__ \\/ / / / /_ / / ___/ __ \\ / /_/ / / / / / / / / / / /_/ / / /_(__ ) / / / \\____/_/ /_/ /_/ /_/ /_/\\__, / /___/____/_/ /_/ /____/ ....is now installed! Please look over the ~/.zshrc file to select plugins, themes, and options. p.s. Follow us at https://twitter.com/ohmyzsh. p.p.s. Get stickers, shirts, and coffee mugs at https://shop.planetargon.com/collections/oh-my-zsh. 5. 修改主题及配置oh-my-zsh 的默认主题是robbyrussell，可以在~/.zshrc中修改ZSH_THEME主题字段，主题清单参见 Themes | oh-my-zsh。 # Set name of the theme to load --- if set to &quot;random&quot;, it will # load a random theme each time oh-my-zsh is loaded, in which case, # to know which specific one was loaded, run: echo $RANDOM_THEME # See https://github.com/robbyrussell/oh-my-zsh/wiki/Themes ZSH_THEME=&quot;agnoster&quot; 另外还可以在~/.zshrc中设置PATH路径或添加alias命令别名，使用方法与~/.bashrc相同： &gt; vim ~/.zshrc # If you come from bash you might have to change your $PATH. # export PATH=$HOME/bin:/usr/local/bin:$PATH export GOLANDPATH=$HOME/GoLand-2018.3.5/ export GOPATH=$HOME/go export PATH=&quot;$PATH:$GOPATH/bin:$GOLANDPATH:bin&quot; # Path to your oh-my-zsh installation. export ZSH=&quot;/root/.oh-my-zsh&quot; # Set name of the theme to load --- if set to &quot;random&quot;, it will # load a random theme each time oh-my-zsh is loaded, in which case, ZSH_THEME=&quot;agnoster&quot; ... ... # Set list of themes to pick from when loading at random # If set to an empty array, this variable will have no effect. # ZSH_THEME_RANDOM_CANDIDATES=( &quot;robbyrussell&quot; &quot;agnoster&quot; ) # Set personal aliases, overriding those provided by oh-my-zsh libs, # plugins, and themes. Aliases can be placed here, though oh-my-zsh # users are encouraged to define aliases within the ZSH_CUSTOM folder. # For a full list of active aliases, run `alias`. # # Example aliases # alias zshconfig=&quot;mate ~/.zshrc&quot; # alias ohmyzsh=&quot;mate ~/.oh-my-zsh&quot; alias rm=&#39;rm -i&#39; alias cp=&#39;cp -i&#39; alias mv=&#39;mv -i&#39; alias vi=&#39;vim&#39; alias pc=&#39;proxychains4&#39; 保存之后更新配置： source ~/.zshrc 例如下图所示即为agnoster-zsh-theme主题效果： agnoster-zsh-theme 注意：在 CentOS 7 下使用agnoster主题，部分符号在终端无法正常显示，还需安装 Powerline fonts 字体： # clone git clone https://github.com/powerline/fonts.git --depth=1 # install cd fonts ./install.sh # clean-up a bit cd .. rm -rf fonts 之后在终端输入以下命令测试Powerline font字体是否成功安装： echo &quot;\\ue0b0 \\u00b1 \\ue0a0 \\u27a6 \\u2718 \\u26a1 \\u2699&quot; 字体安装成功后符号可正常显示 6. zsh 小技巧输入d命令，即可查看在这个终端会话中访问过的目录，输入目录对应的序号即可跳转： ~ &gt; d 0 ~ 1 ~/.oh-my-zsh/plugins/git 2 /opt/google 3 ~/.oh-my-zsh 4 ~/.oh-my-zsh/plugins 5 ~/GolandProjects/go-rest-api-server 6 ~/GolandProjects ~ &gt; 6 ~/GolandProjects ~/GolandProjects &gt; 另外还可以忽略cd命令，输入..、...或目录名都可以跳转。 参考文章 oh my zsh oh-my-zsh | Github Themes - oh-my-zsh | Github oh-my-zsh,让你的终端从未这么爽过 | 简书 CentOS 7 安装 zsh 配置 oh-my-zsh | 简书 oh-my-zsh配置你的zsh提高shell逼格终极选择 | 一介布衣 使用 oh-my-zsh 的 agnoster theme | Medium.com 强大的终端工具ohMyZsh | 技术特工队 agnoster.zsh-theme | Github Powerline fonts | Github 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色zsh安装配置zsh安装配置","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"zsh","slug":"zsh","permalink":"https://abelsu7.top/tags/zsh/"}]},{"title":"腾讯暑期实习常规批笔试 Golang 题解","slug":"tencent-2019-spring-test","date":"2019-04-06T09:33:47.000Z","updated":"2019-09-01T13:04:11.697Z","comments":true,"path":"2019/04/06/tencent-2019-spring-test/","link":"","permalink":"https://abelsu7.top/2019/04/06/tencent-2019-spring-test/","excerpt":"云计算开发，2019.4.5","text":"云计算开发，2019.4.5 1. 0/1 Stringpackage main import ( &quot;fmt&quot; &quot;strings&quot; ) func main() { var n int var s string fmt.Scanln(&amp;n) fmt.Scanln(&amp;s) bitsOf1 := strings.Count(s, &quot;1&quot;) bitsOf0 := n - bitsOf1 if bitsOf1 &gt;= bitsOf0 { fmt.Println(bitsOf1 - bitsOf0) } else { fmt.Println(bitsOf0 - bitsOf1) } } ------ 10 1001000101 2 Process finished with exit code 0 2. 零钱组合package main import ( &quot;fmt&quot; &quot;sort&quot; ) func main() { var m, n int fmt.Scanf(&quot;%d %d&quot;, &amp;m, &amp;n) coinValues := make([]int, n) for i := 0; i &lt; n; i++ { fmt.Scanln(&amp;coinValues[i]) } sort.Slice(coinValues, func(i, j int) bool { return coinValues[i] &gt; coinValues[j] }) fmt.Println(minCoins(m, n, coinValues)) } func minCoins(target, n int, coinValues []int) int { if coinValues[n-1] != 1 { // 若没有 1 元硬币，则此题无解 return -1 } coinNum := 0 // 当前硬币总数 maxValue := 0 // 当前硬币总金额 coinNums := make([]int, target+1) // 记录每个硬币的数量 coinNums[0] = 0 for i := 1; i &lt;= target; i++ { if i &gt; maxValue { // 目标金额比 maxValue 大 for _, coinValue := range coinValues { if i &gt;= coinValue { // 取可凑成该金额的最大硬币 coinNum++ maxValue += coinValue break } } coinNums[i] = coinNum } else { coinNums[i] = coinNums[i-1] } } return coinNums[target] } ------ 20 4 1 5 2 10 5 Process finished with exit code 0 3. 怪兽过关package main import &quot;fmt&quot; func main() { var n int // 怪兽数量 fmt.Scanln(&amp;n) boss := make([]int, n) coins := make([]int, n) for i := 0; i &lt; n; i++ { fmt.Scan(&amp;boss[i]) } for i := 0; i &lt; n; i++ { fmt.Scan(&amp;coins[i]) } curValue := boss[0] curCoins := coins[0] fmt.Println(challenge(boss, coins, 1, n, curValue, curCoins)) } func challenge(boss []int, coins []int, curIndex, n int, curValue, curCoins int) int { if curIndex == n { return curCoins } if boss[curIndex] &gt; curValue { return challenge(boss, coins, curIndex+1, n, curValue+boss[curIndex], curCoins+coins[curIndex]) } else { return min(challenge(boss, coins, curIndex+1, n, curValue, curCoins), challenge(boss, coins, curIndex+1, n, curValue+boss[curIndex], curCoins+coins[curIndex])) } } func min(a, b int) int { if a &lt; b { return a } else { return b } } ------ 5 8 1 1 10 13 2 1 1 3 4 5 Process finished with exit code 0 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"腾讯","slug":"腾讯","permalink":"https://abelsu7.top/tags/腾讯/"}]},{"title":"Leetcode 题解 in Golang（不定期更新）","slug":"leetcode-solution-golang","date":"2019-04-02T09:30:44.000Z","updated":"2019-10-15T09:55:45.940Z","comments":true,"path":"2019/04/02/leetcode-solution-golang/","link":"","permalink":"https://abelsu7.top/2019/04/02/leetcode-solution-golang/","excerpt":"Leetcode、牛客刷题之旅，不定期更新中","text":"Leetcode、牛客刷题之旅，不定期更新中 目录 目录 剑指 Offer 1. 二维数组中的查找 2. 数组中重复的数字 3. 构建乘积数组 4. 替换空格 22. 斐波那契数列 26. 二进制中 1 的个数 28. 调整数组顺序使奇数位于偶数前面 Leetcode 179. 最大数 赛码 分数序列和 - 百度 SQL 175. 组合两个表 参考文章 剑指 Offer1. 二维数组中的查找 原题传送门👉二维数组中的查找 | 牛客 func find(target int, array [][]int) bool { if array == nil || len(array) == 0 || len(array[0]) == 0 { return false } rows := len(array) cols := len(array[0]) // 从右上角开始 curRow := 0 curCol := cols - 1 for curRow &lt;= rows-1 &amp;&amp; curCol &gt;= 0 { switch { case target == array[curRow][curCol]: return true case target &lt; array[curRow][curCol]: curCol-- case target &gt; array[curRow][curCol]: curRow++ default: break } } return false } 2. 数组中重复的数字 原题传送门👉数组中重复的数字 | 牛客 // Parameters: // numbers: an array of integers // length: the length of array numbers // duplication: (Output) the duplicated number in the array number,length of duplication array is 1,so using duplication[0] = ? in implementation; // Here duplication like pointor in C/C++, duplication[0] equal *duplication in C/C++ // 这里要特别注意~返回任意重复的一个，赋值duplication[0] // Return value: true if the input is valid, and there are some duplications in the array number // otherwise false func duplicate(numbers []int, length int, duplication []int) bool { if numbers == nil || length &lt;= 0 { return false } for i := 0; i &lt; length; i++ { for numbers[i] != i { if numbers[i] == numbers[numbers[i]] { duplication[0] = numbers[i] return true } numbers[i], numbers[numbers[i]] = numbers[numbers[i]], numbers[i] } } return false } 3. 构建乘积数组 原题传送门👉构建乘积数组 | 牛客 func multiply(A []int) []int { if A == nil || len(A) == 0 { return []int{} } n := len(A) B := make([]int, n) B[0] = 1 for i := 1; i &lt; n; i++ { // 计算下三角连乘 B[i] = B[i-1] * A[i-1] } product := 1 for j := n - 2; j &gt;= 0; j-- { // 计算上三角连乘 product *= A[j+1] B[j] *= product } return B } 4. 替换空格 原题传送门👉替换空格 | 牛客 func replaceSpace(str string) string { return strings.Replace(str, &quot; &quot;, &quot;%20&quot;, -1) } 22. 斐波那契数列 原题传送门👉斐波那契数列 | 牛客 func Fibonacci(n int) int { if n == 0 || n == 1 { return n } fn1, fn2, cur := 0, 1, 0 for i := 2; i &lt;= n; i++ { cur = fn1 + fn2 fn1, fn2 = fn2, cur } return cur } 26. 二进制中 1 的个数 原题传送门👉二进制中 1 的个数 | 牛客 func numberOf1(n int) int { num := 0 for n != 0 { num++ n &amp;= n - 1 } return num } 28. 调整数组顺序使奇数位于偶数前面 原题传送门👉调整数组顺序使奇数位于偶数前面 | 牛客 func reOrderArray(nums []int) { oddNum := 0 for _, val := range nums { if val&amp;0x1 == 1 { oddNum++ } } copyNums := make([]int, len(nums)) copy(copyNums, nums) i, j := 0, oddNum for _, val := range copyNums { if val&amp;0x1 == 1 { nums[i] = val i++ } else { nums[j] = val j++ } } } Leetcode179. 最大数 原题传送门👉179. 最大数 | Leetcode 题目描述给定一组非负整数，重新排列它们的顺序使之组成一个最大的整数。 测试用例 输出结果可能非常大，所以你需要返回一个字符串而不是整数 输入: [10, 2] 输出: 210 输入: [3, 30, 34, 5, 9] 输出: 9534330 Golang 题解 需要注意输入全为0的特殊情况 func largestNumber(nums []int) string { length := len(nums) if length &lt; 1 { return &quot;0&quot; } strs := make([]string, length) for i := 0; i &lt; length; i++ { strs[i] = strconv.Itoa(nums[i]) } sort.Slice(strs, func(i, j int) bool { return (strs[i] + strs[j]) &gt; (strs[j] + strs[i]) }) numsStr := strings.Join(strs, &quot;&quot;) numsStr = strings.TrimLeft(numsStr, &quot;0&quot;) if numsStr == &quot;&quot; { return &quot;0&quot; } return numsStr } 本地测试package main import ( &quot;fmt&quot; &quot;sort&quot; &quot;strconv&quot; &quot;strings&quot; ) func main() { strings1 := []int{3, 30, 34, 5, 9} strings2 := []int{10, 2} strings3 := []int{0, 0, 0, 0} strings4 := make([]int, 10) fmt.Println(largestNumber(strings1)) fmt.Println(largestNumber(strings2)) fmt.Println(largestNumber(strings3)) fmt.Println(largestNumber(strings4)) } func largestNumber(nums []int) string { length := len(nums) if length &lt; 1 { return &quot;0&quot; } strs := make([]string, length) for i := 0; i &lt; length; i++ { strs[i] = strconv.Itoa(nums[i]) } sort.Slice(strs, func(i, j int) bool { return (strs[i] + strs[j]) &gt; (strs[j] + strs[i]) }) numsStr := strings.Join(strs, &quot;&quot;) numsStr = strings.TrimLeft(numsStr, &quot;0&quot;) if numsStr == &quot;&quot; { return &quot;0&quot; } return numsStr } ------ 9534330 210 0 0 Process finished with exit code 0 引申一下上面的解法是在 Leetcode 评论区看到的，比较好奇sort.Slice是用什么算法对切片进行排序。翻了一下sort/slice.go的源码，如下所示： // Copyright 2017 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // +build !compiler_bootstrap go1.8 package sort import &quot;reflect&quot; // Slice sorts the provided slice given the provided less function. // // The sort is not guaranteed to be stable. For a stable sort, use // SliceStable. // // The function panics if the provided interface is not a slice. func Slice(slice interface{}, less func(i, j int) bool) { rv := reflect.ValueOf(slice) swap := reflect.Swapper(slice) length := rv.Len() quickSort_func(lessSwap{less, swap}, 0, length, maxDepth(length)) } // SliceStable sorts the provided slice given the provided less // function while keeping the original order of equal elements. // // The function panics if the provided interface is not a slice. func SliceStable(slice interface{}, less func(i, j int) bool) { rv := reflect.ValueOf(slice) swap := reflect.Swapper(slice) stable_func(lessSwap{less, swap}, rv.Len()) } // SliceIsSorted tests whether a slice is sorted. // // The function panics if the provided interface is not a slice. func SliceIsSorted(slice interface{}, less func(i, j int) bool) bool { rv := reflect.ValueOf(slice) n := rv.Len() for i := n - 1; i &gt; 0; i-- { if less(i, i-1) { return false } } return true } 可以看到默认的sort.Slice()方法是用快排对切片进行排序的。 我们知道，快排是不稳定的，所以如果希望使用稳定排序算法对切片进行排序，则可以使用SliceStable()方法。 而SliceStable()所使用的stable_func()定义在sort/zfuncversion.go中，而实际上该函数在sort/sort.go中定义： func stable(data Interface, n int) { blockSize := 20 // must be &gt; 0 a, b := 0, blockSize for b &lt;= n { insertionSort(data, a, b) a = b b += blockSize } insertionSort(data, a, n) for blockSize &lt; n { a, b = 0, 2*blockSize for b &lt;= n { symMerge(data, a, a+blockSize, b) a = b b += 2 * blockSize } if m := a + blockSize; m &lt; n { symMerge(data, a, m, n) } blockSize *= 2 } } 可以看到SliceStable()中定义了变量blocksize := 20，用来控制插入排序的区间大小。当待排序的切片长度&lt;=20时，相当于直接对该切片进行插入排序： // Insertion sort func insertionSort(data Interface, a, b int) { for i := a + 1; i &lt; b; i++ { for j := i; j &gt; a &amp;&amp; data.Less(j, j-1); j-- { data.Swap(j, j-1) } } } 而当b &lt;= n即切片长度超过20时，SliceStable()会先调用insertionSort_func()，对切片按照blockSize分段进行插入排序。之后，调用symMerge_func()，对每一段有序的切片元素进行归并排序，逐步翻倍blockSize大小直至归并排序完成： // SymMerge merges the two sorted subsequences data[a:m] and data[m:b] using // the SymMerge algorithm from Pok-Son Kim and Arne Kutzner, &quot;Stable Minimum // Storage Merging by Symmetric Comparisons&quot;, in Susanne Albers and Tomasz // Radzik, editors, Algorithms - ESA 2004, volume 3221 of Lecture Notes in // Computer Science, pages 714-723. Springer, 2004. // // Let M = m-a and N = b-n. Wolog M &lt; N. // The recursion depth is bound by ceil(log(N+M)). // The algorithm needs O(M*log(N/M + 1)) calls to data.Less. // The algorithm needs O((M+N)*log(M)) calls to data.Swap. // // The paper gives O((M+N)*log(M)) as the number of assignments assuming a // rotation algorithm which uses O(M+N+gcd(M+N)) assignments. The argumentation // in the paper carries through for Swap operations, especially as the block // swapping rotate uses only O(M+N) Swaps. // // symMerge assumes non-degenerate arguments: a &lt; m &amp;&amp; m &lt; b. // Having the caller check this condition eliminates many leaf recursion calls, // which improves performance. func symMerge(data Interface, a, m, b int) { // Avoid unnecessary recursions of symMerge // by direct insertion of data[a] into data[m:b] // if data[a:m] only contains one element. if m-a == 1 { // Use binary search to find the lowest index i // such that data[i] &gt;= data[a] for m &lt;= i &lt; b. // Exit the search loop with i == b in case no such index exists. i := m j := b for i &lt; j { h := int(uint(i+j) &gt;&gt; 1) if data.Less(h, a) { i = h + 1 } else { j = h } } // Swap values until data[a] reaches the position before i. for k := a; k &lt; i-1; k++ { data.Swap(k, k+1) } return } // Avoid unnecessary recursions of symMerge // by direct insertion of data[m] into data[a:m] // if data[m:b] only contains one element. if b-m == 1 { // Use binary search to find the lowest index i // such that data[i] &gt; data[m] for a &lt;= i &lt; m. // Exit the search loop with i == m in case no such index exists. i := a j := m for i &lt; j { h := int(uint(i+j) &gt;&gt; 1) if !data.Less(m, h) { i = h + 1 } else { j = h } } // Swap values until data[m] reaches the position i. for k := m; k &gt; i; k-- { data.Swap(k, k-1) } return } mid := int(uint(a+b) &gt;&gt; 1) n := mid + m var start, r int if m &gt; mid { start = n - b r = mid } else { start = a r = m } p := n - 1 for start &lt; r { c := int(uint(start+r) &gt;&gt; 1) if !data.Less(p-c, c) { start = c + 1 } else { r = c } } end := n - start if start &lt; m &amp;&amp; m &lt; end { rotate(data, start, m, end) } if a &lt; start &amp;&amp; start &lt; mid { symMerge(data, a, start, mid) } if mid &lt; end &amp;&amp; end &lt; b { symMerge(data, mid, end, b) } } // Rotate two consecutive blocks u = data[a:m] and v = data[m:b] in data: // Data of the form &#39;x u v y&#39; is changed to &#39;x v u y&#39;. // Rotate performs at most b-a many calls to data.Swap. // Rotate assumes non-degenerate arguments: a &lt; m &amp;&amp; m &lt; b. func rotate(data Interface, a, m, b int) { i := m - a j := b - m for i != j { if i &gt; j { swapRange(data, m-i, m, j) i -= j } else { swapRange(data, m-i, m+j-i, i) j -= i } } // i == j swapRange(data, m-i, m, i) } /* Complexity of Stable Sorting Complexity of block swapping rotation Each Swap puts one new element into its correct, final position. Elements which reach their final position are no longer moved. Thus block swapping rotation needs |u|+|v| calls to Swaps. This is best possible as each element might need a move. Pay attention when comparing to other optimal algorithms which typically count the number of assignments instead of swaps: E.g. the optimal algorithm of Dudzinski and Dydek for in-place rotations uses O(u + v + gcd(u,v)) assignments which is better than our O(3 * (u+v)) as gcd(u,v) &lt;= u. Stable sorting by SymMerge and BlockSwap rotations SymMerg complexity for same size input M = N: Calls to Less: O(M*log(N/M+1)) = O(N*log(2)) = O(N) Calls to Swap: O((M+N)*log(M)) = O(2*N*log(N)) = O(N*log(N)) (The following argument does not fuzz over a missing -1 or other stuff which does not impact the final result). Let n = data.Len(). Assume n = 2^k. Plain merge sort performs log(n) = k iterations. On iteration i the algorithm merges 2^(k-i) blocks, each of size 2^i. Thus iteration i of merge sort performs: Calls to Less O(2^(k-i) * 2^i) = O(2^k) = O(2^log(n)) = O(n) Calls to Swap O(2^(k-i) * 2^i * log(2^i)) = O(2^k * i) = O(n*i) In total k = log(n) iterations are performed; so in total: Calls to Less O(log(n) * n) Calls to Swap O(n + 2*n + 3*n + ... + (k-1)*n + k*n) = O((k/2) * k * n) = O(n * k^2) = O(n * log^2(n)) Above results should generalize to arbitrary n = 2^k + p and should not be influenced by the initial insertion sort phase: Insertion sort is O(n^2) on Swap and Less, thus O(bs^2) per block of size bs at n/bs blocks: O(bs*n) Swaps and Less during insertion sort. Merge sort iterations start at i = log(bs). With t = log(bs) constant: Calls to Less O((log(n)-t) * n + bs*n) = O(log(n)*n + (bs-t)*n) = O(n * log(n)) Calls to Swap O(n * log^2(n) - (t^2+t)/2*n) = O(n * log^2(n)) */ 另外，如果想判断一个切片是否已经有序，则可以使用SliceIsSorted()方法，返回一个bool值。 赛码 编程题考试须知 | 赛码 OJ 输入输出详细讲解 | 赛码 分数序列和 - 百度 原题传送门👉分数序列和（百度2017秋招真题）| 赛码 package main import ( &quot;fmt&quot; ) func main() { n := 0 // total number of test cases part := 0 // how many elements to calculate fmt.Scan(&amp;n) for i := 0; i &lt; n; i++ { fmt.Scan(&amp;part) fmt.Printf(&quot;%.4f&quot;, partSum(part)) } } func partSum(n int) float64 { sum := 0.0 for i := 1; i &lt;= n; i++ { sum += float64(fibonacci(i+1)) / float64(fibonacci(i)) } return sum } func fibonacci(n int) int { f1, f2 := 1, 2 var f3 int switch n { case 1: return f1 case 2: return f2 default: for i := 3; i &lt;= n; i++ { f3 = f1 + f2 f1, f2 = f2, f3 } return f3 } } SQL175. 组合两个表 原题传送门👉175. 组合两个表 | Leetcode-SQL 题目描述表 1：Person +-------------+---------+ | 列名 | 类型 | +-------------+---------+ | PersonId | int | | FirstName | varchar | | LastName | varchar | +-------------+---------+ PersonId 是上表主键 表 2：Address +-------------+---------+ | 列名 | 类型 | +-------------+---------+ | AddressId | int | | PersonId | int | | City | varchar | | State | varchar | +-------------+---------+ AddressId 是上表主键 编写一个 SQL 查询，满足条件：无论Person是否有地址信息，都需要基于上述两表提供Person的以下信息： FirstName, LastName, City, State SQL 题解 使用左外连接以及on过滤条件，参见 SQL中on条件与where条件的区别 | 博客园 SELECT p.FirstName AS FirstName, p.LastName AS LastName, a.City AS City, a.State AS State FROM Person p LEFT JOIN Address a ON p.PersonId = a.PersonId; 参考文章 halfrost/leetcode-go - LeetCode by Go | Github golang sort.Slice | 简书 SQL 中 on 条件与 where 条件的区别 | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"SQL","slug":"SQL","permalink":"https://abelsu7.top/tags/SQL/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://abelsu7.top/tags/Leetcode/"}]},{"title":"KVM 虚拟化相关知识点汇总","slug":"kvm-review","date":"2019-03-28T07:39:33.000Z","updated":"2019-09-01T13:04:11.446Z","comments":true,"path":"2019/03/28/kvm-review/","link":"","permalink":"https://abelsu7.top/2019/03/28/kvm-review/","excerpt":"整理自书籍、博客、网络，更新中…","text":"整理自书籍、博客、网络，更新中… 目录0. 腾讯云肖光荣关于 KVM 的简述肖光荣：KVM 是 Kernel-based Virtual Machine 的简称，KVM 要求 CPU 支持硬件虚拟化技术（例如Intel VT或AMD-V），是 Linux 下的全虚拟化解决方案。KVM 由处于内核态的 KVM 模块kvm.ko和用户态的 QEMU 两部分构成。内核模块kvm.ko实现了 CPU 和内存虚拟化等决定关键性能和核心安全的功能，并向用户空间提供了使用这些功能的接口，QEMU 利用 KVM 模块提供的接口来实现设备模拟、I/O 虚拟化和网络虚拟化等。单个虚拟机是宿主机上的一个普通 QEMU 进程，虚拟机中的 CPU 核（vCPU）是 QEMU 的一个线程，VM 的物理地址空间是 QEMU 的虚拟地址空间（图 1）。 1. 虚拟化基础虚拟化是云计算的基础。简单来说，虚拟化使得一台物理的服务器上可以跑多台虚拟机，虚拟机共享物理机的 CPU、内存、I/O 硬件资源，但逻辑上虚拟机之间是相互隔离的。 Host：宿主机，即物理机 Guest：客户机，即虚拟机 Host将自己的硬件资源虚拟化，并提供给Guest使用，主要是通过Hypervisor来实现的。根据Hypervisor的实现方式和所处的位置，虚拟化又可以分为两种：1 型虚拟化和 2 型虚拟化。 1 型虚拟化 1 型虚拟化 Hypervisor直接安装在物理机上，多个虚拟机在Hypervisor上运行。Hypervisor的实现方式一般是一个特殊定制的 Linux 系统，Xen 和 VMWare ESXi 都属于这个类型。 2 型虚拟化 2 型虚拟化 物理机上首先安装常规的操作系统，而Hypervisor作为 OS 上的一个程序模块运行，并对虚拟机进行管理。KVM、VirtualBox、VMWare Workstation 都属于这个类型。 由于 KVM 目前已经是 Linux 内核中的一个模块，因此也有人将其视为 1 型虚拟化 二者对比理论上讲： 1 型虚拟化一般对硬件虚拟化功能进行了特别优化，性能上比 2 型虚拟化要高 2 型虚拟化因为基于普通的操作系统，会比较灵活，例如支持嵌套虚拟化 QEMU-KVM 摘自 虚拟化技术之 KVM，搭建 KVM | CSDN KVM 包含了一个内核加载模块kvm.ko，它只会负责提供vCPU以及对虚拟内存进行管理和调度 QEMU-KVM 是通过修改 QEMU 代码而得出的专门用来创建和管理虚拟机的管理工具，为的是 KVM 能更好的和内核打交道 VM 运行期间，QEMU 会通过kvm.ko模块提供的系统调用进入内核，由 KVM 负责将虚拟机置于特殊模式运行 QEMU-KVM 是 KVM 团队针对 QEMU 改善和二次开发的一套工具 /dev/kvm是 KVM 内核模块提供给用户空间的一个接口，这个接口被qemu-kvm调用，通过ioctl系统调用就可以给用户提供一个工具，用以创建、删除、管理虚拟机 qemu-kvm就是通过open()、close()、ioctl()等方法去打开、关闭和调用这个接口，从而实现与 KVM 的互动 open(&quot;/dev/kvm&quot;) ioctl(KVM_CREATE_VM) ioctl(KVM_CREATE_VCPU) for (;;) { ioctl(KVM_RUN) switch (exit_reason) { case KVM_EXIT_IO: /* ... */ case KVM_EXIT_HLT: /* ... */ } } qemu-kvm通过/dev/kvm接口来调用 KVM： 打开/dev/kvm设备 通过KVM_CREATE_VM创建一个虚拟机对象 通过KVM_CREATE_VCPU为虚拟机创建vcpu对象 通过KVM_RUN设置vcpu为运行状态 外设是怎么管理的虚拟机只有vCPU和vMEM是无法运行的，还需要外设的支持。真实的外设需要利用 Linux 系统内核进行管理，而通常来说我们使用的还是虚拟外设。VM 要和虚拟外设进行交互的话，就需要利用 QEMU 模拟的虚拟外设。 2. KVM 原理简介 摘自 KVM 虚拟化原理探究 - Overview | CSDN KVM 实现主要基于Intel-V或者AMD-V提供的虚拟化平台，利用普通的 Linux 进程运行虚拟态的指令集，模拟虚拟机监视器和 CPU。KVM 本身并不提供硬件虚拟化操作，其 I/O 操作都借助 QEMU 完成。 KVM 全称为Kernel-based Virtual Machine，也就是说 KVM 是基于 Linux 内核实现的。KVM 有一个核心的内核模块kvm.ko，它只用于管理 vCPU 和内存。 作为一个Hypervisor，KVM 本身只关注虚拟机调度和内存管理这两个方面，I/O 外设的任务就交给了 Linux 内核和 QEMU libvirtlibvirt 主要包含三个模块：后台daemon程序libvirtd、API 库以及命令行工具virsh。 libvirtd：守护进程，接收并处理 API 请求 API 库使得其他人可以开发出基于 libvirt 的虚拟机管理工具，例如virt-manager virsh是经常会使用到的 KVM 命令行工具 Guest 特点 Guest作为一个普通进程运行于宿主机 Guest的 CPU（vCPU）作为进程的线程存在，并受到宿主机内核的调度 Guest继承了宿主机内核的一些属性，例如Huge Pages Guest的磁盘 I/O 和网络 I/O 会受到宿主机设置的影响 Guest通过宿主机上的虚拟网桥与外部相连 3. KVM 整体架构概览 KVM 架构示意图 每一个虚拟机Guest在Host上都被模拟为一个 QEMU 进程，即emulation进程。创建虚拟机后，使用virsh命令即可查看： &gt; virsh list --all Id Name State ---------------------------------------------------- 1 kvm-01 running &gt; ps aux | grep qemu libvirt+ 20308 15.1 7.5 5023928 595884 ? Sl 17:29 0:10 /usr/bin/qemu-system-x86_64 -name kvm-01 -S -machine pc-i440fx-wily,accel=kvm,usb=off -m 2048 -realtime mlock=off -smp 2 qemu .... 可以看到，此虚拟机就是一个普通的 Linux 进程，有自己的PID，并且有四个线程。线程数量不是固定的，但是至少会有三个（vCPU、I/O、Signal）。其中有两个是vCPU线程，一个I/O线程，还有一个Signal信号处理线程。 &gt; pstree -p 20308 qemu-system-x86(20308)-+-{qemu-system-x86}(20353) |-{qemu-system-x86}(20408) |-{qemu-system-x86}(20409) |-{qemu-system-x86}(20412) 虚拟 CPUGuest的所有用户级别的指令集，都会直接由宿主机线程执行，此线程会调用 KVM 的ioctl方式提供的接口加载Guest的指令，并在特殊的 CPU 模式下运行。这样就不需要经过 CPU 指令集的软件模拟转换，降低了虚拟化的成本，这也是 KVM 优于其他虚拟化方式的原因之一。 KVM 对外提供了一个虚拟设备/dev/kvm，可以通过ioctl（I/O 设备带外管理接口）来对 KVM 进行操作。 虚拟 I/O 设备Guest虽然作为一个进程存在，但其内核的所有驱动都依然存在。只是硬件设备由 QEMU 模拟。Guest的所有硬件操作都会由 QEMU 来接管，QEMU 负责与真实的宿主机硬件打交道。 虚拟内存Guest的内存在Host上由 Emulator 提供（即 QEMU）。对于 QEMU 来说，Guest访问的内存就是 QEMU 的虚拟地址空间。Guest上需要经过一次虚拟地址到物理地址的转换，转换得到的Guest的物理地址其实也就是 QEMU 的虚拟地址。这时 QEMU 再做一次转换，将虚拟地址转换为Host的物理地址。 虚拟机启动过程 参见 KVM 虚拟化原理探究 - Overview | CSDN 第一步，获取到kvm句柄 kvmfd = open(&quot;/dev/kvm&quot;, O_RDWR); 第二步，创建虚拟机，获取到虚拟机句柄。 vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0); 第三步，为虚拟机映射内存，还有其他的PCI，信号处理的初始化。 ioctl(kvmfd, KVM_SET_USER_MEMORY_REGION, &amp;mem); 第四步，将虚拟机镜像映射到内存，相当于物理机的boot过程，把镜像映射到内存。 第五步，创建vCPU，并为vCPU分配内存空间。 ioctl(kvmfd, KVM_CREATE_VCPU, vcpuid); vcpu-&gt;kvm_run_mmap_size = ioctl(kvm-&gt;dev_fd, KVM_GET_VCPU_MMAP_SIZE, 0); 第五步，创建vCPU个数的线程并运行虚拟机。 ioctl(kvm-&gt;vcpus-&gt;vcpu_fd, KVM_RUN, 0); 第六步，线程进入循环，并捕获虚拟机退出原因，做相应的处理。 这里的退出并不一定是虚拟机关机，虚拟机如果遇到IO操作，访问硬件设备，缺页中断等都会退出执行，退出执行可以理解为将CPU执行上下文返回到QEMU。 虚拟机的启动过程总结如下： 创建KVM句柄 创建VM 分配内存 加载镜像到内存 启动线程执行KVM_RUN open(&quot;/dev/kvm&quot;) ioctl(KVM_CREATE_VM) ioctl(KVM_CREATE_VCPU) for (;;) { ioctl(KVM_RUN) switch (exit_reason) { case KVM_EXIT_IO: /* ... */ case KVM_EXIT_HLT: /* ... */ } } 4. KVM 内存虚拟化及其实现 摘自 KVM 内存虚拟化及其实现 | IBM Developer 客户机物理地址空间为了实现内存虚拟化，让Guest使用一个隔离的、从零开始且连续的内存空间，KVM 引入了一层新的地址空间，即客户机物理地址空间（Guest Physical Address，GPA）。 这个地址空间并不是真正的物理地址空间，它只是Host虚拟地址空间在Guest地址空间的一个映射。对客户机来说，客户机物理地址空间都是从零开始的连续地址空间。但对宿主机来说，客户机的物理地址空间并不一定是连续的，客户机物理地址空间有可能映射在若干个不连续的宿主机地址区间，如下图所示： 客户机物理地址到宿主机虚拟地址的转换 为了将客户机物理地址转换成宿主机虚拟地址（Host Virtual Address，HVA），KVM 用一个kvm_memory_slot数据结构来记录每一个地址区间的映射关系，此数据结构包含了对应此映射区间的起始客户机页帧号（Guest Frame Number，GFN）、映射的内存页数目以及起始宿主机虚拟地址，从而实现 GPA 到 HPA 的转换。 实现内存虚拟化，最主要的是实现客户机虚拟地址GVA到宿主机物理地址HPA之间的转换。如果通过之前提到的两步映射的方式，客户机的每次内存访问都需要 KVM 介入，并由软件进行多次地址转换，其效率是非常低的。 因此，为了提高GVA到HPA的转换效率，KVM 提供了两种实现方式来进行GVA到HPA之间的直接转换： 影子页表（Shadow Page Table）：纯软件的实现方式 基于硬件对虚拟化的支持 影子页表由于宿主机 MMU 不能直接装载客户机的页表来进行内存访问，所以当客户机访问宿主机物理内存时，需要经过多次地址转换。而通过影子页表，则可以实现客户机虚拟地址到宿主机物理地址的直接转换： GPA 到 HPA 的转换 影子页表简化了地址转换过程，实现了客户机虚拟地址空间到宿主机物理地址空间的直接映射。 由于客户机中每个进程都有自己的虚拟地址空间，所以 KVM 需要为客户机中的每个进程页表都维护一套相应的影子页表。在客户机访问内存时，真正被装入宿主机 MMU 的是客户机当前页表所对应的影子页表 在使用影子页表的情况下，客户机的大多数内存访问都可以在没有 KVM 介入的情况下正常执行，没有额外的地址转换开销，也就大大提高了客户机运行的效率。 但是影子页表的引入也意味着 KVM 需要为每个客户机的每个进程页表都要维护一套相应的影子页表，这会带来较大的内存开销。此外，客户机页表和影子页表之间的同步也较为复杂。因此，Intel 的 EPT（Extent Page Table）技术和 AMD 的 NPT（Nest Page Table）技术都为内存虚拟化提供了硬件支持，在硬件层面上实现了GVA到HPA之间的转换。 EPT 页表EPT（Extent Page Table） 技术在原有客户机页表对GVA到GPA映射的基础上，又引入了 EPT 页表来实现GPA到HPA的另一次映射，这两次地址映射都是由硬件自动完成。 EPT 页表转换 EPT 页表相对于影子页表，其实现方式大大简化。而且，由于客户机内部的缺页异常不会导致客户机退出，因此也提高了客户机性能。此外，KVM 只需为每个客户机维护一套 EPT 页表，从而大大减少了内存的额外开销。 5. virtio 半虚拟化全虚拟化和半虚拟化 全虚拟化：Guest运行于物理机的Hypervisor之上，Guest操作系统并不知道它已被虚拟化，而且不需要任何更改就可以在该配置下工作 半虚拟化：Guest操作系统不仅知道它运行在Hypervisor之上，还包含了让Guest操作系统更高效的过渡到Hypervisor的代码 全虚拟化和半虚拟化环境下的设备模拟 在传统的全虚拟化环境中，Hypervisor必须捕捉Guest的 I/O 请求，然后模拟物理硬件的行为，虽然比较灵活，但是效率较低。 而在半虚拟化环境中，Guest知道自己运行在Hypervisor之上，并且包含了充当前端程序的驱动程序。Hypervisor为特定的设备模拟实现后端驱动程序。通过前端和后端驱动程序中的virtio，为模拟设备提供标准化接口，从而提高了代码的跨平台重用率与运行效率。 针对 Linux 的抽象总结来看，virtio是对半虚拟化Hypervisor中的一组通用模拟设备的抽象。有了半虚拟化Hypervisor之后，Guest操作系统就能够实现一组通用的接口，针对不同的后端驱动程序采用特定的设备模拟。后端驱动程序不需要是通用的，因为它们只需要实现前端所需的行为。 virtio 的驱动程序抽象 virtio 架构virtio API依赖一个简单的缓冲抽象来封装Guest操作系统所需要的命令和数据。在前端和后端驱动程序之外，virtio还定义了两个层来支持Guest到Hypervisor的通信。 6. 镜像文件格式 Qemu虚拟机QCOW2格式镜像文件的组成部分及关键算法分析 | 开源中国 KVM-QEMU, QCOW2, QEMU-IMG and Snapshots | 开源中国 KVM 磁盘扩容 | 51CTO RAW（裸） 与 QCOW2（写时复制） 的区别 | CSDN QCOW2实现原理的一般性思考 | CSDN QEMU 使用的镜像文件：qcow2 与 raw | CSDN qcow2 文件格式详解（I）| 简书 参考文章 【必看】KVM 虚拟化原理探究 - Overview | CSDN CloudMan KVM 内存虚拟化及其实现 | IBM Developer 【必看】虚拟化技术之KVM，搭建KVM | CSDN Virtio：针对 Linux 的 I/O 虚拟化框架 | IBM Developer Linux 虚拟化技术和 PCI 透传技术 | IBM Developer CPU 和内存虚拟化原理 - CloudMan | CSDN 热迁移、RTC 计时与安全增强 - 腾讯云 KVM 性能优化实践经验谈 | InfoQ qemu+kvm的IO路径分析 | CSDN QEMU-KVM 原理综述 | FlyFlyPeng 阿里云郑晓：浅谈GPU虚拟化技术（一）| 阿里云栖社区 阿里云郑晓：浅谈GPU虚拟化技术（二）| 阿里云栖社区 阿里云郑晓：浅谈GPU虚拟化技术（三）| 阿里云栖社区 浅谈GPU虚拟化技术（四）- GPU分片虚拟化 | 阿里云栖社区 浅谈GPU虚拟化技术（五）- VDI 的用户体验 一文带你领略虚拟化领域顶级技术会议 KVM Forum 2018 | 阿里云栖社区 【必看】KVM 虚拟化原理探究—启动过程及各部分虚拟化原理 | CSDN KVM 计算虚拟化原理，偏基础 | 博客园 Qemu虚拟机QCOW2格式镜像文件的组成部分及关键算法分析 | 开源中国 KVM-QEMU, QCOW2, QEMU-IMG and Snapshots | 开源中国 KVM 磁盘扩容 | 51CTO RAW（裸） 与 QCOW2（写时复制） 的区别 | CSDN QCOW2实现原理的一般性思考 | CSDN QEMU 使用的镜像文件：qcow2 与 raw | CSDN KVM虚拟化原理 | 开源中国 virtio基本原理(kvm半虚拟化驱动) | 开源中国 qemu,kvm,qemu-kvm,xen,libvir 区别 | 开源中国 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集CentOS 7 安装配置 NFS半虚拟化 I/O 框架 virtioLinux 系统常用监控命令Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"}]},{"title":"Go 语言常用算法及数据结构汇总","slug":"go-algo-and-data-structure","date":"2019-03-24T07:49:11.000Z","updated":"2019-09-01T13:04:11.246Z","comments":true,"path":"2019/03/24/go-algo-and-data-structure/","link":"","permalink":"https://abelsu7.top/2019/03/24/go-algo-and-data-structure/","excerpt":"Keep calm and use Go.","text":"Keep calm and use Go. 目录 目录 一、排序算法 1. 冒泡排序 2. 插入排序 3. 选择排序 4. 归并排序 5. 快速排序 6. 计数排序 7. 堆排序 二、二分查找 三、数据结构 1. 二叉树 2. 链表 3. 栈 4. 队列 5. 堆 一、排序算法 常用排序算法汇总 1. 冒泡排序//冒泡排序，a是数组，n表示数组大小 func BubbleSort(a []int, n int) { if n &lt;= 1 { return } for i := 0; i &lt; n; i++ { // 提前退出标志 flag := false for j := 0; j &lt; n-i-1; j++ { if a[j] &gt; a[j+1] { a[j], a[j+1] = a[j+1], a[j] //此次冒泡有数据交换 flag = true } } // 如果没有交换数据，提前退出 if !flag { break } } } 2. 插入排序// 插入排序，a表示数组，n表示数组大小 func InsertionSort(a []int, n int) { if n &lt;= 1 { return } for i := 1; i &lt; n; i++ { value := a[i] j := i - 1 //查找要插入的位置并移动数据 for ; j &gt;= 0; j-- { if a[j] &gt; value { a[j+1] = a[j] } else { break } } a[j+1] = value } } 3. 选择排序// 选择排序，a表示数组，n表示数组大小 func SelectionSort(a []int, n int) { if n &lt;= 1 { return } for i := 0; i &lt; n; i++ { // 查找最小值 minIndex := i for j := i + 1; j &lt; n; j++ { if a[j] &lt; a[minIndex] { minIndex = j } } // 交换 a[i], a[minIndex] = a[minIndex], a[i] } } 4. 归并排序// 归并排序 func MergeSort(a []int, n int) { if n &lt;= 1 { return } mergeSort(a, 0, n-1) } func mergeSort(a []int, start, end int) { if start &gt;= end { return } mid := (start + end) / 2 mergeSort(a, start, mid) mergeSort(a, mid+1, end) merge(a, start, mid, end) } func merge(a []int, start, mid, end int) { tmpArr := make([]int, end-start+1) i := start j := mid + 1 k := 0 for ; i &lt;= mid &amp;&amp; j &lt;= end; k++ { if a[i] &lt; a[j] { tmpArr[k] = a[i] i++ } else { tmpArr[k] = a[j] j++ } } for ; i &lt;= mid; i++ { tmpArr[k] = a[i] k++ } for ; j &lt;= end; j++ { tmpArr[k] = a[j] j++ } copy(a[start:end+1], tmpArr) } 5. 快速排序func QuickSort(a []int, n int) { separateSort(a, 0, n-1) } func separateSort(a []int, start, end int) { if start &gt;= end { return } i := partition(a, start, end) separateSort(a, start, i-1) separateSort(a, i+1, end) } func partition(a []int, start, end int) int { // 选取最后一位当对比数字 pivot := a[end] i := start for j := start; j &lt; end; j++ { if a[j] &lt; pivot { if !(i == j) { // 交换位置 a[i], a[j] = a[j], a[i] } i++ } } a[i], a[end] = a[end], a[i] return i } 6. 计数排序func CountingSort(a []int, n int) { if n &lt;= 1 { return } var max = math.MinInt32 for i := range a { if a[i] &gt; max { max = a[i] } } c := make([]int, max+1) for i := range a { c[a[i]]++ } for i := 1; i &lt;= max; i++ { c[i] += c[i-1] } r := make([]int, n) for i := range a { index := c[a[i]] - 1 r[index] = a[i] c[a[i]]-- } copy(a, r) } 7. 堆排序 父节点：(x-1)/2 左子节点：2x+1 右子节点：2x+2 堆中最后一个父节点：(n/2)-1 func HeapSort(arr []int, n int) { // 1. 建立一个大顶堆 buildMaxHeap(arr, n) length := n // 2. 交换堆顶元素与堆尾，并对剩余的元素重新建堆 for i := n - 1; i &gt; 0; i-- { swap(arr, 0, i) length-- heapify(arr, 0, length) } // 3. 返回堆排序后的数组 return } func buildMaxHeap(arr []int, n int) { for i := n/2 - 1; i &gt;= 0; i-- { heapify(arr, i, n) } } // 从上至下堆化 func heapify(arr []int, i int, n int) { left := 2*i + 1 right := 2*i + 2 largest := i if left &lt; n &amp;&amp; arr[left] &gt; arr[largest] { largest = left } if right &lt; n &amp;&amp; arr[right] &gt; arr[largest] { largest = right } if largest != i { swap(arr, i, largest) heapify(arr, largest, n) } } func swap(arr []int, i int, j int) { arr[i], arr[j] = arr[j], arr[i] } 二、二分查找func BinarySearch(a []int, v int) int { n := len(a) if n == 0 { return -1 } low := 0 high := n - 1 for low &lt;= high { mid := (low + high) / 2 if a[mid] == v { return mid } else if a[mid] &gt; v { high = mid - 1 } else { low = mid + 1 } } return -1 } // 递归写法 func BinarySearchRecursive(a []int, v int) int { n := len(a) if n == 0 { return -1 } return bs(a, v, 0, n-1) } func bs(a []int, v int, low, high int) int { if low &gt; high { return -1 } mid := (low + high) / 2 if a[mid] == v { return mid } else if a[mid] &gt; v { return bs(a, v, low, mid-1) } else { return bs(a, v, mid+1, high) } } // 查找第一个等于给定值的元素 func BinarySearchFirst(a []int, v int) int { n := len(a) if n == 0 { return -1 } low := 0 high := n - 1 for low &lt;= high { mid := low + (high-low)&gt;&gt;1 if a[mid] &gt; v { high = mid - 1 } else if a[mid] &lt; v { low = mid + 1 } else { if mid == 0 || a[mid-1] != v { return mid } else { high = mid - 1 } } } return -1 } // 查找最后一个值等于给定值的元素 func BinarySearchLast(a []int, v int) int { n := len(a) if n == 0 { return -1 } low := 0 high := n - 1 for low &lt;= high { mid := low + (high-low)&gt;&gt;1 if a[mid] &gt; v { high = mid - 1 } else if a[mid] &lt; v { low = mid + 1 } else { if mid == n-1 || a[mid+1] != v { return mid } else { low = mid + 1 } } } return -1 } // 查找第一个大于等于给定值的元素 func BinarySearchFirstGT(a []int, v int) int { n := len(a) if n == 0 { return -1 } low := 0 high := n - 1 for low &lt;= high { mid := (high + low) &gt;&gt; 1 if a[mid] &gt; v { high = mid - 1 } else if a[mid] &lt; v { low = mid + 1 } else { if mid != n-1 &amp;&amp; a[mid+1] &gt; v { return mid + 1 } else { low = mid + 1 } } } return -1 } // 查找最后一个小于等于给定值的元素 func BinarySearchLastLT(a []int, v int) int { n := len(a) if n == 0 { return -1 } low := 0 high := n - 1 for low &lt;= high { mid := (low + high) &gt;&gt; 1 if a[mid] &gt; v { high = mid - 1 } else if a[mid] &lt; v { low = mid + 1 } else { if mid == 0 || a[mid-1] &lt; v { return mid - 1 } else { high = mid - 1 } } } return -1 } 三、数据结构1. 二叉树type Node struct { data interface{} left *Node right *Node } func NewNode(data interface{}) *Node { return &amp;Node{data: data} } func (this *Node) String() string { return fmt.Sprintf(&quot;v:%+v, left:%+v, right:%+v&quot;, this.data, this.left, this.right) } 2. 链表单链表package _6_linkedlist import &quot;fmt&quot; /* 单链表基本操作 author:leo */ type ListNode struct { next *ListNode value interface{} } type LinkedList struct { head *ListNode length uint } func NewListNode(v interface{}) *ListNode { return &amp;ListNode{nil, v} } func (this *ListNode) GetNext() *ListNode { return this.next } func (this *ListNode) GetValue() interface{} { return this.value } func NewLinkedList() *LinkedList { return &amp;LinkedList{NewListNode(0), 0} } //在某个节点后面插入节点 func (this *LinkedList) InsertAfter(p *ListNode, v interface{}) bool { if nil == p { return false } newNode := NewListNode(v) oldNext := p.next p.next = newNode newNode.next = oldNext this.length++ return true } //在某个节点前面插入节点 func (this *LinkedList) InsertBefore(p *ListNode, v interface{}) bool { if nil == p || p == this.head { return false } cur := this.head.next pre := this.head for nil != cur { if cur == p { break } pre = cur cur = cur.next } if nil == cur { return false } newNode := NewListNode(v) pre.next = newNode newNode.next = cur this.length++ return true } //在链表头部插入节点 func (this *LinkedList) InsertToHead(v interface{}) bool { return this.InsertAfter(this.head, v) } //在链表尾部插入节点 func (this *LinkedList) InsertToTail(v interface{}) bool { cur := this.head for nil != cur.next { cur = cur.next } return this.InsertAfter(cur, v) } //通过索引查找节点 func (this *LinkedList) FindByIndex(index uint) *ListNode { if index &gt;= this.length { return nil } cur := this.head.next var i uint = 0 for ; i &lt; index; i++ { cur = cur.next } return cur } //删除传入的节点 func (this *LinkedList) DeleteNode(p *ListNode) bool { if nil == p { return false } cur := this.head.next pre := this.head for nil != cur { if cur == p { break } pre = cur cur = cur.next } if nil == cur { return false } pre.next = p.next p = nil this.length-- return true } //打印链表 func (this *LinkedList) Print() { cur := this.head.next format := &quot;&quot; for nil != cur { format += fmt.Sprintf(&quot;%+v&quot;, cur.GetValue()) cur = cur.next if nil != cur { format += &quot;-&gt;&quot; } } fmt.Println(format) } 链表常用操作package _7_linkedlist import &quot;fmt&quot; //单链表节点 type ListNode struct { next *ListNode value interface{} } //单链表 type LinkedList struct { head *ListNode } //打印链表 func (this *LinkedList) Print() { cur := this.head.next format := &quot;&quot; for nil != cur { format += fmt.Sprintf(&quot;%+v&quot;, cur.value) cur = cur.next if nil != cur { format += &quot;-&gt;&quot; } } fmt.Println(format) } /* 单链表反转 时间复杂度：O(N) */ func (this *LinkedList) Reverse() { if nil == this.head || nil == this.head.next || nil == this.head.next.next { return } var pre *ListNode = nil cur := this.head.next for nil != cur { tmp := cur.next cur.next = pre pre = cur cur = tmp } this.head.next = pre } /* 判断单链表是否有环 */ func (this *LinkedList) HasCycle() bool { if nil != this.head { slow := this.head fast := this.head for nil != fast &amp;&amp; nil != fast.next { slow = slow.next fast = fast.next.next if slow == fast { return true } } } return false } /* 两个有序单链表合并 */ func MergeSortedList(l1, l2 *LinkedList) *LinkedList { if nil == l1 || nil == l1.head || nil == l1.head.next { return l2 } if nil == l2 || nil == l2.head || nil == l2.head.next { return l1 } l := &amp;LinkedList{head: &amp;ListNode{}} cur := l.head curl1 := l1.head.next curl2 := l2.head.next for nil != curl1 &amp;&amp; nil != curl2 { if curl1.value.(int) &gt; curl2.value.(int) { cur.next = curl2 curl2 = curl2.next } else { cur.next = curl1 curl1 = curl1.next } cur = cur.next } if nil != curl1 { cur.next = curl1 } else if nil != curl2 { cur.next = curl2 } return l } /* 删除倒数第N个节点 */ func (this *LinkedList) DeleteBottomN(n int) { if n &lt;= 0 || nil == this.head || nil == this.head.next { return } fast := this.head for i := 1; i &lt;= n &amp;&amp; fast != nil; i++ { fast = fast.next } if nil == fast { return } slow := this.head for nil != fast.next { slow = slow.next fast = fast.next } slow.next = slow.next.next } /* 获取中间节点 */ func (this *LinkedList) FindMiddleNode() *ListNode { if nil == this.head || nil == this.head.next { return nil } if nil == this.head.next.next { return this.head.next } slow, fast := this.head, this.head for nil != fast &amp;&amp; nil != fast.next { slow = slow.next fast = fast.next.next } return slow } 3. 栈栈的接口type Stack interface { Push(v interface{}) Pop(v interface{}) IsEmpty() bool Top() interface{} Flush() } 基于数组的栈type ArrayStack struct { // 数据 data []interface{} // 栈顶指针 top int } func NewArrayStack() *ArrayStack { return &amp;ArrayStack{ data: make([]interface{}, 0, 32), top: -1, } } func (this *ArrayStack) IsEmpty() bool { if this.top &lt; 0 { return true } return false } func (this *ArrayStack) Push(v interface{}) { if this.top &lt; 0 { this.top = 0 } else { this.top += 1 } if this.top &gt; len(this.data)-1 { this.data = append(this.data, v) } else { this.data[this.top] = v } } func (this *ArrayStack) Pop() interface{} { if this.IsEmpty() { return nil } v := this.data[this.top] this.top -= 1 return v } func (this *ArrayStack) Top() interface{} { if this.IsEmpty() { return nil } return this.data[this.top] } func (this *ArrayStack) Flush() { this.top = -1 } func (this *ArrayStack) Print() { if this.IsEmpty() { fmt.Println(&quot;empty stack&quot;) } else { for i:= this.top; i&gt;=0; i-- { fmt.Println(this.data[i]) } } } 基于链表的栈package _8_stack import &quot;fmt&quot; /* 基于链表实现的栈 */ type node struct { next *node val interface{} } type LinkedListStack struct { topNode *node } func NewLinkedListStack() *LinkedListStack { return &amp;LinkedListStack{nil} } func (this *LinkedListStack) IsEmpty() bool { if this.topNode == nil { return true } return false } func (this *LinkedListStack) Push(v interface{}) { this.topNode = &amp;node{next: this.topNode, val: v} } func (this *LinkedListStack) Pop() interface{} { if this.IsEmpty() { return nil } v := this.topNode.val this.topNode = this.topNode.next return v } func (this *LinkedListStack) Top() interface{} { if this.IsEmpty() { return nil } return this.topNode.val } func (this *LinkedListStack) Flush() { this.topNode = nil } func (this *LinkedListStack) Print() { if this.IsEmpty() { fmt.Println(&quot;empty stack&quot;) } else { cur := this.topNode for nil != cur { fmt.Println(cur.val) cur = cur.next } } } 4. 队列基于数组的队列package queue import &quot;fmt&quot; type ArrayQueue struct { q []interface{} capacity int head int tail int } func NewArrayQueue(n int) *ArrayQueue { return &amp;ArrayQueue{make([]interface{}, n), n, 0, 0} } func (this *ArrayQueue) EnQueue(v interface{}) bool { if this.tail == this.capacity { // head == 0 &amp;&amp; tail == capacity 表示整个队列都占满了 if this.head == 0 { return false } // 数据搬移 for i := this.head; i &lt; this.tail; i++ { this.q[i-this.head] = this.q[this.tail] } // 搬移完之后，更新 head 和 tail this.tail -= this.head this.head = 0 } this.q[this.tail] = v this.tail++ return true } func (this *ArrayQueue) DeQueue() interface{} { if this.head == this.tail { return nil } v := this.q[this.head] this.head++ return v } func (this *ArrayQueue) String() string { if this.head == this.tail { return &quot;empty queue&quot; } result := &quot;head&quot; for i := this.head; i &lt;= this.tail-1; i++ { result += fmt.Sprintf(&quot;&lt;-%+v&quot;, this.q[i]) } result += &quot;&lt;-tail&quot; return result } 5. 堆结构体声明type Heap struct { a []int n int count int } 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件【数据结构】线段树转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"数据结构","slug":"数据结构","permalink":"https://abelsu7.top/tags/数据结构/"}]},{"title":"数据库系统原理笔记","slug":"database-basics","date":"2019-03-20T02:02:18.000Z","updated":"2019-09-01T13:04:11.117Z","comments":true,"path":"2019/03/20/database-basics/","link":"","permalink":"https://abelsu7.top/2019/03/20/database-basics/","excerpt":"摘自 数据库系统原理 | CS-Notes","text":"摘自 数据库系统原理 | CS-Notes 目录一、事务事务指满足 ACID 特性的一组操作，可以通过Commit提交一个事务，也可以通过Rollback进行回滚。 ACID1. Atomicity 原子性事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 使用回滚日志Undo Log保证原子性 2. Consistency 一致性数据库在事务执行前后都保持一致性状态，所有事务对一个数据的读取结果都是相同的。 3. Isolation 隔离性一个事务所做的修改在最终提交以前，对其他事务不可见。 4. Durability 持久性一旦事务提交，则其所做的修改将会永远保存到数据库中，即使系统发生崩溃，事务的执行结果也不能丢失。 使用重做日志Redo Log保证持久性 ACID 之间的关系 只有满足一致性，事务的执行结果才是正确的 无并发的情况下，事务串行执行，隔离性一定满足。此时只要满足原子性，就可以满足一致性 有并发的情况下，多个事务并行执行，事务不仅要满足原子性，还要满足隔离性，才能满足一致性 事务满足持久性是为了应对数据库崩溃的情况 AUTOCOMMITMySQL 默认采用自动提交模式，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询都会被当作一个事务自动提交。 二、并发一致性在并发环境下，事务的隔离性很难保证，有可能出现很多并发一致性问题。 丢失修改T2的修改覆盖了T1的修改： 丢失修改 读脏数据T1修改一个数据，T2随后读取这个数据，如果T1撤销了这次修改，那么T2读取的数据就是脏数据： 读脏数据 不可重复读T2读取一个数据，T1对该数据进行了修改。如果T2再次读取这个数据，结果会和第一次读取的结果不同： 不可重复读 幻影读T1读取某个范围的数据，T2在这个范围内插入新的数据。T1再次读取这个范围的数据，结果会和第一次读不同： 总结 主要原因：破坏了事务的隔离性 解决方法：通过并发控制来保证隔离性 如何实现：通过封锁，但需要用户自己控制，相当复杂 数据库管理系统提供了事务的隔离级别，可以让用户轻松的处理并发一致性问题 三、封锁封锁粒度MySQL中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择锁粒度时，需要在锁开销和并发程度之间做一个权衡。 封锁类型1. 读写锁 排它锁（Exclusive）：简写为X锁，又称为写锁 共享锁（Shared）：简写为S锁，又称为读锁 2. 意向锁使用意向锁（Intention Locks）可以更容易的支持多粒度封锁。 意向锁在原来的X/S锁之上引入了IX/IS，都是表级锁，用来表示一个事务想要在表中的某个数据行上加X锁或S**锁。有以下两个规定： 一个事务在获得某个数据行对象的S锁之前，必须获得表的IS锁或更强的锁 一个事务在获得某个数据行对象的X锁之前，必须先获得表的IX锁 封锁协议1. 三级封锁协议一级封锁协议 事务T要修改数据A时必须加X锁，直到T结束才释放锁. 可以解决丢失修改的问题，因为不能同时有两个事务对同一个数据进行修改，那么事务就不会被覆盖 二级封锁协议 在一级的基础上，要求读取数据A时必须加S锁，读取完马上释放S锁。 可以解决读脏数据的问题，因为如果一个事务在对数据A进行修改，根据一级封锁协议，会加X锁，那么就不能再加S锁了，也就不会读入脏数据 三级封锁协议 在二级的基础上，要求读取数据A时必须加S锁，直到事务结束了才能释放S锁。 可以解决不可重复读的问题，因为读A时，其他事务不能对A加X锁，从而避免了在读的期间数据发生改变 2. 两段锁协议加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果串行执行的事务结果相同**。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，是可串行化调度： lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但它仍是可串行化调度： lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) MySQL 隐式与显式锁定MySQL的InnoDB存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB也支持使用特定的语句进行显式锁定： SELECT ... LOCK In SHARE MODE; SELECT ... FOR UPDATE; 四、隔离级别未提交读 READ UNCOMMITTED 事务中的修改，即使没有提交，对其他事务也是可见的 提交读 READ COMMITED 一个事务只能读取已经提交事务所做的修改。也就是说，一个事务所做的修改在提交之前对其他事务是不可见的 可重复读 REPEATABLE READ 保证在同一个事务中多次读取同样数据的结果是一样的 可串行化 SERIALIZABLE 强制事务串行执行 五、多版本并发控制多版本并发控制（Multi-Version Concurrency Control，MVCC）是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。 未提交读隔离级别总是读取最新的数据行，无需使用 MVCC 可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现 版本号 系统版本号：是一个递增的数字，每开始一个新事务，系统版本号就会自动递增 事务版本号：事务开始时的系统版本号 隐藏的列MVVC 在每行记录后都保存着两个隐藏的列，用来存储两个版本号： 创建版本号：表示创建一个数据行的快照时的系统版本号 删除版本号：如果该快照的删除版本号大于当前事务的版本号，则该快照有效，否则表示该快照已经被删除了 Undo 日志MVCC 使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 更新中… 参考文章 数据库系统原理 | CS-Notes 🚩推荐阅读（由hexo文章推荐插件驱动）Golang ORM 框架：GORMSQL 必知必会《数据库系统概论》学习笔记之关系数据库《数据库系统概论》学习笔记之绪论","categories":[{"name":"数据库","slug":"数据库","permalink":"https://abelsu7.top/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://abelsu7.top/tags/数据库/"}]},{"title":"近期复习合集","slug":"recent-review","date":"2019-03-19T06:35:46.000Z","updated":"2019-11-26T07:35:14.711Z","comments":true,"path":"2019/03/19/recent-review/","link":"","permalink":"https://abelsu7.top/2019/03/19/recent-review/","excerpt":"Hold on just a little while longer…","text":"Hold on just a little while longer… 目录1. Golang基础 Go 程序是怎样跑起来的 | 码农桃花源 如何写出优雅的 Golang 代码 | Draveness.me 【必看】Go 语言学习笔记 | Zhongfox 【必看】年终盘点！2017年超有价值的 Golang 文章 | 鸟窝 今日头条Go建千亿级微服务的实践 | 36Kr Go 语言链接收藏 | Zhongfox 《学习 Go 语言》中文版 The Little Go Book 【很多 Golang 的学习文章】| static.markbest.site go-algorithms | Github Golang 资料集 | Github Go 语言圣经 | GitBook Go 夜读 Go 学习之路 | Github build-web-application-with-golang | Github Go Web 编程 - 上面教程的中文版 | LearnKu Writing Web Applications | golang.org Golang 社区文档 | LearnKu Go 语言入门资料 | 傅小黑 《Go 编程基础》视频教程 by 无闻 | Github 《Go 入门指南》- 《The Way to Go》中文版 by 无闻 | Github 如何客观评价 Go 语言？| Legendtkl 博客 The Go Blog | golang.org Golang 中国 Go 语言中文网 Go 语言中文网博客 Go Walker | 在线生成浏览 Go 项目 API 文档 Go Programming Blog | Ardan Labs 面向信仰编程 | Draveness’s Blog RyuGou 的博客 spf13 Steve Francia | 也就是 spf13 Unknwon 无闻 | Github Lunny Xiao | Github 风笑痴 | Lunny Xiao FuXiaoHei | Github FuXiaohei.Me | 傅小黑的自留地 Tony Bai | 东软白明 codeskyblue | Github TY·Loafer Bingo Huang 飞雪无情 鸟窝 码农桃花源 - 饶全成 码洞 - 掌阅钱文品 Legendtkl（阿里云-陶克路）的博客、知乎专栏、微信公众号legendtkl Go 中国 | 微信公众号 会议报告、PPT Go’s New Brand | The Go Blog Go 2018 Survey Results | The Go Blog Codewalks | golang.org Advanced Go Concurrency Patterns | Sameer Ajmani - Google GopherChina 2019 讲师 PPT | 百度网盘 第二届 GopherChina 2016 大会 | 傅小黑 PPT shared by spf13 | SlideShare 演讲：Go, A Global Phenomenon (英语演讲) | spf13 How To Contribute To Go | spf13 Life, Liberty, And Golang | spf13 What Should A Modern Practical Programming Language Look Like | spf13 Go – On The Shoulders Of Giants | spf13 State Of The Go Nation – Gophercon Brasil 2017 | spf13 用 Go 语言编程的利与弊 | InfoQ 再见，Python！你好，Go 语言 | InfoQ 初始化 make/new Go 语言中的 make 和 new | Draveness 字典 map 深入理解 Go - sync.Map 原理 | TY·Loafer 解剖 Go 语言 map 底层实现 | RyuGou 理解 Golang 哈希表 Map 的原理 | 码农桃花源 深度解密 Go 语言之 map | 码农桃花源 解剖 Go 语言 map 底层实现 | CSDN golang map源码详解 | 掘金 切片 Slice 深度解密 Go 语言之 Slice | 码农桃花源 Go 语言 slice 的本质 - SliceHeader | 飞雪无情 Go 数组和切片的内部实现原理 | RyuGou Go 判断数组中是否包含某个 item | 温欣爸比 字符串 string Package strings | Golang Docs golang讲解（go语言）标准库分析之strings（3）| 微度网络 谈 Golang 中的字符串和字节数组 | 真没什么逻辑 golang strings 包方法 | Go 语言中文网 golang strings 包的使用详解【还有很多其他包】 | CSDN golang 中 strings 包用法 | CSDN golang 没有 char类型，str[0] 类型讲解 | CSDN golang 使用 strings.Split 切割的注意 | CSDN Go 语言字符串高效拼接（一）| 飞雪无情 Go 语言字符串高效拼接（二）| 飞雪无情 Go 语言字符串高效拼接（三）| 飞雪无情 接口 interface 浅入浅出 Go 语言接口的原理 | Draveness Go 语言 interface 底层实现 | RyuGou 深度解密 Go 语言之关于 interface 的 10 个问题 | 码农桃花源 深入理解 Go 的 interface | Go 中国 深入理解 Go 的 interface | TY·Loafer 协程调度 goroutine Go 采用 goroutine 和 channel 实现工作池 | 格物 深入理解 Go - goroutine 的实现及调度器分析 | TY·Loafer 也谈 goroutine 调度器 | Tony Bai Go 调度器: M, P 和 G | 鸟窝 go 语言之行— golang 核武器 goroutine 调度原理、channel 详解 | 掘金 Golang 的 goroutine 是如何实现的？| 知乎 goroutine 调度 | 开源中国 Scheduling In Go : Part I - OS Scheduler | ArdanLabs Scheduling In Go : Part II - Go Scheduler | ArdanLabs Scheduling In Go : Part III - Concurrency | ArdanLabs 为什么能有上百万个 Goroutines，却只能有上千个 Java 线程？| InfoQ 详尽干货！从源码角度看 Golang 的调度 | Go 中国 深度揭秘 Go 语言之 scheduler | 码农桃花源 【图示】控制 Goroutine 的并发数量的方式 | 敬维 用 GODEBUG 看调度跟踪 | 煎鱼说 通道 channel 深入理解 go - channel 和 select 的原理 | TY·Loafer 深度揭秘 Go 语言之 channel | 码农桃花源 图解 Go 的 Channel 底层原理 | RyuGou Go 语言 Channel 实现原理精要 | 真没什么逻辑 浅谈 Go 语言 select 的实现原理 | 真没什么逻辑 Golang 中 Channel 的使用 | 开源中国 深入理解 Go 语言之 Channel | Legendtkl Go 学习之 Channel 总结 | TY·Loafer Go 学习之 Channel 的一些模式 | TY·Loafer 并发 CSP Golang 并发编程与 Context | Draveness Go 并发编程小测验： 你能答对几道题？| 鸟窝 go-concurrent-quiz | Github Gopher 2019 Go 并发编程的分享 | 鸟窝 从并发模型看 Go 的语言设计 | 腾讯技术工程 Go 并发原理 | 贝壳产品技术 Go 并发原理 | RyuGou Go 语言之并发 | 博客园 Golang 非 CSP 并发模型外的其他并行方法总结 | RyuGou 图解 Go 并发编程 | Go 语言中文网 可视化学习 Go 并发编程 | Go 中国 Golang 的并发实现 | 百家号 Go 语言并发编程指南 | Gitbook GoLang 之协程、channel、select、同步锁 | CSDN Sync.Pool 浅析 | TY·Loafer 上下文 context Golang 并发编程与 Context | Draveness 深度解密 Go 语言之 context | 码农桃花源 互斥锁 Mutex 当我们谈论锁，我们谈什么 | Legendtkl Go 语言中的锁源码实现：Mutex | Legendtkl Go 语言中的读写锁实现：RWMutex Go 中的锁 | 知乎专栏 网络 HTTP/HTTPS Go 开发 HTTP | 傅小黑 Go 和 HTTPS | Tony Bai Go 开发 HTTP 的另一个选择 fasthttp | 傅小黑 排序 Sort Go sort包使用与源码剖析 | 薯条的自我修养 内嵌静态资源 Go 内嵌静态资源 | 傅小黑 go-bindata | Github go.rice | Github esc | Github 原子操作 atomic Go 语言 atomic 原子操作 | Go 语言中文网 Golang atomic 包的使用 | 简书 golang语言中sync/atomic包的学习与使用 | 博客园 go数据同步（sync与atomic包）| CSDN 【必看】golang 原子计数，互斥锁，耗时 | 博客园 输入输出 I/O Go 读取控制台输入 | Go 语言中文网 Golang Printf、Sprintf 、Fprintf 格式化 | CSDN Golang 的交互模式进阶-读取用户的输入 | Go 语言中文网 Go基础系列：读取标准输入 | 骏马金龙 Golang 的交互模式进阶-读取用户的输入 | 博客园 Go 字符串格式化 | Go 语言中文网 Go 如何给屏幕打印信息加上颜色 | 温欣爸比 Go 语言在 Linux 环境下输出彩色字符 | 博客园 内存分配 探索 Go 内存管理(分配) | 简书 简单易懂的 Go 内存分配原理解读 | 阿里云栖社区 图解 Go 语言的内存分配 | 码农桃花源 图解 Golang 的内存分配 | RyuGou Go 语言 - 内存管理 | 简书 深入理解 Go - 内存分配 | TY·Loafer 逃逸分析 参见 Go 逃逸分析 | 开源中国 所谓逃逸分析（Escape Analysis）是指编译器决定内存分配的位置，不需要程序员指定。在函数中申请一个新的对象： 如果分配在栈中，则函数执行结束时可自动将内存回收 如果分配在堆中，则函数执行结束可交给 GC 处理 参考文章： 深入理解 Go - 逃逸分析 | TY·Loafer Go 逃逸分析 | 开源中国 垃圾回收 GC 深入理解 Go - 垃圾回收机制 | TY·Loafer 【必看】Go 垃圾回收原理 | 开源中国 Go 语言 - 垃圾回收 GC | 简书 Golang GC 算法 | Go 语言中文网 图解 Golang 的 GC 算法 | RyuGou 用 GODEBUG 看 GC | 我要煎鱼说 深入理解 Go - runtime.SetFinalizer 原理剖析 | TY·Loafer Golang 里一个有趣的小细节 - xlzd | 知乎 延迟调用 defer 理解 Go 语言 defer 关键字的原理 | 真没什么逻辑 Golang 之轻松化解 defer 的温柔陷阱 | 码农桃花源 Go 延迟函数 defer 详解 | 茶歇驿站 深入理解 Go 语言 defer | legendtkl 深入理解 Go - defer 的原理剖析 | TY·Loafer 错误处理 Golang error 的突围 | 码农桃花源 谈谈 panic 和 recover 的原理 | Draveness 循环遍历 for range Go 语言 for 和 range 的实现 | 真没什么逻辑 位运算 整数x按位取反：-(x+1)判断奇偶：i&amp;0x1 == 1 Go语言/golang/位操作/取反/异或/左移/右移 | 开源中国 Golang 的位运算操作符的使用 | Go 语言中文网 按位取反运算解析 | CSDN 取反！和按位取反~的区别 | CSDN 位运算之左移右移运算详解 | cnblogs 网络编程 Golang 的 HTTP 操作大全 | RyuGou Go 语言 TCP Socket编程 | Tony Bai 网络编程-一个简单的echo程序(0) | 编程珠玑 反射 reflection Golang 反射浅析 | LawTech’s Blog 深度解密 Go 语言之反射 | 码农桃花源 Reflect 为什么慢 | Legendtkl 浅谈 Go 语言反射实现原理 | Draveness 语言陷阱 我为什么放弃 Go 语言 | CSDN Go 语言的那些坑 | RyuGou Go 语言的那些坑（二） | RyuGou Go 语言的那些坑（三）- Golang 错题集 | RyuGou 如何避开 Go 中的各种陷阱 | newton 【必看】Go的50度灰：Golang新开发者要注意的陷阱和常见错误 | 鸟窝 包管理 Go Modules 不完全教程 | Golang 成神之路 Go Modules 不完全教程 - Golang Inside | 知乎专栏 Go Modules 使用教程 | SegmentFault Using Go Modules | The Go Blog 拜拜了，GOPATH君！新版本 Golang 的包管理入门教程 | 知乎 Go module 机制下升级 major 版本号的实践 | TonyBai 微博@小弟调调的几篇教程 设计模式 [译]Go开发中一些有用的模式 | 鸟窝 明白了，原来 Go Web 框架中的中间件都是这样实现的 | 鸟窝 Go 语言的修饰器编程 | 酷壳 CoolShell Go Patterns - GitBook go-patterns - tmrts | Github 写扩展性好的代码：函数 | Legendtkl 微服务 go-micro go-kit kite go-chassis 性能测试、调试 深度解密 Go 语言之 pprof | 码农桃花源 Go 的调试工具: gdb vs dlv | TY·Loafer Golang程序调试工具介绍(gdb vs dlv) | lday go benchmark 实践与原理 | Go中国 Golang 之 GDB 调试 | 胡伟煌 使用 pprof 比较两个时间点的内存占用 | 鸟窝 unsafe 指针 Go unsafe Pointer | 飞雪无情 Go 之 unsafe.Pointer &amp;&amp; uintptr 类型 | 开源中国 Go 语言 unsafe 的妙用 | Go 语言中文网 高效使用 Go 中的指针 | 简书 随机数 一步步提升 Go 语言生成随机字符串的效率 | 飞雪无情 init 函数 每个包可以包含任意多个init函数，这些函数都会在程序执行开始的时候被调用。所有被编译器发现的init函数都会安排在main函数之前执行。init函数用在设置包、初始化变量或其他要在程序运行前优先完成的引导工作。——《Go 语言实战》 Go 的 init 函数会被执行几次？| Bingo Huang 五分钟理解 golang 的 init 函数 | 知乎 Go 中的 init 函数 | Go 语言中文网 函数式编程 Go 学习笔记之学习函数式编程前不要忘了函数基础 | 雪之梦技术驿站 面试题 Go 面试必考题目之 slice 篇 | Golang 中国 Go 面试必考题目之 method 篇 | Golang 中国 框架工具Web Beego 原理探究 - 初章 | 技术原始积累 Beego 原理探究 - 启动流程 | 技术原始积累 Beego Beego 学习 | Zhongfox Gin Iris Echo Macaron tango Peach Go 语言 Web 框架 Tango 中的中间件应用级别 | 风笑痴 6 款最棒的 Go 语言 Web 框架简介 | Go 语言中文网 爬虫 colly - Elegant Scraper and Crawler Framework for Golang | Github 静态建站 Hugo - 静态建站 | Github Hugo: A Fast And Flexible Static Site Generator Built In GoLang | spf13 Pugo gohttpserver - HTTP Static File Server | Github PPT 写给程序员看的“幻灯片”制作教程 - 谢伟 | 知乎 数据库 gorm | Github gorm.io GORM 指南 | gorm.io GORM 中文文档 Xorm 配置管理 Viper - 配置管理| Github goconfig - 无闻 | Github go-ini/ini - 无闻 | Github RPC gRPC RPCX Dubbo for Go，Ready for Now. | 阿里巴巴中间件 程序员如何用 gRPC 谈一场恋爱 | 腾讯技术工程 gRPC 及相关介绍 | 我要煎鱼说 包管理 Gopm.io gopm | Github 性能测试 GoMock - Github cweill/gotests - Generate Go tests from your source code | Github 【译】Go 性能分析工具工具和手段 | 鸟窝 性能测试应该怎么做？| 酷壳 CoolShell Nitro - 性能分析| Github Nitro : A Quick And Simple Profiler For Golang | spf13 资源监控 跨平台系统监控库 - gopsutils | 紫川秀的博客 gopsutil - psutil for golang | Github grmon - Command line monitoring for goroutines | Github fswatch - 文件变更监控，跨平台 命令行 如何使用 Golang 编写漂亮的命令行工具 | 紫川秀的博客 cobra - spf13 | Github GoTTY：基于 Go 语言的 Linux 终端 Web 共享 | 知乎 gotty | Share your terminal as a web application go-sh - 替代 os/exec 执行命令 | Github go-homedir - 替代 os/user，支持交叉编译 | Github SSH gossh - 极简的 ssh 管理工具，支持多台主机、远程执行命令、传递文件 | Github 日志 log Package log glog - golang | Github pass-lager - go-chassis | Github log - lexkong | Github Logrus - sirupsen | Github Golang 日志之 logrus 的使用 | 紫川秀的博客 数据可视化 go-echarts - The adorable charts library for Golang go-echarts | Github go-echarts 开源啦 - chenjiandongx | 知乎专栏 其他 Go 编写的一些常用小工具 | 漠然 Now - a time toolkit for golang | Github taskino - 老钱的 Go 分布式任务调度框架 | Github Create A Real Time Chat App With Golang, Angular and websockets Go Walker - Go 项目 API 搜索 | Github Gogs - 自建 Git 服务 | Github fswatch - 监控文件变更，触发命令 | Github 使用 fswatch 工具进行 Golang 的热编译 | 开源中国 com - Common Functions by 无闻 | Github Consul Guide - legendtkl | Github godag - legendtkl | Github bloomfilter - legendtkl | Github bitmap - legendtkl | Github gpool.v1 - legendtkl | Github 构建 Golang 程序最小 Docker 镜像 | 紫川秀的博客 2. Docker容器网络 深入理解容器网络 | Zhongfox 从 Docker 到 Kubernetes 中的容器网络图书资料分享 | Jimmy Song Kubernetes中的 CI/CD | Jimmy Song containerd dockerd、contaierd、containerd-shim、runC通信机制分析 | CSDN 谈谈docker，containerd，runc，docker-shim之间的关系 | CSDN 常见报错 About docker login in Ubuntu 18.04 | CSDN 相关文章 使用 docker-compose 一键部署 Gitlab | 民工哥技术之路 通过 seafile 搭建私有云存储平台 | cpper 使用 Docker+Seafile 搭建私有云存储 | DiskSing 3. Kubernetes文章 kubernetes 资源管理概述 | Cizixs 面向 Kubernetes 编程：Kubernetes 是下一代操作系统 | ServiceMesher 面向 Kubernetes 编程： Kubernetes 是下一代操作系统 | Github 腾讯云容器团队内部 Istio 专题分享 | ServiceMesher K8s 架构 谈 Kubernetes 的架构设计与实现原理 | 真没什么逻辑 从 Kubernetes 中的对象谈起 | 真没什么逻辑 kubernetes 简介：kube-dns 和服务发现 | Cizixs Pod 详解 Kubernetes Service 的实现原理 | 真没什么逻辑 从外部访问Kubernetes中的Pod 你需要知道的访问Pod的5种方式 | CSDN Service 详解 Kubernetes Service 的实现原理 | 真没什么逻辑 etcd raft 一致性算法 | Cizixs raft一致性算法详解 | RyuGou 高可用分布式键值存储 etcd 的原理（一）| 真没什么逻辑 高可用分布式键值存储 etcd 的原理（二）| 真没什么逻辑 Ingress Kubernetes Ingress 日志分析与监控的最佳实践 | 阿里系统软件技术 4. 数据库SQL 查询数据库，你还在 Select * 吗？| Python 网络爬虫与数据挖掘 图解 MySQL 内连接、外连接、左连接、右连接、全连接 | CSDN 深入理解SQL的四种连接-左外连接、右外连接、内连接、全连接 | 脚本之家 SQL的几种连接：内连接、左联接、右连接、全连接、交叉连接 | 博客园 MySQL开发规范 一份完整的 MySQL 开发规范，进大厂必看！| Java技术栈 索引 【面试现场】为什么 MySQL 数据库要用 B+ 树存储索引？| 五分钟学算法 为什么 MySQL 用 B+ 树做索引而不用 B 树或红黑树 | CSDN MySQL 索引设计概要 | 真没什么逻辑 数据库引擎 MyISAM 与 InnoDB 性能测试对比 | TY·Loafer 『浅入浅出』MySQL 和 InnoDB | 真没什么逻辑 『浅入深出』MySQL 中事务的实现 | Draveness.me 秒懂 InnoDB 的锁 | RyuGou MySQL FAQ 系列 — 新手必看：一步到位之InnoDB | 老叶茶馆 锁的优化 大牛总结的 MySQL 锁优化 | 51CTO技术栈 SQL 优化 MySQL 的 SQL 性能优化总结 | RyuGou Redis 为什么单线程的 Redis 却能支撑高并发？| 51CTO 技术栈 使用 Go 语言读写 Redis 协议 | 鸟窝 Benchmark Go 生态圈的 K/V 数据库 benchmark | 鸟窝 分布式场景的数据一致性 CAP 定理的含义 | 阮一峰 一致性哈希算法 - 虚拟节点 | 博客园 分布式事务的实现原理 | 真没什么逻辑 常用的分布式事务解决方案介绍有多少种？| 网易云 5. TCP/IP 为什么 TCP 建立连接需要三次握手 | 面向信仰编程 “三次握手，四次挥手”你真的懂吗？| 码农桃花源 tcpdump 示例教程 | 鸟窝 感受一把面试官通过一道题目引出的关于 TCP 的 5 个连环炮！| 石杉的架构笔记 TCP 的那些事儿（上）| 酷壳 CoolShell TCP 的那些事儿（下）| 酷壳 CoolShell TCP 是什么？面试时必须知道吗？| Gitchat 6. 数据结构 《数据结构与算法之美》代码 | Github 栈与队列 栈与队列 | 五分钟学算法 堆 堆其实是个很简单的数据结构 | 算法爱好者 哈希 Hash HashMap？面试？我是谁？我在哪 | Java 编程 深入理解 hash 结构的另一种形式 —— 开放地址法 | 码洞 二叉树相关 【必看】浅谈AVL树,红黑树,B树,B+树原理及应用（转）| 博客园 二叉查找树、平衡二叉树（AVLTree）和平衡多路查找树（B-Tree），B+树 | CSDN 一组动画彻底理解二叉树遍历 | 五分钟学算法 学习二分搜索树 | 五分钟学算法 红黑树 30 张图带你彻底理解红黑树 | 五分钟学算法 哈夫曼树 哈夫曼树 | 博客园 图论 图论基础与图存储结构 | 五分钟学算法 汇总 最常用的经典数据结构和算法汇总 | 程序员私房菜 那些你必须要掌握的的经典数据结构和算法汇总 | Java 技术驿站 7. 算法 面试常见手撕模板题以及笔试模板总结(附带少数ACM入门算法)-ZXZxin | Github 剑指 Offer 题解 | Github 设计模式 | Github 排序 十大经典排序算法 | 五分钟学算法 快速幂 快速幂讲解 | 博客园 正则表达式 正则表达式 | Ryugou 除法取模 取模运算 | CSDN 除法取模 | CSDN ACM技巧——为何要对 1000000007 取模 | CSDN 取模运算的性质 | CSDN 最长回文子串 Leetcode（5）-最长回文子串（包含动态规划以及Manacher算法） 随机数生成器 随机数生成器 | CSDN Top K Top K 问题解法 | Github KMP 字符串匹配 字符串匹配的 KMP 算法 | 码农有道 深度/广度优先遍历 漫画：深度优先遍历和广度优先遍历 | 算法与数据结构 蓄水池抽样算法 蓄水池抽样算法（Reservoir Sampling）| 简书 8. 操作系统基本原理 用一个创业故事串起操作系统原理（一）| 刘超的通俗云计算 用一个创业故事串起操作系统原理（二）| 刘超的通俗云计算 用一个创业故事串起操作系统原理（三）| 刘超的通俗云计算 用一个创业故事串起操作系统原理（四）| 刘超的通俗云计算 用一个创业故事串起操作系统原理（五）| 刘超的通俗云计算 CPU 关于 CPU 的一些基本知识总结 - 骏马金龙 | 算法与数据结构 So Hot ？快给 CPU 降降温！| 阿里巴巴中间件 内存 什么是堆？什么是栈？他们之间有什么区别和联系？ | 知乎 堆和栈的区别 | 简书 细说 Cache-L1/L2/L3/TLB | 知乎 什么是内存(一)：存储器层次结构 - eleven_yw | 博客园 什么是内存(二)：虚拟内存 - eleven_yw | 博客园 关于跨平台的一些认识 - eleven_yw | 博客园 浮点数 浮点计算引发的血案 | 是不是很酷 浮点数表示 | CSDN 为什么叫浮点数 | 知乎 进程/线程 当多个线程访问某个方法时，不管你通过怎样的调用方式或者说这些线程如何交替的执行，我们在主程序中不需要去做任何的同步，这个类的结果行为都是我们设想的正确行为，那么我们就可以说这个类是线程安全的 Linux 进程的生命周期 | 卡瓦邦噶 进程和线程有哪些区别和联系？| Leetcode linux中fork（）函数详解 | CSDN 什么是线程安全，你真的了解吗？| 简书 孤儿/僵尸进程 僵尸进程的产生原因和避免方法 | CSDN 孤儿进程与僵尸进程 | 博客园 I/O 模型 聊聊 Linux 五种 I/O 模型 | 简书 select、poll、epoll epoll 和 select | 软件架构设计 - 知乎专栏 epoll 重要源码注释 - lijie | Github epoll 的本质是什么？| 开源中国 【必看】epoll使用详解（精髓）| 博客园 高并发网络编程之 epoll 详解 | CSDN 我读过的最好的 epoll 讲解 | CSDN 聊聊 IO 多路复用之 select、poll、epoll 详解 | 简书 select、poll、epoll之间的区别总结 | 博客园 IO多路复用之select、poll、epoll详解 | 博客园 linux中的select和epoll模型 | 博客园 IPC Linux 下的进程间通信：共享存储 | Linux 中国 Linux 下的进程间通信：使用管道和消息队列 | Linux 中国 Linux 下的进程间通信：套接字和信号 | Linux 中国 Linux 共享内存实现机制的详解 | 脚本之家 深刻理解 Linux 进程间通信（IPC）| IBM Developer 详解共享内存以及所有进程间通信的特点 | CSDN 共享内存 进程间通信 - 共享内存（Shared Memory）| CSDN 中断 漫画 - Linux中断子系统综述 | Linux 学习 9. 计算机网络基础 计算机网络基础学习指南 | 民工哥技术之路 计算机网络 | Zhongfox 快速过一遍计算机网络 | Java3y 域名背后那些事 | LeanCloud Blog OSI 七层模型 计算机网络的各种基本概念总结（七层模型，TCP，HTTP，socket，RPC等）| CSDN 网络七层模型与四层模型区别 | 掘金 TCP TCP 拥塞控制 | 简书 TCP 对往返时延 RTT 的定义 | 知乎 TCP | Woowen HTTP HTTP 协议理解及服务端与客户端的设计实现 | Web开发 HTTP API 认证授权技术 | 酷壳 CoolShell RESTful RESTful API 设计指南 | 阮一峰 RESTful API 最佳实践 | 阮一峰 RESTful API 规范 | RyuGou 如何给老婆解释什么是Restful | Java3y RPC RPC | Zhongfox 分布式 【必看】分布式系统 | Zhongfox 云原生时代，分布式系统设计必备知识图谱（内含22个知识点）| 阿里巴巴云原生 一文读懂分布式架构知识体系（内含超全核心知识大图）| 阿里巴巴云原生 负载均衡 负载均衡（Load Balance）是集群技术（Cluster）的一种应用 负载均衡可以将工作任务分摊到多个处理单元，从而提高并发处理能力 目前最常见的负载均衡应用是 Web 负载均衡 常见的 Web 负载均衡技术包括：DNS 轮询、IP 负载均衡和 CDN 其中 IP 负载均衡可以使用硬件设备或软件方式来实现 关于负载均衡 | Zhongfox 实现负载均衡的几种方式 | CSDN Nginx 实现负载均衡的几种方式 | Markbest 除了负载均衡，Nginx 还可以做很多，限流、缓存、黑白名单等 | 民工哥技术之路 10. LinuxUNIX设计哲学Douglas McIlroy 认为的 UNIX 三条哲学： Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface. KISS: Keep it simple, stupid 相关文章 Linux 和 UNIX 的关系及区别 | C 语言中文网 UNIX 40 年：UNIX 年鉴 | 酷壳 CoolShell UNIX 传奇（上篇）| 酷壳 CoolShell UNIX 传奇（下篇）| 酷壳 CoolShell UNIX 40 年：昨天，今天和明天 | 酷壳 CoolShell C 编程 Linux C 编程一站式学习 wybuhui/c-language-with-latex - C 语言总结 | Github 如何写好 C main 函数 | Linux 中国 【整理】libc、glibc 和 glib 的关系 | 开源中国 glibc，eglibc 和 glib的区别 | NieNet libc、glibc 和 glib 的关系 | CSDN 回调函数 回调函数（callback）是什么 | 知乎 C 语言实现 Callback Function 例子 | Srefan C 语言中的回调函数（Callback Function）| CSDN C 语言回调函数 | cnblogs shell/bash Linux 工具快速教程 | Linux Tools Quick Tutorials 这些必备的 Linux Shell 知识你都掌握了吗 | Linux 学习 如何理解 Linux shell中“2&gt;&amp;1”？| 编程珠玑 Shell 十三问 | ChinaUnix bash-utils - wklken | Github 如何快速优雅的编写一个脚本程序？用这个！| GithubDaily 查找命令 Linux下的五个查找命令，有什么区别？| Linux 学习 Linux 下的文本查找技巧，你掌握了吗？| 编程珠玑 Linux 中的文件查找技巧 | 编程珠玑 find 命令高级用法 | 编程珠玑 如何查看 Linux 中文件打开情况？| 编程珠玑 常用的终端命令 Linux 常用命令 - 文本查看篇 | 编程珠玑 Linux 常用命令 - 系统状态篇 | 编程珠玑 Linux 常用命令 - 开发调试篇 | 编程珠玑 Linux 常用命令 - 解压缩篇 | 编程珠玑 ps 命令常见实用用法 | 编程珠玑 ls 命令常见实用用法 | 编程珠玑 19 个强大、有趣、又好玩的 Linux 命令！| 民工哥技术之路 screenFetch | Github 内核内核编译 内核模块编译过程探秘 | 阿里智能运维 内核源码 Linux Source Code | bootlin Linux 内核加载启动过程分析 | FlyFlyPeng 如何在 CentOS 7 中安装或升级最新的内核 | Linux 中国 性能杀手：“潜伏” 的 memset | CSDN malloc Linux 内核空间内存申请函数 kmalloc、kzalloc、vmalloc 的区别 | CSDN kmalloc、vmalloc、malloc 的区别 | CSDN RCU Linux RCU 机制详解 （透彻）| CSDN Linux内核编程 - 可睡眠锁之 SRCU | CSDN Sleepable RCU | LWN.net Read-modify-write | Wikipedia Read-Copy Update，向无锁编程进发！| airekans Linux 2.6内核中新的锁机制 - RCU | IBM Developer Linux RCU 内核同步机制 | hyuuhit Linux 2.6 内核中新的锁机制 - RCU | IBM Developer 深入理解 Linux 的 RCU 机制 - 腾讯云技术社区 | 知乎 伙伴系统 伙伴系统之伙伴系统概述 —— Linux 内存管理(十五) - JeanCheng | CSDN Linux伙伴系统(一) —— 伙伴系统的概述 | CSDN 内核调试 kprobe jprobe 环境变量 如何管理你的 Linux 环境变量 | Linux 中国 Linux 设置和删除环境变量 | CSDN Shell 环境变量以及 set、env、export 的区别 | CSDN 系统调用 [译] Linux 系统调用权威指南 | ArthurChiao’s Blog Linux 系统调用内核源码分析 | FlyFlyPeng 编译 【必看】Linux make 和 Makefile 详解 | FlyFlyPeng I/O 模型 Linux I/O 模型详解 | FlyFlyPeng Asynchronous I/O and event notification on linux 如何给女朋友解释什么是 Linux 的五种 I/O 模型？ | 漫话编程 权限 更深入的了解 Linux 权限 | Linux 中国 开机启动流程 按下开机键，Linux 做了什么？| Linux 学习 文件系统 Linux 文件系统 inode 介绍 | 卡瓦邦噶 理解 inode | 阮一峰 文件描述符（File Descriptor）简介 | SegmentFault 调试工具 【干货】Linux 工具快速教程 | Linux Tools Quick Tutorial The Linux Perf Master | Ribose Yim 穷佐罗的 Linux 书 | GitBook 性能分析利器之 perf 浅析 - WalkerTalking 系统级性能分析工具 perf 的介绍与使用 - Arnold Lu | cnblogs 在 Linux 下做性能分析 3：perf | 知乎专栏 - 软件架构设计 Linux 性能优化 9：KVM 环境 | 知乎专栏 - 软件架构设计 使用 gprof 对程序的性能分析（集合贴）| CSDN 使用 GNU profiler 来提高代码运行速度 | IBM Developer [译] tcpdump 示例教程 | 鸟窝 使用 truss、strace 或 ltrace 诊断软件的”疑难杂症” | IBM Developer 调试工具 ltrace strace ftrace 的使用 | JasonLe 使用 ltrace 跟踪库函数调用 | Liujingwen’s Blog [译] Linux 系统调用权威指南 | ARTHURCHIAO’S BLOG [译] strace 是如何工作的 | ARTHURCHIAO’S BLOG [译] ltrace 是如何工作的 | ARTHURCHIAO’S BLOG tcpdump/wireshark 抓包及分析 | ARTHURCHIAO’S BLOG 11. 值得关注的技术 Ansible Chef Puppet Saltstack AWS Firecracker Kata Container Vagrant 12. 运维开发Linux 不掉坑，不背锅！史上最全的服务器安全管理规范开源了 | 民工哥技术之路 运维工程师打怪升级进阶之路 V2.0 | 民工哥技术之路 精华文章汇总 | 民工哥技术之路 【必读】应该知道的 Linux 技巧 | 酷壳 CoolShell Linux Distribution Timeline | 酷壳 CoolShell sed 简明教程 | 酷壳 CoolShell awk 简明教程 | 酷壳 CoolShell Linux 流编辑器 sed 详解 | Linux 学习 Ansible ansible | Github Ansible Documentation Ansible 中文权威指南 20 分钟玩转 Ansible 系列手册 | 民工哥技术之路 Ansible 学习指北 | 简书 以 Chef 和 Ansible 为例快速入门服务器配置 | 高效开发运维 ansible 小结（一）ansible 的安装 | 运维之路 ansible 小结（二）ansible 架构 | 运维之路 DevOps DevOps 时代的软件过程改进探讨 | 腾讯云加社区 DevOps 和 SRE | Log4D 架构之道 - 现代发布模式 | 波波微课 从技术雷达看 DevOps 十年 - DevOps 和持续交付 | ThoughtWorks 洞见 从技术雷达看 DevOps 的十年 – 基础设施即代码和云计算 | ThoughtWorks 洞见 中台 白话中台战略：中台是个什么鬼? | ThoughtWorks 洞见 白话中台战略 2：中台到底长啥样？| ThoughtWorks 洞见 白话中台战略 3：中台的定义 | ThoughtWorks 洞见 深入浅出话中台 | 高效开发运维 CI/CD微服务架构 微服务架构 - 基础篇 | 方志朋 大规模微服务场景下的十大痛点问题定位与优化 | 云技术 唯品会容器环境与应用一键拉起——大规模微服务多环境部署管理实践 | InfoQ 微服务编排之道 | 普元 架构的本质是管理复杂性，微服务本身也是架构演化的结果 | 腾讯云+社区 一个系列： 微服务实践一: 架构图谱 | cnblogs 微服务实践二: 服务容错与降级 | cnblogs 微服务实践三: 服务编排 | cnblogs 微服务实践四: 配置管理 | cnblogs 蓝绿发布 蓝绿发布的整个部署过程 | CSDN 什么是蓝绿发布？| 简书 金丝雀发布 金丝雀发布、滚动发布、蓝绿发布到底有什么差别？关键点是什么？| 博客园 Linux 常用监控命令 参见 每天学习一个命令 | Verne in Github 10 分钟教你如何划重点 —— Systemd 最全攻略 | 阿里智能运维 20 个命令行工具监控 Linux 系统性能 | Linux Story vmstat 命令查看虚拟内存 | 51CTO # 综合 top htop glances dstat &amp; sar mpstat # 性能分析 perf # 进程 ps pstree -p pgrep pkill pidof Ctrl+z &amp; jobs &amp; fg # 网络 ip ifconfig dig ping traceroute iftop pingtop nload netstat vnstat slurm scp tcpdump # 磁盘 I/O iotop iostat # 虚拟机 virt-top # 用户 w whoami # 运行时间 uptime # 磁盘 du df lsblk # 权限 chown chmod # 服务 systemctl list-unit-files # 定位 find locate Grafana | Github 28 个 UNIX/Linux 的命令行神器 | 酷壳 CoolShell CentOS 7 查看网络带宽使用情况 | 陈沙克日志 【必看】Linux 问题故障定位，看这一篇就够了 | 民工哥技术之路 Load Average 的含义 | 博客园 Linux 性能调优工具 perf 的使用 | cpper 10 个非常赞的 Linux 网络监控工具 | Python 网络爬虫与数据挖掘 13. 文章收藏Github 学习资源 StabilityGuide - 稳定性领域知识库 | Github 【必看】fullstack tutorial - 全栈开发指南 后端架构师图谱 | Github Java 生态圈汇总 | Github Linux Linux nohup、&amp;、 2&gt;&amp;1是什么？| CSDN 一分钟了解 nohup 和 &amp; 的功效 | 架构师之路 nohup 和 &amp; 后台运行，进程查看及终止 | 博客园 深入理解 Linux 的 RCU 机制 | 腾讯云+社区 逼格高又实用的 Linux 命令，开发、运维一定要懂！| 民工哥技术之路 How to use SSHFS to Mount Remote Directories over SSH | Linuxize Java Java 中的 Copy-On-Write 容器 | 酷壳 悲观锁、乐观锁、可重入锁、自旋锁、偏向锁、轻量/重量级锁、读写锁、各种锁及其Java实现！| 知乎 云计算 云计算时代携程的网络架构变迁 | ArthurChiao’s Blog 企业云平台的昨天、今天和明天 | 世民谈云计算 十年再出发！阿里云智能总裁张建锋演讲全记录 | 阿里技术 网易云首席解决方案架构师刘超 - 网易容器云实践与云计算的那些坑 | MySlide 云计算的前世今生（上）| SegmentFault 云计算的前世今生（下）| SegmentFault IaaS，PaaS，SaaS 的区别 | 阮一峰的网络日志 云原生 CNCF 云原生时代，分布式系统设计必备知识图谱（内含22个知识点）| 阿里巴巴云原生 一文读懂分布式架构知识体系（内含超全核心知识大图）| 阿里巴巴云原生 cncf/landscape - Cloud Native Landscape | Github CNCF Cloud Native Interactive Landscape CNCF × Alibaba 云原生技术公开课 | 阿里云大学 KVM 虚拟化 Qemu，KVM，Virsh 傻傻的分不清 | 刘超的通俗云计算 我是虚拟机内核我困惑？！| 刘超的通俗云计算 我的虚拟机挂了！怎么把镜像里面的数据找回来？| 刘超的通俗云计算 虚拟化技术基础知识全面了解 | CSDN KVM 面试前总结 | CSDN KVM 虚拟化技术实践 | CSDN KVM halt-polling 机制分析 | SegmentFault virt-install xml 格式配置文件粗解 | 开源中国 QEMU QEMU 源码架构 | ChinaUnix vGPU 国内首款基于 KVM 技术的 NVIDIA vGPU 虚拟桌面解决方案正式商用 | CSDN VDI + vGPU 来的正是时候 | CSDN Kubernetes 【好文】Kubernetes 如何打赢容器之战？| 阿里技术 Kubernetes 与云原生 2018 年终总结及 2019 年展望 | Jimmy Song 【记得买书】未来架构——从服务化到云原生 | Jimmy Song Service Mesh 敖小剑的博客 Cizixs 的博客 Qcon2017实录-Service Mesh：下一代微服务 | 简书 蚂蚁金服 Service Mesh 实践探索 | InfoQ 腾讯云 Zhongfox 的博客 关于 Service Mesh 和 Kubernetes 的最前沿思考 - 十问蚂蚁金服 | InfoQ 蚂蚁金服大规模微服务架构下的 Service Mesh 探索之路 | ServiceMesher 从蚂蚁金服实践入手，带你深入了解 Service Mesh | 技术文 【必看】我为啥不看好 ServiceMesh | 架构师杨波 Serverless 一图读懂无服务器云函数 | ServerlessCloudNative 周维跃：Severless 云函数架构精解(附视频回放）| 腾讯云加社区 四种软件架构：Serverless架构、微服务架构、分布式架构、单体架构 | 云技术 35 个平台、框架、数据库细说什么是 Serverless | 数人云 什么是Serverless（无服务器）架构？| Jimmy Song OpenFaaS 快速入门指南 | Jimmy Song Google 开源的 Serverless 平台 knative 简介 | ServiceMesher 【笔记】《由浅入深 SCF 无服务器云函数实践》| CSDN 热度 3 年猛增 20 倍，Serverless &amp; 云开发的技术架构全解析 | InfoQ Istio 什么是 istio | Cizixs Openshift 之服务网格 Istio | 简书 CNCF CNCF 云原生容器生态系统概要 | Cizixs 面经 【牛客】我的 C++ 后台/基础架构岗位学习路线 | 牛客 2019年蚂蚁金服、头条、拼多多的面试总结 | JavaGuide 网易游戏 SRE 虚拟化与云计算方向面试记录 | 牛客 头条一二三面（后台开发）| 牛客 字节跳动 基础架构部 暑假实习面经 | 牛客 腾讯技术面经-后台-云计算虚拟化部门 | 程序园 云计算开发腾讯提前批一面面经 | 牛客 腾讯技术面经-后台-云计算虚拟化部门 | CSDN 招银网络面试题总结 | 牛客 蚂蚁 Java 面经 | 牛客 字节跳动 后端开发实习生（日常实习） 一、二面凉经 | 牛客 腾讯后端笔试题 | 牛客 阿里云二面 | 牛客 CyC2018 的面试经历 | InfoQ 腾讯后台面经大全 | 云栖社区 腾讯后台面经 | 牛客 腾讯云后台开发实习一面面经 | 知乎 字节跳动后台开发实习三面 | 牛客 头条面经 后台开发 | 牛客 头条/字节跳动 后端开发面经 | 牛客 字节跳动一面凉经 | 牛客 头条后台开发面经 | 牛客 2019 校招面经大汇总 | 牛客 今日头条/字节跳动 一、二面凉经（后端开发工程师）| 简书 腾讯后台开发一面 | 牛客 Golang 的一些面试题汇总 | chasiny 的博客 给以后的同学攒点golang的面经 | 牛客 后端面试进阶指南 | Github 【干货】写在19年初的后端社招面试经历(两年经验): 蚂蚁 头条 PingCAP | Github 算法求职之路分享+个人教训 蚂蚁金服offer | 知乎 蚂蚁金服面试经历 | 应届生 秋招总结分享 | 牛客 记一次蚂蚁金服的面试经历 | 纯洁的微笑 拿到头条的实习offer来回馈一波面经 | 牛客 腾讯面经攒人品（后台开发1+2+3+4+hr面）| 牛客 腾讯 CSIG 微服务框架 Java 面经 | 牛客 笔试题 【机试题】2019华为优招机试题（附超详细解答）| CSDN 2019 年华为春招实习笔试题 | CSDN 2019年华为2020届寒假招聘实习生软件类编程题Java篇 | CSDN 2019华为实习笔试题——重排字符串 | CSDN 架构 图解大型网站技术架构的历史演化过程 | 腾讯云加社区 浅谈 MVC、MVP 和 MVVM 架构模式 | Draveness Git 30 分钟让你掌握 Git 的黑魔法 | 阿里巴巴中间件 Git 自救指南 | 扣钉 Git 打标签与版本控制规范 | 掘金 UML 每一个开发人员都应该懂的 UML 规范 | 码匠笔记 其他 DaoVoice Feed43 操作系统和计组的B站视频 | 五分钟学算法 Python Python 教程 python-parallel-programming-cookbook-cn | Github - laixintao Python 并行编程 - 中文版 数据分析 - 看过复联 4 的人都在谈什么 | Legendtkl Python 如何给屏幕打印信息加上颜色 | 温欣爸比 学习方法 工作七年小结: 学习,生活及其他 | wklken 如何做好一名实习生 | 小胡子哥 “努力就会成功” | 酷壳 CoolShell 这么多年来我一直在钻研的技术 | 酷壳 CoolShell 读书 Legendtkl 的书单 测试 聊聊测试 | 小胡子哥 14. 前端Vue Nuxt.js | The Vue.js Framework Electron electron | Github awesome-electron | Github electron-quick-start | Github 用 JS 开发跨平台桌面应用，从原理到实践 | SegmentFault Electron 构建跨平台应用 Mac/Windows/Linux | 掘金 Electron 构建跨平台应用 mac/windows/linux | Poetry’s Blog Electron 中文文档 | W3Cschool electron 入门心得 | 博客园 electron-vue | Gitbook Get Started - electron-vue | Gitbook electron-quick-start | Github electron-sample-apps | Github electron-api-demos | Github Ant Design Ant Design Ant Desgin of Vue Element Element Semantic UI Semantic UI Semantic-UI | Github webpack webpack 还学不会webpack？看这篇！| SegmengFault CSS Pure.css Mock API RAP2 - Smart API manage tool 15. C/C++教程 Linux C 编程一站式学习 如何学好 C 语言 | 酷壳 CoolShell 如何学好 C++ 语言 | 酷壳 CoolShell 关键字 const, volatile 同时修饰一个变量 | CSDN 内存管理 C++ 动态内存管理 | 博客园 C++ 对象的内存布局 | 酷壳 CoolShell 内存对齐 C/C++ 内存对齐 | 神奕的博客 C/C++ 内存对齐详解 | 知乎 内存对齐的规则以及作用 | 蜗牛小居 面试 2019 C++ 开发工程师面试题大合集 | 高性能服务器开发 相关文章 C++ 避坑指南 | 腾讯技术工程 C++ 的坑真的多吗？| 酷壳 CoolShell C 语言的演变史 | 酷壳 CoolShell C++ 虚函数表解析 | 酷壳 CoolShell 十个 C++ 隐藏特性 | DiskSing 16. 工具软件Windows Installer NSIS | Open Source Windows Installer PDF 提取 【干货】3 款免费 PDF 分割/页面提取工具推荐 | 少数派 smallPDF lightPDF PDF 转换器 | PDFdo.com 格式转换 使用 pandoc 将 markdown 文档转换成 pdf | 紫川秀的博客 开源音乐播放器 代码开源，音乐无价，GitHub 上这几个高颜值音乐播放器你值得拥有！| GithubDaily 喜欢听歌的程序员，都在 GitHub 上折腾出了哪些有趣的应用？| GithubDaily 下载工具 喜欢屯视频的你，一定会喜欢 GitHub 上这几款视频下载神器！| GithubDaily 画图 有什么画 ER 关系比较好用的软件图？| 知乎 ProcessOn draw.io mermaid 文档 Mermaid Live Editor NaoTu/DesktopNaoTu - 百度脑图离线版 | Github 截图 Snipaste FSCapture 图床 PicGo - 图床客户端 输入法 Linux 下的输入法 fcitx vs ibus | Verne in Github Guitar Pro 7 Guitar Pro 7 中文破解版 | 懒得勤快 Guitar Pro 7.exe 补丁下载地址 1 补丁下载地址 2 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://abelsu7.top/tags/面试/"},{"name":"春招","slug":"春招","permalink":"https://abelsu7.top/tags/春招/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"}]},{"title":"Linux 内核笔记 1：绪论","slug":"understanding-linux-kernel","date":"2019-03-18T03:30:42.000Z","updated":"2019-09-01T13:04:11.755Z","comments":true,"path":"2019/03/18/understanding-linux-kernel/","link":"","permalink":"https://abelsu7.top/2019/03/18/understanding-linux-kernel/","excerpt":"摘自 《深入理解 Linux 内核（第三版）》","text":"摘自 《深入理解 Linux 内核（第三版）》 目录 目录 1. 与其他类 Unix 内核的比较 1.1 单块结构的内核（Monolithic kernel） 1.2 内核模块 1.3 内核线程 1.4 多线程支持 1.5 抢占式（preemptive）内核 1.6 多处理器支持 1.7 文件系统 2. 操作系统基本概念 2.1 操作系统与内核 2.2 多用户系统 2.3 用户和组 2.4 进程 2.5 内核体系结构 3. Unix 文件系统概述 4. Unix 内核概述 参考文章 1. 与其他类 Unix 内核的比较Linux 也是一种类 Unix（Unix-like）操作系统，基于 GNU GPL 协议开源。与其他一些著名的商用 Unix 内核相比，Linux 具有以下特点： 1.1 单块结构的内核（Monolithic kernel）Linux 是一个do-it-yourself自我完善的程序，由几个逻辑上独立的成分构成。大多数商用 Unix 变体也是单块结构。 1.2 内核模块大部分现代操作系统可以动态的装载或卸载部分内核代码（例如设备驱动程序）。Linux 对模块的支持很完备，可以自动按需装载或卸载模块。 1.3 内核线程内核线程（kernel thread）是一个能被独立调度的执行环境，通常在同一个地址空间执行，因此内核线程之间的上下文切换比普通进程之间的上下文切换花费的代价要少很多。 1.4 多线程支持一个多线程用户程序由很多轻量级进程（lightweight process，LWP）组成，这些进程可能对共同的地址空间、物理内存页、打开文件等进行操作。Linux 定义了自己的 LWP 版本，并把 LWP 当作基本的执行上下文，通过非标准的clone()系统调用来处理它们。 1.5 抢占式（preemptive）内核当采用“可抢占的内核”选项CONFIG_PREEMPT来编译内核时，Linux 2.6可以随意交错执行处于特权模式的执行流。 1.6 多处理器支持几种 Unix 内核变体都利用了多处理器系统。Linux 2.6支持不同存储模式的对称多处理（SMP），包括 NUMA：系统不仅可以使用多处理器，而且每个处理器可以无差别的处理任何一个任务。 1.7 文件系统Ext2/3/4、XFS、JFS等。 2. 操作系统基本概念2.1 操作系统与内核任何计算机系统都包含一个名为操作系统（Operating System，OS）的基本程序集合。在这个集合里，最重要的程序称为内核（kernel）。 当操作系统启动时，内核被装入到 RAM 中，内核中包含了系统运行所必需的核心过程（procudre）。 操作系统必须完成两个主要目标： 与硬件部分交互，对外提供服务 为用户程序提供执行环境 一些操作系统允许所有的用户程序都直接与硬件部分进行交互（例如 MS-DOS）。与此相反，类 Unix 操作系统把与计算机硬件相关的所有底层细节都对用户程序隐藏起来。 当程序想使用硬件资源时，必须向操作系统发出请求，由内核对这个请求进行评估。 如果允许，则内核将代表应用程序与相关的硬件部分进行交互。 为了实现这种机制，硬件为 CPU 引入了至少两种不同的执行模式： 用户程序的非特权模式，即用户态（User Mode） 内核的特权模式，即内核态（Kernel Mode） 2.2 多用户系统多用户系统（multiuser system）就是一台能并发和独立的执行分别属于两个或多个用户应用程序的计算机： 并发（concurrently）意味着几个应用程序能够同时处于活动状态并竞争各种资源 独立（independently）意味着每个应用程序能执行自己的任务，而无需考虑其他用户的应用程序在干些什么 2.3 用户和组在多用户系统中，每个用户在机器上都有一个私有空间。操作系统必须保证用户空间的私有部分仅仅对其拥有者可见。 所有的用户由一个唯一的用户标识符（User ID，UID）来标识。而为了和其他用户有选择的共享资料，每个用户都是一个或多个用户组的一名成员，用户组由唯一的用户组标识符（user group ID）标识，每个文件也恰好与一个用户组相对应。 任何类 Unix 操作系统都有一个超级用户root，系统管理员必须以root的身份登录 2.4 进程一个进程（process）可以定义为：程序执行时的一个实例，或一个运行程序的“执行上下文”。 在传统的操作系统中，一个进程在地址空间（address space）中执行一个单独的指令序列。地址空间是允许进程引用的内存地址集合。 现代操作系统允许具有多个执行流的进程，即在相同的地址空间可执行多个指令序列 几个进程能并发的执行同一程序，而同一进程能顺序的执行几个程序。允许进程并发活动的系统称为多道程序系统（multiprogramming）或多处理系统（multiprocessing）。 Unix 是具有抢占式进程的多处理操作系统，即使没有用户登录或者程序运行，也会一直有一些系统进程在监视外围设备。例如有几个进程在监听系统终端等待用户登录。 类 Unix 操作系统采用进程/内核模式。每个进程都自认为它是系统中唯一的进程，可以独占操作系统所提供的服务。只要进程发出系统调用，硬件就会把特权模式由用户态变成内核态，然后进程以非常有限的目的开始一个内核过程的执行。一旦这个请求得到满足，内核将迫使硬件返回到用户态，而进程将从系统调用的下一条指令继续执行。 2.5 内核体系结构如前所述，大部分 Unix 内核是单块结构：每一个内核层都被集成到整个内核程序中，并代表当前进程在内核态下运行。 相反，微内核（microkernel）操作系统只需要内核有一个很小的函数集，通常包括几个同步原语、一个简单的调度程序和进程间通信机制 为了达到微内核理论上的诸多优点而不影响性能，Linux 内核提供了模块（module）。模块是一个目标文件，其代码可以在运行时链接到内核或从内核解除链接。 这种目标代码通常由一组函数组成，用来实现文件系统、驱动程序或其他内核上层功能 与微内核操作系统的外层不同，模块不是作为一个特殊的进程执行的。相反，与任何其他静态链接的内核函数一样，模块代表当前进程在内核态下执行。 使用模块（module）的主要优点如下： 模块化方法 平台无关性 节省内存使用 无性能损失 3. Unix 文件系统概述4. Unix 内核概述更新中… 参考文章 《深入理解 Linux 内核（第三版）》 Linux和UNIX的关系及区别（详解版）| C 语言中文网 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令使用 GNU Global 在 VS Code 中阅读内核源码Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"Kernel","slug":"Kernel","permalink":"https://abelsu7.top/tags/Kernel/"}]},{"title":"Kubernetes 实践简明指南","slug":"k8s-quick-guides","date":"2019-03-17T17:33:40.000Z","updated":"2019-09-01T13:04:11.420Z","comments":true,"path":"2019/03/18/k8s-quick-guides/","link":"","permalink":"https://abelsu7.top/2019/03/18/k8s-quick-guides/","excerpt":"摘自 Kubernetes 从上手到实践 | 掘金小册","text":"摘自 Kubernetes 从上手到实践 | 掘金小册 目录1. Kubernetes 基础概念 Node：工作节点，可以是物理机或虚拟机，当状态满足要求后达到Ready状态 Deployment：部署，一种对期望状态的描述 Pod：集群中可调度的最小调度单元，可包含多个容器 Container Runtime：容器运行时，这里默认为 Docker 2. Kubernetes 整体架构C/S 架构从宏观上看，K8S 遵循 C/S 架构，可以用下面的图来表示： +-------------+ | | | | +---------------+ | | +-----&gt; | Node 1 | | Kubernetes | | +---------------+ +-----------------+ | Server | | | CLI | | | | +---------------+ | (Kubectl) |-----------&gt;| ( Master ) |&lt;------+-----&gt; | Node 2 | | | | | | +---------------+ +-----------------+ | | | | | | +---------------+ | | +-----&gt; | Node 3 | | | +---------------+ +-------------+ MasterMaster是整个 K8S 集群的大脑，他有几个重要的功能： 接收：外部的请求和集群内部的通知反馈 发布：对集群整体的调度和管理 存储：存储集群所需持久化的状态信息 上述功能通过一些组件来共同完成，我们称其为Control Plane： +----------------------------------------------------------+ | Master | | +-------------------------+ | | +-------&gt;| API Server |&lt;--------+ | | | | | | | | v +-------------------------+ v | | +----------------+ ^ +--------------------+ | | | | | | | | | | Scheduler | | | Controller Manager | | | | | | | | | | +----------------+ v +--------------------+ | | +------------------------------------------------------+ | | | | | | | Cluster state store | | | | | | | +------------------------------------------------------+ | +----------------------------------------------------------+ Master主要包含以下几个重要的组成部分： 1. Cluster state store用来存储集群所有需要持久化的状态，并且提供watch的功能支持，可以快速的通知各组件的变更等操作。 目前 Kubernetes 的存储层选择是etcd，所以一般情况下，我们直接以etcd来代表集群状态存储服务，即将所有状态存储到etcd实例中。 2. API Server这是整个集群的入口，类似于人体的感官，接收外部的信号和请求，并将相应的信息写入到etcd中。 为了保证安全，API Server 还提供了认证相关的功能，用于判断客户端是否有权限进行操作。API Server 支持多种认证方法，不过一般情况下，我们使用x509证书来进行认证。 API Server 的目标是成为一个极简的 Server，只提供REST操作，更新etcd，并充当着集群的网关。至于其他的业务逻辑，则通过插件或者其他组件来实现 3. Controller ManagerController Manager 大概是 K8S 集群中最繁忙的部分，它在后台运行着许多不同的控制器进程，用来调节集群的状态。 当集群的配置发生改变时，控制器就会朝着预期的状态开始工作。 4. SchedulerScheduler 是集群的调度器，它会持续关注集群中未被调度的 Pod，并根据资源可用性、节点亲和性或是其他一些限制条件，通过绑定的 API 将 Pod 调度/绑定到 Node 上。 在这个过程中，调度程序一般只考虑调度开始时 Node 的状态，而不考虑在调度过程中 Node 的状态变化 Node与Master相对应，可以将Node简单理解为加入集群中的机器，它有以下几个核心组件： +--------------------------------------------------------+ | +---------------------+ +---------------------+ | | | kubelet | | kube-proxy | | | | | | | | | +---------------------+ +---------------------+ | | +----------------------------------------------------+ | | | Container Runtime (Docker) | | | | +---------------------+ +---------------------+ | | | | |Pod | |Pod | | | | | | +-----+ +-----+ | |+-----++-----++-----+| | | | | | |C1 | |C2 | | ||C1 ||C2 ||C3 || | | | | | | | | | | || || || || | | | | | +-----+ +-----+ | |+-----++-----++-----+| | | | | +---------------------+ +---------------------+ | | | +----------------------------------------------------+ | +--------------------------------------------------------+ 1. kubeletKubelet实现了集群中最重要的关于 Node 和 Pod 的控制功能。 K8S 原生的执行模式是操作应用程序的容器，基于这种模式，可以让应用程序之间相互隔离，互不影响。 此外，由于是操作容器，所以应用程序和主机之间也是相互隔离的，在任何容器运行时（比如 Docker）上都可以部署和运行。 K8S 将Pod作为可调度的基本单位，Pod可以是一组容器（也可以包含存储卷），它分离开了构建时和部署时的关注点： 构建时：重点关注某个容器是否能正确构建，如何快速构建 部署时：关心某个应用程序的服务是否可用，是否符合预期，依赖的相关资源是否都能访问到 这种隔离的模式，可以很方便的将应用程序与底层的基础设施解耦，极大提高了集群扩/缩容、迁移的灵活性 之前提到Master的Scheduler组件，它会调度未绑定的 Pod 到符合条件的 Node 上。至于最终该 Pod 是否能运行于 Node 上，则是由kubelet来决定。 2. Container Runtime容器运行时最主要的功能是下载镜像和运行容器，最常见的实现是Docker，目前还有其他一些实现，例如rkt、cri-o等。 K8S 提供了一套通用的容器运行时接口 CRI (Container Runtime Interface)，凡是符合这套标准的容器运行时实现，都可以在 K8S 上使用。 3. kube-proxy要想访问某个服务，要么通过域名，要么通过 IP 地址。而每个 Pod 在创建后都有一个虚拟 IP，在 K8S 中有一个抽象的概念叫做Service。kube-proxy提供的便是代理的服务，让我们可以通过Service访问到 Pod。 实际的工作原理是：K8S 会在每个 Node 上启动一个kube-proxy进程，通过编排iptables规则来达到上述效果 3. 搭建 Kubernetes 集群 略。参见 使用 kubeadm 搭建 Kubernetes 集群 | 苏易北 4. 使用 kubectl 管理集群首先在终端下执行kubectl： &gt; kubectl kubectl controls the Kubernetes cluster manager. Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/ Basic Commands (Beginner): create Create a resource from a file or from stdin. expose Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service run Run a particular image on the cluster set Set specific features on objects Basic Commands (Intermediate): explain Documentation of resources get Display one or many resources edit Edit a resource on the server delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage the rollout of a resource scale Set a new size for a Deployment, ReplicaSet, Replication Controller, or Job autoscale Auto-scale a Deployment, ReplicaSet, or ReplicationController Cluster Management Commands: certificate Modify certificate resources. cluster-info Display cluster info top Display Resource (CPU/Memory/Storage) usage. cordon Mark node as unschedulable uncordon Mark node as schedulable drain Drain node in preparation for maintenance taint Update the taints on one or more nodes Troubleshooting and Debugging Commands: describe Show details of a specific resource or group of resources logs Print the logs for a container in a pod attach Attach to a running container exec Execute a command in a container port-forward Forward one or more local ports to a pod proxy Run a proxy to the Kubernetes API server cp Copy files and directories to and from containers. auth Inspect authorization Advanced Commands: diff Diff live version against would-be applied version apply Apply a configuration to a resource by filename or stdin patch Update field(s) of a resource using strategic merge patch replace Replace a resource by filename or stdin wait Experimental: Wait for a specific condition on one or many resources. convert Convert config files between different API versions Settings Commands: label Update the labels on a resource annotate Update the annotations on a resource completion Output shell completion code for the specified shell (bash or zsh) Other Commands: api-resources Print the supported API resources on the server api-versions Print the supported API versions on the server, in the form of &quot;group/version&quot; config Modify kubeconfig files plugin Provides utilities for interacting with plugins. version Print the client and server version information Usage: kubectl [flags] [options] Use &quot;kubectl &lt;command&gt; --help&quot; for more information about a given command. Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands). 基础配置首先来看~/.kube/config配置文件的内容（以minikube为例）： &gt; ls $HOME/.kube/config /home/tao/.kube/config &gt; cat $HOME/.kube/config apiVersion: v1 clusters: - cluster: certificate-authority: /home/tao/.minikube/ca.crt server: https://192.168.99.101:8443 name: minikube contexts: - context: cluster: minikube user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: client-certificate: /home/tao/.minikube/client.crt client-key: /home/tao/.minikube/client.key 可以看出，$HOME/.kube/config中主要包含： K8S 集群的 API 地址 用于认证的证书地址 如果想指定配置文件路径，可以使用--kubeconfig或者环境变量KUBECONFIG来传递。 另外如果你并不想使用配置文件的话，也可以在命令行直接传递相关参数来使用： &gt; kubectl --client-key=&#39;/home/tao/.minikube/client.key&#39; --client-certificate=&#39;/home/tao/.minikube/client.crt&#39; --server=&#39;https://192.168.99.101:8443&#39; get nodes NAME STATUS ROLES AGE VERSION minikube Ready master 2d v1.11.3 kubectl get使用kubectl get nodes命令查看集群中的所有节点： &gt; kubectl get nodes NAME STATUS ROLES AGE VERSION abelsu7-ubuntu Ready master 20d v1.13.3 centos-1 Ready &lt;none&gt; 20d v1.13.3 centos-2 Ready &lt;none&gt; 20d v1.13.3 传递-o wide/yaml/json可以得到不同格式的输出： &gt; kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME abelsu7-ubuntu Ready master 20d v1.13.3 xxx.xxx.xxx.xxx &lt;none&gt; Ubuntu 18.04.1 LTS 4.15.0-38-generic docker://18.6.1 centos-1 Ready &lt;none&gt; 20d v1.13.3 xxx.xxx.xxx.xxx &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.14.4.el7.x86_64 docker://18.9.2 centos-2 Ready &lt;none&gt; 20d v1.13.3 xxx.xxx.xxx.xxx &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.14.4.el7.x86_64 docker://18.9.1 当使用-o json将内容以 JSON 格式输出时，可以配合jq进行内容提取，例如： &gt; kubectl get nodes -o json | jq &quot;.items[] | {name: .metadata.name} + .status.nodeInfo&quot; { &quot;name&quot;: &quot;abelsu7-ubuntu&quot;, &quot;architecture&quot;: &quot;amd64&quot;, &quot;bootID&quot;: &quot;efeb7bb0-9c57-40d1-b592-47c0974db9c5&quot;, &quot;containerRuntimeVersion&quot;: &quot;docker://18.6.1&quot;, &quot;kernelVersion&quot;: &quot;4.15.0-38-generic&quot;, &quot;kubeProxyVersion&quot;: &quot;v1.13.3&quot;, &quot;kubeletVersion&quot;: &quot;v1.13.3&quot;, &quot;machineID&quot;: &quot;c7eeb3f409394ad79a08c27afcc8958c&quot;, &quot;operatingSystem&quot;: &quot;linux&quot;, &quot;osImage&quot;: &quot;Ubuntu 18.04.1 LTS&quot;, &quot;systemUUID&quot;: &quot;314AB8CC-38BC-11E6-9C43-BC0000500000&quot; } { &quot;name&quot;: &quot;centos-1&quot;, &quot;architecture&quot;: &quot;amd64&quot;, &quot;bootID&quot;: &quot;f109d499-2dea-45e8-834a-907f78d267bc&quot;, &quot;containerRuntimeVersion&quot;: &quot;docker://18.9.2&quot;, &quot;kernelVersion&quot;: &quot;3.10.0-862.14.4.el7.x86_64&quot;, &quot;kubeProxyVersion&quot;: &quot;v1.13.3&quot;, &quot;kubeletVersion&quot;: &quot;v1.13.3&quot;, &quot;machineID&quot;: &quot;b9d5ec44cf284913b48d1ca1a7662c83&quot;, &quot;operatingSystem&quot;: &quot;linux&quot;, &quot;osImage&quot;: &quot;CentOS Linux 7 (Core)&quot;, &quot;systemUUID&quot;: &quot;E364DF48-5F20-11E6-8BF7-57717FCC0F00&quot; } { &quot;name&quot;: &quot;centos-2&quot;, &quot;architecture&quot;: &quot;amd64&quot;, &quot;bootID&quot;: &quot;8fadfee7-e09b-4ee9-81c2-d5464f60a4c0&quot;, &quot;containerRuntimeVersion&quot;: &quot;docker://18.9.1&quot;, &quot;kernelVersion&quot;: &quot;3.10.0-862.14.4.el7.x86_64&quot;, &quot;kubeProxyVersion&quot;: &quot;v1.13.3&quot;, &quot;kubeletVersion&quot;: &quot;v1.13.3&quot;, &quot;machineID&quot;: &quot;bbe91187ab474caebff29ffc64bcd487&quot;, &quot;operatingSystem&quot;: &quot;linux&quot;, &quot;osImage&quot;: &quot;CentOS Linux 7 (Core)&quot;, &quot;systemUUID&quot;: &quot;A1C63AE4-5F04-11E6-88F2-108D9A211300&quot; } 此方法可以得到Node的基础信息。 kubectl api-resources可以使用kubectl api-resources查看服务端支持的 API 资源及其别名、描述等信息： &gt; kubectl api-resources NAME SHORTNAMES APIGROUP NAMESPACED KIND bindings true Binding componentstatuses cs false ComponentStatus configmaps cm true ConfigMap endpoints ep true Endpoints events ev true Event limitranges limits true LimitRange namespaces ns false Namespace nodes no false Node persistentvolumeclaims pvc true PersistentVolumeClaim persistentvolumes pv false PersistentVolume pods po true Pod podtemplates true PodTemplate replicationcontrollers rc true ReplicationController resourcequotas quota true ResourceQuota secrets true Secret serviceaccounts sa true ServiceAccount services svc true Service mutatingwebhookconfigurations admissionregistration.k8s.io false MutatingWebhookConfiguration validatingwebhookconfigurations admissionregistration.k8s.io false ValidatingWebhookConfiguration customresourcedefinitions crd,crds apiextensions.k8s.io false CustomResourceDefinition apiservices apiregistration.k8s.io false APIService controllerrevisions apps true ControllerRevision daemonsets ds apps true DaemonSet deployments deploy apps true Deployment replicasets rs apps true ReplicaSet statefulsets sts apps true StatefulSet tokenreviews authentication.k8s.io false TokenReview localsubjectaccessreviews authorization.k8s.io true LocalSubjectAccessReview selfsubjectaccessreviews authorization.k8s.io false SelfSubjectAccessReview selfsubjectrulesreviews authorization.k8s.io false SelfSubjectRulesReview subjectaccessreviews authorization.k8s.io false SubjectAccessReview horizontalpodautoscalers hpa autoscaling true HorizontalPodAutoscaler cronjobs cj batch true CronJob jobs batch true Job certificatesigningrequests csr certificates.k8s.io false CertificateSigningRequest leases coordination.k8s.io true Lease events ev events.k8s.io true Event daemonsets ds extensions true DaemonSet deployments deploy extensions true Deployment ingresses ing extensions true Ingress networkpolicies netpol extensions true NetworkPolicy podsecuritypolicies psp extensions false PodSecurityPolicy replicasets rs extensions true ReplicaSet networkpolicies netpol networking.k8s.io true NetworkPolicy poddisruptionbudgets pdb policy true PodDisruptionBudget podsecuritypolicies psp policy false PodSecurityPolicy clusterrolebindings rbac.authorization.k8s.io false ClusterRoleBinding clusterroles rbac.authorization.k8s.io false ClusterRole rolebindings rbac.authorization.k8s.io true RoleBinding roles rbac.authorization.k8s.io true Role priorityclasses pc scheduling.k8s.io false PriorityClass storageclasses sc storage.k8s.io false StorageClass volumeattachments storage.k8s.io false VolumeAttachment kubectl explain可以使用kubectl explain &lt;API&gt;来查看 API 的相应说明： &gt; kubectl explain nodes KIND: Node VERSION: v1 DESCRIPTION: Node is a worker node in Kubernetes. Each node will have a unique identifier in the cache (i.e. in etcd). FIELDS: apiVersion &lt;string&gt; APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#resources kind &lt;string&gt; Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds metadata &lt;Object&gt; Standard object&#39;s metadata. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata spec &lt;Object&gt; Spec defines the behavior of a node. https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status status &lt;Object&gt; Most recently observed status of the node. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status kubectl run 之前提到，Pod 是 K8s 中最小的调度单元，所以我们无法直接在 K8s 中运行一个 container，但是可以运行一个只包含一个 container 的 Pod kubectl run的基础用法如下： Usage: kubectl run NAME --image=image [--env=&quot;key=value&quot;] [--port=port] [--replicas=replicas] [--dry-run=bool] [--overrides=inline-json] [--command] -- [COMMAND] [args...] [options] NAME和--image是必须项，分别代表此次部署的名字及所使用的镜像。而在实际使用时，推荐编写配置文件并通过kubectl create进行部署。 例如部署一个Redis实例： &gt; kubectl run redis --image=&#39;redis:alpine&#39; deployment.apps/redis created 可以看到已创建部署deployment.apps/redis created。使用kubectl get all查看发生了什么： &gt; kubectl get all NAME READY STATUS RESTARTS AGE pod/redis-7c7545cbcb-2m6rp 1/1 Running 0 30s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 32s NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/redis 1 1 1 1 30s NAME DESIRED CURRENT READY AGE replicaset.apps/redis-7c7545cbcb 1 1 1 30s 使用kubectl get all输出内容的格式，/前代表类型，/后代表名称 DeploymentDeployment是一种高级别的抽象，允许我们进行扩容、滚动更新及降级等操作。我们使用kubectl run redis --image=&#39;redis:alpine&#39;命令便创建了一个名为redis的Deployment，并指向了其使用的镜像为redis:alpine。 同时 K8S 会默认为其增加一些标签Label，可以添加-o wide选项进行查看： &gt; kubectl get deployment.apps/redis -o wide NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR redis 1 1 1 1 40s redis redis:alpine run=redis &gt; kubectl get deploy redis -o wide NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR redis 1 1 1 1 40s redis redis:alpine run=redis 可以将这些Label作为选择条件使用： &gt; kubectl get deploy -l run=redis -o wide NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR redis 1 1 1 1 11h redis redis:alpine run=redis Deployment的创建除了使用上述方式之外，更推荐的方式是使用yaml格式的配置文件。在配置文件中主要是声名一种预期的状态，而其他组件则负责协同调度并最终达成这种预期的状态。最后，Deployment会将Pod托管给下面将要介绍的ReplicaSet。 ReplicaSetReplicaSet是一种较低级别的结构，允许进行扩容。 之前提到了Deployment主要是声明一种预期的状态，并且会将Pod托管给ReplicaSet，而ReplicaSet则会检查当前的Pod数量及状态是否符合预期，并尽量满足这一预期。 ReplicaSet可简写为rs，通过以下命令查看： &gt; kubectl get rs -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR redis-7c7545cbcb 1 1 1 11h redis redis:alpine pod-template-hash=3731017676,run=redis Service简单来说，Service就是提供稳定访问入口的一组Pod，通过Service可以很方便的实现服务发现和负载均衡。 &gt; kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16m &lt;none&gt; Service目前有 4 种类型： ClusterIP：目前 K8s 默认的Service类型，将Service暴露于一个仅集群内可访问的虚拟 IP 上 NodePort：通过在集群内所有Node上都绑定固定端口的方式将服务暴露出来 LoadBalancer：是通过Cloud Provider创建一个外部的负载均衡器，将服务暴露出来，并且会自动创建外部负载均衡器路由请求所需的NodePort或ClusterIP ExternalName：将服务由DNS CNAME的方式转发到指定的域名上将服务暴露出来 kubectl expose&gt; kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server service/redis-server exposed &gt; kubectl get svc -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 49m &lt;none&gt; redis-server ClusterIP 10.108.105.63 &lt;none&gt; 6379/TCP 4s run=redis 现在redis-server这个Service使用的是默认类型ClusterIP，所以并不能直接从外部进行访问。需要使用port-forward的方式让它可以在集群外部访问到： &gt; kubectl port-forward svc/redis-server 6379:6379 Forwarding from 127.0.0.1:6379 -&gt; 6379 Forwarding from [::1]:6379 -&gt; 6379 Handling connection for 6379 这样在另一个本地终端上就可以通过redis-cli工具进行连接： &gt; redis-cli -h 127.0.0.1 -p 6379 127.0.0.1:6379&gt; ping PONG 当然，也可以使用NodePort方式对外暴露服务： &gt; kubectl expose deploy/redis --port=6379 --protocol=TCP --target-port=6379 --name=redis-server-nodeport --type=NodePort service/redis-server-nodeport exposed &gt; kubectl get service/redis-server-nodeport -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR redis-server-nodeport NodePort 10.109.248.204 &lt;none&gt; 6379:31913/TCP 11s run=redis 这样就可以通过任意Node上的31913端口访问到redis服务。 更新中… 参考文章 Kubernetes 从上手到实践 | 掘金小册 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Docker 实践简明指南docker build 相关疑问解惑","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/categories/Kubernetes/"}],"tags":[{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"}]},{"title":"Docker 实践简明指南","slug":"docker-quick-guides","date":"2019-03-14T13:01:12.000Z","updated":"2019-09-01T13:04:11.189Z","comments":true,"path":"2019/03/14/docker-quick-guides/","link":"","permalink":"https://abelsu7.top/2019/03/14/docker-quick-guides/","excerpt":"摘自 开发者必备的 Docker 实践指南 | 掘金小册","text":"摘自 开发者必备的 Docker 实践指南 | 掘金小册 目录 目录 1. Docker 的技术实现 Namespace CGroups Union File System 2. Docker 的理念 3. Docker 的核心组成 镜像 容器 网络 数据卷 Docker Engine docker daemon docker CLI 4. 安装 Docker docker version docker info 配置国内镜像源 5. 镜像与容器 Docker 镜像 深入镜像实现 查看镜像 镜像命名 容器的生命周期 主进程 写时复制机制 6. 镜像仓库 拉取镜像 Docker Hub 搜索镜像 管理镜像 删除镜像 7. 运行和管理容器 容器的创建和启动 创建容器 启动容器 管理容器 停止和删除容器 进入容器 连接到容器主程序 8. 为容器配置网络 容器网络 浅析 Docker 的网络实现 容器互联 暴露端口 通过别名连接 管理网络 创建网络 端口映射 9. 管理和存储数据 挂载方式 挂载文件到容器 挂载临时文件目录 使用数据卷 共用数据卷 删除数据卷 数据卷容器 备份和迁移数据卷 通过 mount 选项挂载 10. 保存和共享镜像 提交容器更改 为镜像命名 镜像的迁移 导入镜像 批量迁移 导入和导出容器 11. 通过 Dockerfile 创建镜像 关于 Dockerfile 编写 Dockerfile Dockerfile 的结构 Dockerfile 常见指令 构建镜像 12. Dockerfile 使用技巧 构建中使用变量 环境变量 合并命令 构建缓存 搭配 ENTRYPOINT 和 CMD 13. 使用 Docker Compose 管理容器 Docker Compose 安装 Docker Compose Docker Compose 的基本使用逻辑 1. Docker 的技术实现Docker 的实现，主要归结于三大技术：命名空间 (Namespaces)、控制组 (Control Groups) 和联合文件系统 (Union File System)。 实现 Docker 的三大技术 Namespace命名空间是 Linux 内核在2.4版本之后逐渐引入的一项用于进程运行隔离的模块。 和很多编程语言中命名空间的概念类似，Linux Kernel 中的 Namespace 能够将计算机资源进行切割划分，形成各自独立的空间。 就实现而言，命名空间可以分为很多具体的子系统，如User Namespace、Net Namespace、PID Namespace、Mount Namespace等等。 利用PID Namespace，Docker 就实现了容器中运行进程相互隔离这一目标。 CGroups资源控制组（常缩写为CGroups）是 Linux 内核在2.6版本后逐渐引入的一项对计算机资源进行控制的模块。 顾名思义，CGroups 的作用就是控制计算机资源。它与 Namespace 的对比如下： Namespace：以隔离进程、网络、文件系统等虚拟资源为目的 CGroups：主要做的是硬件资源的隔离 虚拟化除了制造出虚拟的环境以隔离统一物理平台运行的不同程序之外，另一大作用就是控制硬件资源的分配。CGroups的使用正是为了这样的目的。 CGroups 除了隔离硬件资源，还有控制资源分配这个关键性作用。通过 CGroups，我们可以指定任意一个隔离环境对任意资源的占用值或占用率，在很多分布式场景下会很有帮助 Union File System联合文件系统（Union File System）是一种能够同时挂载不同实际文件或文件夹到同一目录，形成一种联合文件结构的文件系统。Docker 创新性的将其引入到容器实现中，用它解决虚拟环境对文件系统占用过量、实现虚拟环境快速启停等问题。 在 Docker 中，提供了一种对 UnionFS 的改进实现，也就是 AUFS（Advanced Union File System）。 AUFS 将文件的更新挂载到旧的文件上，而不去修改那些不更新的内容（类似差量更新的概念）。这样一来，Docker 就大幅减少了虚拟文件系统对物理存储空间的占用。 2. Docker 的理念先来看一张 Docker 官方提供的容器结构设计架构图： Docker 容器结构设计架构图 与其他虚拟化实现甚至其他容器引擎不同的是，Docker 推崇一种轻量级容器结构，即一个应用一个容器。 Docker 的轻量级容器实现和虚拟机的相关参数对比如下： 属性 Docker 虚拟机 启动速度 秒级 分钟级 硬盘使用 MB 级 GB 级 性能 接近原生 较低 普通机器支撑量 数百个 几个 3. Docker 的核心组成 之前提到了 Docker 实现容器引擎的一些技术，但都是相对底层的原理实现。在 Docker 将它们进行封装后，我们并不会直接去操作它们。在 Docker 中，还另外提供了一些软件层面的概念，这才是我们操作 Docker 所针对的对象 在 Docker 的体系中，有四大基本组件（Object）： 镜像（Image） 容器（Container） 网络（Network） 数据卷（Volume） 镜像镜像（Image）也是其他虚拟化技术中常常使用的一个概念。所谓镜像，可以理解为一个只读的文件包，其中包含了虚拟环境运行最原始文件系统的内容。 Docker 的镜像与虚拟机中的镜像还是存在一定区别的。首先，Docker 利用 AUFS 作为底层文件系统实现。通过这种方式，Docker 实现了一种增量式的镜像结构： Docker 镜像的增量式分层结构 每次对镜像内容的修改，Docker 都会将这些修改写入一个新镜像层。因此，Docker 镜像实质上是无法修改的，因为所有对镜像的修改只会产生新的镜像，而不是更新原有的镜像。 容器在容器技术中，容器（Container）就是用来隔离虚拟环境的基础设施。而在 Docker 里，它也被引申为隔离出来的虚拟环境。 可以将镜像理解为编程中的类，那么容器就是类的一个实例。镜像内存放的是不可变化的东西，而当以它们为基础的容器启动后，容器内也就成为了一个“活”的空间 网络Docker 实现了强大的网络功能，我们不但能够轻松的对每个容器的网络进行配置，还可以在容器间建立虚拟网络，将多个容器包裹其中，同时与其他网络环境隔离。 另外，Docker 还可以在容器中构建独立的域名解析环境，这使得我们可以在不修改代码和配置的前提下直接迁移容器，而 Docker 会为我们完成新环境的网络适配。 对于这个功能，甚至可以在不同的物理服务器之间实现，让处在两台物理机上的两个 Docker 容器，加入到同一个虚拟网络中，形成完全屏蔽硬件的效果 数据卷得益于 Docker 底层 UnionFS 技术的支持，我们除了能够从宿主机操作系统中挂载目录之外，还可以建立独立的目录以持久化存放数据，或者在容器之间共享数据。 在 Docker 中，通过这几种方式进行数据共享或持久化的文件或目录，我们都称之为数据卷（Volume）。 Docker Engine目前这款实现容器化的工具是由 Docker 官方进行维护的，Docker 官方将其命名为 Docker Engine，同时定义其为工业级的容器引擎（Industry-standard Container Engine）。在 Docker Engine 中，实现了 Docker 技术最核心的部分——容器引擎。 docker daemon深究 Docker Engine，会发现它其实是由多个独立软件所组成的软件包。在这些程序中，最核心的就是 docker daemon 和 docker CLI。 Docker 所提供的容器管理、应用编排、镜像分发等功能，都集中在了 docker daemon 中。而我们之前所提到的镜像模块、容器模块、数据卷模块和网络模块也都实现在其中。 在操作系统中，docker daemon 通常以服务的形式运行以便静默的提供这些功能，所以我们通常称之为 Docker 服务 docker CLI在 docker daemon 管理容器等相关资源的同时，它也向外暴露了一套 RESTful API，我们能够通过这套接口对 docker daemon 中运行的容器和其他资源进行管理。 为了方便我们通过控制台对 docker daemon 进行管理，Docker Engine 直接附带了 docker CLI 这个控制台程序。 容易看出，docker daemon 和 docker CLI 组成了一个标准的 C/S 结构应用程序。而衔接这两者的，正是 docker daemon 所提供的 RESTful API 4. 安装 Docker 略。参见 CentOS 7 安装 Docker CE | 苏易北 docker version&gt; docker version Client: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:24:56 2018 OS/Arch: linux/amd64 Experimental: false Server: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:21 2018 OS/Arch: linux/amd64 Experimental: false docker info&gt; docker info Containers: 32 Running: 16 Paused: 0 Stopped: 16 Images: 33 Server Version: 18.06.1-ce Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e runc version: 69663f0bd4b60df09991c08812a60108003fa340 init version: fec3683 Security Options: apparmor seccomp Profile: default Kernel Version: 4.15.0-38-generic Operating System: Ubuntu 18.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 31.21GiB Name: abelsu7-ubuntu ID: RT3B:UYYD:MO4K:IMYS:3TG6:ZKGT:PUUK:DZBO:4FF5:KUA5:2OH7:YTDL Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false 配置国内镜像源修改/etc/docker/daemon.json（若文件不存在则直接新建）这个 Docker 服务的配置文件： { &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ] } 之后重启 Docker 使配置生效： &gt; sudo systemctl restart docker 可通过docker info来查阅当前注册的镜像源列表： &gt; docker info ## ...... Registry Mirrors: https://registry.docker-cn.com/ ## ...... 5. 镜像与容器Docker 镜像可以将 Docker 镜像理解为包含应用程序及其相关依赖的一个基础文件系统，在 Docker 容器启动的过程中，它会以只读的方式被用于创建容器的运行环境。 深入镜像实现与其他虚拟机的镜像管理不同，Docker 将镜像管理纳入到了自身设计中，也就是说，所有的 Docker 镜像都是按照 Docker 所设定的逻辑打包的，也是受到 Docker Engine 所控制的。 对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成一个 Hash 码，这是一个长度为 64 位的字符串，足以保证全球唯一性 由于镜像层都拥有唯一的编码，我们就能够区分不同的镜像层并保证它们的内容与编码是一致的，从而允许我们在镜像之间共享镜像层： 查看镜像使用docker images命令查看当前连接的 docker daemon 中存放和管理了哪些镜像： &gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis alpine a5cff96d7b8f 5 weeks ago 50.8MB k8s.gcr.io/kube-controller-manager v1.13.3 0482f6400933 5 weeks ago 146MB k8s.gcr.io/kube-proxy v1.13.3 98db19758ad4 5 weeks ago 80.3MB k8s.gcr.io/kube-apiserver v1.13.3 fe242e556a99 5 weeks ago 181MB k8s.gcr.io/kube-scheduler v1.13.3 3a6f709e97a0 5 weeks ago 79.6MB quay.io/coreos/flannel v0.11.0-amd64 ff281650a721 6 weeks ago 52.6MB ubuntu 16.04 b0ef3016420a 2 months ago 117MB influxdb latest 623f651910b3 3 months ago 238MB memcached latest 8230c836a4b3 3 months ago 62.2MB mongo 3.2 fb885d89ea5c 3 months ago 300MB mist/mailmock latest 95c29bda552f 3 months ago 299MB mist/docker-socat latest f00ed0eed13f 3 months ago 7.8MB mistce/logstash v3-3-1 0f90a36d12c8 4 months ago 730MB mistce/api v3-3-1 4a21b676352f 4 months ago 705MB mistce/nginx v3-3-1 4f55dd9b39e0 4 months ago 109MB mistce/gocky v3-3-1 ee93caf66f70 4 months ago 440MB mistce/elasticsearch-manage v3-3-1 10a48b9ea0e1 4 months ago 65.8MB mistce/ui v3-3-1 b8fdbe0ccb23 4 months ago 626MB ubuntu-with-vi-dockerfile latest 74ba87f80b96 4 months ago 169MB ubuntu-with-vi latest 9d2fac08719d 4 months ago 169MB k8s.gcr.io/coredns 1.2.6 f59dcacceff4 4 months ago 40MB ubuntu latest ea4c82dcd15a 4 months ago 85.8MB centos latest 75835a67d134 5 months ago 200MB k8s.gcr.io/etcd 3.2.24 3cab8e1b9802 5 months ago 220MB hello-world latest 4ab4c602aa5e 6 months ago 1.84kB elasticsearch 5.6.10 73e6fdf8bd4f 7 months ago 486MB mistce/landing v3-3-1 b0e433749aa9 7 months ago 532MB kibana 5.6.10 bc661616b61c 8 months ago 389MB hello-world &lt;none&gt; 2cb0d9787c4d 8 months ago 1.85kB traefik v1.5 fde722950ccf 12 months ago 49.7MB mist/swagger-ui latest 0b5230f1b6c4 12 months ago 24.8MB k8s.gcr.io/pause 3.1 da86e6ba6ca1 14 months ago 742kB rabbitmq 3.6.6-management c74093aa9895 2 years ago 179MB 镜像命名在docker images命令打印出来的内容中，我们还能看到两个与镜像命名有关的数据：REPOSITORY和TAG，这两者共同组成了 Docker 镜像的命名规则： 准确来说，Docker 镜像的命名可以分成三个部分：username、repository和tag： username：主要用于识别上传镜像的不同用户，与 Github 中的用户空间类似 repository：主要用于识别镜像的内容，形成对镜像的表意描述 tag：主要用于标记镜像的版本，方便区分镜像内容的不同细节 有的镜像没有username这个部分，表示这个镜像是由 Docker 官方所维护和提供的，就不再单独标记用户了 另外，Docker 中还有一个约定，当我们在操作中没有具体给出镜像的tag时，Docker 会采用latest作为缺省tag。 容器的生命周期下面是一张容器运行的状态流转图： 上图展示了几种常见的对 Docker 容器的操作命令，以及执行它们之后容器运行状态的变化。重点关注容器以下几个核心状态： Created：容器已创建，但尚未运行 Running：容器运行中 Paused：容器暂停运行 Stopped：容器停止运行（注意与Create的区别） Deleted：容器被删除 主进程在 Docker 的设计中，容器的生命周期其实与容器中PID为1的进程有着密切的关系。容器的启动，本质上可以理解为这个进程的启动，而容器的停止也意味着这个进程的停止，反之亦然。 当我们启动容器时，Docker 会按照镜像中的定义，启动对应的程序，并将这个程序的主进程作为容器的主进程（也就是PID为1的进程）。而当我们控制容器停止时，Docker 会向主进程发送结束信号，通知程序退出 写时复制机制Docker 的写时复制（Copy on Write）与编程中的相类似，也就是在通过镜像运行容器时，并不是马上就把镜像里的所有内容拷贝到容器所运行的沙盒文件系统中，而是利用 UnionFS 将镜像以只读的方式挂载到沙盒文件系统中。只有在容器中发生对文件的修改时，修改才会体现到沙盒环境上。 换言之，容器在创建和启动的过程中，不需要进行任何的文件系统复制操作，也不需要为容器单独开辟大量的硬盘空间，Docker 容器的启动速度也由此得到了保障 Docker 官网关于容器与镜像关系的说明 A container is launched by running an image. An image is an executable package that includes everything needed to run an application—the code, a runtime, libraries, environment variables, and configuration files.A container is a runtime instance of an image—what the image becomes in memory when executed (that is, an image with state, or a user process). You can see a list of your running containers with the command, docker ps, just as you would in Linux. 6. 镜像仓库 如果说我们把镜像的结构用 Git 项目的结构做类比，那么镜像仓库就可以看作是 Gitlab、Github 等代码托管平台，只不过 Docker 的镜像仓库托管的不是代码项目，而是镜像 借助镜像仓库这个中转站，Docker 实现了镜像的分发功能。我们可以将开发环境上所使用的镜像推送至镜像仓库，并在测试或生产环境上拉取它们，而这个过程仅需要几个命令，甚至可以自动化的完成。 拉取镜像可以使用docker pull命令拉取镜像： &gt; docker pull ubuntu Using default tag: latest latest: Pulling from library/ubuntu 124c757242f8: Downloading [===============================================&gt; ] 30.19MB/31.76MB 9d866f8bde2a: Download complete fa3f2f277e67: Download complete 398d32b153e8: Download complete afde35469481: Download complete 当没有显式指定镜像的标签时，Docker 将默认使用latest。当然，也可以使用完整的镜像名来拉取镜像： &gt; docker pull openresty/openresty:1.13.6.2-alpine 1.13.6.2-alpine: Pulling from openresty/openresty ff3a5c916c92: Pull complete ede0a2a1012b: Pull complete 0e0a11843023: Pull complete 246b2c6f4992: Pull complete Digest: sha256:23ff32a1e7d5a10824ab44b24a0daf86c2df1426defe8b162d8376079a548bf2 Status: Downloaded newer image for openresty/openresty:1.13.6.2-alpine Docker HubDocker Hub 是 Docker 官方建立的中央镜像仓库，同时也是 Docker Engine 的默认镜像仓库。 搜索镜像使用docker search命令搜索 Docker Hub 中的镜像： &gt; docker search ubuntu NAME DESCRIPTION STARS OFFICIAL AUTOMATED ubuntu Ubuntu is a Debian-based Linux operating sys… 9312 [OK] dorowu/ubuntu-desktop-lxde-vnc Docker image to provide HTML5 VNC interface … 281 [OK] rastasheep/ubuntu-sshd Dockerized SSH service, built on top of offi… 208 [OK] consol/ubuntu-xfce-vnc Ubuntu container with &quot;headless&quot; VNC session… 161 [OK] ubuntu-upstart Upstart is an event-based replacement for th… 96 [OK] ansible/ubuntu14.04-ansible Ubuntu 14.04 LTS with ansible 96 [OK] neurodebian NeuroDebian provides neuroscience research s… 56 [OK] 1and1internet/ubuntu-16-nginx-php-phpmyadmin-mysql-5 ubuntu-16-nginx-php-phpmyadmin-mysql-5 49 [OK] ubuntu-debootstrap debootstrap --variant=minbase --components=m… 40 [OK] nuagebec/ubuntu Simple always updated Ubuntu docker images w… 23 [OK] tutum/ubuntu Simple Ubuntu docker images with SSH access 19 i386/ubuntu Ubuntu is a Debian-based Linux operating sys… 17 1and1internet/ubuntu-16-apache-php-7.0 ubuntu-16-apache-php-7.0 13 [OK] ppc64le/ubuntu Ubuntu is a Debian-based Linux operating sys… 12 eclipse/ubuntu_jdk8 Ubuntu, JDK8, Maven 3, git, curl, nmap, mc, … 8 [OK] codenvy/ubuntu_jdk8 Ubuntu, JDK8, Maven 3, git, curl, nmap, mc, … 5 [OK] darksheer/ubuntu Base Ubuntu Image -- Updated hourly 5 [OK] pivotaldata/ubuntu A quick freshening-up of the base Ubuntu doc… 2 smartentry/ubuntu ubuntu with smartentry 1 [OK] 1and1internet/ubuntu-16-sshd ubuntu-16-sshd 1 [OK] paasmule/bosh-tools-ubuntu Ubuntu based bosh-cli 1 [OK] pivotaldata/ubuntu-gpdb-dev Ubuntu images for GPDB development 0 1and1internet/ubuntu-16-healthcheck ubuntu-16-healthcheck 0 [OK] ossobv/ubuntu Custom ubuntu image from scratch (based on o… 0 1and1internet/ubuntu-16-rspec ubuntu-16-rspec 0 [OK] 管理镜像要想获得镜像更详细的信息，可以使用docker inspect命令： &gt; docker inspect mongo:3.2 [ { &quot;Id&quot;: &quot;sha256:fb885d89ea5c35ac02acf79a398b793555cbb3216900f03f4b5f7dc31e595e31&quot;, &quot;RepoTags&quot;: [ &quot;mongo:3.2&quot; ], &quot;RepoDigests&quot;: [ &quot;mongo@sha256:9e09fe9e747fb0ee1e64b572818e7397eb9a73e36a2b08bcc7846e9acf0a587f&quot; ], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2018-11-16T00:55:06.547559408Z&quot;, &quot;Container&quot;: &quot;16a23b0d45ef66220aec0a2e542ff527da9da07889d4d862087630912d9ad86f&quot;, &quot;ContainerConfig&quot;: { &quot;Hostname&quot;: &quot;16a23b0d45ef&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: { &quot;27017/tcp&quot;: {} }, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;, &quot;GOSU_VERSION=1.10&quot;, &quot;JSYAML_VERSION=3.10.0&quot;, &quot;GPG_KEYS=DFFA3DCF326E302C4787673A01C4E7FAAAB2461C \\t42F3E95A2C4F08279C4960ADD68FA50FEA312927&quot;, &quot;MONGO_PACKAGE=mongodb-org&quot;, &quot;MONGO_REPO=repo.mongodb.org&quot;, &quot;MONGO_MAJOR=3.2&quot;, &quot;MONGO_VERSION=3.2.21&quot; ], &quot;Cmd&quot;: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop) &quot;, &quot;CMD [\\&quot;mongod\\&quot;]&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:d7430950b72ba7ecb5986396f9a3404b5b0d88c2ba39eb7f2d4b51b002db00ea&quot;, &quot;Volumes&quot;: { &quot;/data/configdb&quot;: {}, &quot;/data/db&quot;: {} }, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: [ &quot;docker-entrypoint.sh&quot; ], &quot;OnBuild&quot;: [], &quot;Labels&quot;: {} }, &quot;DockerVersion&quot;: &quot;17.06.2-ce&quot;, &quot;Author&quot;: &quot;&quot;, &quot;Config&quot;: { &quot;Hostname&quot;: &quot;&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: { &quot;27017/tcp&quot;: {} }, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;, &quot;GOSU_VERSION=1.10&quot;, &quot;JSYAML_VERSION=3.10.0&quot;, &quot;GPG_KEYS=DFFA3DCF326E302C4787673A01C4E7FAAAB2461C \\t42F3E95A2C4F08279C4960ADD68FA50FEA312927&quot;, &quot;MONGO_PACKAGE=mongodb-org&quot;, &quot;MONGO_REPO=repo.mongodb.org&quot;, &quot;MONGO_MAJOR=3.2&quot;, &quot;MONGO_VERSION=3.2.21&quot; ], &quot;Cmd&quot;: [ &quot;mongod&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:d7430950b72ba7ecb5986396f9a3404b5b0d88c2ba39eb7f2d4b51b002db00ea&quot;, &quot;Volumes&quot;: { &quot;/data/configdb&quot;: {}, &quot;/data/db&quot;: {} }, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: [ &quot;docker-entrypoint.sh&quot; ], &quot;OnBuild&quot;: [], &quot;Labels&quot;: null }, &quot;Architecture&quot;: &quot;amd64&quot;, &quot;Os&quot;: &quot;linux&quot;, &quot;Size&quot;: 300019217, &quot;VirtualSize&quot;: 300019217, &quot;GraphDriver&quot;: { &quot;Data&quot;: { &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/de4bf7c9580fda62420fd6a4e529783aeb161b44457ec6636bfaa97e94084ab0/diff:/var/lib/docker/overlay2/31a2f54b5cf142ae50d5ff530fd9159cd61129a47ab76b6b32656b6db42b765b/diff:/var/lib/docker/overlay2/f495f57ba2b9e665444151dc913bd1b8952a2e3d416d546b6722e44a038900c0/diff:/var/lib/docker/overlay2/51696b913195f45c1ce36c76240a0cf9836b593a16b0853238a5515bd9178322/diff:/var/lib/docker/overlay2/bcb73a5809c820e1eeb3c7cf4acc04c89b9e4d17be7c5ce9e3962580d14f2446/diff:/var/lib/docker/overlay2/d84695101463e67d0a4c901285a557cb0f4fc84a56840ce6433a225b799e2fc4/diff:/var/lib/docker/overlay2/d86783053f0a3e71f89c7b05328b2021a75bcf833911f7dc5fdad50e166a3d39/diff:/var/lib/docker/overlay2/a7a9a982dc727d527a3af4d04a19e359062c2d74bdd8fb497a057ca09ffcf290/diff:/var/lib/docker/overlay2/cbd9ce2cce4a6e2ec032e6cf25281016715a57f11ede109097c796383d13aac2/diff:/var/lib/docker/overlay2/339f33b0ff9703a7e50cce8459b89f5fb932ccc9460c8489a0f5d2cf65114033/diff&quot;, &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/6ba7ad9bf4a5e344d1edd12b87fe42d9abd828d480385a2637a47947c9a4af7f/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/6ba7ad9bf4a5e344d1edd12b87fe42d9abd828d480385a2637a47947c9a4af7f/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/6ba7ad9bf4a5e344d1edd12b87fe42d9abd828d480385a2637a47947c9a4af7f/work&quot; }, &quot;Name&quot;: &quot;overlay2&quot; }, &quot;RootFS&quot;: { &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:337a2e6463ae008c12681f29c50edde52ea5be2cc2f46d09b8254fd835b1f5a9&quot;, &quot;sha256:9d3049f87bb2ba7ac0469cad7ee11f871ff4fc735cc4dfdc1be6a1fe877861a5&quot;, &quot;sha256:75c2031620755be658ab335a6abb72376804e533e91fecb52315682b21aeeeca&quot;, &quot;sha256:ed81bb40beffca626f698965d5ec236b394ad8db229bb6dbfeb7be7a61b32768&quot;, &quot;sha256:38ccb1166c8a15aedf5a9d7f12b81436b9812175c3ce6c50fac39246a3ffc935&quot;, &quot;sha256:1f5a9fb2648f17bd23ab13f9e70f8631d233f33f73329302144da1aa2e4a5b0f&quot;, &quot;sha256:fcd5eec06559827da59d45500626b2dbf5673d03bba7aea9c9b9b786e8a10b54&quot;, &quot;sha256:2bcf250f248858339faf2dc746c44197c9eecc34999d485c60d636c7fcbc4d20&quot;, &quot;sha256:f6a5611931ed6ed6db65ad6a87abd7774f267c68c6f6d84cae65e0760c8a47b0&quot;, &quot;sha256:b436f480c034edfc426e1fcadbebaf50c72c0ce92c66924b6cf6ba344e455560&quot;, &quot;sha256:7eaf69109a2207f735d6423fe61a05200e3431ba9cdeafd6a27fa3c067c9f0ae&quot; ] }, &quot;Metadata&quot;: { &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot; } } ] 删除镜像可以使用docker rmi命令删除镜像，参数是镜像名或 ID，可以同时删除多个镜像。需要注意的是，需要先通过docker rm删除依赖该镜像的容器之后，该镜像才可以被删除： &gt; docker rmi redis:3.2 redis:4.0 Untagged: redis:3.2 Untagged: redis@sha256:745bdd82bad441a666ee4c23adb7a4c8fac4b564a1c7ac4454aa81e91057d977 Deleted: sha256:2fef532eadb328740479f93b4a1b7595d412b9105ca8face42d3245485c39ddc ## ...... Untagged: redis:4.0 Untagged: redis@sha256:b77926b30ca2f126431e4c2055efcf2891ebd4b4c4a86a53cf85ec3d4c98a4c9 Deleted: sha256:e1a73233e3beffea70442fc2cfae2c2bab0f657c3eebb3bdec1e84b6cc778b75 ## ...... 7. 运行和管理容器容器的创建和启动先来回顾一下容器的状态转换图： Docker 容器的状态转换图 可以看到，Docker 容器的生命周期共分为以下五种状态： Created：容器已经被创建，容器所需的相关资源已经准备就绪，但容器中的程序还未处于运行状态 Running：容器正在运行，其中的应用程序也正在运行 Paused：容器已经暂停，其中的所有程序都处于暂停状态 Stopped：容器处于停止状态，占用的资源和沙盒环境依然存在，只是容器中的应用程序均已停止运行 Deleted：容器已删除，相关占用的资源及存储在 Docker 中的管理信息也都被释放和移除 创建容器&gt; docker create --name=nginx nginx:1.12 34f277e22be252b51d204acbb32ce21181df86520de0c337a835de6932ca06c3 启动容器&gt; docker start nginx Docker 还允许我们通过docker run这个命令将docker create和docker start这两步操作合成为一步： &gt; docker run --name nginx -d nginx:1.12 通过-d或--detach选项告诉 Docker 在启动后将程序与控制台分离，使其在后台运行。 管理容器使用docker ps查看正在运行中的 Docker 容器： &gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 89f2b769498a nginx:1.12 &quot;nginx -g &#39;daemon of…&quot; About an hour ago Up About an hour 80/tcp nginx 添加-a或--al选项查看所有状态下的容器： &gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 425a0d3cd18b redis:3.2 &quot;docker-entrypoint.s…&quot; 2 minutes ago Created redis 89f2b769498a nginx:1.12 &quot;nginx -g &#39;daemon of…&quot; About an hour ago Up About an hour 80/tcp nginx 停止和删除容器使用docker stop命令停止正在运行中的容器： &gt; docker stop nginx 容器停止后，其维持的文件系统沙盒环境还是存在的，内部被修改的内容也都会保留，我们可以通过docker start命令再次启动这个容器。 当需要完全删除容器时，可以使用docker rm命令： &gt; docker rm nginx 正在运行中的容器默认情况下是不能被删除的，可以增加-f或--force选项来强制停止并删除容器，不过这样做并不妥当 进入容器我们知道，容器是一个隔离运行环境的东西，它里面除了镜像所规定的主进程之外，其他进程也是能够运行的。Docker 为我们提供了docker exec命令来让容器运行我们所给出的命令： &gt; docker exec nginx more /etc/hostname :::::::::::::: /etc/hostname :::::::::::::: 83821ea220ed 通过下列命令可以在容器中另外启动一个bash终端，并利用-it参数启用一个伪终端，方便我们与容器中的bash进行交互： &gt; docker exec -it nginx bash root@83821ea220ed:/&gt; -i（--interactive）表示保持我们的输入流，只有使用它才能保证控制台程序能够正确识别我们的命令 -t（--tty）表示启用一个伪终端，形成我们与bash的交互。如果没有它，我们就无法看到bash内部的执行结果 连接到容器主程序Docker 为我们提供了一个docker attach命令，用于将当前的输入输出流连接到指定的容器上： &gt; docker attach nginx 可以理解为：将容器中的主程序转为了前台运行 由于我们的输入输出流连接到了容器的主程序上，我们的输入输出操作也就直接针对了这个程序，而我们发送的 Linux 信号也会转移到这个程序上。例如我们可以通过Ctrl^C来向程序发送停止信号，这样一来容器也会停止运行。 8. 为容器配置网络容器网络容器网络实质上也是由 Docker 为应用程序所创造的虚拟环境的一部分，它能让应用从宿主机操作系统的网络环境中独立出来，形成容器自有的网络设备、IP 协议栈、端口套接字、IP 路由表、防火墙等等与网络相关的模块。 在 Docker 网络中，有三个比较核心的概念，沙盒（Sandbox）、网络（Network）、端点（Endpoint）： 沙盒：提供了容器的虚拟网络栈，隔离了容器网络与宿主机网络，形成了完全独立的容器网络环境 网络：可以理解为 Docker 内部的虚拟子网，网络内的参与者相互可见并能够进行通讯。Docker 的这种虚拟网络也是与宿主机网络存在隔离关系的，主要是为了形成容器间的安全通讯环境 端点：是位于容器或网络隔离墙之上的洞，其主要目的是形成一个可以控制的、突破封闭网络环境的出入口。当容器的端点与网络的端点形成配对后，就如同在这两者之间架起了桥梁，便能够进行数据传输了 这三者一起构成了 Docker 网络的核心模型，即容器网络模型（Container Network Model） 浅析 Docker 的网络实现容器网络模型为容器引擎提供了一套标准的网络对接范式，而在 Docker 中，实现这套范式的是 Docker 所封装的libnetwork模块。 目前 Docker 官方提供了五种网络驱动：Bridge、Host、Overlay、MacLan、None。 其中，Bridge网络是 Docker 容器的默认网络驱动，而Overlay网络则是借助 Docker Swarm 来搭建的跨 Docker Daemon 网络，我们可以通过它搭建跨物理主机的虚拟网络，进而让不同物理机中运行的容器感知不到多个物理机的存在。 容器互联要让一个容器连接到另外一个容器，我们可以在容器通过docker create或docker run创建时通过--link选项进行配置： &gt; docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes mysql &gt; docker run -d --name webapp --link mysql webapp:latest 要想在 Web 应用中连接到 MySQL 数据库，只需要将容器的网络命名填入到连接地址中。例如下面的代码，连接地址中的mysql就类似我们常见的域名解析，Docker 会将其指向 MySQL 容器的 IP 地址： String url = &quot;jdbc:mysql://mysql:3306/webapp&quot; 暴露端口虽然容器间的网络打通了，但并不意味着我们可以任意访问被连接容器中的任何服务。Docker 为容器网络增加了一套安全机制，只有容器自身允许的端口，才能被其他容器所访问。 在docker ps的结果中可以看到容器暴露给其他容器访问的端口： &gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 95507bc88082 mysql:5.7 &quot;docker-entrypoint.s…&quot; 17 seconds ago Up 16 seconds 3306/tcp, 33060/tcp mysql 暴露端口可以通过 Docker 镜像定义，也可以在容器创建时通过--expose选项进行定义： &gt; docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes --expose 13306 --expose 23306 mysql:5.7 可以看到13306和23306这两个端口已经成功的打开： &gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3c4e645f21d7 mysql:5.7 &quot;docker-entrypoint.s…&quot; 4 seconds ago Up 3 seconds 3306/tcp, 13306/tcp, 23306/tcp, 33060/tcp mysql 通过别名连接Docker 还支持连接时使用别名来摆脱容器名的限制： &gt; docker run -d -name webapp --link mysql:database webapp:latest 这里使用了--link &lt;name&gt;:&lt;alias&gt;的形式连接到 MySQL 容器，并设置它的别名为database。这样当我们要在 Web 应用中使用 MySQL 连接时，就可以用database替代连接地址： String url = &quot;jdbc:mysql://database:3306/webapp&quot;; 管理网络容器能够互相连接的前提是两者同处于一个网络中，这里的网络可以理解为 Docker 所虚拟的子网，而容器网络沙盒可以看作是虚拟的主机。只有当多个主机在同一个子网时，才能互相看到并进行网络数据交换。 当我们启动 Docker 服务时，他会为我们创建一个默认的bridge网络。而我们创建的容器在不专门指定网络的情况下，都会连接到这个网络上。 通过docker inspect命令查看容器，可在Network部分看到容器网络的相关信息： &gt; docker inspect mysql [ { ## ...... &quot;NetworkSettings&quot;: { ## ...... &quot;Networks&quot;: { &quot;bridge&quot;: { &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;bc14eb1da66b67c7d155d6c78cb5389d4ffa6c719c8be3280628b7b54617441b&quot;, &quot;EndpointID&quot;: &quot;1e201db6858341d326be4510971b2f81f0f85ebd09b9b168e1df61bab18a6f22&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;DriverOpts&quot;: null } } ## ...... } ## ...... } ] 创建网络使用docker network create命令创建网络，通过-d选项指定驱动类型，默认为bridge： &gt; docker network create -d bridge individual 通过docker network ls或者docker network list查看 Docker 中已经存在的网络： &gt; docker network ls NETWORK ID NAME DRIVER SCOPE bc14eb1da66b bridge bridge local 35c3ef1cc27d individual bridge local 在之后创建容器时，可以通过--network来指定容器所要加入的网络： &gt; docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes --network individual mysql:5.7 通过docker inspect mysql观察一下此时的容器网络： &gt; docker inspect mysql [ { ## ...... &quot;NetworkSettings&quot;: { ## ...... &quot;Networks&quot;: { &quot;individual&quot;: { &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: [ &quot;2ad678e6d110&quot; ], &quot;NetworkID&quot;: &quot;35c3ef1cc27d24e15a2b22bdd606dc28e58f0593ead6a57da34a8ed989b1b15d&quot;, &quot;EndpointID&quot;: &quot;41a2345b913a45c3c5aae258776fcd1be03b812403e249f96b161e50d66595ab&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot;, &quot;IPAddress&quot;: &quot;172.18.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;DriverOpts&quot;: null } } ## ...... } ## ...... } ] 可以看到容器所加入的网络已经变成为individual。 当两个容器处于不同的网络时，之间是不能互相连接引用的 端口映射Docker 提供了端口映射的功能来允许我们从容器外部通过网络访问容器中的应用： Docker 中的端口映射 要映射端口，我们可以在创建容器时使用-p或--publish选项**，格式为-p &lt;ip&gt;:&lt;host-port&gt;:&lt;container-port&gt;： &gt; docker run -d --name nginx -p 80:80 -p 443:443 nginx:1.12 之后就可以在容器列表里看到端口映射的配置： &gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bc79fc5d42a6 nginx:1.12 &quot;nginx -g &#39;daemon of…&quot; 4 seconds ago Up 2 seconds 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp nginx 9. 管理和存储数据Docker 中的沙盒文件系统虽然说有很多优势，但也存在弊端： 沙盒文件系统是随容器生命周期所创建和移除的，数据无法直接被持久化存储 由于容器隔离，我们很难从容器外部直接获得或操作容器内部文件中的数据 为了解决这些问题，UnionFS 支持挂载不同类型的文件系统到统一的目录结构中。 挂载方式基于底层存储实现，Docker 提供了三种适用于不同场景的文件系统挂载方式：Bind Mount、Volume 和 Tmpfs Mount。 Docker 中三种不同的文件系统挂载方式 Bind Mount：能够直接将宿主机操作系统中的目录和文件挂载到容器内的文件系统中，需要同时指定容器内、外的路径。在容器内外对文件读写，都是相互可见的 Volume：也是从宿主机操作系统中挂载目录到容器，只不过这个挂载的目录由 Docker 进行管理，我们只需要指定容器内的目录即可 Tmpfs Mount：支持挂载系统内存的中的一部分到容器的文件系统里，不过存储并不是持久的，其中的内容会随着容器的停止而消失 挂载文件到容器在创建容器时通过传递-v或--volume选项来指定挂载对应的目录或文件，格式为-v &lt;host-path&gt;:&lt;container-path&gt;： &gt; docker run -d --name nginx -v /webapp/html:/usr/share/nginx/html nginx:1.12 容器启动后，就可以看到挂载的目录或文件已经出现在容器中： &gt; docker exec nginx ls /usr/share/nginx/html index.html 可以通过docker inspect查看容器数据挂载的相关信息： &gt; docker inspect nginx [ { ## ...... &quot;Mounts&quot;: [ { &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/webapp/html&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; } ], ## ...... } ] 可以看到有一个RW字段，表示挂载目录或文件具有读写性（Read and Write）。 Docker 还支持以只读的方式挂载，这样目录或文件只能被容器中的程序读取，而无法修改。只需要在挂载选项后添加:ro： &gt; docker run -d --name nginx -v /webapp/html:/usr/share/nginx/html:ro nginx:1.12 挂载临时文件目录Tmpfs Mount是一种特殊的挂载方式，它主要利用内存来存储数据，因此其特征就是高读写速度、临时性挂载。 在创建容器时，通过--tmpfs传递挂载到容器内的目录即可，不需要指定内存的具体位置： &gt; docker run -d --name webapp --tmpfs /webapp/cache webapp:latest 也可以通过docker inspect命令进行查看： &gt; docker inspect webapp [ { ## ...... &quot;Tmpfs&quot;: { &quot;/webapp/cache&quot;: &quot;&quot; }, ## ...... } ] Tmpfs Mount有以下几种常见的使用场景： 应用不需要进行持久化保存的敏感数据，可以借助内存的非持久性和程序隔离性来保障安全 读写速度要求较高、数据变化量大，但不需要持久化保存的数据，可以借助内存的高读写速度减少操作的时间 使用数据卷数据卷（Volume）本质上仍然是宿主机操作系统上的一个目录，只不过它存放在 Docker 内部，接受 Docker 的管理。 在使用Volume进行挂载时，我们不需要知道数据具体存储在了宿主机操作系统的何处，只需要给定容器中的哪个目录会被挂载即可： &gt; docker run -d --name webapp -v /webapp/storage webapp:latest 数据卷挂载到容器后，可以通过docker inspect命令查看容器中数据卷的挂载信息： &gt; docker inspect webapp [ { ## ...... &quot;Mounts&quot;: [ { &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;2bbd2719b81fbe030e6f446243386d763ef25879ec82bb60c9be7ef7f3a25336&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/2bbd2719b81fbe030e6f446243386d763ef25879ec82bb60c9be7ef7f3a25336/_data&quot;, &quot;Destination&quot;: &quot;/webapp/storage&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; } ], ## ...... } ] 为了方便识别数据卷，可以通过-v &lt;name&gt;:&lt;container-path&gt;的形式来命名数据卷： &gt; docker run -d --name webapp -v appdata:/webapp/storage webapp:latest 共用数据卷由于数据卷的命名在 Docker 中是唯一的，因此可以很方便的让多个容器挂载同一个数据卷： &gt; docker run -d --name webapp -v html:/webapp/html webapp:latest &gt; docker run -d --name nginx -v html:/usr/share/nginx/html:ro nginx:1.12 使用-v选项来挂载数据卷时，如果数据卷不存在，Docker 就会自动创建和分配宿主机操作系统的目录。如果同名数据卷已经存在，则会直接引用 删除数据卷可以直接通过docker volume rm命令来删除指定的数据卷： &gt; docker volume rm appdata 在删除数据卷之前，我们必须保证数据卷没有被任何容器所使用，否则 Docker 会报错 在docker rm删除容器的命令中，还可以添加-v选项来删除容器关联的数据卷： docker rm -v webapp 如果没有随容器删除这些数据卷，Docker 在创建新的容器时也不会启用它们。这时可以通过docker volume prune命令删除那些没有被容器引用的数据卷： &gt; docker volume prune Deleted Volumes: af6459286b5ce42bb5f205d0d323ac11ce8b8d9df4c65909ddc2feea7c3d1d53 0783665df434533f6b53afe3d9decfa791929570913c7aff10f302c17ed1a389 65b822e27d0be93d149304afb1515f8111344da9ea18adc3b3a34bddd2b243c7 ## ...... 数据卷容器所谓数据卷容器（Volume Container），就是一个没有具体指定应用，甚至不需要运行的容器。我们使用它的目的，是为了定义一个或多个数据卷并持有它们的引用： 数据卷容器 可通过以下命令创建一个数据卷容器： &gt; docker create --name appdata -v /webapp/storage ubuntu 数据卷容器可以看作是容器间的文件系统桥梁，可以像加入网络一样引用数据卷容器，添加--volumes-from参数即可： &gt; docker run -d -name webapp --volumes-from appdata webapp:latest 备份和迁移数据卷利用数据卷容器，可以很方便的对数据卷中的数据进行迁移。 数据备份、迁移、恢复的过程可以理解为对数据进行打包，移动到其他位置，在需要的地方解压的过程 首先建立一个用来存放打包文件的目录/backup。要备份数据，我们还需要建立一个临时容器，将用于备份的目录和要备份的数据卷都挂载上去： &gt; docker run --rm --volumes-from appdata -v /backup:/backup ubuntu tar cvf /backup/backup.tar /webapp/storage --rm选项用来让容器在停止后自动删除 备份后，就可以在/backup目录下找到数据卷的备份文件backup.tar了。 要恢复数据卷中的数据，也可以借助临时容器来完成： &gt; docker run --rm --volumes-from appdata -v /backup:/backup ubuntu tar xvf /backup/backup.tar -C /webapp/storage --strip 通过 mount 选项挂载Docker 还为我们提供了一个支持相对丰富的挂载方式，也就是通过--mount选项来配置挂载： &gt; docker run -d --name webapp webapp:latest --mount &#39;type=volume,src=appdata,dst=/webapp/storage,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;&#39; webapp:latest 10. 保存和共享镜像提交容器更改Docker 将容器内沙盒文件系统记录成镜像层的时候，会先暂停容器的运行，保证容器内的文件系统处于一个相对稳定的状态，以确保数据的一致性。 &gt; docker commit -m &quot;Configured&quot; webapp sha256:0bc42f7ff218029c6c4199ab5c75ab83aeaaed3b5c731f715a3e807dda61d19e &gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE &lt;none&gt; &lt;none&gt; 0bc42f7ff218 3 seconds ago 372MB ## ...... 为镜像命名使用docker tag能够为未命名的镜像指定镜像名： &gt; docker tag 0bc42f7ff218 webapp:1.0 也可以为已有的镜像创建一个新的命名： &gt; docker tag webapp:1.0 webapp:2.0 当我们对未命名的镜像进行命名后，Docker 就不会在镜像列表里继续显示这个镜像，取而代之的是我们新的命名。而如果我们对已有镜像使用docker tag时，旧的镜像依然会存在于镜像列表中： &gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE webapp 1.0 0bc42f7ff218 29 minutes ago 372MB webapp latest 0bc42f7ff218 29 minutes ago 372MB ## ...... 还可以直接在提交镜像更改时指定新的镜像名： &gt; docker commit -m &quot;Upgrade&quot; webapp webapp:2.0 镜像的迁移可以使用管道： &gt; docker save webapp:1.0 &gt; webapp-1.0.tar 或者可以使用docker save命令，并添加-o选项，用来指定输出文件： &gt; docker save -o ./webapp-1.0.tar webapp:1.0 导入镜像可以使用管道： &gt; docker load &lt; webapp-1.0.tar 或者添加-i选项指定输入文件： &gt; docker load -i webapp-1.0.tar 批量迁移通过docker save和docker load命令还可以批量迁移镜像，只要在docker save中传入多个镜像名作为参数，就可以将这些镜像都打成一个包，方便我们一次性迁移多个镜像： &gt; docker save -o ./images.tar webapp:1.0 nginx:1.12 mysql:5.7 导入和导出容器使用docker export命令可以直接导出容器，可以简单的将其理解为docker commit和docker save命令的结合体： &gt; docker export -o ./webapp.tar webapp 相对的，使用docker export导出的容器包，我们可以使用docker import导入。使用docker import并非直接将容器导入，而是将容器运行时的内容以镜像的形式导入，所以导入的结果还是一个镜像，而不是容器： &gt; docker import ./webapp.tar webapp:1.0 11. 通过 Dockerfile 创建镜像关于 DockerfileDockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件，在 Dockerfile 中，包含了构建镜像过程中需要执行的命令和其他操作。 Dockerfile 的内容很简单，主要以两种形式呈现：一种是注释行，另一种是指令行。 编写 Dockerfile首先来看一个完整的 Dockerfile 例子，这是用于构建 Docker 官方所提供的Redis镜像的 Dockerfile 文件： FROM debian:stretch-slim # add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get added RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis # grab gosu for easy step-down from root # https://github.com/tianon/gosu/releases ENV GOSU_VERSION 1.10 RUN set -ex; \\ \\ fetchDeps=&quot; \\ ca-certificates \\ dirmngr \\ gnupg \\ wget \\ &quot;; \\ apt-get update; \\ apt-get install -y --no-install-recommends $fetchDeps; \\ rm -rf /var/lib/apt/lists/*; \\ \\ dpkgArch=&quot;$(dpkg --print-architecture | awk -F- &#39;{ print $NF }&#39;)&quot;; \\ wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch&quot;; \\ wget -O /usr/local/bin/gosu.asc &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch.asc&quot;; \\ export GNUPGHOME=&quot;$(mktemp -d)&quot;; \\ gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \\ gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \\ gpgconf --kill all; \\ rm -r &quot;$GNUPGHOME&quot; /usr/local/bin/gosu.asc; \\ chmod +x /usr/local/bin/gosu; \\ gosu nobody true; \\ \\ apt-get purge -y --auto-remove $fetchDeps ENV REDIS_VERSION 3.2.12 ENV REDIS_DOWNLOAD_URL http://download.redis.io/releases/redis-3.2.12.tar.gz ENV REDIS_DOWNLOAD_SHA 98c4254ae1be4e452aa7884245471501c9aa657993e0318d88f048093e7f88fd # for redis-sentinel see: http://redis.io/topics/sentinel RUN set -ex; \\ \\ buildDeps=&#39; \\ wget \\ \\ gcc \\ libc6-dev \\ make \\ &#39;; \\ apt-get update; \\ apt-get install -y $buildDeps --no-install-recommends; \\ rm -rf /var/lib/apt/lists/*; \\ \\ wget -O redis.tar.gz &quot;$REDIS_DOWNLOAD_URL&quot;; \\ echo &quot;$REDIS_DOWNLOAD_SHA *redis.tar.gz&quot; | sha256sum -c -; \\ mkdir -p /usr/src/redis; \\ tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1; \\ rm redis.tar.gz; \\ \\ # disable Redis protected mode [1] as it is unnecessary in context of Docker # (ports are not automatically exposed when running inside Docker, but rather explicitly by specifying -p / -P) # [1]: https://github.com/antirez/redis/commit/edd4d555df57dc84265fdfb4ef59a4678832f6da grep -q &#39;^#define CONFIG_DEFAULT_PROTECTED_MODE 1$&#39; /usr/src/redis/src/server.h; \\ sed -ri &#39;s!^(#define CONFIG_DEFAULT_PROTECTED_MODE) 1$!\\1 0!&#39; /usr/src/redis/src/server.h; \\ grep -q &#39;^#define CONFIG_DEFAULT_PROTECTED_MODE 0$&#39; /usr/src/redis/src/server.h; \\ # for future reference, we modify this directly in the source instead of just supplying a default configuration flag because apparently &quot;if you specify any argument to redis-server, [it assumes] you are going to specify everything&quot; # see also https://github.com/docker-library/redis/issues/4#issuecomment-50780840 # (more exactly, this makes sure the default behavior of &quot;save on SIGTERM&quot; stays functional by default) \\ make -C /usr/src/redis -j &quot;$(nproc)&quot;; \\ make -C /usr/src/redis install; \\ \\ rm -r /usr/src/redis; \\ \\ apt-get purge -y --auto-remove $buildDeps RUN mkdir /data &amp;&amp; chown redis:redis /data VOLUME /data WORKDIR /data COPY docker-entrypoint.sh /usr/local/bin/ ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] EXPOSE 6379 CMD [&quot;redis-server&quot;] Dockerfile 的结构总体上来看，可以将 Dockerfile 理解为一个由上往下执行指令的脚本文件。可以将 Dockerfile 的指令简单的分为五大类： 基础指令：用于定义新镜像的基础和性质 控制指令：是指导镜像构建的核心部分 引入指令：用于将外部文件直接引入到构建镜像内部 执行指令：能够为基于镜像所创建的容器，指定在启动时需要执行的脚本或命令 配置指令：对镜像以及基于镜像所创建的容器，可以通过配置指令对其网络、用户等内容进行配置 Dockerfile 常见指令1. FROM在镜像构建的过程中，可以通过FROM指令指定一个基础镜像。Docker 会先获取到这个基础镜像，再在这个镜像的基础上进行构建操作 FROM &lt;image&gt; [AS &lt;name&gt;] FROM &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;] FROM &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;] 2. RUN在RUN指令之后，我们直接拼接上需要执行的命令。在构建时，Docker 就会执行这些命令，并将它们对文件系统的修改记录下来，形成镜像的变化： RUN &lt;command&gt; RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN指令支持以\\换行，如果单行的长度过大，建议对内容进行切割，方便阅读 3. ENTRYPOINT 和 CMD基于镜像启动的容器，在容器启动时会根据镜像所定义的一条命令来启动容器中进程号为1的进程。而这个命令的定义，就是通过 Dockerfile 中的ENTRYPOINT和CMD实现的。 ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT command param1 param2 CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] CMD [&quot;param1&quot;,&quot;param2&quot;] CMD command param1 param2 ENTRYPOINT和CMD指令用法近似，都是给出需要执行的指令，并且它们都可以为空 当ENTRYPOINT和CMD同时给出时，CMD中的内容会作为ENTRYPOINT定义命令的参数，最终执行容器启动的还是ENTRYPOINT所给出的命令 4. EXPOSE通过EXPOSE指令可以为镜像指定要暴露的端口： EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...] 当我们通过EXPOSE指令配置了镜像的端口暴露定义，那么基于这个镜像所创建的容器，在被其他容器通过--link选项连接时，就能够直接允许来自其他容器对这些端口的访问。 5. VOLUME在一些程序里，我们需要持久化一些数据。可以通过VOLUME指令来定义基于此镜像的容器所自动建立的数据卷，这样就无需单独使用-v选项进行配置： VOLUME [&quot;/data&quot;] 6. COPY 和 ADD在制作新镜像时，我们可能需要将一些软件配置、程序代码、执行脚本等直接导入到镜像内的文件系统里。使用COPY或ADD指令能够帮助我们直接从宿主机的文件系统里拷贝内容到镜像里的文件系统中： COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt; ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt; COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] ADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] COPY与ADD指令的定义完全一样，主要区别在于ADD能够支持使用网络端的URL地址作为src源，并且在源文件被识别为压缩包时，自动进行解压，而COPY则没有这两个能力。 构建镜像在编写好Dockerfile之后，我们就可以使用docker build命令构建我们所定义的镜像： &gt; docker build ./webapp docker build可以接收一个参数，这个参数为一个目录路径（本地路径或 URL 路径）。Docker 会将这个目录作为构建的环境目录，默认情况下，也会从这个目录下寻找名为Dockerfile的文件。 如果我们的Dockerfile文件路径不在这个目录下，则可以通过-f选项单独给出Dockerfile文件的路径： &gt; docker build -t webapp:latest -f ./webapp/a.Dockerfile ./webapp 最好在构建镜像时添加-t选项，用来指定新生成的镜像的名称： &gt; docker build -t webapp:latest ./webapp 12. Dockerfile 使用技巧构建中使用变量在 Dockerfile 里，可以使用ARG指令建立一个参数变量。我们可以在构建时通过构建指令传入这个参数变量，并且在 Dockerfile 里使用它： FROM debian:stretch-slim ## ...... ARG TOMCAT_MAJOR ARG TOMCAT_VERSION ## ...... RUN wget -O tomcat.tar.gz &quot;https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz&quot; ## ...... 如果我们需要通过这个 Dockerfile 文件构建 Tomcat 镜像，可以在构建时通过docker build的--build-arg选项来设置参数变量： &gt; docker build --build-arg TOMCAT_MAJOR=8 --build-arg TOMCAT_VERSION=8.0.53 -t tomcat:8.0 ./tomcat 环境变量环境变量通过ENV指令定义： FROM debian:stretch-slim ## ...... ENV TOMCAT_MAJOR 8 ENV TOMCAT_VERSION 8.0.53 ## ...... RUN wget -O tomcat.tar.gz &quot;https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz&quot; 与参数变量只能影响构建过程不同，环境变量不仅能够影响构建，还能够影响基于此镜像创建的容器。 环境变量设置的实质，其实就是定义操作系统环境变量，所以在运行的容器里，一样拥有这些变量，而容器中运行的程序也能够得到这些变量的值 由于环境变量在容器运行时依然有效，所以运行容器时我们还可以对其进行覆盖。 在创建容器时使用-e或--env选项，可以对环境变量的值进行修改或定义新的环境变量： &gt; docker run -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:5.7 ENV指令所定义的变量，永远会覆盖ARG所定义的变量，即使它们定义时的顺序是相反的 合并命令在构建镜像时，RUN指令有两种写法： RUN apt-get update; \\ apt-get install -y --no-install-recommends $fetchDeps; \\ rm -rf /var/lib/apt/lists/*; # 或 RUN apt-get update RUN apt-get install -y --no-install-recommends $fetchDeps RUN rm -rf /var/lib/apt/lists/* 而我们更常见的是第一种形式，这就要从镜像构建的过程说起了。 看似连续的镜像构建过程，其实是由多个小段组成的。每当一条能够形成对文件系统改动的指令在被执行前，Docker 先会基于上条命令的结果启动一个容器，在容器中运行这条指令的内容，之后将结果打包成一个镜像层，如此反复，最终形成镜像 所以，构建而来的镜像是由多个镜像层叠加而得的，而这些镜像层其实就是在我们 Dockerfile 中每条指令所生成的。 因此，绝大多数镜像会将命令合并到一条指令中，因为这样不但减少了镜像层的数量，也减少了镜像构建过程中反复创建容器的次数，提高了镜像构建的速度。 构建缓存Docker 在镜像构建的过程中，还支持一种缓存策略来提高镜像的构建速度。 由于镜像是多个指令所创建的镜像层组合而得，那么如果我们判断新编译的镜像层与已经存在的镜像层未发生变化，那么我们完全可以直接利用之前构建的结果，而不需要再执行这条构建指令，这就是镜像构建缓存的原理 基于这个原则，我们在条件允许的前提下，更建议将不容易发生变化的搭建过程放到 Dockerfile 的前部，充分利用构建缓存提高镜像构建的速度。 另外，指令的合并也不宜过度，而是将易变和不易变的过程拆分，分别放到不同的指令里。 当不希望 Docker 在构建镜像中使用构建缓存时，可以通过--no-cache选项禁用： &gt; docker build --no-cache ./webapp 搭配 ENTRYPOINT 和 CMDENTRYPOINT和CMD两个命令都是用来指定基于此镜像所创建容器里主进程的启动命令，而它们的区别在于，ENTRYPOINT指令的优先级高于CMD指令。当ENTRYPOINT和CMD同时在镜像中被指定时，CMD里的内容会作为ENTRYPOINT的参数，两者拼接之后，才是最终执行的命令。 ENTRYPOINT 和 CMD 的组合 之所以ENTRYPOINT和CMD要分成两个不同的命令，是因为它们的设计目的是不同的： ENTRYPOINT：主要用于对容器进行一些初始化 CMD：用于真正定义容器中主程序的启动命令 以Redis镜像为例： ## ...... COPY docker-entrypoint.sh /usr/local/bin/ ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] ## ...... CMD [&quot;redis-server&quot;] 可以看到，CMD指令定义的正是启动Redis的服务程序，而ENTRYPOINT使用的则是外部引入的脚本文件docker-entrypoint.sh，内容如下： #!/bin/sh set -e # first arg is `-f` or `--some-option` # or first arg is `something.conf` if [ &quot;${1#-}&quot; != &quot;$1&quot; ] || [ &quot;${1%.conf}&quot; != &quot;$1&quot; ]; then set -- redis-server &quot;$@&quot; fi # allow the container to be started with `--user` if [ &quot;$1&quot; = &#39;redis-server&#39; -a &quot;$(id -u)&quot; = &#39;0&#39; ]; then find . \\! -user redis -exec chown redis &#39;{}&#39; + exec gosu redis &quot;$0&quot; &quot;$@&quot; fi exec &quot;$@&quot; 脚本的最后一条命令exec &quot;$@&quot;其作用是运行一个程序，而运行命令就是ENTRYPOINT脚本的参数，所以实际执行的就是CMD里的命令。 13. 使用 Docker Compose 管理容器Docker Compose在 Docker 开发中最常使用的多容器定义和运行软件就是 Docker Compose。 如果说 Dockerfile 是将容器内运行环境的搭建固化下来，那么 Docker Compose 就可以理解为将多个容器运行的方式和配置固化下来。 在 Docker Compose 里，我们通过一个docker-compose.yml配置文件，将所有与应用系统相关的软件及它们对应的容器进行配置，之后使用 Docker Compose 提供的命令进行启动，就能让 Docker Compose 将刚才我们所提到的那些复杂问题解决掉。 安装 Docker ComposeDocker Compose 是一个由 Python 编写的软件。通过下面的命令下载 Docker Compose 到应用执行目录，并附上运行权限，这样 Docker Compose 就可以在机器中使用了： &gt; sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose &gt; sudo chmod +x /usr/local/bin/docker-compose &gt; sudo docker-compose version docker-compose version 1.21.2, build a133471 docker-py version: 3.3.0 CPython version: 3.6.5 OpenSSL version: OpenSSL 1.0.1t 3 May 2016 也可以通过pip安装： &gt; sudo pip install docker-compose Docker Compose 的基本使用逻辑简单来说，使用 Docker Compose 的步骤共分为三步： 如果需要，编写容器所需镜像的Dockerfile（也可以使用现有镜像） 编写用于配置容器的docker-compose.yml 使用docker-compose命令启动应用栈 1. 编写 docker-compose.yml一个简单的例子： version: &#39;3&#39; services: webapp: build: ./image/webapp ports: - &quot;5000:5000&quot; volumes: - ./code:/code - logvolume:/var/log links: - mysql - redis redis: image: redis:3.2 mysql: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=my-secret-pw volumes: logvolume: {} 2. 启动和停止对与开发而言，最常使用的就是docker-compose up和docker-compose down命令： docker-compose up docker-compose up命令类似于 Docker Engine 中的docker run。它会根据docker-compose.yml中配置的内容，创建所有的容器、网络、数据卷等内容，并将它们启动。 默认情况下，docker-compose up会在前台运行，可以使用-d选项使其在后台运行： &gt; sudo docker-compose up -d 需要注意的是，docker-compose命令默认会识别当前控制台所在目录内的docker-compose.yml文件，而且会以当前目录的名字作为组装的应用项目的名称。可以通过-f选项来指定配置文件名，通过-p选项来定义项目名： &gt; sudo docker-compose -f ./compose/docker-compose.yml -p myapp up -d docker-compose down docker-compose down命令用于停止所有的容器，并将它们删除，同时清除网络等配置内容： &gt; sudo docker-compose down 3. 容器命令除了启动和停止命令之外，Docker Compose 还为我们提供了很多直接操作服务的命令，服务可以看成是一组相同容器的集合。 可以使用docker-compose logs命令查看容器中主进程的输出内容： &gt; sudo docker-compose logs nginx 通过docker-compose create/start/stop可以实现与docker create/start/stop相似的效果，只不过操作的对象由 Docker Engine 中的容器变为了 Docker Compose 中的服务： &gt; sudo docker-compose create webapp &gt; sudo docker-compose start webapp &gt; sudo docker-compose stop webapp 更新中… 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Kubernetes 实践简明指南docker build 相关疑问解惑","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"}]},{"title":"《Go 语言核心 36 讲》笔记","slug":"core-go-notes","date":"2019-03-13T06:52:43.000Z","updated":"2019-09-01T13:04:11.057Z","comments":true,"path":"2019/03/13/core-go-notes/","link":"","permalink":"https://abelsu7.top/2019/03/13/core-go-notes/","excerpt":"摘自 Go 语言核心 36 讲 | 极客时间","text":"摘自 Go 语言核心 36 讲 | 极客时间 目录1. 工作区和 GOPATH 问题：你知道设置GOPATH有什么意义吗？ 可以把GOPATH简单理解成 Go 语言的工作目录，它的值是一个目录的路径，也可以是多个目录路径，每个目录都代表 Go 语言的一个工作区（workspace）。 我们需要利用这些工作区，来放置 Go 语言的源码文件（source file），以及安装后的归档文件（archieve file，以.a为扩展名的文件）和可执行文件（executable file）。 GOPATH 和工作区 2. 源码文件的分类Go 语言中的源码文件可分为三种： 命令源码文件 库源码文件 测试源码文件 三种源码文件的区别 2.1 命令源码文件 问题：命令源码文件的用途是什么，怎样编写它？ 命令源码文件是程序的运行入口，是每个可独立运行的程序必须拥有的。我们可以通过构建go build或安装go install，生成与其对应的可执行文件，后者一般会与该命令源码文件的直接父目录同名。 如果一个源码文件声明属于main包，并且包含一个无参数声明且无结果声明的main函数，那么它就是命令源码文件： package main import &quot;fmt&quot; func main() { fmt.Println(&quot;Hello, Golang!&quot;) } 对于一个独立的程序来说，命令源码文件永远只会也只能有一个。如果有与命令源码文件同包的源码文件，那么它们也应该声明属于main包 1. 接收命令行参数Go 语言标准库中的flag包专门用于接收和解析命令参数，可使用如下语句： flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;) // 或 var name = flag.String(&quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;) 函数flag.stringVar接受 4 个参数： &amp;name：用于存储该命令参数值的地址 &quot;name&quot;：指定该命令参数的名称 &quot;everyone&quot;：指定在为追加该命令参数时的默认值 &quot;The greeting object.&quot;：该命令参数的简短说明，打印命令说明时会用到 package main import ( &quot;flag&quot; &quot;fmt&quot; ) var name string func init() { flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object&quot;) } func main() { flag.Parse() // 解析命令参数，并把它们的值赋给相应的变量 fmt.Printf(&quot;Hello, %s!\\n&quot;, name) } 将上述代码保存为demo1.go，运行以下命令： go run demo1.go -name=&quot;abelsu7&quot; ------ Hello, abelsu7! 查看参数说明： go run demo1.go --help ------ Usage of C:\\Users\\abel1\\AppData\\Local\\Temp\\go-build617189518\\b001\\exe\\demo1.exe: -name string The greeting object (default &quot;everyone&quot;) exit status 2 2. 自定义参数使用说明有多种方式，最简单的就是对变量flag.Usage重新赋值。flag.Usage的类型是func()，无参数声明也无结果声明。 在flag.Parse()之前加入如下语句： flag.Usage = func() { fmt.Fprintf(os.Stderr, &quot;Usage of %s:\\n&quot;, &quot;question&quot;) flag.PrintDefaults() } 这样调用go run demo1.go --help后就会输出： Usage of question: -name string The greeting object (default &quot;everyone&quot;) exit status 2 再深入来看，当我们调用flag包中的一些函数时（比如stringVar、Parse等），实际上是在调用flag.CommandLine变量的对应方法。 flag.CommandLine相当于默认情况下的命令参数容器，所以，通过对flag.CommandLine重新赋值，就可以更深层次的定制当前命令源码文件的参数使用说明。 将程序修改为： package main import ( &quot;flag&quot; &quot;fmt&quot; &quot;os&quot; ) var name string func init() { flag.CommandLine = flag.NewFlagSet(&quot;&quot;, flag.ExitOnError) flag.CommandLine.Usage = func() { fmt.Fprintf(os.Stderr, &quot;Usage of %s:\\n&quot;, &quot;question&quot;) flag.PrintDefaults() } flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object&quot;) } func main() { //flag.Usage = func() { // fmt.Fprintf(os.Stderr, &quot;Usage of %s:\\n&quot;, &quot;question&quot;) // flag.PrintDefaults() //} flag.Parse() fmt.Printf(&quot;Hello, %s!\\n&quot;, name) } ------ &gt; go run demo1.go --help Usage of question: -name string The greeting object (default &quot;everyone&quot;) exit status 2 就会得到一样的输出。而当我们把flag.CommandLine赋值的那条语句改为： flag.CommandLine = flag.NewFlagSet(&quot;&quot;, flag.PanicOnError) 再次运行得到： &gt; go run demo1.go --help Usage of question: -name string The greeting object (default &quot;everyone&quot;) panic: flag: help requested goroutine 1 [running]: flag.(*FlagSet).Parse(0xc000084060, 0xc0000443f0, 0x1, 0x1, 0x4, 0x4d0ab5) C:/Go/src/flag/flag.go:938 +0x107 flag.Parse() C:/Go/src/flag/flag.go:953 +0x76 main.main() C:/Users/abel1/go/src/github.com/abelsu7/hello/demo1.go:25 +0x2d exit status 2 flag.ExitOnError：告诉命令参数容器，当命令后跟--help或者参数设置不正确的时候，在打印命令参数使用说明以后，以exit status 2结束当前程序 flag.PanicOnError：区别在于最后会抛出运行时恐慌panic 另外，还可以创建一个私有的命令参数容器，这样就不会影响到全局变量flag.CommandLine： package main import ( &quot;flag&quot; &quot;fmt&quot; &quot;os&quot; ) var name string var cmdLine = flag.NewFlagSet(&quot;question&quot;, flag.ExitOnError) func init() { cmdLine.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object&quot;) } func main() { cmdLine.Parse(os.Args[1:]) fmt.Printf(&quot;Hello, %s!\\n&quot;, name) } ------ &gt; go run demo1.go --help Usage of question: -name string The greeting object (default &quot;everyone&quot;) exit status 2 关于flag包的更多用法可以参考 Package flag | golang.google.cn 2.2 库源码文件库源码文件是不能被直接运行的源码文件，它仅用于存放程序实体，这些程序实体可以被其他代码使用。 在 Go 语言中，程序实体是变量、常量、函数、结构体和接口的统称 程序实体的名字被统称为标识符，它可以是任何 Unicode 编码可以表示的字母字符、数字以及下划线_，但其首字母不能是数字。 首先新建一个_03_demo的包，在该路径下创建命令源码文件demo4.go： package main import ( &quot;flag&quot; ) var name string func init() { flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;) } func main() { flag.Parse() hello(name) } 然后在相同路径下，新建demo4_lib.go： package main import &quot;fmt&quot; func hello(name string) { fmt.Printf(&quot;Hello, %s!\\n&quot;, name) } 在{project_path}/_03_demo/路径下，使用以下命令运行程序： &gt; go run demo4.go demo4_lib.go Hello, every one! // 或者 &gt; go build &gt; _03_demo.exe Hello, every one! 代码包声明的基本规则 同目录下的源码文件的代码包package声明语句要一致。如果目录中有命令源码文件，那么其他种类的源码文件也应该声明属于main**包，这样才能成功构建和运行 源码文件声明的代码包的名称可以与其所在的目录的名称不同。在针对代码包进行构建go build时，生成的结果文件的主名称与其父目录的名称一致 源码文件所在的目录相对于src目录的相对路径，就是它的代码包导入路径，而实际使用其程序实体时给定的限定符要与它声明所属的代码包名称对应 名称的首字母为大写的程序实体才可以被当前包外的代码引用，这样就很自然的把程序实体的访问权限划分为包级私有的和公开的 还可以通过创建internal代码包让一些程序实体仅仅能被当前模块中的其他代码引用。具体规则是，internal代码包中声明的公开程序实体仅能被该代码包的直接父包及其子包中的代码引用。当然，引用前需要先导入internal包。对于其他代码包，导入都是非法的，无法通过编译 3. 变量Go 语言中的程序实体包括变量、常量、函数、结构体和接口。 Go 语言是静态类型的编程语言，所以在声明变量或常量时，需要指定它们的类型，或者给予足够的信息，这样才能让 Go 语言推导出变量的类型 3.1 定义变量的三种方式package main import &quot;fmt&quot; func main() { var s1 int = 42 // 显式定义，可读性最强 var s2 = 42 // 编译器自动推导变量类型 s3 := 42 // 自动推导类型 + 赋值 fmt.Println(s1, s2, s3) } ------------- 42 42 42 如果一个变量很重要，建议使用第一种显式声明类型的方式来定义，比如全局变量的定义就比较偏好第一种定义方式 如果要使用一个不那么重要的局部变量，就可以使用第三种，比如循环下标变量 关键字var无法直接写进循环条件的初始化语句中 变量的多种声明方式 问题：Go 语言的类型推断可以带来哪些好处？ 除了写代码时可以省略变量类型之外，真正的好处体现在代码重构。 例如下面的代码： package main import ( &quot;flag&quot; &quot;fmt&quot; ) func main() { var name = getTheFlag() flag.Parse() fmt.Printf(&quot;Hello, %v!\\n&quot;, *name) } func getTheFlag() *string { return flag.String(&quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;) } 这样一来，我们可以随意改变getTheFlag函数的内部实现，及其返回结果的类型，而不用修改main函数中的任何代码，这个命令源码文件依然可以通过编译，并成功构建、运行。 通过这种类型推断，可以初步体验动态类型编程语言所带来的一部分优势，即以程序的可维护性和运行效率换来程序灵活性的明显提升。 事实上，Go 语言是静态类型的，所以一旦在初始化变量时确定了它的类型，之后就不可能再改变。这种类型的确定是在编译器完成的，因此不会对程序的运行效率产生任何影响 3.2 旧变量的重声明var err error n, err := io.WriteString(os.Stdout, &quot;Hello, everyone!\\n&quot;) 这里使用短变量声明对新变量n和旧变量err进行了声明并赋值，同时也是对旧变量err的重声明。 3.3 Go 语言基础类型大全package main import &quot;fmt&quot; func main() { // 有符号整数，可以表示正负 var a int8 = 1 // 1 字节 var b int16 = 2 // 2 字节 var c int32 = 3 // 4 字节 var d int64 = 4 // 8 字节 fmt.Println(a, b, c, d) // 无符号整数，只能表示非负数 var ua uint8 = 1 var ub uint16 = 2 var uc uint32 = 3 var ud uint64 = 4 fmt.Println(ua, ub, uc, ud) // int 类型，在32位机器上占4个字节，在64位机器上占8个字节 var e int = 5 var ue uint = 5 fmt.Println(e, ue) // bool 类型 var f bool = true fmt.Println(f) // 字节类型 var j byte = &#39;a&#39; fmt.Println(j) // 字符串类型 var g string = &quot;abcdefg&quot; fmt.Println(g) // 浮点数 var h float32 = 3.14 var i float64 = 3.141592653 fmt.Println(h, i) } ------------- 1 2 3 4 1 2 3 4 5 5 true abcdefg 3.14 3.141592653 97 3.4 代码块中变量的作用域 3.5 判断一个变量的类型以下面的代码为例： package main import &quot;fmt&quot; var container = []string{&quot;zero&quot;, &quot;one&quot;, &quot;two&quot;} func main() { container := map[int]string{0: &quot;zero&quot;, 1: &quot;one&quot;, 2: &quot;two&quot;} fmt.Printf(&quot;The element is %q.\\n&quot;, container[1]) } 要想在打印其中元素之前，正确判断变量container的类型，则可以使用「类型断言」表达式x.(T)： package main import &quot;fmt&quot; var container = []string{&quot;zero&quot;, &quot;one&quot;, &quot;two&quot;} func main() { container := map[int]string{0: &quot;zero&quot;, 1: &quot;one&quot;, 2: &quot;two&quot;} value, ok := interface{}(container).(map[int]string) if ok { fmt.Println(value[1]) } fmt.Printf(&quot;The element is %q.\\n&quot;, container[1]) } ------ one The element is &quot;one&quot;. Process finished with exit code 0 需要注意的是，在类型断言表达式x.(T)中，x代表要被判断类型的值，这个值当下的类型必须是接口类型，所以当container变量类型不是任何的接口类型时，就需要先把它转成某个接口类型的值。 类型断言表达式 问题：类型转换规则中有哪些值得注意的地方？ 在类型转换表达式T(x)中，x可以是一个变量，也可以是一个代表值的字面量（例如1.23和struct{}），还可以是一个表达式。 如果是表达式，那么该表达式的结果只能是一个值，而不能是多个值。如果从源类型到目标类型的转换是不合法的，就会引发一个编译错误。 对于整数类型值、整数常量之间的类型转换，原则上只要源值在目标类型的可表示范围内就是合法的 虽然直接把一个整数值转换成一个string类型是可行的，但如果被转换的整数值不是一个有效的 Unicode 代码点，则结果会是� 问题：什么是别名类型？什么是潜在类型？ 可以用关键字type声明自定义的各种类型。其中有一种「别名类型」，可以像下面一样声明： type MyString = string 别名类型与其源类型除了名称不同，其他是完全相同的。例如 Go 语言内建的基本类型中就存在两个别名类型：byte是uint8的别名类型，rune是uint32的别名类型。 而下面没有=的语法被称为对类型的再定义： type MyString2 string // MyString2 是一个新的类型 别名类型、类型再定义、潜在类型 对于这里的类型再定义来说，string可以被称为MyString2的潜在类型：即某个类型在本质上是哪个类型，或者是哪个类型的集合。 如果两个值潜在类型相同，却属于不同类型，则它们之间是可以进行类型转换的。例如MyString2与string类型的值，就可以互相转换 但对于集合类型[]MyString2与[]string来说，这样做是不合法的，因为它们的潜在类型不同，分别是MyString2和string 另外，即使两个类型的潜在类型相同，它们的值之间也不能进行判等或比较，它们的变量之间也不能赋值 4. 数组和切片Go 语言的数组（array）和切片（slice）类型： 相同点：都属于集合类的类型，并且，它们的值都可以用来存储某一种类型的值 不同点：数组的长度是固定的，而切片是可变长的 数组的长度在声明它时就必须给定，并且之后不会再改变。可以说，数组的长度是其类型的一部分。例如，[1]string和[2]string就是两个不同的数组类型。 而切片的类型字面量中只有元素的类型，没有长度。切片的长度可以自动的随着其中元素数量的增长而增长，但不会随之减少。 数组与切片 可以把切片看作是对数组的一层简单的封装，因为每个切片都会有一个底层数组，而切片也可以被看作是对数组的某个连续片段的引用。 Go 语言的切片类型属于引用类型，同属引用类型的还有：字典类型、通道类型、函数类型等 Go 语言的数组类型则属于值类型，同属值类型的还有：基础数据类型、结构体类型 Go 语言中不存在所谓的“传值还是传引用”的问题。只要看被传递的值的类型就可判断：如果是引用类型，则可看作“传引用”。如果是值类型，则可看作“传值”。从传递成本的角度看，引用类型的值往往比值类型的值低很多 来看一个例子： s3 := []int{1, 2, 3, 4, 5, 6, 7, 8} s4 := s3[3:6] fmt.Printf(&quot;The length of s4: %d\\n&quot;, len(s4)) fmt.Printf(&quot;The capacity of s4: %d\\n&quot;, cap(s4)) fmt.Printf(&quot;The value of s4: %d\\n&quot;, s4) ------ The length of s4: 3 The capacity of s4: 5 The value of s4: [4 5 6] 切片与数组的关系 切片表达式中的方括号s3[3:6]可看作[3,6)，这里的3被称为起始索引，6被称为结束索引 切片代表的窗口是无法向左扩展的，但可以向右扩展，直至其底层数组的末尾 一个切片的容量，可以被看作是透过这个窗口最多可以看到的底层数组中的元素个数 切片表达式s4[0:cap(s4)]的结果值即为把切片的窗口向右扩展到最大 问题：怎样估算切片容量的增长？ 一旦一个切片无法容纳更多的元素，Go 语言就会生成一个容量更大的切片（一般情况下容量扩为 2 倍），并将原切片的元素和新元素一并拷贝到新切片中。 但是，当原切片的长度&gt;=1024时候，Go 语言将会以原容量的1.25倍作为新容量的基准，新容量基准会被调整（不断与1.25相乘），直到结果不低于新长度。 另外，如果我们一次追加的元素过多，以至于新长度比原容量的 2 倍还要大，那么新容量就会以新长度为基准。最终的新容量在很多时候都要比新容量基准更大一些。 更多细节可以查看runtime包中slice.go文件里的growslice及相关函数的具体实现 package main import &quot;fmt&quot; func main() { // 示例1。 s6 := make([]int, 0) fmt.Printf(&quot;The capacity of s6: %d\\n&quot;, cap(s6)) for i := 1; i &lt;= 5; i++ { s6 = append(s6, i) fmt.Printf(&quot;s6(%d): len: %d, cap: %d\\n&quot;, i, len(s6), cap(s6)) } fmt.Println() // 示例2。 s7 := make([]int, 1024) fmt.Printf(&quot;The capacity of s7: %d\\n&quot;, cap(s7)) s7e1 := append(s7, make([]int, 200)...) fmt.Printf(&quot;s7e1: len: %d, cap: %d\\n&quot;, len(s7e1), cap(s7e1)) s7e2 := append(s7, make([]int, 400)...) fmt.Printf(&quot;s7e2: len: %d, cap: %d\\n&quot;, len(s7e2), cap(s7e2)) s7e3 := append(s7, make([]int, 600)...) fmt.Printf(&quot;s7e3: len: %d, cap: %d\\n&quot;, len(s7e3), cap(s7e3)) fmt.Println() // 示例3。 s8 := make([]int, 10) fmt.Printf(&quot;The capacity of s8: %d\\n&quot;, cap(s8)) s8a := append(s8, make([]int, 11)...) fmt.Printf(&quot;s8a: len: %d, cap: %d\\n&quot;, len(s8a), cap(s8a)) s8b := append(s8a, make([]int, 23)...) fmt.Printf(&quot;s8b: len: %d, cap: %d\\n&quot;, len(s8b), cap(s8b)) s8c := append(s8b, make([]int, 45)...) fmt.Printf(&quot;s8c: len: %d, cap: %d\\n&quot;, len(s8c), cap(s8c)) } ------ The capacity of s6: 0 s6(1): len: 1, cap: 1 s6(2): len: 2, cap: 2 s6(3): len: 3, cap: 4 s6(4): len: 4, cap: 4 s6(5): len: 5, cap: 8 The capacity of s7: 1024 s7e1: len: 1224, cap: 1280 s7e2: len: 1424, cap: 1696 s7e3: len: 1624, cap: 2048 The capacity of s8: 10 s8a: len: 21, cap: 22 s8b: len: 44, cap: 44 s8c: len: 89, cap: 96 Process finished with exit code 0 问题：切片的底层数组什么时候会被替换？ 确切地说，一个切片的底层数组永远也不会被替换。虽然在扩容的时候 Go 语言也会生成新的底层数组，但同时也生成了新的切片。它只是把新的切片作为了新底层数组的窗口，而没有对原切片及其底层数组做任何改动。 在无需扩容时，append函数返回的是指向原底层数组的新切片。而在需要扩容时，append函数返回的是指向新底层数组的新切片。 5. container 包中的容器5.1 List 链表Go 语言的链表实现在标准库container/list中，有两个公开的程序实体：List和Element，List实现了一个双向链表，而Element则代表了链表中元素的结构。 package main import ( &quot;container/list&quot; &quot;fmt&quot; ) func main() { link := list.New() // 循环插入到头部 for i := 0; i &lt;= 10; i++ { link.PushBack(i) } // 遍历链表 for p := link.Front(); p != link.Back(); p = p.Next() { fmt.Println(&quot;Number&quot;, p.Value) } } ------ Number 0 Number 1 Number 2 Number 3 Number 4 Number 5 Number 6 Number 7 Number 8 Number 9 Process finished with exit code 0 参考： Go标准库学习笔记-双向链表 (container/list) | CSDN Golang标准库深入 - 双向链表（container/list）| 开源中国 5.2 Ring 环标准库contianer/ring包中的Ring类型实现的是一个循环链表，也就是我们俗称的环。其实List在内部就是一个循环链表，它的根元素永远不会持有任何实际的元素值，而该元素的存在就是为了连接这个循环链表的首尾两端。 List可以作为Queue和Stack的基础数据结构 Ring可以用来保存固定数量的元素，例如保存最近 100 万条日志，用户最近 10 次操作等 Heap可以用来排序，可用于构造优先级队列 package main; import ( &quot;container/ring&quot; &quot;fmt&quot; ) func printRing(r *ring.Ring) { r.Do(func(v interface{}) { fmt.Print(v.(int), &quot; &quot;) }) fmt.Println() } func main() { //创建环形链表 r := ring.New(5) //循环赋值 for i := 0; i &lt; 5; i++ { r.Value = i //取得下一个元素 r = r.Next() } printRing(r) //环的长度 fmt.Println(r.Len()) //移动环的指针 r.Move(2) //从当前指针删除n个元素 r.Unlink(2) printRing(r) //连接两个环 r2 := ring.New(3) for i := 0; i &lt; 3; i++ { r2.Value = i + 10 //取得下一个元素 r2 = r2.Next() } printRing(r2) r.Link(r2) printRing(r) } ------ 0 1 2 3 4 5 0 3 4 10 11 12 0 10 11 12 3 4 Process finished with exit code 0 5.3 Heap 堆package main import ( &quot;container/heap&quot; &quot;fmt&quot; ) type IntHeap []int //我们自定义一个堆需要实现5个接口 //Len(),Less(),Swap()这是继承自sort.Interface //Push()和Pop()是堆自已的接口 //返回长度 func (h *IntHeap) Len() int { return len(*h) } //比较大小(实现最小堆) func (h *IntHeap) Less(i, j int) bool { return (*h)[i] &lt; (*h)[j] } //交换值 func (h *IntHeap) Swap(i, j int) { (*h)[i], (*h)[j] = (*h)[j], (*h)[i] } //压入数据 func (h *IntHeap) Push(x interface{}) { //将数据追加到h中 *h = append(*h, x.(int)) } //弹出数据 func (h *IntHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] //让h指向新的slice *h = old[0 : n-1] //返回最后一个元素 return x } //打印堆 func (h *IntHeap) PrintHeap() { //元素的索引号 i := 0 //层级的元素个数 levelCount := 1 for i+1 &lt;= h.Len() { fmt.Println((*h)[i : i+levelCount]) i += levelCount if (i + levelCount*2) &lt;= h.Len() { levelCount *= 2 } else { levelCount = h.Len() - i } } } func main() { a := IntHeap{6, 2, 3, 1, 5, 4} //初始化堆 heap.Init(&amp;a) a.PrintHeap() //弹出数据，保证每次操作都是规范的堆结构 fmt.Println(heap.Pop(&amp;a)) a.PrintHeap() fmt.Println(heap.Pop(&amp;a)) a.PrintHeap() heap.Push(&amp;a, 0) heap.Push(&amp;a, 8) a.PrintHeap() } ------ [1] [2 3] [6 5 4] 1 [2] [4 3] [6 5] 2 [3] [4 5] [6] [0] [3 5] [6 4 8] Process finished with exit code 0 参考： golang 标准库 container/ring 及 container/heap | 开源中国 go语言中container容器数据结构heap、list、ring | 博客园 6. 字典Go 语言中的字典（map）用来存储键值对的集合，它其实是一个哈希表（Hash Table）的特定实现。Go 语言字典的键类型不可以是函数类型、字典类型和切片类型，键类型的值必须支持判等操作。 7. 通道Go 语言的通道（channel）类型的值本身就是并发安全的，这也是 Go 语言自带的、唯一一个可以满足并发安全性的类型。 略 8. 函数在 Go 语言中，函数是一等（first class）公民，函数类型也是一等数据类型。也就是说，函数本身也可以化身为普通的值，在其他函数间传递、赋予变量、做类型判断和转换等： package main import &quot;fmt&quot; type Printer func(contents string) (n int, err error) func printToStd(contents string) (byteNum int, err error) { return fmt.Println(contents) } func main() { var p Printer p = printToStd p(&quot;something&quot;) } ------ something Process finished with exit code 0 函数签名其实就是函数的参数列表和结果列表的统称，它定义了可用来鉴别不同函数的那些特征，同时也定义了我们与函数交互的方式 只要两个函数的参数列表和结果列表中的元素顺序及其类型是一致的，就可以说它们是实现了同一个函数类型的函数。 因此，在上面的代码中，函数printToStd是函数类型Printer的一个具体实现。 8.1 高阶函数只要满足下面的任意一个条件，就可以说这个函数是一个高阶函数： 接受其他函数作为参数传入 把其他函数作为结果返回 8.2 接受其他函数作为参数传入首先声明一个operate函数类型： type operate func(x, y int) int 注意：函数类型属于引用类型，它的值可以为nil 然后编写calculate函数： func calculate(x int, y int, op operate) (int, error) { if op == nil { return 0, errors.New(&quot;invalid operation&quot;) } return op(x, y), nil } 完整代码如下： package main import ( &quot;errors&quot; &quot;fmt&quot; ) type operate func(x, y int) int func sum(x, y int) int { return x + y } func calculate(x int, y int, op operate) (int, error) { if op == nil { return 0, errors.New(&quot;invalid operation&quot;) } return op(x, y), nil } func main() { sumResult, _ := calculate(4, 5, sum) fmt.Println(sumResult) } ------ 9 Process finished with exit code 0 8.3 把其他函数作为结果返回package main import ( &quot;errors&quot; &quot;fmt&quot; ) type operate func(x, y int) int // 方案 1 func calculate(x int, y int, op operate) (int, error) { if op == nil { return 0, errors.New(&quot;invalid operation&quot;) } return op(x, y), nil } // 方案 2 type calculateFunc func(x int, y int) (int, error) func genCalculator(op operate) calculateFunc { return func(x int, y int) (int, error) { if op == nil { return 0, errors.New(&quot;invalid operation&quot;) } return op(x, y), nil } } func main() { // 方案 1 x, y := 12, 23 op := func(x, y int) int { return x + y } result, err := calculate(x, y, op) fmt.Printf(&quot;The result: %d (error: %v)\\n&quot;, result, err) result, err = calculate(x, y, nil) fmt.Printf(&quot;The result: %d (error: %v)\\n&quot;, result, err) // 方案 2 x, y = 56, 78 add := genCalculator(op) result, err = add(x, y) fmt.Printf(&quot;The result: %d (error: %v)\\n&quot;, result, err) } ------ The result: 35 (error: &lt;nil&gt;) The result: 0 (error: invalid operation) The result: 134 (error: &lt;nil&gt;) Process finished with exit code 0 8.4 闭包 高阶函数与闭包 8.5 传入参数时区分值类型和引用类型package main import &quot;fmt&quot; func main() { array1 := [3]string{&quot;a&quot;, &quot;b&quot;, &quot;c&quot;} fmt.Printf(&quot;The array: %v\\n&quot;, array1) array2 := modifyArray(array1) fmt.Printf(&quot;The modified array: %v\\n&quot;, array2) fmt.Printf(&quot;The original array: %v\\n&quot;, array1) } func modifyArray(a [3]string) [3]string { a[1] = &quot;x&quot; return a } ------ The array: [a b c] The modified array: [a x c] The original array: [a b c] Process finished with exit code 0 所有传给函数的参数值都会被复制，函数在其内部使用的并不是参数值的原值，而是它的副本 由于数组是值类型，所以每一次复制都会拷贝它，以及它的所有元素值 对于引用类型，比如：切片、字典、通道，想下面代码中那样复制它们的值，只会拷贝它们本身而已，并不会拷贝底层数据，即只发生“浅拷贝” 9. 结构体10. 接口在 Go 语言的语境中，当我们谈论“接口”的时候，一定是指接口类型，因为接口类型与其他数据类型不同，是没法被实例化的。 具体来讲，就是说我们既不能通过调用new或make函数创建出一个接口类型的值，也无法用字面量来表示一个接口类型的值。 对于任何数据类型，只要它的方法集合中完全包含了一个接口的全部特征（即实现了全部方法），那么它就是这个接口的实现类型。 11. Go 语句及其执行规则goroutine代表着并发编程模型中的用户级线程。 11.1 进程与线程进程，描述的是程序的执行过程，是运行着的程序代表，也是资源分配的基本单位。 线程，总是在进程之内，可以被视为进程中运行着的控制流，是调度的基本单位。 一个进程至少会包含一个线程。如果一个进程只包含了一个线程，那么它里面的所有代码都只会被串行的执行。每个进程的第一个线程都会随着该进程的启动而被创建，被称为其所属进程的主线程 相应的，如果一个进程中包含了多个线程，那么其中的代码就可以被并发的执行。除了主线程之外，其他的线程都是由进程中已存在的线程创建出来的 Go 语言的运行时（runtime）系统会帮助我们自动的创建和销毁系统级的线程，而用户级的线程需要用户自己手动创建和销毁 11.2 调度器Go 语言不但有独特的并发编程模型，以及用户级线程goroutine，还有提供了一个用于调度goroutine、对接系统级线程的调度器。这个调度器是 Go 语言 runtime 的重要组成部分，它主要负责统筹调配 Go 并发编程模型中的三个主要元素：G（goroutine）、P（processor）、M（machine）。 M、P、G 之间的关系 例如以下代码： package main import ( &quot;fmt&quot; &quot;time&quot; ) func main() { for i := 0; i &lt; 10; i++ { time.Sleep(time.Millisecond) go func() { fmt.Println(i) }() } time.Sleep(time.Second) } ------ 1 2 3 4 5 6 7 8 9 10 Process finished with exit code 0 11.3 让主协程等待其他协程先创建一个通道，长度与我们要手动启用的goroutine数量一致。在每个协程即将运行完毕时，都要向通道发送一个值。 需要注意的是，在通道声明sign := make(chan struct{}, num)中，通道的类型为struct{}，其中的类型字面量struct有些类似于空接口类型interface{}，它代表了既不包含任何字段也不拥有任何方法的空结构体类型。而它类型值的表示法只有一个，那就是struct{}{}。并且，它占用的内存空间是0字节。 确切的说，struct{}{}这个值在整个 Go 程序中永远都只会存在一份。虽然我们可以无数次的使用这个值字面量，但用到的却都是同一个值 package main import ( &quot;fmt&quot; //&quot;time&quot; ) func main() { num := 10 sign := make(chan struct{}, num) for i := 0; i &lt; num; i++ { go func() { fmt.Println(i) sign &lt;- struct{}{} }() } // 办法 1 //time.Sleep(time.Millisecond * 500) // 办法 2 for j := 0; j &lt; num; j++ { &lt;-sign } } ------ // 结果不唯一 10 6 3 10 8 10 10 10 10 10 Process finished with exit code 0 使用sync.WaitGroup会比使用通道更加优雅，之后再来看 11.4 让多个协程按照既定的顺序运行package main import ( &quot;fmt&quot; &quot;sync/atomic&quot; &quot;time&quot; ) func main() { var count uint32 trigger := func(i uint32, fn func()) { for { if n := atomic.LoadUint32(&amp;count); n == i { fn() atomic.AddUint32(&amp;count, 1) break } time.Sleep(time.Nanosecond) } } for i := uint32(0); i &lt; 10; i++ { go func(i uint32) { fn := func() { fmt.Println(i) } trigger(i, fn) }(i) } trigger(10, func() { fmt.Println(&quot;End in main goroutine&quot;) }) } ------ 0 1 2 3 4 5 6 7 8 9 End in main goroutine Process finished with exit code 0 12. 流程控制语句 略 13. 错误处理13.1 使用 errors 的示例package main import ( &quot;errors&quot; &quot;fmt&quot; ) func echo(request string) (response string, err error) { if request == &quot;&quot; { err = errors.New(&quot;empty request&quot;) return } response = fmt.Sprintf(&quot;echo: %s&quot;, request) return } func main() { for _, req := range []string{&quot;&quot;, &quot;hello!&quot;} { fmt.Printf(&quot;request: %s\\n&quot;, req) resp, err := echo(req) if err != nil { fmt.Printf(&quot;error: %s\\n&quot;, err) } fmt.Printf(&quot;response: %s\\n&quot;, resp) } } ------ request: error: empty request response: request: hello! response: echo: hello! Process finished with exit code 0 13.2 判断错误的具体类型package main import ( &quot;fmt&quot; &quot;os&quot; &quot;os/exec&quot; &quot;runtime&quot; ) // underlyingError 会返回已知的操作系统相关错误的潜在错误值。 func underlyingError(err error) error { switch err := err.(type) { case *os.PathError: return err.Err case *os.LinkError: return err.Err case *os.SyscallError: return err.Err case *exec.Error: return err.Err } return err } func main() { // 示例1。 r, w, err := os.Pipe() if err != nil { fmt.Printf(&quot;unexpected error: %s\\n&quot;, err) return } // 人为制造 *os.PathError 类型的错误。 r.Close() _, err = w.Write([]byte(&quot;hi&quot;)) uError := underlyingError(err) fmt.Printf(&quot;underlying error: %s (type: %T)\\n&quot;, uError, uError) fmt.Println() // 示例2。 paths := []string{ os.Args[0], // 当前的源码文件或可执行文件。 &quot;/it/must/not/exist&quot;, // 肯定不存在的目录。 os.DevNull, // 肯定存在的目录。 } printError := func(i int, err error) { if err == nil { fmt.Println(&quot;nil error&quot;) return } err = underlyingError(err) switch err { case os.ErrClosed: fmt.Printf(&quot;error(closed)[%d]: %s\\n&quot;, i, err) case os.ErrInvalid: fmt.Printf(&quot;error(invalid)[%d]: %s\\n&quot;, i, err) case os.ErrPermission: fmt.Printf(&quot;error(permission)[%d]: %s\\n&quot;, i, err) } } var f *os.File var index int { index = 0 f, err = os.Open(paths[index]) if err != nil { fmt.Printf(&quot;unexpected error: %s\\n&quot;, err) return } // 人为制造潜在错误为 os.ErrClosed 的错误。 f.Close() _, err = f.Read([]byte{}) printError(index, err) } { index = 1 // 人为制造 os.ErrInvalid 错误。 f, _ = os.Open(paths[index]) _, err = f.Stat() printError(index, err) } { index = 2 // 人为制造潜在错误为 os.ErrPermission 的错误。 _, err = exec.LookPath(paths[index]) printError(index, err) } if f != nil { f.Close() } fmt.Println() // 示例3。 paths2 := []string{ runtime.GOROOT(), // 当前环境下的Go语言根目录。 &quot;/it/must/not/exist&quot;, // 肯定不存在的目录。 os.DevNull, // 肯定存在的目录。 } printError2 := func(i int, err error) { if err == nil { fmt.Println(&quot;nil error&quot;) return } err = underlyingError(err) if os.IsExist(err) { fmt.Printf(&quot;error(exist)[%d]: %s\\n&quot;, i, err) } else if os.IsNotExist(err) { fmt.Printf(&quot;error(not exist)[%d]: %s\\n&quot;, i, err) } else if os.IsPermission(err) { fmt.Printf(&quot;error(permission)[%d]: %s\\n&quot;, i, err) } else { fmt.Printf(&quot;error(other)[%d]: %s\\n&quot;, i, err) } } { index = 0 err = os.Mkdir(paths2[index], 0700) printError2(index, err) } { index = 1 f, err = os.Open(paths[index]) printError2(index, err) } { index = 2 _, err = exec.LookPath(paths[index]) printError2(index, err) } if f != nil { f.Close() } } ------ underlying error: The pipe is being closed. (type: syscall.Errno) error(closed)[0]: file already closed error(invalid)[1]: invalid argument nil error error(exist)[0]: Cannot create a file when that file already exists. error(not exist)[1]: The system cannot find the path specified. nil error Process finished with exit code 0 14. 异常处理14.1 panic一个panic的示例如下（在运行时抛出）： panic: runtime error: index out of range goroutine 1 [running]: main.main() /Users/haolin/GeekTime/Golang_Puzzlers/src/puzzlers/article19/q0/demo47.go:5 +0x3d exit status 2 问题：从panic被引发到程序终止运行的大致过程是什么？ package main import ( &quot;fmt&quot; ) func main() { fmt.Println(&quot;Enter function main.&quot;) caller1() fmt.Println(&quot;Exit function main.&quot;) } func caller1() { fmt.Println(&quot;Enter function caller1.&quot;) caller2() fmt.Println(&quot;Exit function caller1.&quot;) } func caller2() { fmt.Println(&quot;Enter function caller2.&quot;) s1 := []int{0, 1, 2, 3, 4} e5 := s1[5] _ = e5 fmt.Println(&quot;Exit function caller2.&quot;) } ------ Enter function main. Enter function caller1. Enter function caller2. panic: runtime error: index out of range goroutine 1 [running]: main.caller2() C:/Users/abel1/go/src/github.com/abelsu7/hello/main.go:22 +0x69 main.caller1() C:/Users/abel1/go/src/github.com/abelsu7/hello/main.go:15 +0x6d main.main() C:/Users/abel1/go/src/github.com/abelsu7/hello/main.go:9 +0x6d Process finished with exit code 2 当某个函数中的某行代码有意或无意引发了一个panic，这时，初始的panic详情会被建立起来，并且该程序的控制权会立即从此行代码转移至调用栈的上一级函数，而此行代码所属函数的执行随即终止。 紧接着，控制权并不会有任何停留，它又会立即转移至再上一级的调用代码处理，如此一级一级沿着调用栈的反方向传播至顶端，就是我们编写的最外层函数。 最后，控制权被 Go 语言运行时系统收回，程序崩溃并终止运行，承载程序这次运行的进程也随之死亡并消失。与此同时，在控制权传播的过程中，panic详情会被逐渐积累和完善，并会在程序终止之前打印出来。 14.2 recover14.3 defer参考文章 Go 语言核心 36 讲 | 极客时间 Go 命令教程 | Github Go 标准库学习笔记-双向链表 (container/list) | CSDN Golang 标准库深入 - 双向链表（container/list）| 开源中国 golang 标准库 container/ring 及 container/heap | 开源中国 go语言中container容器数据结构heap、list、ring | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"}]},{"title":"Go 语言测试框架 testing 快速体验","slug":"go-testing-demo","date":"2019-03-13T03:29:53.000Z","updated":"2019-09-01T13:04:11.271Z","comments":true,"path":"2019/03/13/go-testing-demo/","link":"","permalink":"https://abelsu7.top/2019/03/13/go-testing-demo/","excerpt":"Go 语言内置了测试包 testing，可以很方便的为函数编写测试方法","text":"Go 语言内置了测试包 testing，可以很方便的为函数编写测试方法 1. 引入 testing 包import &quot;testing&quot; 2. 源代码文件假设源代码文件为_1_sorts/Sort.go： package _1_sorts /* 冒泡排序、插入排序、选择排序 */ //冒泡排序，a是数组，n表示数组大小 func BubbleSort(a []int, n int) { if n &lt;= 1 { return } for i := 0; i &lt; n; i++ { // 提前退出标志 flag := false for j := 0; j &lt; n-i-1; j++ { if a[j] &gt; a[j+1] { a[j], a[j+1] = a[j+1], a[j] //此次冒泡有数据交换 flag = true } } // 如果没有交换数据，提前退出 if !flag { break } } } // 插入排序，a表示数组，n表示数组大小 func InsertionSort(a []int, n int) { if n &lt;= 1 { return } for i := 1; i &lt; n; i++ { value := a[i] j := i - 1 //查找要插入的位置并移动数据 for ; j &gt;= 0; j-- { if a[j] &gt; value { a[j+1] = a[j] } else { break } } a[j+1] = value } } // 选择排序，a表示数组，n表示数组大小 func SelectionSort(a []int, n int) { if n &lt;= 1 { return } for i := 0; i &lt; n; i++ { // 查找最小值 minIndex := i for j := i + 1; j &lt; n; j++ { if a[j] &lt; a[minIndex] { minIndex = j } } // 交换 a[i], a[minIndex] = a[minIndex], a[i] } } // 归并排序 func MergeSort(a []int, n int) { if n &lt;= 1 { return } mergeSort(a, 0, n-1) } func mergeSort(a []int, start, end int) { if start &gt;= end { return } mid := (start + end) / 2 mergeSort(a, start, mid) mergeSort(a, mid+1, end) merge(a, start, mid, end) } func merge(a []int, start, mid, end int) { tmpArr := make([]int, end-start+1) i := start j := mid + 1 k := 0 for ; i &lt;= mid &amp;&amp; j &lt;= end; k++ { if a[i] &lt; a[j] { tmpArr[k] = a[i] i++ } else { tmpArr[k] = a[j] j++ } } for ; i &lt;= mid; i++ { tmpArr[k] = a[i] k++ } for ; j &lt;= end; j++ { tmpArr[k] = a[j] j++ } copy(a[start:end+1], tmpArr) } func QuickSort(a []int, n int) { separateSort(a, 0, n-1) } func separateSort(a []int, start, end int) { if start &gt;= end { return } i := partition(a, start, end) separateSort(a, start, i-1) separateSort(a, i+1, end) } func partition(a []int, start, end int) int { // 选取最后一位当对比数字 pivot := a[end] i := start for j := start; j &lt; end; j++ { if a[j] &lt; pivot { if !(i == j) { // 交换位置 a[i], a[j] = a[j], a[i] } i++ } } a[i], a[end] = a[end], a[i] return i } 3. 测试代码文件 测试文件_1_sorts/Sort_test.go的文件名后缀必须为_test，文件名前半部分无要求，一般与被测源代码文件相同 测试函数如TestBubbleSort，函数名必须以Test为前缀，函数名后半部分无要求 测试函数参数必须为test *testing.T package _1_sorts import ( &quot;fmt&quot; &quot;math/rand&quot; &quot;testing&quot; ) func createRandomArr(len int) []int { arr := make([]int, len, len) for i := 0; i &lt; len; i++ { arr[i] = rand.Intn(100) } return arr } func TestBubbleSort(t *testing.T) { arr := []int{1, 5, 9, 6, 3, 7, 5, 10} fmt.Println(&quot;排序前：&quot;, arr) BubbleSort(arr, len(arr)) fmt.Println(&quot;排序后：&quot;, arr) } func TestInsertionSort(t *testing.T) { arr := []int{1, 5, 9, 6, 3, 7, 5, 10} fmt.Println(&quot;排序前：&quot;, arr) InsertionSort(arr, len(arr)) fmt.Println(&quot;排序后：&quot;, arr) } func TestSelectionSort(t *testing.T) { arr := []int{1, 5, 9, 6, 3, 7, 5, 10} fmt.Println(&quot;排序前：&quot;, arr) SelectionSort(arr, len(arr)) fmt.Println(&quot;排序后：&quot;, arr) } func TestMergeSort(t *testing.T) { a := []int{5, 4} MergeSort(a, len(a)) t.Log(a) a = []int{5, 4, 3, 2, 1} MergeSort(a, len(a)) t.Log(a) } func TestQuickSort(t *testing.T) { a := []int{5, 4} QuickSort(a, len(a)) t.Log(a) a = createRandomArr(100) QuickSort(a, len(a)) t.Log(a) } 4. 运行结果=== RUN TestBubbleSort 排序前： [1 5 9 6 3 7 5 10] 排序后： [1 3 5 5 6 7 9 10] --- PASS: TestBubbleSort (0.00s) === RUN TestInsertionSort 排序前： [1 5 9 6 3 7 5 10] 排序后： [1 3 5 5 6 7 9 10] --- PASS: TestInsertionSort (0.00s) === RUN TestSelectionSort 排序前： [1 5 9 6 3 7 5 10] 排序后： [1 3 5 5 6 7 9 10] --- PASS: TestSelectionSort (0.00s) === RUN TestMergeSort --- PASS: TestMergeSort (0.00s) Sort_test.go:41: [4 5] Sort_test.go:45: [1 2 3 4 5] === RUN TestQuickSort --- PASS: TestQuickSort (0.00s) Sort_test.go:51: [4 5] Sort_test.go:55: [0 0 2 2 2 3 3 5 5 5 6 7 8 10 11 11 13 15 18 18 20 21 23 24 25 26 28 28 28 29 31 31 33 33 33 36 37 37 37 38 40 40 41 41 43 43 45 46 46 47 47 47 47 47 51 52 53 53 55 56 56 56 57 58 59 59 59 61 62 63 63 63 66 66 74 76 77 78 78 81 81 83 85 87 87 87 88 88 89 89 90 90 91 94 94 94 95 96 98 99] PASS Process finished with exit code 0 参考文章 Go语言测试框架（testing）用法 | CSDN Go testing 使用 | 简书 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"}]},{"title":"Java 笔记 5：集合","slug":"core-java-notes-5","date":"2019-03-11T06:39:15.000Z","updated":"2019-09-01T13:04:11.090Z","comments":true,"path":"2019/03/11/core-java-notes-5/","link":"","permalink":"https://abelsu7.top/2019/03/11/core-java-notes-5/","excerpt":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》","text":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》 集合1. Java 集合框架1.1 将集合的结构与实现分离Java 集合类库也将接口（interface）与实现（implementation）分离。 例如队列接口的最简形式类似下面的代码： public interface Queue&lt;E&gt; {// a simplified form of the interface in the standard library void add(E element); E remove(); int size(); } 这个接口并没有说明队列是如何实现的，通常有两种实现方式：一种是使用循环数组；另一种是使用链表。 这样做的好处是：当在程序中使用队列时，一旦构建了集合，就不需要知道究竟使用了哪种实现。因此，只有在构建集合对象的时候，使用具体的类才有意义。可以使用接口类型存放集合的引用： Queue&lt;Customer&gt; expressLane = new CircularArrayQueue&lt;&gt;(100); expressLane.add(new Customer(&quot;Harry&quot;)); 这样一来，一旦改变了想法，就可以轻松的使用另外一种不同的实现。只需要对程序的一个地方做出修改，即调用构造器的地方。如果觉得LinkedListQueue是个更好的选择，就将代码修改为： Queue&lt;Customer&gt; expressLane = new LinkedListQueue&lt;&gt;(100); expressLane.add(new Customer(&quot;Harry&quot;)); 注：循环数组是一个有界集合，即容量有限。如果程序中要收集的对象数量没有上限，就最好使用链表来实现 1.2 Collection 接口在 Java 类库中，集合类的基本接口是Collection接口，它有两个基本方法： public interface Collection&lt;E&gt; { boolean add(E element); Iterator&lt;E&gt; iterator(); ... } 方法add用于向集合中添加元素。如果添加元素确实改变了集合就返回true，如果集合没有发生变化就返回false。 方法iterator用于返回一个实现了Iterator接口的对象，可以使用这个迭代器依次访问集合中的元素。 1.3 迭代器接口Iterator包含了 4 个方法： public interface Iterator&lt;E&gt; { E next(); boolean hasNext(); void remove(); default void forEachRemaining(Consumet&lt;? super E&gt; action); } 用for each循环可以简练的表示循环操作： for (String element : c) { do something with element } 编译器简单的将for each循环翻译为带有迭代器的循环。for each循环可以与任何实现了Iterable接口的对象一起工作，这个接口只包含一个抽象方法： public interface Iterable&lt;E&gt; { Iterator&lt;E&gt; iterator(); ... } Collection接口扩展了Iterable接口。因此，对于标准类库中的任何集合，对可以使用for each循环。 在 Java SE 8 中，甚至不用写循环，可以调用forEachRemaining方法并提供一个 lambda 表达式： iterator.forEachRemaining(element -&gt; do something with element); 注：Java 迭代器应该被视作位于两个元素之间。当调用next时，迭代器就越过下一个元素，并返回刚刚越过的那个元素的引用，而Iterator接口的remove方法将会删除上次调用next方法时返回的元素。 例如，删除字符串集合中的第一个元素： Iterator&lt;String&gt; it = c.iterator(); it.next(); // skip over the first element it.remove(); // now remove it 类似的，要想删除两个相邻的元素，必须先调用next越过将要删除的元素： it.remove(); it.next(); it.remove(); 1.4 泛型实用方法由于Collection和Iterator都是泛型接口，可以编写操作任何集合类型的实用方法： public static &lt;E&gt; boolean contains(Collection&lt;E&gt; c, Object obj) { for (E element : c) if (element.equals(obj)) return true; return false; } int size() boolean isEmpty() boolean contains(Object obj) boolean containsAll(Collection&lt;?&gt; c) boolean equals(Object other) boolean addAll (Collection&lt;? extends E&gt; from) boolean remove(Object obj) boolean removeAll(Collection&lt;?&gt; c) void clear() boolean retainAll(Col1ection&lt;?&gt; c) Object[] toArray() &lt;T&gt; T[] toArray(T[] arrayToFill) 1.5 集合框架中的接口Java 集合框架为不同类型的集合定义了大量接口： 集合框架的接口 集合有两个基本接口：Collection和Map： boolean add(E element) // 用于集合 iterator.next() V put(K key, V value) // 用于映射 V get(K key) 2. 线性表与队列下面展示了 Java 类库中的集合，并简要描述了每个集合类的用途。除了以Map结尾的类之外，其他类都实现了Collection接口，而以Map结尾的类则实现了Map接口： ArrayList：一种可以动态增长和缩减的索引序列 LinkedList：一种可以在任何位置进行高效的插入和删除操作的有序序列 ArrayQueue：一种用循环数组实现的双端队列 HashSet：一种没有重复元素的无序集合 TreeSet：一种有序集 EnumSet：一种包含枚举类型值的集 LinkedHashSet：一种可以记住元素插入次序的集 PriorityQueue：一种允许高效删除最小元素的集合 HashMap：一种存储键/值关联的数据结构 TreeMap：一种键值有序排列的映射表 EnumMap：一种键值属于枚举类型的映射表 LinkedHashMap：一种可以记住键/值项并添加次序的映射表 WeakHashMap：一种其值无用武之地后可以被 GC 回收的映射表 IdentityHashMap：一种用==而不是用equals比较键值的映射表 2.1 链表 LinkedList在 Java 中，所有链表（Linked List）都是双向链接（Doubly Linked）的，即每个节点还存放着指向前驱节点的引用。 例如下面的代码示例，先添加 3 个元素，然后再将第 2 个元素删除： import java.util.Iterator; import java.util.LinkedList; import java.util.List; public class Main { public static void main(String[] args) { List&lt;String&gt; staff = new LinkedList&lt;&gt;(); staff.add(&quot;Amy&quot;); staff.add(&quot;Bob&quot;); staff.add(&quot;Carl&quot;); System.out.println(staff); Iterator iterator = staff.iterator(); String first = iterator.next().toString(); String second = iterator.next().toString(); iterator.remove(); for (String name : staff) { System.out.println(name); } } } ------ [Amy, Bob, Carl] Amy Carl Process finished with exit code 0 但是，链表与泛型集合有一个重要的区别：链表是一个有序集合（Ordered Collection），每个对象的位置十分重要。 关于 Java 中Iterator和ListIterator的区别，可以参考 Java 中 ListIterator 和 Iterator 详解与辨析 | CSDN 另外，链表不支持快速的随机访问。如果要查看链表中第n个元素，就必须从头开始，越过n-1个元素，没有捷径可走。鉴于这个原因，在程序需要采用整数索引访问元素时，通常不会采用链表而会选择数组，因为LinkedList对象根本不做任何缓存位置信息的操作。 package linkedList; import java.util.*; /** * This program demonstrates operations on linked lists. * * @author Cay Horstmann * @version 1.11 2012-01-26 */ public class LinkedListTest { public static void main(String[] args) { List&lt;String&gt; a = new LinkedList&lt;&gt;(); a.add(&quot;Amy&quot;); a.add(&quot;Carl&quot;); a.add(&quot;Erica&quot;); List&lt;String&gt; b = new LinkedList&lt;&gt;(); b.add(&quot;Bob&quot;); b.add(&quot;Doug&quot;); b.add(&quot;Frances&quot;); b.add(&quot;Gloria&quot;); // merge the words from b into a ListIterator&lt;String&gt; aIter = a.listIterator(); Iterator&lt;String&gt; bIter = b.iterator(); while (bIter.hasNext()) { if (aIter.hasNext()) aIter.next(); aIter.add(bIter.next()); } System.out.println(a); // remove every second word from b bIter = b.iterator(); while (bIter.hasNext()) { bIter.next(); // skip one element if (bIter.hasNext()) { bIter.next(); // skip next element bIter.remove(); // remove that element } } System.out.println(b); // bulk operation: remove all words in b from a a.removeAll(b); System.out.println(a); } } ------ [Amy, Bob, Carl, Doug, Erica, Frances, Gloria] [Bob, Frances] [Amy, Carl, Doug, Erica, Gloria] Process finished with exit code 0 2.2 数组列表 ArrayList集合类库提供了ArrayList类，这个类也实现了List接口。ArrayList封装了一个动态再分配的对象数组。 Vector 类的所有方法都是同步的，可以由两个线程安全的访问一个 Vector 对象。但是，如果由一个线程访问 Vector，代码要在同步操作上耗费大量的时间。而 ArrayList 方法不是同步的，因此，建议在不需要同步的时候使用ArrayList，而不要使用Vector。 2.3 散列集 HashSet散列表（Hash Table）可以快速的查找所需要的对象，而忽略元素出现的次序。散列表为每个对象计算一个整数，称为散列码（Hash Code）。散列码是由对象的实例域产生的一个整数。 在 Java 中，散列表用链表数组实现。每个链表被称为桶（bucket）。要想查找表中对象的位置，就要先计算它的散列码，然后与桶的总数取余，所得到的结果就是保存这个元素的桶的索引。 当然，有时候会遇到桶被占满的情况，这种现象被称为散列冲突（hash collision）。 在 Java SE 8 中，桶满时会从链表变为平衡二叉树。 Java 集合类库提供了一个HashSet类，它实现了基于散列表的集，可以用add方法添加元素。contains方法已经被重新定义，用来快速的查看是否某个元素已经出现在集中。它只在某个桶中查找元素，而不必查看集合中的所有元素。 package set; import java.util.*; /** * This program uses a set to print all unique words in System.in. * * @author Cay Horstmann * @version 1.12 2015-06-21 */ public class SetTest { public static void main(String[] args) { Set&lt;String&gt; words = new HashSet&lt;&gt;(); // HashSet implements Set long totalTime = 0; try (Scanner in = new Scanner(System.in)) { while (in.hasNext()) { String word = in.next(); long callTime = System.currentTimeMillis(); words.add(word); callTime = System.currentTimeMillis() - callTime; totalTime += callTime; } } Iterator&lt;String&gt; iter = words.iterator(); for (int i = 1; i &lt;= 20 &amp;&amp; iter.hasNext(); i++) System.out.println(iter.next()); System.out.println(&quot;. . .&quot;); System.out.println(words.size() + &quot; distinct words. &quot; + totalTime + &quot; milliseconds.&quot;); } } 2.4 树集 TreeSet树集（TreeSet）与散列集十分类似，不过比散列集有所改进。树集是一个有序集合，可以以任意顺序将元素插入到集合中。在对集合进行遍历时，每个值将自动的按照字典顺序呈现： import java.util.SortedSet; import java.util.TreeSet; public class Main { public static void main(String[] args) { SortedSet&lt;String&gt; sorter = new TreeSet&lt;&gt;(); // TreeSet implements SortedSet sorter.add(&quot;Bob&quot;); sorter.add(&quot;Amy&quot;); sorter.add(&quot;Carl&quot;); for (String s : sorter) { System.out.println(s); } } } ------ Amy Bob Carl Process finished with exit code 0 正如TreeSet类名所示，排序是用树结构（红黑树）完成的。每次将一个元素添加到树中时，都被放置在正确的排序位置上。因此，迭代器总是以排好序的顺序访问每个元素。 添加元素到树集中的速度比散列表中要慢，不过还是比数组或链表快。另外，要使用树集，必须能够比较元素，这些元素必须实现Comparable接口，或者构造集的时候必须提供一个Comparator 2.5 队列与双端队列队列（Queue）可以让我们有效的在尾部添加一个元素，在头部删除一个元素。有两个端头的队列，即双端队列（Deque），可以有效的在头部和尾部同时添加或删除元素，但不支持在队列中间添加元素。 在 Java SE 6 中引入了Deque接口，并由ArrayDeque和LinkedList类实现。这两个类都提供了双端队列，而且在必要时可以增加队列的长度。 Queue&lt;String&gt; student = new LinkedList&lt;&gt;(); Deque&lt;String&gt; teacher = new ArrayDeque&lt;&gt;(); Deque&lt;String&gt; employee = new LinkedList&lt;&gt;(); 2.6 优先级队列优先级队列（priority queue）中的元素可以按照任意的顺序插入，却总是按照排序的顺序进行检索。也就是说，无论何时调用remove方法，总会获得当前优先级队列中最小的元素。 优先级队列使用了一个优雅且高效的数据结构，称为堆（heap）。堆是一个可以自我调整的二叉树，对树执行添加add和删除remove操作，可以让最小的元素移动到根，而不必花费时间对元素进行排序。 使用优先级队列的典型示例是任务调度。每一个任务有一个优先级，任务以随机顺序添加到队列中。每当启动一个新任务的时候，就将优先级最高的任务从队列中删除 import java.time.LocalDate; import java.util.PriorityQueue; public class Main { public static void main(String[] args) { PriorityQueue&lt;LocalDate&gt; pq = new PriorityQueue&lt;&gt;(); pq.add(LocalDate.of(1906, 12, 9)); // G. Hopper pq.add(LocalDate.of(1815, 12, 10)); // A. Lovelace pq.add(LocalDate.of(1903, 12, 3)); // J. von Neumann pq.add(LocalDate.of(1910, 6, 22)); // K. Zuse System.out.println(&quot;Iterating over elements...&quot;); for (LocalDate date : pq) { System.out.println(date); } System.out.println(&quot;Removing elements...&quot;); while (!pq.isEmpty()) { System.out.println(pq.remove()); } } } 3. 映射映射（map）用来存放键/值对，如果提供了键，就能查找到值。 3.1 基本映射操作Java 类库为映射提供了两个通用的实现：HashMap和TreeMap，这两个类都实现了Map接口。 HashMap对键进行散列，TreeMap用键的整体顺序对元素进行排序，并将其组织成搜索树。散列或比较函数只能作用于键，与键关联的值不能进行散列或比较。 与集一样，HashMap比TreeMap稍微快一些。如果不需要按照排列顺序访问键，就最好选择散列 Map&lt;String, Employee&gt; staff = new HashMap&lt;&gt;(); // HashMap implements Map Employee harry = new Employee(&quot;Harry Hacker&quot;, 8000, 1990, 11, 07); staff.put(&quot;987-98-9996&quot;, harry); // 使用键来检索对象，如果不存在则返回 null String id = &quot;987-98-9996&quot;; Employee e = staff.get(id); 还可以设定一个默认值，用作映射中不存在的键： Map&lt;String, Integer&gt; scores = ...; int score = scores.get(id, 0); // Gets 0 if the id is not present 键必须是唯一的，不能对同一个键存放两个值。如果对同一个键两次调用put方法，则第二个值就会覆盖第一个值 remove方法用于从映射中删除给定键对应的元素 size方法用于返回映射中的元素个数 可以使用 lambda 表达式和forEach方法，迭代处理映射的键和值 scores.forEach((k, v) -&gt; System.out.println(&quot;key=&quot; + k + &quot;value=&quot; + v)); 如下的示例代码显示了映射的操作过程： package map; import java.util.*; /** * This program demonstrates the use of a map with key type String and value type Employee. * @version 1.12 2015-06-21 * @author Cay Horstmann */ public class MapTest { public static void main(String[] args) { Map&lt;String, Employee&gt; staff = new HashMap&lt;&gt;(); staff.put(&quot;144-25-5464&quot;, new Employee(&quot;Amy Lee&quot;)); staff.put(&quot;567-24-2546&quot;, new Employee(&quot;Harry Hacker&quot;)); staff.put(&quot;157-62-7935&quot;, new Employee(&quot;Gary Cooper&quot;)); staff.put(&quot;456-62-5527&quot;, new Employee(&quot;Francesca Cruz&quot;)); // print all entries System.out.println(staff); // remove an entry staff.remove(&quot;567-24-2546&quot;); // replace an entry staff.put(&quot;456-62-5527&quot;, new Employee(&quot;Francesca Miller&quot;)); // look up a value System.out.println(staff.get(&quot;157-62-7935&quot;)); // iterate through all entries staff.forEach((k, v) -&gt; System.out.println(&quot;key=&quot; + k + &quot;, value=&quot; + v)); } } 3.2 更新映射项当更新一个之前不存在的键值时会抛出NullPointerException异常，作为补救，可以使用getOrDefault方法设置一个默认值： counts.put(word, counts.getOrDefault(word, 0) + 1); 或者首先调用putIfAbsent方法，当原先的键不存在时才会放入一个值： counts.putIfAbsent(word, 0); counts.put(word, counts.get(word) + 1); 还可以使用merge方法来简化操作。如果键原先不存在，则下面的调用： counts.merge(word, 1, Integer::sum); 将把word与1关联，否则使用Integer::sum函数组合将原值和1相加求和。 3.3 映射视图集合框架不认为映射本身是一个集合。不过，可以得到映射的视图（view）——这是实现了Collection接口或某个子接口的对象。 有三种视图：键集、值集合（不是一个集）以及键/值对集。键和键/值对可以构成一个集，因为映射中一个键只能有一个副本。下面的方法： Set&lt;K&gt; keySet() Collection&lt;V&gt; values() Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet() 会分别返回这三个视图。需要注意的是，keySet不是HashSet或者TreeSet，而是实现了Set接口的另外某个类的对象。Set接口扩展了Collection接口，因此可以像使用集合一样使用ketSet。例如可以枚举一个映射的所有键： Set&lt;String&gt; keys = map.keySet(); for (String key: keys) { do something with key } 如果想同时查看键和值，可以通过枚举条目来避免查找值： for (Map.Entry&lt;String, Employee&gt; entry: staff.entrySet()) { String k = entry.getKey(); Employee v = entry.getValue(); do something with k, v } 现在，还可以使用forEach方法： counts.forEach((k, v) -&gt; { do something with k, v }) 3.4 弱散列映射对于类WeakHashMap，如果有一个值，假定对该值对应的键的最后一次引用已经消亡，不再有任何途径引用这个值的对象了，这时这个键/值对就会被 GC 回收。 3.5 LinkedHashSet 与 LinkedHashMapLinkedHashSet与LinkedHashMap两个类用来记住插入元素项的顺序。当条目插入到散列表中时，就会被并入到双向链表中： LinkedHashList 3.6 枚举集与映射EnumSet是一个枚举类型元素集的高效实现。可以使用静态工厂方法构造这个集： enum Weekday { MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY }; EnumSet&lt;Weekday&gt; always = EnumSet.allOf(Weekday.class); EnumSet&lt;Weekday&gt; never = EnumSet.noneOf(Weekday.class); EnumSet&lt;Weekday&gt; workday = EnumSet.range(Weekday.MONDAY, Weekday.FRIDAY); EnumSet&lt;Weekday&gt; mwf = EnumSet.of(Weekday.MONDAY, Weekday.WEDNESDAY, Weekday.FRIDAY); EnumMap是一个键类型为枚举类型的映射，可以直接且高效的用一个值数组实现。在使用时，需要在构造器中指定键类型： EnumMap&lt;Weekday, Employee&gt; personInCharge = new EnumMap&lt;&gt;(Weekday.class); 3.7 标识散列映射在类IdentityHashMap中，键的散列值不是用hashCode函数计算的，而是用System.identityHashCode方法计算的。这是Object.hashCode方法根据对象的内存地址来计算散列码时所使用的方式。而且，在对两个对象进行比较时，IdentityHashMap类使用==，而不是equals，所以不同的键对象，即使内容相同，也被视为是不同的对象。 4. 视图与包装器4.1 轻量级集合包装器Arrays 类的静态方法asList将返回一个包装了普通 Java 数组的 List 包装器，这个方法可以将数组传递给一个期望得到列表或者集合参数的方法： Card[] cardDeck = new Card[52]; ... List&lt;Card&gt; cardList = Arrays.asList(cardDeck); List&lt;String&gt; names = Arrays.asList(&quot;Amy&quot;, &quot;Bob&quot;, &quot;Carl&quot;); 4.2 子范围可以为很多集合建立子范围（subrange）视图： import java.util.ArrayList; import java.util.List; public class Main { public static void main(String[] args) { List&lt;String&gt; names = new ArrayList&lt;&gt;(); names.add(&quot;Abel&quot;); names.add(&quot;Bob&quot;); names.add(&quot;Carl&quot;); List group2 = names.subList(0, 2); System.out.println(group2); group2.clear(); System.out.println(names); System.out.println(group2); } } ------ [Abel, Bob] [Carl] [] Process finished with exit code 0 对于有序集和映射，可以使用排序顺序而不是元素位置建立子范围： // 有序集 SortedSet&lt;E&gt; subSet(E from, E to) SortedSet&lt;E&gt; headSet(E to) SortedSet&lt;E&gt; tailSet(E from) // 有序映射 SortedMap&lt;K, V&gt; subMap(K from, K to) SortedMap&lt;K, V&gt; headMap(K to) SortedMap&lt;K, V&gt; tailMap(K from) 4.3 不可修改的视图Collections 还有几个方法，用于产生集合的不可修改视图（unmodifiable views）。这些视图对现有集合增加了一个运行时检查，如果发现试图对集合进行修改，就抛出一个异常，同时这个集合将保持未修改的状态： Collections.unmodifiableCollection Collections.unmodifiableList Collections.unmodifiableSet Collections.unmodifiableSortedSet Collections.unmodifiableNavigableSet Collections.unmodifiableMap Collections.unmodifiableSortedMap Collections.unmodifiableNavigableMap ... List&lt;String&gt; staff = new LinkedList&lt;&gt;(); ... lookAt(Collections.unmodifiableList(staff)); 4.4 同步视图例如，Collections 类的静态synchronizedMap方法可以将任何一个映射表转换成具有同步访问方法的 Map： Map&lt;String, Employee&gt; map = Collections.synchronizedMap(new HashMap&lt;String, Employee&gt;); 这样一来，就可以由多线程访问map对象了。 4.5 受查视图List&lt;String&gt; safeStrings = Collections.checkedList(strings, String.class); 视图的add方法将检测插入的对象是否属于给定的类。如果不属于给定的类，就立即抛出一个ClassCastException。 5. 算法可以将max方法实现为能够接收任何实现了Collections接口的对象： public static &lt;T extends Comparable&gt; T max(Collection&lt;T&gt; c) { if (c.isEmpty()) throw new NoSuchElementException(); Iterator&lt;T&gt; iter = c.iterator(); T largest = iter.next(); while (iter.hasNext()) { T next = iter.next(); if (largest.compareTo(next) &lt; 0) largest = next; } return largest; } 5.1 排序与混排Collections 类中的sort方法可以对实现了List接口的集合进行排序： List&lt;String&gt; staff = new LinkedList&lt;&gt;(); // fill collection Collections.sort(staff); 这个方法假定列表元素实现了*8Comparable接口。如果想采用其他方式对列表进行排序，可以使用List接口的sort方法并传入一个Comparator对象**： staff.sort(Comparator.comparingDouble(Employee::getSalary)); // 逆序排 staff.sort(Comparator.reverseOrder()); staff.sort(Comparator.comparingDouble(Employee::getSalary).reversed()); 5.2 二分查找Collections 类的binarySearch方法实现了二分查找算法。需要注意的是，集合必须是排好序的，否则算法将返回错误的答案。要想查找某个元素，必须提供集合（实现List接口）以及要查找的元素。如果集合没有采用Comparable接口的compareTo方法进行排序，就还要提供一个比较器对象： i = Collections.binarySearch(c, element); i = Collections.binarySearch(c, element, comparator); 只有采用随机访问，二分查找才有意义。如果必须利用迭代方式来一次次的遍历链表，二分查找就完全失去了优势，退化为线性查找 5.3 简单算法 略 5.4 批操作coll1.removeAll(coll2); coll1.retainAll(coll2); // 删除所有未在`coll2`中出现的元素 例如求a和b的交集： Set&lt;String&gt; result = new HashSet&lt;&gt;(a); result.retainAll(b); 5.5 集合与数组的转换将数组转换为集合，可利用Arrays.asList包装器： String[] values = ...; HashSet&lt;String&gt; staff = new HashSet&lt;&gt;(Arrays.asList(values)); 将集合转换为数组： String[] values = staff.toArray(new String[0]); 6 遗留的集合6.1 HashTableHashTable 与 HashMap 类的作用一样，且拥有相同的接口，它本身也是同步的。如果对同步性和遗留代码的兼容性没有任何要求，就应该使用HashMap。如果需要并发访问，则要使用ConcurrentHashMap。 6.2 枚举 Enumeration6.3 属性映射6.4 栈 StackE stack.push(E item) // 将 item 压入栈并返回 item E pop() // 弹出并返回栈顶的 item。如果栈为空，请勿调用 E peek() // 返回 6.5 位集 BitSetBitSet 类提供了一个便于读取、设置或清除各个位的接口。使用这个接口可以避免屏蔽和其他麻烦的位操作。例如，对于一个名为bucketsOfBits的 BitSet： bucketOfBits.get(i); // 如果第 i 位有设置过，则返回 true bucketOfBits.set(i); // 将第 i 位设置为 “开” 状态 bucketOfBits.clear(i); // 清除第 i 位 筛法求质数： package sieve; import java.util.*; /** * This program runs the Sieve of Erathostenes benchmark. It computes all primes up to 2,000,000. * @version 1.21 2004-08-03 * @author Cay Horstmann */ public class Sieve { public static void main(String[] s) { int n = 2000000; long start = System.currentTimeMillis(); BitSet b = new BitSet(n + 1); int count = 0; int i; for (i = 2; i &lt;= n; i++) b.set(i); i = 2; while (i * i &lt;= n) { if (b.get(i)) { count++; int k = 2 * i; while (k &lt;= n) { b.clear(k); k += i; } } i++; } while (i &lt;= n) { if (b.get(i)) count++; i++; } long end = System.currentTimeMillis(); System.out.println(count + &quot; primes&quot;); System.out.println((end - start) + &quot; milliseconds&quot;); } } ------ 148933 primes 61 milliseconds Process finished with exit code 0 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序5 分钟 Docker 笔记 5：存储后端开发 - Java开发环境配置 - 入门篇影响力","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"Java 笔记 6：异常、断言和日志","slug":"core-java-notes-6","date":"2019-03-11T06:39:15.000Z","updated":"2019-09-01T13:04:11.094Z","comments":true,"path":"2019/03/11/core-java-notes-6/","link":"","permalink":"https://abelsu7.top/2019/03/11/core-java-notes-6/","excerpt":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》","text":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》 异常、断言和日志1. 处理错误 用户输入错误 设备错误 物理限制 代码错误 1.1 异常分类在 Java 中，异常对象都是派生于Throwable类的一个实例。 Java 中的异常层次结构 需要注意的是，所有的异常都是由Throwable继承而来，但在下一层立即分解为两个分支：Error和Exception。 Error类层次结构描述了 Java 运行时系统的内部错误和资源耗尽错误。应用程序不应该抛出这种类型的对象。如果出现了这样的内部情况，只能通告给用户，并尽力使程序安全的终止，再无能为力了。 Exception类层次结构又可以分解为两个分支：一个分支派生于RuntimeException，另一个分支包含其他异常，划分规则是：由程序错误导致的异常属于RuntimeException，而程序本身没有问题，但由于像I/O错误这类问题导致的异常属于其他异常。 1.2 声明受查异常对于那些可能被他人使用的 Java 方法，应该根据异常规范（exception specification），在方法的首部声明这个方法可能抛出的异常： class MyAnimation { ... public Image loadImage(String s) throws IOException { ... } } 如果有可能抛出多个受查异常类型，那么就必须在方法的首部列出所有的异常类，每个异常类之间用逗号隔开： class MyAnimation { ... public Image loadImage(String s) throws FileNotFoundException, EOFException { ... } } 但是，不需要声明 Java 的内部错误，即从Error继承的错误。任何程序代码都具有抛出那些异常的可能，而我们对其也没有任何控制能力 1.3 如何抛出异常throw new EOFException(); // 或者 EOFException e = new EOFException(); throw e; 在异常类中抛出异常： String readData(Scanner in) throws EOFException { ... while (...) { if (!in.hasNext()) { // EOF encountered if (n &lt; len) throw new EOFException(); } ... } return s; } 1.4 创建异常类class FileFormatException extends IOException { public FileFormatException() {} public FileFormatException(String gripe) { super(gripe); } } 2. 捕获异常2.1 如何捕获异常如果某个异常发生的时候没有在任何地方进行捕获，那么程序就会终止执行，并在控制台上打印出异常信息，其中包括异常的类型和堆栈的内容。 try { code more code } catch (Exception e) { handler for this type } 如果在try语句块中的任何代码抛出了一个在catch子句中说明的异常类，那么： 程序将跳过try语句块的其余代码 程序将执行catch子句中的handler代码 如果在try语句块中的代码没有抛出任何异常，那么程序将跳过catch子句。 如果方法中的任何代码抛出了一个在catch子句中没有声明的异常类型，那么这个方法就会立刻退出。 public void read(String filename) { try { InputStream in = new FileInputStream(filename); int b; while ((b = in.read()) != -1) { // process input } } catch (IOException e) { e.printStackTrace(); } } 还可以什么都不做，将异常传递给调用者，这样就必须声明这个方法可能会抛出一个IOException： public void read(String filename) throws IOException { InputStream in = new FileInputStream(filename); int b; while ((b = in.read()) != -1) { // process input } } Java 编译器严格的执行throws说明符。如果调用了一个抛出受查异常的方法，就必须对它进行处理，或者继续传递 2.2 捕获多个异常在一个try语句块中可以捕获多个异常类型，并对不同类型的异常做出不同的处理： try { // some code } catch (FileNotFoundException e) { // handle exception } catch (UnknownHostException e) { // handle exception } catch (IOException e) { // handle exception } 还可以通过以下语句获得对象的更多信息： e.getMessage(); e.getClass().getName(); 在 Java SE 7 中，同一个catch子句中可以合并多个异常类型： try { // some code } catch (FileNotFoundException | UnknownHostException e) { // handle exception } catch (IOException e) { // handle exception } 2.3 再次抛出异常与异常链🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合排序算法 1：冒泡排序、插入排序、选择排序5 分钟 Docker 笔记 5：存储后端开发 - Java开发环境配置 - 入门篇影响力","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"基于 Golang Web 框架 Gin 搭建 RESTful API 服务","slug":"go-restful-api-using-gin","date":"2019-03-11T01:38:21.000Z","updated":"2019-11-10T09:16:36.176Z","comments":true,"path":"2019/03/11/go-restful-api-using-gin/","link":"","permalink":"https://abelsu7.top/2019/03/11/go-restful-api-using-gin/","excerpt":"摘自 《基于 Go 语言构建企业级的 RESTful API 服务》| 掘金小册，更新中…","text":"摘自 《基于 Go 语言构建企业级的 RESTful API 服务》| 掘金小册，更新中… 目录1. 账号系统 API 功能简介技术雷达 业务功能小册构建了一个账号系统apiserver，功能如下： API 服务器状态检查 登录用户 新增用户 删除用户 更新用户 获取指定用户的详细信息 获取用户列表 运行环境CentOS 7.5.1804 2. RESTful API 简介要实现一个 API 服务器，首先要考虑两个方面：API 风格和媒体类型。Go 语言中常用的 API 风格是RPC和REST，常用的媒体类型是JSON、XML和Protobuf。在 Go API 开发中常用的组合是gRPC + Protobuf和REST + JSON。 REST 简介REST 代表表现层状态转移（REpresentational State Transfer），是一种软件架构风格，不是技术框架。 REST 有一系列规范，满足这些规范的 API 均可称为 RESTful API，核心规范如下： REST 中一切实体都被抽象成资源，每个资源有一个唯一的标识URI，所有行为都应该是在资源上的CRUD操作 使用标准的方法来更改资源的状态，常见的操作有：资源的增删改查操作 无状态：这里的无状态是指每个RESTful API请求都包含了所有足够完成本次操作的信息，服务端无需保持 Session 无状态对于服务端的弹性扩容来说至关重要 在实际开发中，REST 由于天生和 HTTP 协议相辅相成，因此 HTTP 协议已经成为实现 RESTful API 的事实标准。在 HTTP 协议中通过POST、DELETE、PUT、GET方法来对应 REST 资源的CRUD操作，具体对应关系如下： HTTP 方法 行为 URI 示例说明 GET 获取资源列表 /users 获取用户列表 GET 获取一个具体的资源 /users/admin 获取 admin 用户的详细信息 POST 创建一个新的资源 /users 创建一个新用户 PUT 以整体的方式更新一个资源 /users/1 更新 id 为 1 的用户 DELETE 删除服务器上的一个资源 /users/1 删除 id 为 1 的用户 RPC 简介远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议，它允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外为这个交互操作编程。 RPC 的调用过程如下： Client通过本地调用，调用Client Stub Client Stub将参数打包（也叫序列化Marshalling）成一个消息，然后发送这个消息 Client所在的 OS 将消息发送给Server Server端接收到消息后，将消息传递给Server Stub Server Stub将消息解包（也叫反序列化Unmarshalling）得到参数 Server Stub调用服务端的子程序（函数），处理完后，将最终结果按照相反的步骤返回给Client REST vs RPCRPC 相比于 REST 的优点主要有以下三点： RPC+Protobuf采用 TCP 做传输协议，而REST直接使用 HTTP 做应用层协议，导致REST在调用性能上会比RPC+Protobuf低 对于一些很难抽象成资源的操作例如登录操作，在实际开发中并不能严格按照REST规范编写 API，而RPC就不存在这个问题 RPC屏蔽网络细节、易用，和本地调用类似 而 REST 相比于 RPC 也有很多优势： REST轻量级，简单易用，维护性和扩展性都比较好 REST只要语言支持 HTTP 协议就可以对接，更适合对外。而RPC会有语言限制，不同语言的RPC调用起来很麻烦 JSON格式可读性更强，开发调试都很方便 如果严格按照REST规范来编写 API，那么最终 API 看起来会更加清晰，更容易被其他人理解 媒体类型选择选择JSON。 3. API 流程和代码结构HTTP API 服务器启动流程 HTTP API 服务器启动流程 HTTP 请求处理流程 一次完整的 HTTP 请求处理流程 HTTP 请求和响应格式介绍 HTTP 请求报文 的一般格式 第一行必须是一个请求行request line，用来说明请求类型、要访问的资源以及所使用的 HTTP 版本 紧接着是一个头部header小节，用来说明服务器要使用的附加信息 之后是一个空行 再后面即为主体body，可以添加任意的其他数据 HTTP 响应格式与请求格式类似，也是由四部分组成：状态行、消息报头、空行和响应数据 目录结构├── admin.sh # 进程的start|stop|status|restart控制文件 ├── conf # 配置文件统一存放目录 │ ├── config.yaml # 配置文件 │ ├── server.crt # TLS配置文件 │ └── server.key ├── config # 专门用来处理配置和配置文件的Go package │ └── config.go ├── db.sql # 在部署新环境时，可以登录MySQL客户端，执行source db.sql创建数据库和表 ├── docs # swagger文档，执行 swag init 生成的 │ ├── docs.go │ └── swagger │ ├── swagger.json │ └── swagger.yaml ├── handler # 类似MVC架构中的C，用来读取输入，并将处理流程转发给实际的处理函数，最后返回结果 │ ├── handler.go │ ├── sd # 健康检查handler │ │ └── check.go │ └── user # 核心：用户业务逻辑handler │ ├── create.go # 新增用户 │ ├── delete.go # 删除用户 │ ├── get.go # 获取指定的用户信息 │ ├── list.go # 查询用户列表 │ ├── login.go # 用户登录 │ ├── update.go # 更新用户 │ └── user.go # 存放用户handler公用的函数、结构体等 ├── main.go # Go程序唯一入口 ├── Makefile # Makefile文件，一般大型软件系统都是采用make来作为编译工具 ├── model # 数据库相关的操作统一放在这里，包括数据库初始化和对表的增删改查 │ ├── init.go # 初始化和连接数据库 │ ├── model.go # 存放一些公用的go struct │ └── user.go # 用户相关的数据库CURD操作 ├── pkg # 引用的包 │ ├── auth # 认证包 │ │ └── auth.go │ ├── constvar # 常量统一存放位置 │ │ └── constvar.go │ ├── errno # 错误码存放位置 │ │ ├── code.go │ │ └── errno.go │ ├── token │ │ └── token.go │ └── version # 版本包 │ ├── base.go │ ├── doc.go │ └── version.go ├── README.md # API目录README ├── router # 路由相关处理 │ ├── middleware # API服务器用的是Gin Web框架，Gin中间件存放位置 │ │ ├── auth.go │ │ ├── header.go │ │ ├── logging.go │ │ └── requestid.go │ └── router.go ├── service # 实际业务处理函数存放位置 │ └── service.go ├── util # 工具类函数存放目录 │ ├── util.go │ └── util_test.go └── vendor # vendor目录用来管理依赖包 ├── github.com ├── golang.org ├── gopkg.in └── vendor.json 参考文章 《基于 Go 语言构建企业级的 RESTful API 服务》| 掘金小册 教程：使用 go 的 gin 和 gorm 框架来构建 RESTful API 微服务 | LearnKu Build RESTful API service in golang using gin-gonic framework | Medium 对比 RESTful 与 SOAP，深入理解 RESTful | 紫川秀的博客 RESTful API 设计规范 | 紫川秀的博客 如何使用 swagger 设计出漂亮的 RESTful API | 紫川秀的博客 Go 学习笔记 (六) - 使用 swaggo 自动生成 Restful API 文档 | Razeen’s Blog Gin - 高性能 Golang Web 框架的介绍和使用 | 代码成诗 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Gin","slug":"Gin","permalink":"https://abelsu7.top/tags/Gin/"},{"name":"RESTful","slug":"RESTful","permalink":"https://abelsu7.top/tags/RESTful/"},{"name":"Web 开发","slug":"Web-开发","permalink":"https://abelsu7.top/tags/Web-开发/"}]},{"title":"Go 语言几种常见的格式化输入","slug":"go-input-format","date":"2019-03-08T08:13:06.000Z","updated":"2019-09-20T13:40:08.745Z","comments":true,"path":"2019/03/08/go-input-format/","link":"","permalink":"https://abelsu7.top/2019/03/08/go-input-format/","excerpt":"待更新…","text":"待更新… 1. 牛客package main import &quot;fmt&quot; func main() { a := 0 b := 0 for { n, _ := fmt.Scan(&amp;a, &amp;b) if n == 0 { fmt.Println(n) break } else { fmt.Printf(&quot;%d\\n&quot;, a+b) } } } 2. 小米 OJpackage main import ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot; &quot;strings&quot; ) func solution(line string) string { lineArr := strings.Split(line, &quot; &quot;) l, _ := strconv.Atoi(lineArr[0]) r, _ := strconv.Atoi(lineArr[1]) tmp1 := l + r tmp2 := r - l + 1 if (tmp1 % 2) == 0 { tmp1 /= 2 } else { tmp2 /= 2 } ans := ((tmp1 % 15) * (tmp2 % 15)) % 15 return strconv.Itoa(ans) } func main() { r := bufio.NewReaderSize(os.Stdin, 20480) for line, _, err := r.ReadLine(); err == nil; line, _, err = r.ReadLine() { fmt.Println(solution(string(line))) } } 3. Printf 详细用法 Go 语言 fmt 包 Printf 方法详解 | 简书 Go 学习笔记：Println 与 Printf 的区别，以及 Printf 的详细用法 | CSDN 4. 输入 Golang 各种输入姿势 | 无痕的碎碎念 go fmt.scanf 获取输入的时候，如何获取到包含空格的句子？| segmentFault 参考文章 Golang 的交互模式进阶-读取用户的输入 | Go 语言中文网 Go 读取控制台输入 | Go 语言中文网 Go 基础系列：读取标准输入 | 骏马金龙 Golang 的交互模式进阶-读取用户的输入 | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"}]},{"title":"排序算法 1：冒泡排序、插入排序、选择排序","slug":"sort-algo-in-go","date":"2019-03-08T02:56:06.000Z","updated":"2019-09-01T13:04:11.673Z","comments":true,"path":"2019/03/08/sort-algo-in-go/","link":"","permalink":"https://abelsu7.top/2019/03/08/sort-algo-in-go/","excerpt":"摘自 数据结构与算法之美 | 极客时间","text":"摘自 数据结构与算法之美 | 极客时间 目录 目录 1. 排序算法基础 1.1 常见排序算法的时间复杂度 1.2 如何分析一个排序算法 1.3 排序算法的内存消耗 1.4 排序算法的稳定性 1.5 有序度/逆序度 2. 冒泡排序 2.1 基本思路 2.2 优化技巧 2.3 算法分析 2.4 Java 实现 2.5 Go 实现 3. 插入排序 3.1 基本思路 3.2 算法分析 3.3 Java 实现 3.4 Go 实现 4. 选择排序 4.1 基本思路 4.2 算法分析 4.3 Java 实现 4.4 Go 实现 5. 为何插入比冒泡更受欢迎 6. 小结 参考文章 1. 排序算法基础1.1 常见排序算法的时间复杂度排序算法有很多种，最常用的包括：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。按照时间复杂度可分为三类：O(n^2)、O(nlogn)、O(n)，如下图所示： 常见排序算法的时间复杂度 1.2 如何分析一个排序算法 最好情况、最坏情况、平均时间复杂度 时间复杂度的系数、常数、低阶 比较次数和交换（或移动）次数 1.3 排序算法的内存消耗算法的内存消耗可以通过空间复杂度来衡量。不过，针对排序算法的空间复杂度，我们还引入了一个新的概念，原地排序（Sorted in Place）。原地排序算法，就是特指空间复杂度是O(1)的算法。 本文提到的冒泡、插入、选择排序，都是原地排序算法 1.4 排序算法的稳定性仅仅用执行效率和内存消耗来衡量排序算法的好坏是不够的。针对排序算法，还有一个重要的度量指标，稳定性。这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变，那么这个算法就是稳定的。 1.5 有序度/逆序度1. 有序度 有序度是数组中具有有序关系的元素对的个数： 有序元素对：a[i] &lt;= a[j], 如果 i &lt; j 同理，对于一个倒序排列的数组，例如6, 5, 4, 3, 2, 1，有序度是0；对于一个完全有序的数组，例如1, 2, 3, 4, 5, 6，有序度是n*(n-1)/2，也就是15，又称满有序度。 2. 逆序度 逆序度的定义正好跟有序度相反： 逆序元素对：a[i] &gt; a[j], 如果 i &lt; j 3. 有序度和逆序度之间的关系 关于有序度、逆序度、满有序度这三个概念，还可以得到一个计算公式： 逆序度 = 满有序度 - 有序度 本质上，排序的过程就是一种增加有序度、减少逆序度、最后达到满有序度的过程。 2. 冒泡排序2.1 基本思路冒泡排序（Bubble Sort）只会比较相邻的两个元素，看是否满足大小关系要求，如果不满足就让他俩交换。一次冒泡会让至少一个元素移动到它应该在的位置，重复n次，就完成了n个数据的排序工作。 元素 6 冒泡到了数组末端 可以看到，经过一次冒泡操作之后，6这个元素已经存储在正确的位置上。要想完成所有数据的排序，只需要进行n次这样的冒泡操作就可以： 6 次冒泡后，所有数据排序完成 2.2 优化技巧实际上，上述冒泡的过程还可以进行优化。当某次冒泡操作已经没有数据交换的时候，就说明已经达到了完全有序，不用再继续执行后续的冒泡操作了。如下图的例子，6个元素只需要进行4次冒泡： 四次冒泡后达到完全有序 2.3 算法分析 冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为O(1)，是一个原地排序算法 在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，因此冒泡排序是稳定的排序算法 冒泡排序的最好情况是要排序的数据已经是有序的了，只需要进行一次冒泡操作，时间复杂度为O(n)。而最坏情况是要排序的数据刚好都是倒序的，需要进行n次冒泡操作，所以最坏情况时间复杂度为O(n^2) 再来分析一下平均情况：要排序的数组初始状态下的有序度为3，元素个数n=6。所以排序完成之后终态的满有序度为n*(n-1)/2=15： 冒泡排序包含了两个操作原子：比较和交换。每交换一次，有序度就加 1。所以不管算法怎么改进，交换次数总是确定的，即为逆序度。上图的例子中就是12，所以要进行 12 次交换操作。 最坏情况下，初始状态的有序度为0，要进行n*(n-1)/2次交换 最好情况下，初始状态的有序度为n*(n-1)/2，不需要进行交换 取两者中间值n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况 所以平均情况下，需要n*(n-1)/4次交换操作。比较操作肯定要比交换操作多，而复杂度的上限是O(n^2)，所以经过不严格的推导可得出，冒泡排序平均情况下的时间复杂度为O(n^2)。 2.4 Java 实现// 冒泡排序，a 表示数组，n 表示数组大小 public void bubbleSort(int[] a, int n) { if (n &lt;= 1) return; for (int i = 0; i &lt; n; ++i) { // 提前退出冒泡循环的标志位 boolean flag = false; for (int j = 0; j &lt; n - i - 1; ++j) { if (a[j] &gt; a[j+1]) { // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true; // 表示有数据交换 } } if (!flag) break; // 没有数据交换，提前退出 } } 2.5 Go 实现 注：Go 语言提供了交换操作的语法糖：a[j], a[j+1] = a[j+1], a[j] // 冒泡排序，a 表示数组，n 表示数组大小 func BubbleSort(a []int, n int) { if n &lt;= 1 { return } for i := 0; i &lt; n; i++ { // 提前退出标志 flag := false for j := 0; j &lt; n-i-1; j++ { if a[j] &gt; a[j+1] { a[j], a[j+1] = a[j+1], a[j] //此次冒泡有数据交换 flag = true } } // 如果没有交换数据，提前退出 if !flag { break } } } 3. 插入排序3.1 基本思路对于一个有序的数组，为了继续保持数据有序，我们只需要遍历数组，找到数据应该插入的位置将其插入即可： 插入排序（Insertion Sort）正是借助上面的思想来实现排序。首先，我们将数组中的数据分为两个区间：已排序区间和未排序区间。初始已排序区间只有数组的第一个元素。插入算法的核心思想就是取未排序区间中的元素，在已排序区间中找到合适的插入位置并将其插入，重复这个过程直到未排序区间中元素为空，算法结束： 左侧为已排序区间，右侧为未排序区间 插入排序也包含两种操作原子：元素的比较和移动。 对于不同的查找插入点方法（从头到尾、从尾到头），元素的比较次数是有区别的 但对于一个给定的初始序列，移动操作的次数总是固定的，就等于逆序度： 插入排序中，数据移动的次数等于逆序度 3.2 算法分析 插入排序算法的运行并不需要额外的存储空间，空间复杂度为O(1)，也是一个原地排序算法 对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序也是稳定的排序算法 最好情况下，数据全部有序，只需要从尾到头遍历所有数据，时间复杂度为O(n)。最坏情况下，数据全部逆序，时间复杂度为O(n^2)。总的来看，平均时间复杂度为O(n^2) 3.3 Java 实现// 插入排序，a 表示数组，n 表示数组大小 public void insertionSort(int[] a, int n) { if (n &lt;= 1) return; for (int i = 1; i &lt; n; ++i) { int value = a[i]; int j = i - 1; // 查找插入的位置 for (; j &gt;= 0; --j) { if (a[j] &gt; value) { a[j+1] = a[j]; // 数据移动 } else { break; } } a[j+1] = value; // 插入数据 } } 3.4 Go 实现// 插入排序，a 表示数组，n 表示数组大小 func InsertionSort(a []int, n int) { if n &lt;= 1 { return } for i := 1; i &lt; n; i++ { value := a[i] j := i - 1 // 查找要插入的位置并移动数据 for ; j &gt;= 0; j-- { if a[j] &gt; value { a[j+1] = a[j] } else { break } } a[j+1] = value } } 4. 选择排序4.1 基本思路选择排序（Selection Sort）的实现思路类似于插入排序：也是分为已排序区间和未排序区间，但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾： 4.2 算法分析 选择排序的空间复杂度为O(1)，也是一种原地排序算法 最好、最坏、平均时间复杂度都为O(n^2) 选择排序是一种不稳定的排序算法，原因在于每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性 例如5, 8, 5, 2, 9这组数据，如果使用选择排序算法来排序的话，第一次找到最小元素为2，与第一个5交换位置，导致第一个5和中间的5前后顺序发生改变，所以就不稳定了 4.3 Java 实现// 选择排序，a 表示数组，n 表示数组大小 public static void selectionSort(int[] a, int n) { if (n &lt;= 1) return; for (int i = 0; i &lt; n - 1; ++i) { // 查找最小值 int minIndex = i; for (int j = i + 1; j &lt; n; ++j) { if (a[j] &lt; a[minIndex]) { minIndex = j; } } // 交换 if (minIndex != i) { int tmp = a[i]; a[i] = a[minIndex]; a[minIndex] = tmp; } } } 4.4 Go 实现// 选择排序，a 表示数组，n 表示数组大小 func SelectionSort(a []int, n int) { if n &lt;= 1 { return } for i := 0; i &lt; n; i++ { // 查找最小值 minIndex := i for j := i + 1; j &lt; n; j++ { if a[j] &lt; a[minIndex] { minIndex = j } } // 交换 if minIndex != i { a[i], a[minIndex] = a[minIndex], a[i] } } } 5. 为何插入比冒泡更受欢迎 冒泡排序和插入排序不管怎样优化，其元素交换次数是一个固定值，即原始数据的逆序度 从代码实现上来看，冒泡排序的数据交换比插入排序的数据移动要更复杂，交换需要3个赋值操作，而移动只需要1个： // 冒泡排序中数据的交换操作： if (a[j] &gt; a[j+1]) { // 交换 int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = true; } // 插入排序中数据的移动操作： if (a[j] &gt; value) { a[j+1] = a[j]; // 数据移动 } else { break; } 因此，虽然冒泡排序和插入排序的时间复杂度都为O(n^2)，但是如果我们希望把性能优化做到极致，就首选插入排序。 插入排序的算法思路也有很大的优化空间，可以参考 希尔排序 | Wikipedia 6. 小结 参考文章 数据结构与算法之美 | 极客时间 十大经典排序算法动画与解析，看我就够了！（配代码完全版）| 五分钟学算法 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件归并排序(递归)快速排序(递归)","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"排序","slug":"排序","permalink":"https://abelsu7.top/tags/排序/"}]},{"title":"网络协议笔记 4：传输层之 TCP 协议","slug":"network-protocol-4-tcp","date":"2019-03-06T09:56:33.000Z","updated":"2019-09-01T13:04:11.572Z","comments":true,"path":"2019/03/06/network-protocol-4-tcp/","link":"","permalink":"https://abelsu7.top/2019/03/06/network-protocol-4-tcp/","excerpt":"摘自 趣谈网络协议 | 极客时间","text":"摘自 趣谈网络协议 | 极客时间 目录 目录 1. TCP 包头格式 2. TCP 的三次握手 3. TCP 的四次挥手 4. TCP 状态机 5. TCP 如何保证传输可靠 6. 顺序问题与丢包问题 6.1 超时重试 6.2 自适应重传算法 6.3 超时间隔加倍 6.4 快速重传 6.5 SACK 7. 流量控制问题 7.1 窗口不变的情况 7.2 窗口变化的情况 8. 拥塞控制问题 9. 小结 参考文章 1. TCP 包头格式 TCP 包头格式 源端口号、目标端口号 包的序号、确认序号 状态位：SYN发起连接、ACK回复、RST重新连接、FIN结束连接 窗口大小：用于流量控制、拥塞控制 2. TCP 的三次握手TCP 的连接建立，我们称之为“三次握手”，即“请求 -&gt; 应答 -&gt; 应答之应答”。 三次握手除了确保双方建立连接以外，主要还为了沟通 TCP 包的序号问题。 A 要告诉 B，自己发起的包的序号起始是从哪个号开始的，B 同样也要将自己的起始序号告诉 A。为了确保互相包的序号不发生冲突，TCP 的每个连接都要有不同的序号，这个序号的起始序号是随着时间变化的 当双方终于建立了信任，建立了连接之后，为了维护这个连接，双方都要维护一个状态机。在连接建立的过程中，双方的状态变化时序图如下所示： TCP 建立连接时的状态变化时序图 一开始，客户端和服务端都处于CLOSED状态 先是服务端主动监听某个端口，处于LISTEN状态 然后客户端主动发起连接SYN，之后处于SYN-SENT状态 服务端收到发起的连接，返回SYN，并且ACK客户端的SYN，之后处于SYN-RCVD状态 客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为客户端一发一收已经成功了 最后，服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收成功了 3. TCP 的四次挥手类似的，TCP 在断开连接时，也需要进行四次挥手，如下图所示： TCP 断开连接时的状态变化时序图 断开的时候，当 A 说 “不玩了”，就进入了FIN_WAIT_1状态 B 收到 A “不玩了” 的消息后，发送ACK，就进入CLOSE_WAIT状态 A 收到 B 的ACK后，就进入FIN_WAIT_2状态。这时如果 B 直接跑路，则 A 将永远停留在这个状态。可以在 Linux 中调整tcp_fin_timeout这个参数，设置一个超时时间 如果 B 没有跑路，发送 “B 也不玩了” 的请求到达 A 时，A 发送 “知道 B 也不玩了” 的ACK后，从FIN_WAIT_2状态结束，进入TIME_WAIT状态，等待时间为2MSL（Maximum Segment Lifetime，报文最大生存时间） 最后还有一个异常情况就是，B 超过了2MSL的时间，仍然没有收到它发的FIN的ACK，按照 TCP 的原理，B 就会重发这个FIN，只不过当 A 再收到这个包之后，A 就直接发送RST回复给 B，这时候 B 就会知道 A 早就跑了 4. TCP 状态机 令人头秃的 TCP 状态机 5. TCP 如何保证传输可靠TCP 协议为了保证包的顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但这个应答并不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答（cumulative acknowledgment）。 为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。发送端里的缓存是按照包的 ID 一个个排列的，根据处理的情况分成四个部分： 发送了并且已经确认的 发送了并且尚未确认的 没有发送，但是已经等待发送的 没有发送，并且暂时还不会发送的 在 TCP 里，接收端会给发送端报一个窗口的大小，叫Advertised Window。它的大小应该等于上面的第二部分加上第三部分，即已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。 为此，发送端需要保持下面的数据结构： LastByteAcked：「已发送已确认」的最后一个字节 LastByteSent：「已发送未确认」的最后一个字节 AdvertisedWindow：黑框部分，「已发送未确认」+「未发送可发送」 对于接收端来讲，其缓存里的记录和内容要更简单一些： 接收并确认过的 还没接收，但是马上就能接收的 还没接收，也没法接收的，即超过窗口的部分 对应缓存的数据结构如下图所示： LastByteRead：之后是已经接收了，但是还没被应用层读取的 NextByteExpected：第一部分和第二部分的分界线 MaxRcvBuffer：最大缓存的量，图中黑框部分 第二部分窗口大小AdvertisedWindow即为MaxRcvBuffer减去第一部分「接收已确认」的大小 6. 顺序问题与丢包问题在 TCP 传输的过程中，顺序问题与丢包问题都可能发生：有些包可能丢了，有些包可能还在路上。还有些可能已经到了，还是因为出现了乱序，所以只能先缓存着但是没办法ACK。 为了解决这些问题，TCP 有一套确认与重发的机制。 假设4的确认收到了，不幸的是，5的ACK丢了，6、7的数据包丢了，这种时候该怎么办？ 6.1 超时重试一种解决方法就是超时重试，即对每一个发送了但是没有收到ACK的包，都设置一个定时器，超过一定时间必须重新尝试。这个时间必须大于往返时间 RTT，否则会引起不必要的重传，也不宜过长，导致访问变慢。 6.2 自适应重传算法估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值。由于重传时间是不断变化的，我们称之为自适应重传算法（Adaptive Retransmission Algorithm）。 6.3 超时间隔加倍当一个包再次超时，又需要重传的时候，TCP 的策略是超时间隔加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。 6.4 快速重传TCP 还有一个可以快速重传的机制：当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK。客户端收到后，就在定时器过期之前，重传丢失的报文段。 6.5 SACK还有一种方式称为 Selective Acknowledgement（SACK）。这种方式需要在 TCP 头里加上SACK，可以将缓存的地图发送给发送方。例如可以发送ACK6、SACK8、SACK9，有了地图，发送方就可以看出是序号为7的包丢失了。 7. 流量控制问题TCP 还有流量控制机制，在接收方对于包的确认中，同时会携带一个窗口的大小。 7.1 窗口不变的情况先假设窗口不变的情况，窗口始终为9。4的确认来的时候，会右移一格，这时候第13个包也可以发送了： 这个时候，假设发送端发送过猛，会将第三部分的10、11、12、13全部发送完毕。由于已发送未确认的包已经占满整个窗口，因此之后就停止发送了，未发送可发送的部分变为0： 当对于包5的确认到达时，在客户端相当于窗口再滑动了一格，这个时候，第14个包就可以发送了： 如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为0，则发送方将暂时停止发送 7.2 窗口变化的情况再假设一个极端情况：接收端的应用一直不读取缓存中的数据，当数据包6确认后，窗口大小就要缩小一个变为8： 当新的窗口大小8通过6的确认消息到达发送端之后，发送端的窗口就不会再右移，而是仅仅左边的边右移，窗口大小也从9变成了8： 如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口也会越来越小，直到为0： 当这个窗口通过包14的确认到达发送端的时候，发送端的窗口也调整为0，停止发送： 除了被动接收窗口信息之外，发送方也会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止底能窗口综合征：可以当窗口太小的时候就停止更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口 8. 拥塞控制问题最后来谈一下 TCP 的拥塞控制问题，也是通过窗口的大小来控制的。前面流量控制的滑动窗口rwnd（Receive Window，接收窗口）是怕发送方把接收方缓存塞满，而拥塞窗口cwnd（Congestion Window，拥塞窗口）是怕把网络塞满。 TCP 的发送速度由拥塞窗口和滑动窗口共同控制： swnd = LastByteSent - LastByteAcked &lt;= min {cwnd, rwnd} 对于 TCP 协议来讲，整个网络路径就是一个黑盒。TCP 发送包常被比喻为往一个水管里面灌水，而 TCP 的拥塞控制就是在不堵塞、不丢包的情况下，尽量发挥带宽 如果设置发送窗口swnd，使得发送但未确认的包为通道的容量，就能撑满整个管道： TCP 的拥塞控制主要用来避免两种现象：包丢失和超时重传。一旦出现了这些现象就说明，发送速度太快了，要慢一点。 一条 TCP 连接开始，cwnd设置为 1 个报文段，一次只能发送一个 当收到这一个确认的时候，cwnd加 1，于是一次能够发送两个 当这两个的确认到来的时候，两个确认cwnd加 2，于是一次能够发送四个 当这四个的确认到来的时候，四个确认cwnd加 4，于是一次能够发送八个 这个过程称为 TCP 的慢启动阶段 可以看出在慢启动阶段，cwnd呈指数性的增长。但当swnd超过阈值ssthresh（默认为 65535 字节，即当swnd为 16 时刚好超过），就要改为线性增长，即每收到一个确认后，cwnd增加1/cwnd： 这个过程称为 TCP 的拥塞避免阶段 还是看上图，当cwnd为 20 时，出现了拥塞（例如丢包，需要超时重传），这个时候，需要将ssthresh设为cwnd/2即 10，将cwnd设为 1，重新开始慢启动。下图是另外一个例子： 虽然这种方式避免了拥塞，但是大大降低了原本处于高速状态的传输速度，还可能造成网络卡顿。 之前提到，TCP 还有一个快速重传算法：当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发送端就会快速的重传，不必等待超时再重传，这时cwnd减半变为cwnd/2，然后再令ssthresh=cwnd，当三个包返回时，cwnd=sshthresh+3，继续维持线性增长（即图中的橙线部分）。 正是 TCP 这种知进退的特点，使得在时延很重要的情况下，反而降低了速度。但其实，TCP 的拥塞控制主要来避免的两个现象都是有问题的： 丢包并不代表着通道满了，例如公网上带宽不满也会丢包，这个时候就认为拥塞了、退缩了，其实是不对的 TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这个时候已经晚了，其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满 为了优化这两个问题，后来有了 TCP BBR 拥塞算法（Bottleneck Bandwidth and Round-trip propagation time，由 Google 设计，于 2016 年发布）。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样会导致时延增加，在这个平衡点可以很好的达到高带宽和低时延的平衡 9. 小结 TCP 的 顺序问题、丢包问题、流量控制问题都是通过滑动窗口来解决的 拥塞控制是通过拥塞窗口cwnd来解决的 参考文章 趣谈网络协议 | 极客时间 TCP/IP 拥塞控制 | 简书 TCP 的流量控制和拥塞控制 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）网络协议笔记 3：传输层之 UDP 协议网络协议笔记 2：交换机、VLAN、ICMP、网关、路由协议网络协议笔记 1：初识网络协议、IP、MAC、DHCPHTTP 笔记 1：Web 基础及简单的 HTTP 协议TCP协议从数据包看 TLS 1.2","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://abelsu7.top/tags/TCP/"},{"name":"网络协议","slug":"网络协议","permalink":"https://abelsu7.top/tags/网络协议/"}]},{"title":"网络协议笔记 3：传输层之 UDP 协议","slug":"network-protocol-3-udp","date":"2019-03-06T03:37:25.000Z","updated":"2019-09-01T13:04:11.569Z","comments":true,"path":"2019/03/06/network-protocol-3-udp/","link":"","permalink":"https://abelsu7.top/2019/03/06/network-protocol-3-udp/","excerpt":"摘自 趣谈网络协议 | 极客时间","text":"摘自 趣谈网络协议 | 极客时间 目录 目录 1. UDP 与 TCP 的区别 2. UDP 包头部 3. UDP 的三大特点 4. UDP 的三大使用场景 参考文章 1. UDP 与 TCP 的区别 UDP（User Datagram Protocol，用户数据报协议） TCP（Transmission Control Protocol，传输控制协议） 简单来说，TCP 是面向连接的，而 UDP 是面向无连接的。 在互通之前，面向连接的协议会先建立连接。例如，TCP 会三次握手，而 UDP 不会。 所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性 例如，TCP 提供可靠交付，通过 TCP 连接传输的数据，无差错、不丢失、不重复，并且按序到达；而 UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达 再如，TCP 是面向字节流的，发送的时候发的是一个流，没头没尾；而 UDP 继承了 IP 的特性，是基于数据报的，一个一个的收发 最后，TCP 可以有拥塞控制，当意识到网络环境变差，就会根据情况调整自己的行为；而 UDP 就不会 综上，TCP 其实是一个有状态的服务，精确记录着发送和接收的状态；而 UDP 则是无状态服务，不会在意发送和接收是否出现差错。 可以这样比喻：如果 MAC 层定义了本地局域网的传输行为，IP 层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段，暂时笼统的称之为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因，生下来的孩子 UDP 完全继承了这些特性，几乎没有自己的思想。 2. UDP 包头部无论应用程序写的使用 TCP 传数据，还是 UDP 传数据，都要监听一个端口。正是这个端口，用来区分应用程序。 UDP 包头 3. UDP 的三大特点 沟通简单：不需要大量的数据结构、处理逻辑、包头字段等，秉承性善论，相信网络通路默认就是很容易送达的，不容易被丢弃的 轻信他人：UDP 不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给它数据，它也可以传给任何人数据，甚至可以同时传给多个人数据 不会根据网络情况进行发包的拥塞控制：无论网络丢包有多严重，它该怎么发还怎么发 4. UDP 的三大使用场景 需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用：类似 DHCP、PXE 中下载系统镜像所用的 TFTP 都是基于 UDP 协议 不需要一对一沟通、建立连接，而是可以广播的应用：UDP 的不面向连接的功能，可以承载广播或者多播的协议 需要处理速度快、时延低，可以容忍少数丢包：即便网络拥塞，也毫不退缩，一往无前，继续该怎么发包就怎么发 其他一些使用 UDP 的场景： Google 提出的 QUIC（Quick UDP Internet Connections，快速 UDP 互联网连接） 直播等流媒体的协议 实时游戏 IoT 物联网 移动通信领域 参考文章 趣谈网络协议 | 极客时间 🚩推荐阅读（由hexo文章推荐插件驱动）网络协议笔记 4：传输层之 TCP 协议网络协议笔记 2：交换机、VLAN、ICMP、网关、路由协议网络协议笔记 1：初识网络协议、IP、MAC、DHCPTCP协议从数据包看 TLS 1.2","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://abelsu7.top/tags/网络协议/"},{"name":"UDP","slug":"UDP","permalink":"https://abelsu7.top/tags/UDP/"}]},{"title":"网络协议笔记 2：交换机、VLAN、ICMP、网关、路由协议","slug":"network-protocol-2-link-and-transport","date":"2019-03-05T07:41:35.000Z","updated":"2019-09-01T13:04:11.550Z","comments":true,"path":"2019/03/05/network-protocol-2-link-and-transport/","link":"","permalink":"https://abelsu7.top/2019/03/05/network-protocol-2-link-and-transport/","excerpt":"摘自 趣谈网络协议 | 极客时间","text":"摘自 趣谈网络协议 | 极客时间 目录 目录 1. 从物理层到链路层的局域网连接 2. 交换机与 VLAN 2.1 有两台交换机的拓扑结构 2.2 环路问题 2.3 STP 协议的基本概念 2.4 STP 协议的工作过程 2.5 如何解决广播问题和安全问题 2.6 小结 3. ICMP 与 ping 3.1 ICMP 互联网控制报文协议 3.2 ping 查询报文类型的使用 3.3 Traceroute 差错报文类型的使用 4. 网关 Gateway 4.1 MAC 头和 IP 头 4.2 静态路由 4.3 小结 5. 路由协议 5.1 如何配置路由？ 5.2 如何配置策略路由？ 5.3 动态路由算法 5.4 动态路由协议 5.5 小结 参考文章 1. 从物理层到链路层的局域网连接首先明确三点基础知识： MAC 层（数据链路层）是用来解决多路访问的堵车问题的 ARP（Address Resolution Protocol，地址解析协议）是通过吼的方式来寻找目标 MAC 地址的，吼完之后记住一段时间，这个叫做缓存 交换机是有 MAC 学习能力的，学完就知道谁在哪儿，不用广播了 一个局域网里有多个交换机时，ARP 广播的模式容易产生广播风暴：ARP 广播时，交换机会将一个端口收到的包转发到其他所有的端口上。比如数据包经过交换机 A 到达交换机 B，交换机 B 又将包复制为多分广播出去。如果整个局域网存在一个环路，使得数据包又重新回到了最开始的交换机 A，这个包又会被 A 再次复制多份广播出去。如此循环，数据包会不停的转发，而且越来越多，最终占满带宽，或者使解析协议的硬件过载，形成广播风暴 2. 交换机与 VLAN2.1 有两台交换机的拓扑结构 两台交换机连接三个局域网 2.2 环路问题当两个交换机将两个局域网同时连接起来的时候，就会出现环路问题： 局域网的环路问题 此时就会出现之前提到的广播风暴。 2.3 STP 协议的基本概念在数据结构中，有一个方法叫做最小生成树。在计算机网络中，生成树的算法叫做 STP（Spanning Tree Protocol）。 STP 协议 STP 协议中的基本概念如下： Root Bridge：也就是根交换机，是某棵树的老大，“掌门” Designated Bridges：翻译为指定交换机。可看成是“掌门”的“弟子”。对于树来说，就是一棵树的树枝 Bridge Protocol Data Units（BPDU）：翻译为网桥协议数据单元，可看成相互比较实力的协议。当两个交换机碰见时，就需要互相比一比内力。BPDU 只有掌门能发，已经隶属于某个掌门的交换机只能传达掌门的指示 Priority Vector：翻译为优先级向量，可以比喻为实力（值越小越强），实际是一组 ID 数目，Root Bridge ID, Root Path Cost, Bridge ID, and Port ID 2.4 STP 协议的工作过程 略 2.5 如何解决广播问题和安全问题1. 物理隔离 每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了。 然而问题在于，有的部门人多，有的部门人少。如果每个部门有单独的交换机，口多了浪费，口少了不够用。 2. 虚拟隔离 VLAN 另一种方式是虚拟隔离，就是我们常说的 VLAN，又称虚拟局域网。使用 VLAN，一个交换机上会连属于多个局域网的机器。 二层数据包头的 TAG 中包含了 VLAN ID 为了让交换机区分哪个机器属于哪个局域网，我们只需要在原来的二层的头上加一个 TAG，里面有一个 VLAN ID，一共 12 位，这样就可以划分 4096 个 VLAN。 如果交换机是支持 VLAN 的，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。这样只有相同 VLAN 的包，才会互相转发，不同 VLAN 的包是看不到的，这样就解决了广播问题和安全问题。 可以设置交换机每个口所属的 VLAN。而且对于交换机来说，每个 VLAN 的口都是可以重新设置的。例如，一个财务走了，把他所在的座位的口从 VLAN 30 移除掉。来了一个程序员，坐在财务的位置，就把这个口设置为 VLAN 10，十分灵活。 对于支持 VLAN 的交换机，有一种 Trunk 口，可以转发属于任何 VLAN 的口。交换机之间可以通过 Trunk 口相互连接。 2.6 小结 交换机的数目越来越多时，会遭遇环路问题，让网络包迷路，这时就需要使用 STP 协议，通过华山论剑比武的方式，将有环路的图变成没有环路的树，从而解决环路问题 交换机数目多会面临隔离问题，可以通过 VLAN 形成虚拟局域网，从而解决广播问题和安全问题 3. ICMP 与 ping3.1 ICMP 互联网控制报文协议 ICMP 一般被认为属于网络层，和 IP 协议同一层，是管理和控制 IP 的一种协议 ping 是基于 ICMP 协议工作的。ICMP 全称 Internet Control Message Protocol，即互联网控制报文协议。 ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单，因为作为侦察兵，要轻装上阵，不能携带大量的包袱。 封装在 IP 包里面的 ICMP 报文 ICMP 报文有很多的类型，不同的类型有不同的代码。最常用的类型是主动请求为 8，主动请求的应答为 0。 1. 查询报文类型 ICMP 的查询报文类型，好比主帅传令侦察兵，会主动查看敌情。例如，常用的ping就是查询报文，是一种主动请求、并且获得主动应答的 ICMP 协议。 对ping的主动请求，进行网络抓包，称为 ICMP ECHO REQUEST。同理主动请求的回复，称为 ICMP ECHO REPLY。比起原生的 ICMP，这里面多了两个字段：一个是标识符，用来区分不同的报文；另一个是序号，用来记录报文的顺序。 在选项数据中，ping还会存放发送请求的时间值，用来计算往返时间，说明路程的长短 2. 差错报文类型 由异常情况发起的、来报告差错的报文，对应 ICMP 的差错报文类型。 常见的 ICMP 差错报文的例子如下： 终点不可达：3，包括网络不可达、主机不可达、协议不可达、端口不可达、需要进行分片但设置了不分片位 源站抑制：4，让源站放慢发送速度 时间超时：11，超过网络包的生存时间还是没到 路由重定向：5，让下次发给另一个路由器 3.2 ping 查询报文类型的使用下图展示了ping命令的发送和接收过程： ping 的发送和接收过程 ping命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，这个包内包含多个字段，最重要的有两个：第一个是类型字段，对于请求数据包而言该字段为 8；另一个是顺序号，主要用于区分连续ping的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。 然后，由 ICMP 协议将这个数据包连同地址192.168.1.2一起交给 IP 层。IP 层将以192.168.1.2作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。 接下来，需要加入 MAC 头。可在 ARP 映射表中查找 IP 地址对应的 MAC 地址，如果没有，则需要发送 ARP 协议查询 MAC 地址。获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址，附加上一些控制信息，最后将它们传送出去。 主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，符合本机则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。 主机 B 会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机 A。 在规定的时间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了，则说明可达。此时，源主机会用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。 ping这个程序使用了 ICMP 里面 ECHO REQUEST 和 ECHO REPLY 类型 3.3 Traceroute 差错报文类型的使用有一个程序traceroute，是个“大骗子”，它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。 故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器 故意设置不分片，从而确定路径的 MTU 4. 网关 Gateway在进行网卡配置的时候，除了 IP 地址，还需要配置网关（Gateway）。 4.1 MAC 头和 IP 头一旦配置了 IP 地址和网关，往往就能够指定目标地址进行访问了。但在跨网关访问的时候，还牵扯到 MAC 地址和 IP 地址的变化。 MAC 头和 IP 头 在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断：这个目标 IP 地址和当前机器的 IP 地址是否在同一个网段，需要借助 CIDR（无类型域间选路）和子网掩码来实现。 如果是同一个网段：那就不需要访问网关，直接将源地址和目标地址放入 IP 头中，然后通过 ARP 获得 MAC 地址，将源 MAC 和目的 MAC 放入 MAC 头中，发出去就可以了 如果不是同一个网段：这时就需要发往默认网关 Gateway，Gateway 的地址一定是和源 IP 地址同一个网段的，往往不是第一个，就是第二个。例如192.168.1.0/24这个网段，Gateway 往往会是192.168.1.1/24或者192.168.1.2/24 网关往往是一个路由器，是一个三层转发设备（即会把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备） 4.2 静态路由静态路由，其实就是在路由器上，配置一条一条规则。 MAC 地址是一个局域网内才有效的地址。因而，MAC 地址只要过了网关，就必定会改变，因为已经换了另一个局域网 对于 IP 头和 MAC 头哪些变、哪些不变的问题，可以分为两种类型：不改变 IP 地址的网关，称为转发网关；改变 IP 地址的网关，称为 NAT 网关。 1. 转发网关 转发网关 服务器 A 要访问服务器 B，首先，因为不是一个网段的，会向网关192.168.1.1发送包： 源 MAC：服务器 A 的 MAC 目标 MAC：192.168.1.101这个网口的 MAC 源 IP：192.168.1.101 目标 IP：192.168.4.101 左边的网关收到包后，修改源 MAC 和目标 MAC，向右边的网关转发包： 源 MAC：192.168.56.1的 MAC 地址 目标 MAC：192.168.56.2的 MAC 地址 源 IP：192.168.1.101 目标 IP：192.168.4.101 路由器 B 收到包后，发送 ARP 获取192.168.4.101的 MAC 地址，然后发送包： 源 MAC：192.168.4.1的 MAC 地址 目标 MAC：192.168.4.101的 MAC 地址 源 IP：192.168.1.101 目标 IP：192.168.4.101 包到达服务器 B，MAC 地址匹配，将包收进来。 从上面的过程可以看出，每到一个局域网，MAC 都是要变的，但是 IP 地址都不变。在 IP 头里面，不会保存任何网关的 IP 地址。所谓的下一跳是，某个 IP 要将这个 IP 地址转换为 MAC 放入 MAC 头。 2. NAT 网关 NAT 网关 首先，目标服务器 B 在国际上要有一个国际的身份，例如192.168.56.2。在网关 上，我们记下来，国际身份192.168.56.2对应国内身份192.168.1.101。凡是要访问192.168.56.2的，都转成192.168.1.101。 于是，源服务器 A 要访问目标服务器 B，先向路由器 A 发送包，内容为： 源 MAC：服务器 A 的 MAC 地址 目标 MAC：192.168.1.1这个网口的 MAC 地址 源 IP：192.168.1.101 目标 IP：192.168.56.2 之后路由器 A 发送包到路由器 B： 源 MAC：192.168.56.1的 MAC 地址 目标 MAC：192.168.56.2的 MAC 地址 源 IP：192.168.56.1 目标 IP：192.168.56.2 最后，路由器 B 发送包到服务器 B 的内容： 源 MAC：192.168.1.1的 MAC 地址 目标 MAC：192.168.1.101的 MAC 地址 源 IP：192.168.56.1 目标 IP：192.168.1.101 包到达服务器 B，MAC 地址匹配，将包收进来。 从这个过程可以看出，IP 地址也会改变，用英文说就是 Network Address Translation，简称 NAT。 4.3 小结 如果离开本局域网，就需要经过网关，网关是路由器的一个网口 路由器是一个三层设备，里面有如何寻找下一跳的规则 网关处理 MAC 和 IP 地址时有两种方式，一种是转发网关，另一种是 NAT 网关 5. 路由协议5.1 如何配置路由？通过之前的内容可以知道，路由器就是一台网络设备，它有多张网卡。当一个入口的网络包送到路由器时，他会根据一个本地的转发信息库，来决定如何正确的转发流量，这个转发信息库通常被称为路由表。 一张路由表中会有多条路由规则，每一条规则至少包含这三项信息： 目的网络：这个包想去哪儿？ 出口设备：将包从哪个口扔出去？ 下一跳网关：下一个路由器的地址 通过route或ip route命令都可以对路由表进行查询或配置 例如，我们要设置ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0，就说明要去10.176.48.0/20这个目标网络，要从eth0端口出去，经过10.173.32.1。这种配置方式的核心思想是：根据目的 IP 地址来配置路由。 5.2 如何配置策略路由？在真实的复杂网络环境中，除了根据目的 IP 地址来配置路由外，还可以根据多个参数来配置路由，这就称为策略路由。 例如，我们设置： &gt; ip rule add from 192.168.1.0/24 table 10 &gt; ip rule add from 192.168.2.0/24 table 20 表示从192.168.1.0/24这个网段来的，使用table 10中的路由表，而从192.168.2.0/24网段来的，则使用table 20的路由表。 在一条路由规则中，也可以走多条路径： &gt; ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2 这条规则表示下一跳有两个地方，分别是100.100.100.1和200.200.200.1，权重分别为1和2。 5.3 动态路由算法使用动态路由协议的路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。 可以将复杂的网络拓扑路径，抽象为图的结构。因而这就转化成如何在途中找到最短路径的问题。 1. 距离矢量路由算法第一大类的算法称为距离矢量路由（Distance Vector Routing），它是基于 Bellman-Ford 算法的。 它的基本思想是：每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器。每一行包含两部分信息：一个是要到目标路由器，从哪条线出去；另一个是到目标路由器的距离。 可以看出，每个路由器都知道全局信息，都知道自己和邻居之间的距离。为了更新路由表，每过几秒，每个路由器都将自己所知的到达所有路由器的距离告知邻居。 这样一来，每个路由器根据新收集的信息，计算和其他路由器的距离。例如一个邻居距离目标路由器的距离是M，而自己距离邻居是X，则自己距离目标路由器的距离是X+M 该算法虽然简单，但也存在问题： 好消息传得快，坏消息传得慢：新加入网络的路由器会被很快发现，而挂掉的路由器是没有广播的 每次发送的时候，都要发送整个全局路由表，网络带宽无法承受，从而限制了距离矢量路由的网络规模 挂掉的路由器超过距离阈值才会被判定挂掉了 2. 链路状态路由算法第二大类算法是链路状态路由（Link State Routing），基于 Dijkstra 算法。 它的基本思想是：当一个路由器启动时，首先发现邻居，然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。因而，每个路由器都能在本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。 链路状态路由算法只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛 5.4 动态路由协议1. 基于链路状态路由算法的 OSPFOSPF（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由算法的动态路由协议，主要用于数据中心内部的路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称 IGP）。 OSPF 中的等价路由 内部网关协议的重点就是找到最短路径。当然，有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由。 一般应用的接入层会有负载均衡 LVS，它可以和 OSPF 一起，实现高吞吐量的接入层设计 2. 基于距离矢量路由算法的 BGP外网的路由协议又有所不同，我们称为外网路由协议（Border Gateway Protocol，简称 BGP）。 在网络世界中，一个个局域网成为自治系统 AS（Autonomous System），并根据对外的连接情况分为多种不同的类型。 每个自治系统都有边界路由器，通过它和外面的世界建立联系。 外网路由协议 BGP BGP 又分为两类：eBGP 和 iBGP。自治系统的边界路由器之间使用 eBGP 广播路由。而边界路由器要想将 BGP 学习到的路由导入到内部网络，则需要运行 iBGP，使得内部的路由器能够找到到达外网目的地的最优边界路由器。 BGP 协议使用的算法是路径矢量路由协议（Path Vector Protocol），它是距离矢量路由协议的升级版 5.5 小结 路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略 动态路由主流算法有两种：距离矢量算法和链路状态算法。基于这两种算法产生两种协议：BGP 协议和 OSPF 协议 参考文章 趣谈网络协议 | 极客时间 🚩推荐阅读（由hexo文章推荐插件驱动）网络协议笔记 4：传输层之 TCP 协议网络协议笔记 3：传输层之 UDP 协议网络协议笔记 1：初识网络协议、IP、MAC、DHCPTCP协议从数据包看 TLS 1.2","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://abelsu7.top/tags/网络协议/"},{"name":"VLAN","slug":"VLAN","permalink":"https://abelsu7.top/tags/VLAN/"},{"name":"网关","slug":"网关","permalink":"https://abelsu7.top/tags/网关/"}]},{"title":"网络协议笔记 1：初识网络协议、IP、MAC、DHCP","slug":"network-protocol-1-intro","date":"2019-03-05T02:42:11.000Z","updated":"2019-09-01T13:04:11.539Z","comments":true,"path":"2019/03/05/network-protocol-1-intro/","link":"","permalink":"https://abelsu7.top/2019/03/05/network-protocol-1-intro/","excerpt":"摘自 趣谈网络协议 | 极客时间","text":"摘自 趣谈网络协议 | 极客时间 目录 目录 1. 网络请求概览 2. 各层常用网络协议 3. 层与层之间的关系 4. 查看 IP 地址 5. 初识 IP 地址 6. CIDR 无类型域间选路 7. MAC 地址 8. 配置 IP 地址 9. DHCP 动态主机配置协议 10. 解析 DHCP 的工作方式 11. IP 地址的收回和续租 参考文章 1. 网络请求概览 2. 各层常用网络协议 应用层：DHCP、HTTP、HTTPS、DNS、RPC、P2P、SMTP 传输层：TCP、UDP 网络层：IP、ICMP、OSPF、BGP 链路层：ARP、VLAN、STP 物理层：网络跳线 3. 层与层之间的关系 只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层 对 TCP 协议来说，三次握手也好，重试也好，只要想发出去包，就要有 IP 层和 MAC 层，不然是发不出去的 4. 查看 IP 地址 net-tools中的ifconfig iproute2中的ip address net-tools起源于 BSD，自 2001 年起，Linux 社区已经对其停止维护。而iproute2旨在取代net-tools，并提供了一些新功能。一些 Linux 发行版已经停止支持net-tools，只支持iproute2。 net-tools通过 procfs(/proc) 和 ioctl 系统调用去访问和改变内核网络配置，而iproute2则通过netlink套接字接口与内核通讯。 net-tools中工具的名字比较杂乱，而iproute2则相对整齐和直观，基本是ip命令加后面的子命令。 虽然取代意图很明显，但是这么多年过去了，net-tool依然还在被广泛使用，最好还是两套命令都掌握。 &gt; ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp5s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 4c:cc:6a:70:fc:d9 brd ff:ff:ff:ff:ff:ff inet 116.56.129.153/24 brd 116.56.129.255 scope global noprefixroute dynamic enp5s0 valid_lft 1313sec preferred_lft 1313sec inet6 2001:250:3000:2b80:7171:519:ba83:4ff9/64 scope global noprefixroute dynamic valid_lft 2591975sec preferred_lft 604775sec inet6 fe80::f646:5a2b:929:108c/64 scope link noprefixroute valid_lft forever preferred_lft forever 注意：lo全称是loopback，又称环回接口，往往会被分配到127.0.0.1这个地址，用于本机通信，经过内核处理后直接返回，不会在任何网络中出现 5. 初识 IP 地址 IPv4 总共32位 IPv6 总共128位 IP 地址总共分为以下 5 类： IP 地址的分类 A、B、C 三类地址所能包含的主机数量 6. CIDR 无类型域间选路无类型域间选路，简称 CIDR，打破了原来设计的几类地址的做法，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。例如10.100.122.2/24，表示在 32 位地址中，前 24 位是网络号，后 8 位是主机号。 伴随 CIDR 而来的还有两个概念：广播地址10.100.122.255和子网掩码255.255.255.0。 如果发送广播地址，所有10.100.122网络里面的机器都可以收到。 将子网掩码和 IP 地址进行AND计算，结果得到10.100.122.0，即为网络号。 举个例子 例如16.158.165.91这个 CIDR，网络号为16.158.&lt;101001&gt;，而机器号为&lt;01&gt;.91。 第一个地址是16.158.&lt;101001&gt;&lt;00&gt;.1，即16.158.164.1。子网掩码是255.255.&lt;111111&gt;&lt;00&gt;.0，即255.255.252.0。广播地址是16.158.&lt;101001&gt;&lt;11&gt;.255，即16.158.167.255。 7. MAC 地址 打个比方，IP 是地址，有定位功能；MAC 是身份证，无定位功能。 MAC（Media Access Control）地址是一个网卡的物理地址，用十六进制，6 个 byte 表示，例如fa:16:3e:c7:79:75。 一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要有定位功能。而 MAC 地址更像是身份证，是一个唯一的标识。 MAC 地址是有一定定位功能的，不过通信范围比较小，局限在一个子网里面。例如，从192.168.0.2/24访问192.168.0.3/24是可以用 MAC 地址的。一旦跨子网，即从192.168.0.2/24到192.168.1.2/24，只用 MAC 地址就不行了，还需要 IP 地址才能起作用。 8. 配置 IP 地址使用 net-tools： &gt; sudo ifconfig eth1 10.0.0.1/24 &gt; sudo ifconfig eth1 up 使用 iproute2： &gt; sudo ip addr add 10.0.0.1/24 dev eth1 &gt; sudo ip link set up eth1 9. DHCP 动态主机配置协议动态主机配置协议（Dynamic Host Configuration Protocol），简称 DHCP。 数据中心里面的服务器，IP 一旦配置好，基本不会变，相当于买房自己装修。DHCP 的方式相当于租房，自己不用装修，都是帮你配置好的，暂时用一下，用完退租就可以。 10. 解析 DHCP 的工作方式 DHCP Discover：当一台新机器新加入一个网络的时候，只知道自己的 MAC 地址。这时需要在本地网络先吼一句“我来啦”，即向广播地址发送请求包 DHCP Offer：如果网络管理员在网络里面配置了 DHCP Server 的话，它就相当于这些 IP 的管理员。只有 MAC 唯一，IP 管理员才能知道这是一个新人，需要租给它一个 IP 地址。同时，DHCP Server 为此客户端保留为它提供的 IP 地址，从而不会为其他 DHCP 客户分配此 IP。DHCP Server 仍然使用广播地址作为目的地址，除此之外还发送了子网掩码、网关和 IP 地址租用期 等信息 DHCP Request：如果有多个 DHCP Server，新来的机器一般会选择最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址 等，并告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址 DHCP ACK：当 DHCP Server 接收到客户机的 DHCP Request 后，会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息 都放入该广播包，发给客户机 最终租约达成的时候，还需要广播通知网络内的所有机器。 11. IP 地址的收回和续租客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP Request 消息包。客户机接收到服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。 参考文章 趣谈网络协议 | 极客时间 🚩推荐阅读（由hexo文章推荐插件驱动）网络协议笔记 4：传输层之 TCP 协议网络协议笔记 3：传输层之 UDP 协议网络协议笔记 2：交换机、VLAN、ICMP、网关、路由协议TCP协议从数据包看 TLS 1.2","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://abelsu7.top/tags/网络协议/"},{"name":"IP","slug":"IP","permalink":"https://abelsu7.top/tags/IP/"},{"name":"DHCP","slug":"DHCP","permalink":"https://abelsu7.top/tags/DHCP/"}]},{"title":"Linux 命令查看 CPU、内存、网络、磁盘等系统信息","slug":"linux-list-cpu-info","date":"2019-03-03T09:27:18.000Z","updated":"2019-10-31T13:39:48.946Z","comments":true,"path":"2019/03/03/linux-list-cpu-info/","link":"","permalink":"https://abelsu7.top/2019/03/03/linux-list-cpu-info/","excerpt":"摘自 Linux 查看 CPU 信息，机器型号，内存等信息 | 开源中国","text":"摘自 Linux 查看 CPU 信息，机器型号，内存等信息 | 开源中国 1. 系统&gt; uname -a # 查看内核/操作系统/CPU信息 &gt; head -n 1 /etc/issue # 查看操作系统版本 &gt; cat /proc/cpuinfo # 查看CPU信息 &gt; hostname # 查看计算机名 &gt; lspci -tv # 列出所有PCI设备 &gt; lsusb -tv # 列出所有USB设备 &gt; lsmod # 列出加载的内核模块 &gt; env # 查看环境变量 &gt; cat /etc/issue.net # 查看当前操作系统发行版信息 &gt; dmidecode | grep &#39;Product Name&#39; # 查看机器型号 Product Name: HP Z240 Tower Workstation Product Name: 802F 2. 资源&gt; free -m # 查看内存使用量和交换区使用量 &gt; df -h # 查看各分区使用情况 &gt; du -sh &lt;目录名&gt; # 查看指定目录的大小 &gt; grep MemTotal /proc/meminfo # 查看内存总量 &gt; grep MemFree /proc/meminfo # 查看空闲内存量 &gt; uptime # 查看系统运行时间、用户数、负载 &gt; cat /proc/loadavg # 查看系统负载 &gt; tree # 显示目录树状图 3. 磁盘和分区&gt; mount | column -t # 查看挂接的分区状态 &gt; fdisk -l # 查看所有分区 &gt; swapon -s # 查看所有交换分区 &gt; hdparm -i /dev/hda # 查看磁盘参数(仅适用于IDE设备) &gt; dmesg | grep IDE # 查看启动时IDE设备检测状况 4. 网络&gt; ifconfig # 查看所有网络接口的属性 &gt; iptables -L # 查看防火墙设置 &gt; route -n # 查看路由表 &gt; netstat -lntp # 查看所有监听端口 &gt; netstat -antp # 查看所有已经建立的连接 &gt; netstat -s # 查看网络统计信息 5. 进程&gt; ps -ef # 查看所有进程 &gt; top # 实时显示进程状态 6. 用户&gt; w # 查看活动用户 &gt; id &lt;用户名&gt; # 查看指定用户信息 &gt; last # 查看用户登录日志 &gt; cut -d: -f1 /etc/passwd # 查看系统所有用户 &gt; cut -d: -f1 /etc/group # 查看系统所有组 &gt; crontab -l # 查看当前用户的计划任务 7. 服务&gt; chkconfig --list # 列出所有系统服务 &gt; chkconfig --list | grep on # 列出所有启动的系统服务 8. 程序&gt; rpm -qa # 查看所有安装的软件包 9. CPU&gt; cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c # 查看 CPU 信息 8 Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz &gt; cat /proc/cpuinfo | grep physical | uniq -c 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual 1 physical id : 0 1 address sizes : 39 bits physical, 48 bits virtual &gt; getconf LONG_BIT 64 # 说明当前 CPU 运行在 64 位模式下 &gt; cat /proc/cpuinfo | grep flags | grep &#39; lm &#39; | wc -l 8 # 结果大于 0，说明支持 64 位计算，lm 代表 long mode &gt; dmidecode -s dmidecode: option requires an argument -- &#39;s&#39; String keyword expected Valid string keywords are: bios-vendor bios-version bios-release-date system-manufacturer system-product-name system-version system-serial-number system-uuid baseboard-manufacturer baseboard-product-name baseboard-version baseboard-serial-number baseboard-asset-tag chassis-manufacturer chassis-type chassis-version chassis-serial-number chassis-asset-tag processor-family processor-manufacturer processor-version processor-frequency &gt; dmidecode -s &#39;processor-version&#39; Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz 10. 内存&gt; cat /proc/meminfo MemTotal: 3792120 kB MemFree: 313820 kB MemAvailable: 2639360 kB Buffers: 2288 kB Cached: 2490216 kB SwapCached: 0 kB Active: 1135928 kB Inactive: 1849112 kB Active(anon): 509352 kB Inactive(anon): 65012 kB Active(file): 626576 kB Inactive(file): 1784100 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 0 kB SwapFree: 0 kB Dirty: 0 kB Writeback: 0 kB AnonPages: 492500 kB Mapped: 190708 kB Shmem: 81828 kB Slab: 269808 kB SReclaimable: 201596 kB SUnreclaim: 68212 kB KernelStack: 8000 kB PageTables: 24656 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 1896060 kB Committed_AS: 3072464 kB VmallocTotal: 34359738367 kB VmallocUsed: 348664 kB VmallocChunk: 34358947836 kB HardwareCorrupted: 0 kB AnonHugePages: 159744 kB CmaTotal: 0 kB CmaFree: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 142584 kB DirectMap2M: 3962880 kB DirectMap1G: 0 kB 参考文章 Linux 查看 CPU 信息，机器型号，内存等信息 | 开源中国 Linux 下如何查看 CPU 信息, 包括位数和多核信息 | CSDN Linux下如何查看CPU型号、个数、核数、逻辑CPU数、位数、发行版本、内核信息、内存、服务器生产厂家 | CSDN Linux 下面 CPU 个数的几种方式 | CSDN Linux 下查看系统版本号信息 | 苏易北 Linux 系统调用 sysconf【总结】| Dale 工作学习笔记 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"运维","slug":"运维","permalink":"https://abelsu7.top/tags/运维/"}]},{"title":"Linux 下 Yum、APT 禁用指定软件包更新","slug":"linux-yum-apt-disable-update","date":"2019-03-03T09:08:31.000Z","updated":"2019-10-16T07:56:13.536Z","comments":true,"path":"2019/03/03/linux-yum-apt-disable-update/","link":"","permalink":"https://abelsu7.top/2019/03/03/linux-yum-apt-disable-update/","excerpt":"摘自 4 Ways to Disable/Lock Certain Package Updates Using Yum Command | TecMint","text":"摘自 4 Ways to Disable/Lock Certain Package Updates Using Yum Command | TecMint 待更新… 1. yum 包管理# 1. 安装 yum install &lt;package&gt; # 安装指定的安装包 # 2. 更新和升级 yum update # 全部更新 yum update &lt;package&gt; # 更新指定程序包 yum check-update # 检查可更新的程序 yum upgrade &lt;package&gt; # 升级指定程序包 # 3. 查找和显示 yum info # 列出所有可以安装或更新的包的信息 yum info &lt;package&gt; # 显示安装包信息 yum list # 显示所有已经安装和可以安装的程序包 yum list &lt;package&gt; # 显示指定程序包安装情况 yum search &lt;package&gt; # 搜索匹配特定字符的包的详细信息 # 4. 删除程序 yum remove | erase &lt;package&gt; # 删除程序包 yum deplist &lt;package&gt; # 查看程序包依赖情况 # 5. 清除缓存 yum clean packages # 清除缓存目录下的软件包 yum clean headers # 清除缓存目录下的 headers yum clean oldheaders # 清除缓存目录下旧的 headers yum clean, yum clean all # (= yum clean packages; yum clean oldheaders) 清除缓存目录下的软件包及旧的 headers 参考文章 4 Ways to Disable/Lock Certain Package Updates Using Yum Command | TecMint How to Disable/Lock or Blacklist Package Updates using Apt Tool | TecMint 20 Linux YUM Commands for Package Management | TecMint yum 和 apt-get 的用法和区别 | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Yum","slug":"Yum","permalink":"https://abelsu7.top/tags/Yum/"},{"name":"Apt","slug":"Apt","permalink":"https://abelsu7.top/tags/Apt/"}]},{"title":"小米 OJ 2 月常规赛 T2：Carryon 数数字","slug":"mi-oj-1902-carryon","date":"2019-03-01T02:13:56.000Z","updated":"2019-09-01T13:04:11.531Z","comments":true,"path":"2019/03/01/mi-oj-1902-carryon/","link":"","permalink":"https://abelsu7.top/2019/03/01/mi-oj-1902-carryon/","excerpt":"参见 小米 OJ 编程比赛 02 月常规赛","text":"参见 小米 OJ 编程比赛 02 月常规赛 题目描述 输入单组输入l和r的值 输出输出最终结果 通过率 Up to 2019-3-1 10:36 GMT+8 测试用例 如：10、11、12、13、14的十六进制分别是a、b、c、d、e。依次连在一起是abcde，转换成十进制是703710，对15取模为0 10 14 685003 898583 100 100000000000 ------ 0 3 10 Go 代码 1.11 ms package main import ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot; &quot;strings&quot; ) func solution(line string) string { lineArr := strings.Split(line, &quot; &quot;) l, _ := strconv.Atoi(lineArr[0]) r, _ := strconv.Atoi(lineArr[1]) tmp1 := l + r tmp2 := r - l + 1 if (tmp1 % 2) == 0 { tmp1 /= 2 } else { tmp2 /= 2 } ans := ((tmp1 % 15) * (tmp2 % 15)) % 15 return strconv.Itoa(ans) } func main() { r := bufio.NewReaderSize(os.Stdin, 20480) for line, _, err := r.ReadLine(); err == nil; line, _, err = r.ReadLine() { fmt.Println(solution(string(line))) } } 参考文章 小米 OJ 编程比赛 02 月常规赛 取模运算的性质 | CSDN 待更新 分糖果 | 小米 OJ 小米 OJ：分糖果 | 易学教程 MiOJ-1月常规赛-灯 | Sakura 小米 OJ 编程比赛 01 月常规赛题解 | CSDN 小米 OJ 编程比赛 01 月常规赛 | 血小板自动机’s Blog 灯——小米 OJ 编程比赛 01 月常规赛 （思维）| CSDN LeetCode41. 缺失的第一个正数 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"OJ","slug":"OJ","permalink":"https://abelsu7.top/tags/OJ/"}]},{"title":"Hexo 实现自定义文章置顶","slug":"hexo-pin-top","date":"2019-02-28T03:11:08.000Z","updated":"2019-09-01T13:04:11.286Z","comments":true,"path":"2019/02/28/hexo-pin-top/","link":"","permalink":"https://abelsu7.top/2019/02/28/hexo-pin-top/","excerpt":"待更新…","text":"待更新… 参考文章 Hexo 博客彻底解决置顶问题 | wangwlj’s Blog 解决 Hexo 博客文章置顶问题 | 简书 解决 Hexo 置顶问题 | Netcan_Space Hexo 增加置顶属性 | CSDN 为 Hexo 添加文章置顶功能（三）| Jing’s Blog 解决 Hexo-theme-indigo 的置顶问题 | Chankin 🚩推荐阅读（由hexo文章推荐插件驱动）在 Hexo 中使用 MathJax 渲染数学公式利用 Valine 搭建 Hexo 无后端评论系统解决 RSS 报错：Input is not proper UTF-8, indicate encodingHexo 博客安装 RSS 插件Hexo博客文末添加网站地图Hexo博客文末添加网站地图","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://abelsu7.top/tags/Hexo/"}]},{"title":"复杂度分析 2：浅析最好、最坏、平均、均摊时间复杂度","slug":"complexity-analysis-2","date":"2019-02-26T14:23:27.000Z","updated":"2019-09-01T13:04:11.049Z","comments":true,"path":"2019/02/26/complexity-analysis-2/","link":"","permalink":"https://abelsu7.top/2019/02/26/complexity-analysis-2/","excerpt":"最好情况、最坏情况、平均情况、均摊时间复杂度","text":"最好情况、最坏情况、平均情况、均摊时间复杂度 继续来看四个复杂度分析方面的知识点：最好情况时间复杂度 (Best Case Time Complexity)、最坏情况时间复杂度 (Worst Case Time Complexity)、平均情况时间复杂度 (Average Case Time Complexity)、均摊时间复杂度 (Amortized Time Complexity)。 1. 最好、最坏情况时间复杂度例如在一个无序数组array中查找变量x出现的位置： // n 表示数组 array 的长度 int find(int[] array, int n, int x) { int i = 0; int pos = -1; for (; i &lt; n; ++i) { if (array[i] == x) { pos = i; break; } } return pos; } 最好情况时间复杂度：在最理想的情况下，执行这段代码的时间复杂度，这里为O(1) 最坏情况时间复杂度：在最糟糕的情况下，执行这段代码的时间复杂度，这里为O(n) 2. 平均情况时间复杂度还是上面的例子：要查找变量x在数组中的位置，有n+1种情况：在数组的0 ~ n-1位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以n+1，就可以得到需要遍历的元素个数的平均值，即： 平均时间复杂度 简化后得到的平均时间复杂度为O(n)。 然而上面的考虑还不够全面：若假设变量x在数组中与不在数组中的概率都为1/2，则可得加权平均时间复杂度或者期望时间复杂度： 加权平均时间复杂度 去掉系数和常量，这段代码的加权平均时间复杂度仍为O(n)。 3. 均摊时间复杂度大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。 // array 表示一个长度为 n 的数组 // 代码中的 array.length 就等于 n int[] array = new int[n]; int count = 0; void insert(int val) { if (count == array.length) { int sum = 0; for (int i = 0; i &lt; array.length; ++i) { sum = sum + array[i]; } array[0] = sum; count = 1; } array[count] = val; ++count; } 这段代码实现了一个往数组中插入数据的功能。当数组满了之后，用for循环遍历数组求和，并清空数组，将求和之后的sum值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空间空间，则直接将数据插入数组。 最好情况：O(1) 最坏情况：O(n) 平均复杂度：O(1) 上述代码的加权平均时间复杂度 还是insert()函数这个例子：随着n的不断增长，可以发现每一次O(n)的插入操作，都会跟着n-1次O(1)的插入操作。所以把耗时多的那次操作均摊到接下来的n-1次耗时少的操作上，这一组连续的操作的均摊时间复杂度就是O(1)。这就是均摊分析（又称摊还分析）的大致思路。 简单来看，均摊时间复杂度就是一种特殊的平均时间复杂度 参考文章 数据结构与算法之美 | 极客时间 🚩推荐阅读（由hexo文章推荐插件驱动）Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总排序算法 1：冒泡排序、插入排序、选择排序复杂度分析 1：算法的时间、空间复杂度检查回文数检查回文数","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"复杂度","slug":"复杂度","permalink":"https://abelsu7.top/tags/复杂度/"}]},{"title":"复杂度分析 1：算法的时间、空间复杂度","slug":"complexity-analysis-1","date":"2019-02-26T13:16:32.000Z","updated":"2019-09-01T13:04:11.044Z","comments":true,"path":"2019/02/26/complexity-analysis-1/","link":"","permalink":"https://abelsu7.top/2019/02/26/complexity-analysis-1/","excerpt":"分析、统计算法的执行效率和资源消耗","text":"分析、统计算法的执行效率和资源消耗 1. 大 O 复杂度表示法算法的执行效率简单来说，就是算法代码执行的时间。 例如下面这段代码： int cal(int n) { int sum = 0; // 1 int i = 1; // 1 for (; i &lt;= n; ++i) { // n sum = sum + i; // n } return sum; } 每一行都执行着类似的操作：读数据-运算-写数据。 假设每行代码执行的时间都相同，为unit_time。则第 2、3 行代码分别需要 1 个unit_time的执行时间。第 4、5 行都运行了 n 遍，所以需要2n * unit_time的执行时间。所以总的执行时间就是(2n+2) * unit_time。 对于下面这段代码： int cal(int n) { int sum = 0; // 1 int i = 1; // 1 int j = 1; // 1 for (; i &lt;= n; ++i) { // n j = 1; // n for (; j &lt;= n; ++j) { // n^2 sum = sum + i * j; // n^2 } } } 整段代码的执行时间为T(n) = (2n^2 + 2n + 3) * unit_time。 可以看到，所有代码的执行时间T(n)与每行代码的执行次数成正比。 其中， T(n)：表示代码的执行时间 n：表示数据规模的大小 f(n)：表示每行代码执行的次数总和 O：表示代码的执行时间T(n)与f(n)表达式成正比 大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以也叫做渐进时间复杂度 (Asymptotic Time Complexity)，简称时间复杂度。 用大 O 表示法表示刚才两段代码的时间复杂度，分别为T(n)=O(n)、T(n)=O(n^2) 2. 时间复杂度分析 只关注循环执行次数最多的一段代码 加法法则：总复杂度等于量级最大的那段代码的复杂度 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积 3. 几种常见的时间复杂度 几种常见的时间复杂度 3.1 非多项式时间复杂度可以将上图中的复杂度量级粗略分为两类：多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2^n)和O(n!)。 当数据规模n越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。 3.2 多项式时间复杂度1. O(1)只要代码的执行时间不随n的增大而增长，这样代码的时间复杂度都记作O(1)。 int i = 8; int j = 6; int sum = i + j; 一般情况下，只要算法中不存在循环、递归语句，即使有成千上万行的代码，其时间复杂度也还是O(1) 2. O(logn)、O(nlogn)对数阶时间复杂度非常常见，同时也最难分析。例如下面的代码： i=1; while (i &lt;= n) { i = i * 2; } 实际上，变量i的取值就是一个等比数列： 可得x=log_2^n。忽略对数的底，统一表示为O(logn)。 根据前面提到的乘法法则，如果一段代码的时间复杂度是O(logn)，循环执行n遍，时间复杂度就是O(nlogn)了。 O(nlogn)也是一种非常常见的算法时间复杂度，例如归并排序、快速排序的时间复杂度都是O(nlogn) 3. O(m+n)、O(m*n)有时代码的复杂度由两个数据的规模来决定： int cal(int m, int n) { int sum_1 = 0; int i = 1; for (; i &lt; m; ++i) { sum_1 = sum_1 + i; } int sum_2 = 0; int j = 1; for (; j &lt; n; ++j) { sum_2 = sum_2 + j; } return sum_1 + sum_2; } 从代码中可以看出，m和n分别表示两个数据规模，我们无法事先评估m和n谁的量级更大。因此不能简单的利用加法法则，而要将时间复杂度表示为O(m+n)。 这种情况下加法法则需要改为：T1(m) + T2(n) = O(f(m) + g(n))。 而乘法法则继续有效：T1(m) * T2(n) = O(f(m) * f(n))。 4. 空间复杂度分析类比时间复杂度，空间复杂度的全称就是渐进空间复杂度 (Asymptotic Space Complexity)，表示算法的存储空间与数据规模之间的增长关系。 常见的空间复杂度就是O(1)、O(n)、O(n^2)，像O(logn)、O(nlogn)这样的对数阶复杂度平时基本用不到 5. 复杂度小结 常见时间复杂度对比 复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系 越高阶复杂度的算法，执行效率越低 常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2) 参考文章 数据结构与算法之美 | 极客时间 🚩推荐阅读（由hexo文章推荐插件驱动）Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总排序算法 1：冒泡排序、插入排序、选择排序复杂度分析 2：浅析最好、最坏、平均、均摊时间复杂度检查回文数检查回文数","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"复杂度","slug":"复杂度","permalink":"https://abelsu7.top/tags/复杂度/"}]},{"title":"数据结构与算法文章导航","slug":"data-struct-and-algo-summary","date":"2019-02-26T12:48:42.000Z","updated":"2019-09-01T13:04:11.108Z","comments":true,"path":"2019/02/26/data-struct-and-algo-summary/","link":"","permalink":"https://abelsu7.top/2019/02/26/data-struct-and-algo-summary/","excerpt":"程序 = 数据结构 + 算法","text":"程序 = 数据结构 + 算法 1. 数据结构与算法思维导图 数据结构与算法常见知识点 by 王争 2. 数据结构十大知识点 数组 链表 栈 队列 散列表 二叉树 堆 跳表 图 Trie 树 2.1 数组 Updating… 2.2 链表 Updating… 2.3 栈 Updating… 2.4 队列 Updating… 2.5 散列表 Updating… 2.6 二叉树 Updating… 2.7 堆 Updating… 2.8 跳表 Updating… 2.9 图 Updating… 2.10 Trie 树 Updating… 3. 算法十大知识点 递归 排序 二分查找 搜索 哈希算法 贪心算法 分治算法 回溯算法 动态规划 字符串匹配算法 3.1 递归 Updating… 3.2 排序 Updating… 3.3 二分查找 Updating… 3.4 搜索 Updating… 3.5 哈希算法 Updating… 3.6 贪心算法 Updating… 3.7 分治算法 Updating… 3.8 回溯算法 Updating… 3.9 动态规划 Updating… 3.10 字符串匹配算法 Updating… 参考文章 数据结构与算法之美 | 极客时间 🚩推荐阅读（由hexo文章推荐插件驱动）Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总排序算法 1：冒泡排序、插入排序、选择排序复杂度分析 2：浅析最好、最坏、平均、均摊时间复杂度【数据结构】线段树检查回文数","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://abelsu7.top/categories/数据结构/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"https://abelsu7.top/tags/数据结构/"}]},{"title":"使用 kubeadm 搭建 Kubernetes 集群","slug":"using-kubeadm-to-create-a-k8s-cluster","date":"2019-02-25T01:54:49.000Z","updated":"2019-10-14T13:49:31.929Z","comments":true,"path":"2019/02/25/using-kubeadm-to-create-a-k8s-cluster/","link":"","permalink":"https://abelsu7.top/2019/02/25/using-kubeadm-to-create-a-k8s-cluster/","excerpt":"摘自 Creating a single master cluster with kubeadm | kubernetes.io，更新中…","text":"摘自 Creating a single master cluster with kubeadm | kubernetes.io，更新中… kubeadm 是 Kubernetes 官方提供的一个 CLI (Command Line Interface) 工具，可以很方便的搭建一套符合官方最佳实践的最小化可用集群。当我们使用kubeadm搭建集群时，集群可以通过 K8S 的一致性测试，并且kubeadm还支持其他的集群生命周期功能，比如升级/降级等。 1. 前期准备安装kubeadm前需要在所有节点上检查以下条件是否满足。 1.1 系统与硬件部署集群的所有节点主机需运行以下操作系统： Ubuntu 16.04+ Debian 9 CentOS 7 RHEL 7 Fedora 25/26 (best-effort) HypriotOS v1.0.1+ Container Linux (tested with 1800.6.0) CPU 2 核以上，内存 2 GB 以上。 1.2 节点之间网络互通节点之间需要具备Full network connectivity，公网、局域网均可。 1.3 各不相同的 hostname、MAC 地址通过hostname查看主机名，通过ip link或ifconfig -a查看网卡对应的 MAC 地址，确保每台机器各不相同。 1.4 各不相同的 product_uuid通过sudo cat /sys/class/dmi/id/product_uuid可查看机器的product_uuid，确保要搭建集群的所有节点的product_uuid均不相同。 这样做的原因是每个 Node 都有一些信息会被记录进集群内，而此处我们需要保证的这些唯一的信息，便会记录在集群的nodeInfo中，比如product_uuid在集群内以systemUUID来表示，具体信息则可以通过集群的API Server获取到。 1.5 禁用 swap 交换内存Kubernetes 集群的每个节点上都有个必需的组件kubelet。从Kubernetes 1.8开始，启动kubelet时需要禁用swap，或者需要更改kubelet的启动参数为--fail-swap-on=false。 摘自《Kubernetes 从上手到实践》：虽说可以更改参数让其可用，但是我建议还是禁用 swap 除非你的集群有特殊的需求，比如：有大内存使用的需求，但又想节约成本；或者你知道你将要做什么，否则可能会出现一些非预期的情况，尤其是做了内存限制的时候，当某个 Pod 达到内存限制的时候，它可能会溢出到 swap 中，这会导致 k8s 无法正常进行调度。 禁用方法如下： 1.使用cat /proc/swaps验证swap配置的设备和文件： ~&gt; cat /proc/swaps Filename Type Size Used Priority /dev/dm-1 partition 8126460 0 -1 ~&gt; free -h total used free shared buff/cache available Mem: 7.6G 996M 4.5G 12M 2.2G 6.3G Swap: 7.7G 0B 7.7G ~&gt; cat /etc/fstab # # /etc/fstab # Created by anaconda on Tue Nov 13 11:26:56 2018 # # Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=aadb6c2e-8a99-46e5-b208-1eaee9944490 /boot xfs defaults 0 0 UUID=4797-AB7E /boot/efi vfat umask=0077,shortname=winnt 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 /dev/mapper/centos-swap swap swap defaults 0 0 ~&gt; lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk ├─sda1 8:1 0 200M 0 part /boot/efi ├─sda2 8:2 0 1G 0 part /boot └─sda3 8:3 0 930.3G 0 part ├─centos-root 253:0 0 500G 0 lvm / ├─centos-swap 253:1 0 7.8G 0 lvm [SWAP] └─centos-home 253:2 0 422.6G 0 lvm /home sr0 11:0 1 1024M 0 rom 2.使用swapoff -a禁用/etc/fstab中的所有交换区： 使用swapon -a即可重新启用/etc/fstab中的所有交换区。 ~&gt; swapoff -a ~&gt; cat /proc/swaps Filename Type Size Used Priority ~&gt; free -h total used free shared buff/cache available Mem: 7.6G 989M 4.5G 12M 2.2G 6.3G Swap: 0B 0B 0B ~&gt; lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk ├─sda1 8:1 0 200M 0 part /boot/efi ├─sda2 8:2 0 1G 0 part /boot └─sda3 8:3 0 930.3G 0 part ├─centos-root 253:0 0 500G 0 lvm / ├─centos-swap 253:1 0 7.8G 0 lvm └─centos-home 253:2 0 422.6G 0 lvm /home sr0 11:0 1 1024M 0 rom 可以看到swap分区的挂载点已被卸载。 3.为了确保机器重启或重挂载时，不会再次挂载swap分区，还需将/etc/fstab中的swap分区记录注释掉： ~&gt; vim /etc/fstab # # /etc/fstab # Created by anaconda on Tue Nov 13 11:26:56 2018 # # Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=aadb6c2e-8a99-46e5-b208-1eaee9944490 /boot xfs defaults 0 0 UUID=4797-AB7E /boot/efi vfat umask=0077,shortname=winnt 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 # /dev/mapper/centos-swap swap swap defaults 0 0 1.6 查看端口占用情况Kubernetes 是 C/S 架构，在启动后会固定监听以下端口用于提供服务。 Master node(s)： Worker node(s)： 可以通过sudo netstat -ntlp |grep -E &#39;6443|23[79,80]|1025[0,1,2]&#39;查看Master端口是否被占用。如果被占用，请手动释放。 若提示command not found，则需要先安装netstatCentOS：sudo yum install net-toolsDebian/Ubuntu：sudo apt install net-tools 1.7 容器运行时需要在所有节点上安装容器运行时（Container Runtime），默认为 Docker。可参考 CentOS 7 安装 Docker CE | 苏易北。 1.8 我的集群主机 Role Hostname OS CPU RAM Master abelsu7-ubuntu Ubuntu 18.04 i7-6700 @ 3.40 GHz，4 核 8 线程 32 GB Worker centos-1 CentOS 7.5 i5-4590 @ 3.30 GHz，4 核 4 线程 4 GB Worker centos-2 CentOS 7.5 i5-4590 @ 3.30 GHz，4 核 4 线程 8 GB 2. 安装 kubeadm、kubelet、kubectl 注：国内用户安装以上组件时可能会遇到众所周知的网络问题。我是用代理解决的，可参考 Linux 下使用 SSR + ProxyChains 代理终端流量 | 苏易北 kubeadm：用于初始化集群并对其进行管理 kubelet：在集群中所有机器上运行的组件，负责执行诸如启动 Pod 和容器之类的操作 kubectl：与集群通信的命令行工具 Ubuntu, Debian or HypriotOS： apt-get update &amp;&amp; apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF apt-get update apt-get install -y kubelet kubeadm kubectl apt-mark hold kubelet kubeadm kubectl CentOS, RHEL or Fedora： cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kube* EOF # Set SELinux in permissive mode (effectively disabling it) setenforce 0 sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet 安装完成后验证版本信息，可以看到此处安装的版本均为v1.13.3： ~&gt; kubeadm version kubeadm version: &amp;version.Info{Major:&quot;1&quot;, Minor:&quot;13&quot;, GitVersion:&quot;v1.13.3&quot;, GitCommit:&quot;721bfa751924da8d1680787490c54b9179b1fed0&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-02-01T20:05:53Z&quot;, GoVersion:&quot;go1.11.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;} ~&gt; kubectl version --client Client Version: version.Info{Major:&quot;1&quot;, Minor:&quot;13&quot;, GitVersion:&quot;v1.13.3&quot;, GitCommit:&quot;721bfa751924da8d1680787490c54b9179b1fed0&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-02-01T20:08:12Z&quot;, GoVersion:&quot;go1.11.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;} ~&gt; kubelet --version Kubernetes v1.13.3 3. 配置 kubelet为了在生产环境中保障各组件的稳定运行，同时也为了便于管理，我们增加对kubelet的systemd的配置，由systemd对服务进行管理： 首先创建/etc/systemd/system/kubelet.service（若文件已存在则继续下一步），并输入以下内容： [Unit] Description=kubelet: The Kubernetes Node Agent Documentation=https://kubernetes.io/docs/ [Service] ExecStart=/usr/bin/kubelet Restart=always StartLimitInterval=0 RestartSec=10 [Install] WantedBy=multi-user.target 之后创建/etc/systemd/system/kubelet.service.d/kubeadm.conf（若文件已存在则继续下一步），并输入以下内容： # Note: This dropin only works with kubeadm and kubelet v1.11+ [Service] Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot; Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot; # This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env # This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use # the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file. EnvironmentFile=-/etc/sysconfig/kubelet ExecStart= ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS 最后使用systemctl enable kubelet启用服务： ~&gt; systemctl enable kubelet Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service. 4. 使用 kubeadm 启动集群4.1 提前下载所需镜像使用kubeadm init首次创建集群时会从k8s.gcr.io这个 Registry 下载 Kubernetes 所需的 Docker 镜像。 由于众所周知的网络问题，即使我挂了代理也无法成功下载。好在阿里云上有同步镜像的组件，所以可以提前从阿里云上下载所需镜像，再重新docker tag上k8s.gcr.io这个 Registry。 注：可以参考以下三篇文章： Running kubeadm without an internet connection | kubernetes.io kubeadm config image 阿里云镜像 | 简书 如何成功启动 Docker 自带的 Kubernetes？| 简书 首先需要使用kubeadm config image list查看所需镜像的版本： ~&gt; kubeadm config images list k8s.gcr.io/kube-apiserver:v1.13.3 k8s.gcr.io/kube-controller-manager:v1.13.3 k8s.gcr.io/kube-scheduler:v1.13.3 k8s.gcr.io/kube-proxy:v1.13.3 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.2.24 k8s.gcr.io/coredns:1.2.6 之后新建脚本文件docker-k8s-images.sh，输入以下内容： #!/bin/bash images=( kube-apiserver:v1.13.3 kube-controller-manager:v1.13.3 kube-scheduler:v1.13.3 kube-proxy:v1.13.3 pause:3.1 etcd:3.2.24 coredns:1.2.6 ) for imageName in ${images[@]} ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/${imageName} docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/${imageName} k8s.gcr.io/${imageName} docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/${imageName} done docker images 阿里云镜像仓库地址： registry.cn-hangzhou.aliyuncs.com registry.aliyuncs.com 最后添加执行权限，运行脚本： ~&gt; chmod +x ./docker-k8s-images.sh ~&gt; ./docker-k8s-images.sh ... REPOSITORY TAG IMAGE ID CREATED SIZE k8s.gcr.io/kube-apiserver v1.13.3 fe242e556a99 3 weeks ago 181MB k8s.gcr.io/kube-proxy v1.13.3 98db19758ad4 3 weeks ago 80.3MB k8s.gcr.io/kube-controller-manager v1.13.3 0482f6400933 3 weeks ago 146MB k8s.gcr.io/kube-scheduler v1.13.3 3a6f709e97a0 3 weeks ago 79.6MB k8s.gcr.io/coredns 1.2.6 f59dcacceff4 3 months ago 40MB k8s.gcr.io/etcd 3.2.24 3cab8e1b9802 5 months ago 220MB k8s.gcr.io/pause 3.1 da86e6ba6ca1 14 months ago 742kB ... 4.2 配置 Pod 网络插件 flannel在使用kubeadm init启动集群时，需要传递--pod-network-cidr参数以便 Pod 之间可以相互通信。 关于网络的选择，此处不做过多介绍，暂时选择一个被广泛使用的方案flannel，这时需要指定--pod-network-cidr=10.244.0.0/16。 参见 Installing a pod network add-on 另外，在使用flannel之前，还需查看/proc/sys/net/bridge/bridge-nf-call-iptables是否已设置为1： ~&gt; sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-iptables = 1 否则可以通过sysctl net.bridge.bridge-nf-call-iptables=1更改设置。 Notes: Set/proc/sys/net/bridge/bridge-nf-call-iptablesto1by runningsysctl net.bridge.bridge-nf-call-iptables=1to pass bridged IPv4 traffic to iptables’ chains. This is a requirement for some CNI plugins to work, for more information please see here. 最后，对于Kubernetes v1.7+之后的版本，记得在下一节的kubeadm init --pod-network-cidr=10.244.0.0/16命令执行之后，应用flannel的配置文件： kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 有关flannel的更多信息，请查看 the CoreOS flannel repository on GitHub 4.3 初始化集群 kubeadm init所有的准备工作已经完成，现在开始创建一个 k8s 集群。 首先使用kubeadm init初始化集群，并传递--pod-network-cidr=10.244.0.0/16参数以指定 Pod 网络方案为flannel： ~&gt; kubeadm init --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.13.3 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39; [kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot; [kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot; [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot; [certs] Generating &quot;front-proxy-ca&quot; certificate and key [certs] Generating &quot;front-proxy-client&quot; certificate and key [certs] Generating &quot;etcd/ca&quot; certificate and key [certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key [certs] Generating &quot;apiserver-etcd-client&quot; certificate and key [certs] Generating &quot;etcd/server&quot; certificate and key [certs] etcd/server serving cert is signed for DNS names [abelsu7-ubuntu localhost] and IPs [222.201.139.151 127.0.0.1 ::1] [certs] Generating &quot;etcd/peer&quot; certificate and key [certs] etcd/peer serving cert is signed for DNS names [abelsu7-ubuntu localhost] and IPs [222.201.139.151 127.0.0.1 ::1] [certs] Generating &quot;ca&quot; certificate and key [certs] Generating &quot;apiserver&quot; certificate and key [certs] apiserver serving cert is signed for DNS names [abelsu7-ubuntu kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 222.201.139.151] [certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key [certs] Generating &quot;sa&quot; key and public key [kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot; [kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file [kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file [kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file [kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file [control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot; [control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot; [control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot; [control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot; [etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s [apiclient] All control plane components are healthy after 23.002540 seconds [uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace [kubelet] Creating a ConfigMap &quot;kubelet-config-1.13&quot; in namespace kube-system with the configuration for the kubelets in the cluster [patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;abelsu7-ubuntu&quot; as an annotation [mark-control-plane] Marking the node abelsu7-ubuntu as control-plane by adding the label &quot;node-role.kubernetes.io/master=&#39;&#39;&quot; [mark-control-plane] Marking the node abelsu7-ubuntu as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: ar8quq.bx68gpg2ktjzagk8 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes master has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of machines by running the following on each node as root: kubeadm join 222.201.139.151:6443 --token ar8quq.bx68gpg2ktjzagk8 --discovery-token-ca-cert-hash sha256:125083b871f062c8d4c0c7ab5cefee1ba0b74a6b3fb17c0c4b5ba4d591c1051d 根据提示，使用以下命令配置kubectl： ~&gt; mkdir -p $HOME/.kube ~&gt; sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config ~&gt; sudo chown $(id -u):$(id -g) $HOME/.kube/config 最后，应用flannel配置文件： ~&gt; kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml podsecuritypolicy.extensions/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.extensions/kube-flannel-ds-amd64 created daemonset.extensions/kube-flannel-ds-arm64 created daemonset.extensions/kube-flannel-ds-arm created daemonset.extensions/kube-flannel-ds-ppc64le created daemonset.extensions/kube-flannel-ds-s390x created 稍等片刻，master即处于Ready状态。可在其他机器上输入以下命令加入集群： kubeadm join 222.201.139.151:6443 --token ar8quq.bx68gpg2ktjzagk8 --discovery-token-ca-cert-hash sha256:125083b871f062c8d4c0c7ab5cefee1ba0b74a6b3fb17c0c4b5ba4d591c1051d 4.4 查看集群节点状态可通过kubectl查看集群节点状态： ~&gt; kubectl cluster-info Kubernetes master is running at https://222.201.139.151:6443 KubeDNS is running at https://222.201.139.151:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;. ~&gt; kubectl get nodes NAME STATUS ROLES AGE VERSION abelsu7-ubuntu Ready master 15m v1.13.3 可以看到master已经处于Ready状态。 4.5 查看集群 Pod 状态我们知道 Kubernetes 中的最小调度单元是Pod。使用以下命令查看集群中现有的Pod状态： ~&gt; kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-86c58d9df4-9vwct 1/1 Running 0 19m kube-system coredns-86c58d9df4-mvdnh 1/1 Running 0 19m kube-system etcd-abelsu7-ubuntu 1/1 Running 0 18m kube-system kube-apiserver-abelsu7-ubuntu 1/1 Running 0 18m kube-system kube-controller-manager-abelsu7-ubuntu 1/1 Running 0 18m kube-system kube-flannel-ds-amd64-wktkk 1/1 Running 0 17m kube-system kube-proxy-qv2t8 1/1 Running 0 19m kube-system kube-scheduler-abelsu7-ubuntu 1/1 Running 0 18m 5. 向集群中添加节点根据刚才执行完kubeadm init后给出的提示信息，分别在新机器centos-1和centos-2上执行kubeadm join命令： ~&gt; kubeadm join 222.201.139.151:6443 --token ar8quq.bx68gpg2ktjzagk8 --discovery-token-ca-cert-hash sha256:125083b871f062c8d4c0c7ab5cefee1ba0b74a6b3fb17c0c4b5ba4d591c1051d [preflight] Running pre-flight checks [WARNING Service-Docker]: docker service is not enabled, please run &#39;systemctl enable docker.service&#39; [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 18.09.2. Latest validated version: 18.06 [WARNING Hostname]: hostname &quot;centos-1&quot; could not be reached [WARNING Hostname]: hostname &quot;centos-1&quot;: lookup centos-1 on 222.201.130.30:53: no such host [discovery] Trying to connect to API Server &quot;222.201.139.151:6443&quot; [discovery] Created cluster-info discovery client, requesting info from &quot;https://222.201.139.151:6443&quot; [discovery] Requesting info from &quot;https://222.201.139.151:6443&quot; again to validate TLS against the pinned public key [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;222.201.139.151:6443&quot; [discovery] Successfully established connection with API Server &quot;222.201.139.151:6443&quot; [join] Reading configuration from the cluster... [join] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [kubelet] Downloading configuration for the kubelet from the &quot;kubelet-config-1.13&quot; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot; [kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot; [kubelet-start] Activating the kubelet service [tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap... [patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;centos-1&quot; as an annotation This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run &#39;kubectl get nodes&#39; on the master to see this node join the cluster. 上述命令执行完成后，提示已经成功加入集群。 此时，在master上查看当前集群状态： ~&gt; kubectl get nodes NAME STATUS ROLES AGE VERSION abelsu7-ubuntu Ready master 26m v1.13.3 centos-1 Ready &lt;none&gt; 24m v1.13.3 centos-2 Ready &lt;none&gt; 16m v1.13.3 待更新journalctl -f -u kubelet kubeadm reset cat /var/lib/kubelet/kubeadm-flags.env kubectl get pods --all-namespaces kubectl describe pod kube-flannel-ds-amd64-c2vnq --namespace=kube-system 参考文章 Installing kubeadm | kubernetes.io Creating a single master cluster with kubeadm | kubernetes.io 《Kubernetes 从上手到实践》| 掘金小册 Running kubeadm without an internet connection | kubernetes.io kubeadm config image 阿里云镜像 | 简书 如何成功启动 Docker 自带的 Kubernetes？| 简书 kubernetes 1.11 集群痛苦搭建过程 | Mr.Cai Kubeadm 安装 Kubernetes 环境 | ericnie 的技术博客（RedHat 工程师） Kubernetes的 node NotReady 如何查问题，针对问题解决 | CSDN Kubernetes 初体验 | 时间轨迹 Minikube - Kubernetes本地实验环境 | 阿里云栖社区 使用 minikube 安装 k8s 集群 | 胡伟煌 kubeadm 续坑篇 | 漠然 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总QEMU 3.1.0 源码学习《KVM 实战》笔记 1：构建 KVM 环境","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"},{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/tags/云计算/"}]},{"title":"CentOS 7 关闭 SELinux","slug":"centos7-selinux","date":"2019-02-24T10:16:24.000Z","updated":"2019-09-01T13:04:11.028Z","comments":true,"path":"2019/02/24/centos7-selinux/","link":"","permalink":"https://abelsu7.top/2019/02/24/centos7-selinux/","excerpt":"摘自 How to Disable SELinux on CentOS 7 | Linuxize","text":"摘自 How to Disable SELinux on CentOS 7 | Linuxize 1. 查看 SELinux 状态&gt; getenforce Enabled &gt; sestatus SELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: enforcing Policy MLS status: enabled Policy deny_unknown status: allowed Max kernel policy version: 31 2. 临时关闭 SELinuxsetenforce 0 ## 设置为 Permissive 模式 setenforce 1 ## 设置为 Enforcing 模式 3. 永久关闭 SELinux&gt; vim /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted 修改为SELINUX=disabled，重启后生效。 参考文章 How to Disable SELinux on CentOS 7 | Linuxize CentOS 7.X 关闭 SELinux | 博客园 CentOS 7 关闭 SELinux | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"SELinux","slug":"SELinux","permalink":"https://abelsu7.top/tags/SELinux/"}]},{"title":"Linux 下使用 SSR + ProxyChains 代理终端流量","slug":"ssr-proxychains4-on-linux","date":"2019-02-24T09:20:12.000Z","updated":"2019-10-15T09:21:16.037Z","comments":true,"path":"2019/02/24/ssr-proxychains4-on-linux/","link":"","permalink":"https://abelsu7.top/2019/02/24/ssr-proxychains4-on-linux/","excerpt":"Across the Great Wall we can reach every corner in the world.","text":"Across the Great Wall we can reach every corner in the world. 1. 下载 ShadowsocksR~&gt; wget https://github.com/cndaqiang/shadowsocksr/archive/manyuser.zip ~&gt; unzip manyuser.zip ~&gt; cd shadowsocksr-manyuser ~/shadowsocksr-manyuser&gt; ls apiconfig.py configloader.py Dockerfile initmudbjson.sh mudb.json README.rst setup_cymysql.sh switchrule.py asyncmgr.py CONTRIBUTING.md importloader.py LICENSE mujson_mgr.py run.sh setup.py tail.sh CHANGES db_transfer.py initcfg.bat logrun.sh mysql.json server_pool.py shadowsocks tests config.json debian initcfg.sh MANIFEST.in README.md server.py stop.sh utils 2. 修改 SSR 配置文件 config.jsonSSR 配置文件路径为shadowsocks-manyuser/config.json： { &quot;server&quot;: &quot;xxx.xxx.xxx.xxx&quot;, // 服务器 IP &quot;server_ipv6&quot;: &quot;::&quot;, &quot;server_port&quot;: 8388, // 服务器端口 &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;: 1080, // 本地端口 &quot;password&quot;: &quot;password&quot;, // 密码 &quot;method&quot;: &quot;aes-256-cfb&quot;, // 加密方式 &quot;protocol&quot;: &quot;auth_aes128_md5&quot;, // 协议 &quot;protocol_param&quot;: &quot;&quot;, &quot;obfs&quot;: &quot;origin&quot;, // 混淆 &quot;obfs_param&quot;: &quot;&quot;, &quot;speed_limit_per_con&quot;: 0, &quot;speed_limit_per_user&quot;: 0, &quot;additional_ports&quot; : {}, // only works under multi-user mode &quot;additional_ports_only&quot; : false, // only works under multi-user mode &quot;timeout&quot;: 120, &quot;udp_timeout&quot;: 60, &quot;dns_ipv6&quot;: false, &quot;connect_verbose_info&quot;: 0, &quot;redirect&quot;: &quot;&quot;, &quot;fast_open&quot;: false } 3. 启动/停止 SSRsudo python ./shadowsocks/local.py -c config.json -d start|stop 4. 安装 proxychains-ng~&gt; git clone https://github.com/rofl0r/proxychains-ng.git ~&gt; cd proxychains-ng/ ~/proxychains-ng&gt; ./configure --prefix=/usr --sysconfdir=/etc ~/proxychains-ng&gt; make &amp;&amp; make install ~/proxychains-ng&gt; make install-config 5. 修改 proxychains 配置文件proxychains-ng 配置文件路径为/etc/proxychains.conf，根据实际情况添加代理socks5 127.0.0.1 1080： ## you&#39;ll need to enable it if you want to use an application that ## connects to localhost. # localnet 127.0.0.0/255.0.0.0 ## RFC1918 Private Address Ranges # localnet 10.0.0.0/255.0.0.0 # localnet 172.16.0.0/255.240.0.0 # localnet 192.168.0.0/255.255.0.0 # ProxyList format # type ip port [user pass] # (values separated by &#39;tab&#39; or &#39;blank&#39;) # # only numeric ipv4 addresses are valid # # # Examples: # # socks5 192.168.67.78 1080 lamer secret # http 192.168.89.3 8080 justu hidden # socks4 192.168.1.49 1080 # http 192.168.39.93 8080 # # # proxy types: http, socks4, socks5 # ( auth types supported: &quot;basic&quot;-http &quot;user/pass&quot;-socks ) # [ProxyList] # add proxy here ... # meanwile # defaults set to &quot;tor&quot; socks5 127.0.0.1 1080 6. 设置 proxychains 别名修改~/.bashrc，并设置 alias 别名： # .bashrc # User specific aliases and functions alias rm=&#39;rm -i&#39; alias cp=&#39;cp -i&#39; alias mv=&#39;mv -i&#39; alias pc=&#39;proxychains4&#39; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi 输入source ~/.bashrc或重启终端后生效。 要想在终端命令中使用代理，只需在命令前加上pc。例如：pc yum install kubectl。 7. 验证代理是否可用~&gt; pc Usage: proxychains4 -q -f config_file program_name [arguments] -q makes proxychains quiet - this overrides the config setting -f allows one to manually specify a configfile to use for example : proxychains telnet somehost.com More help in README file ~&gt; pc telnet www.google.com 443 [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.13-git-10-g1198857 Trying 224.0.0.1... [proxychains] Strict chain ... 127.0.0.1:1080 ... www.google.com:443 ... OK Connected to www.google.com. Escape character is &#39;^]&#39;. ~&gt; pc curl myip.ipip.net [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.13-git-10-g1198857 [proxychains] Strict chain ... 127.0.0.1:1080 ... myip.ipip.net:80 ... OK 当前 IP：103.xxx.xxx.xxx 来自于：美国 加利福尼亚州 费利蒙 sakura-host.net 参考文章 Ubuntu 16.04 安装 Python 版 SSR | cndaqiang Centos 7 作为 Client 连接 SSR | 简书 cndaqiang/shadowsocksr | Github shadowsocksr-backup/shadowsocksr | Github ShadowsocksR 一键安装脚本 | Shadowsocks 非官方网站 Linux CentOS 7 安装 SSR 过程 以及一些问题的处理 | 逆流水Team 通过 ProxyChains-NG 实现终端下任意应用代理 | CSDN 2019 优质 VPS 服务商推荐 | 知乎 写给非专业人士看的 Shadowsocks 简介 | vc2tea 打造基于 ShadowSocks + ProxyChains 的全栈式科学上网工具 | Echo’s Blog 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://abelsu7.top/tags/Shadowsocks/"},{"name":"代理","slug":"代理","permalink":"https://abelsu7.top/tags/代理/"},{"name":"SSR","slug":"SSR","permalink":"https://abelsu7.top/tags/SSR/"}]},{"title":"CentOS 7 安装 Shadowsocks 客户端","slug":"centos7-install-shadowsocks-client","date":"2019-02-18T16:47:42.000Z","updated":"2019-09-01T13:04:11.020Z","comments":true,"path":"2019/02/19/centos7-install-shadowsocks-client/","link":"","permalink":"https://abelsu7.top/2019/02/19/centos7-install-shadowsocks-client/","excerpt":"Across the Great Wall we can reach every corner in the world.","text":"Across the Great Wall we can reach every corner in the world. 参考文章 Shadowsocks 原理简介及安装指南 | 小胡子哥 CentOS 7 安装 shadowsocks 客户端 | 全栈渐进之路 在 CentOS 7 下安装配置 shadowsocks | 早起搬砖 morning.work Centos 7 作为 Client 连接 SSR | 简书 CentOS 7 安装配置 Shadowsocks 客户端 | 作业部落proxychains-ng | Github 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://abelsu7.top/tags/Shadowsocks/"}]},{"title":"CentOS 7 调整 grub2 启动项顺序及等待时间","slug":"centos7-grub2","date":"2019-02-18T06:12:31.000Z","updated":"2019-09-01T13:04:11.006Z","comments":true,"path":"2019/02/18/centos7-grub2/","link":"","permalink":"https://abelsu7.top/2019/02/18/centos7-grub2/","excerpt":"摘自 Setting Up grub2 on CentOS 7 | CentOS Wiki","text":"摘自 Setting Up grub2 on CentOS 7 | CentOS Wiki 最近安装了 CentOS 7 + Windows 10 的双系统，开机进入 grub2 的启动菜单。由于平时用 Windows 居多，可以接受在开机时手动选择 CentOS，所以需要修改默认启动项为Windows Boot Manager，并缩短等待时间为 3 秒（默认为 5 秒），下面简单介绍修改方法。 1. 修改 grub2 等待时间grub2 等待时间由/etc/default/grub中的GRUB_TIMEOUT控制，首先查看该文件内容： &gt; cat /etc/default/grub GRUB_TIMEOUT=5 GRUB_DISTRIBUTOR=&quot;$(sed &#39;s, release .*$,,g&#39; /etc/system-release)&quot; GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=&quot;console&quot; GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet&quot; GRUB_DISABLE_RECOVERY=&quot;true&quot; 2. 重新生成 grub2.cfg修改为GRUB_TIMOUT=3后，为使其生效，需要重新生成/boot/efi/EFI/centos/grub2.cfg： &gt; grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg 非 UEFI 设备（Legacy）需将上述文件路径替换为/boot/grub2/grub.cfg 3. 查看所有启动项&gt; awk -F\\&#39; &#39;$1==&quot;menuentry &quot; {print i++ &quot; : &quot; $2}&#39; /etc/grub2-efi.cfg 0 : CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) 1 : CentOS Linux (0-rescue-3af74b34419f4869a2952d4467e303f8) 7 (Core) 2 : Windows Boot Manager (on /dev/sda2) 非 UEFI 设备（Legacy）需将上述文件路径替换为/etc/grub.cfg 或使用下列命令： &gt; grep &quot;^menuentry&quot; /boot/efi/EFI/centos/grub.cfg | cut -d &quot;&#39;&quot; -f2 CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) CentOS Linux (0-rescue-3af74b34419f4869a2952d4467e303f8) 7 (Core) Windows Boot Manager (on /dev/sda2) 非 UEFI 设备（Legacy）需将上述文件路径替换为/boot/grub2/grub.cfg 4. 修改默认启动项默认启动项由/etc/default/grub中的GRUB_DEFAULT控制。 如果GRUB_DEFAULT=saved，则该参数将存储在/boot/grub2/grubenv中。可使用grub2-editenv list查看： &gt; grub2-editenv list saved_entry=CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) 通过grub2-set-default命令修改默认启动项。由之前的输出可知，Windows Boot Manager的启动序号为2： &gt; grub2-set-default 2 &gt; grub2-editenv list saved_entry=2 重启即可生效，修改完成。 参考文章 在 CentOS 7 上设置 grub2 | CentOS Wiki Setting Up grub2 on CentOS 7 | CentOS Wiki Linux GRUB2 配置简介 | Linux 中国 CentOS 7 系统引导程序 Grub2 的配置 | 文卓的笔记 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"grub2","slug":"grub2","permalink":"https://abelsu7.top/tags/grub2/"}]},{"title":"Linux 下安装 RPM 软件包常用操作","slug":"linux-rpm","date":"2019-02-18T05:23:44.000Z","updated":"2019-09-01T13:04:11.505Z","comments":true,"path":"2019/02/18/linux-rpm/","link":"","permalink":"https://abelsu7.top/2019/02/18/linux-rpm/","excerpt":"RPM（Redhat Package Manager）的五种操作模式：安装、卸载、升级、查询、验证。摘自 TecAdmin.net","text":"RPM（Redhat Package Manager）的五种操作模式：安装、卸载、升级、查询、验证。摘自 TecAdmin.net 1. 安装 RPM 包&gt; rpm -ivh vsftpd-2.3.5-2.el6.i686.rpm warning: vsftpd-2.3.5-2.el6.i686.rpm: Header V3 DSA/SHA1 Signature, key ID e9bc4ae1: NOKEY Preparing... ########################################### [100%] 1:vsftpd ########################################### [100%] 参数含义如下： -i：执行安装操作 -v：显示正在安装的文件信息 -h：显示安装进度 -l：显示安装包中的所有文件被安装到哪些目录下 其他附加参数： --force：强制执行操作 --requires：显示该包的依赖关系 --nodeps：忽略依赖关系并继续操作 2. 升级已安装的 RPM 包&gt; rpm -Uvh vsftpd-2.3.5-2.el6.i686.rpm 3. 检查 RPM 包是否已安装&gt; rpm -q vsftpd vsftpd-2.3.5-2.el6.i686 4. 列出系统中所有已安装的 RPM 包&gt; rpm -qa 5. 卸载已安装的 RPM 包 Below command will erase (uninstall) rpm package from your system. &gt; rpm -e vsftpd vsftpd-2.3.5-2.el6.i686 6. 显示 RPM 包的详细信息&gt; rpm -qip vsftpd-2.3.5-2.el6.i686.rpm warning: vsftpd-2.3.5-2.el6.i686.rpm: Header V3 DSA/SHA1 Signature, key ID e9bc4ae1: NOKEY Name : vsftpd Relocations: (not relocatable) Version : 2.3.5 Vendor: (none) Release : 2.el6 Build Date: Thu 23 Feb 2012 07:38:59 AM IST Install Date: (not installed) Build Host: localhost Group : System Environment/Daemons Source RPM: vsftpd-2.3.5-2.el6.src.rpm Size : 453460 License: GPLv2 with exceptions Signature : DSA/SHA1, Fri 11 Jan 2013 06:48:45 PM IST, Key ID 8fbd1684e9bc4ae1 URL : http://vsftpd.devnet.ru Summary : Very Secure Ftp Daemon Description : vsftpd is a Very Secure FTP daemon. It was written completely from scratch. 7. 列出 RPM 包中的所有文件&gt; rpm -qlp vsftpd-2.3.5-2.el6.i686.rpm warning: vsftpd-2.3.5-2.el6.i686.rpm: Header V3 DSA/SHA1 Signature, key ID e9bc4ae1: NOKEY /etc/logrotate.d/vsftpd /etc/pam.d/vsftpd /etc/rc.d/init.d/vsftpd /etc/vsftpd /etc/vsftpd/ftpusers /etc/vsftpd/user_list /etc/vsftpd/vsftpd-403-serv.html /etc/vsftpd/vsftpd-403.html /etc/vsftpd/vsftpd-404.html 8. 搜索文件归属的 RPM 软件包&gt; rpm -qf /etc/vsftpd/ftpusers vsftpd-2.3.5-2.el6.i686 9. 列出 RPM 包的所有依赖项&gt; rpm -qpR vsftpd-2.3.5-2.el6.i686.rpm 10. 还原 RPM 包到旧版本&gt; rpm -Uvh --oldpackage vsftpd-&lt;old-version&gt;.el6.i686.rpm 参考文章 Linux RPM Comamnd with 10 Useful Examples | TecAdmin.net Linux 的 RPM Comamnd 10 实用举例 | Howtoing 运维教程 Linux 下 RPM 软件包的安装及卸载 | 51CTO 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"RPM","slug":"RPM","permalink":"https://abelsu7.top/tags/RPM/"}]},{"title":"2020 届互联网春招实习汇总 (2019年春)","slug":"2019-spring-offer","date":"2019-02-15T17:23:44.000Z","updated":"2019-09-01T13:04:10.956Z","comments":true,"path":"2019/02/16/2019-spring-offer/","link":"","permalink":"https://abelsu7.top/2019/02/16/2019-spring-offer/","excerpt":"2019-3-1 更新","text":"2019-3-1 更新 春招信息 校招官网 微信 内推 腾讯 腾讯招聘 可内推 网易游戏 网易游戏综合招聘 可内推 网易游戏-互娱 网易游戏互娱校园招聘 已内推 网易游戏-雷火 网易游戏雷火伏羲招聘 可内推 网易互联网 网易招聘 暂未开始 网易有道 有道招聘 暂未开始 字节跳动 字节跳动招聘 可内推 招银网络科技 招银网络科技 可内推 顺丰科技 顺丰科技招聘 暂未开始 平安科技 平安科技招聘 仅应届 华为 华为招聘 暂未开始 阿里 阿里技术栈 暂未开始 哔哩哔哩 哔哩哔哩招聘 暂未开始 小米 小米校园招聘 暂未开始 Job-Recommend | 互联网内推信息 网易游戏-基础架构工程师 | 腾讯云+社区 蚂蚁金服容器与服务创新组毕业生招聘 | Jimmy Song 加入蚂蚁金服 | Jimmy Song 蚂蚁金服-网商银行 实习生春招/ 顺便帮朋友找擅长容器的同学 | 牛客 【含实习生】找工作吗？网易有道2019春招了解一下 | 牛客 阿里云基础设施2020届实习招聘 | 牛客 2019年阿里巴巴-阿里云智能事业群-实习招聘继续进行中 | 牛客 阿里云智能事业群基础设施事业部招聘信息 | 微信 京东 蚂蚁金服 菜鸟 百度 中移互联网 联通 电信 亚信 360 美团点评 滴滴 小米 微博 搜狐 360 微信公众号整理 … 赖信涛 | 蚂蚁金服 SRE 蚂蚁中间件 阿里巴巴 蚂蚁实习内推 | 牛客 阿里实习生内推！！！师兄免费帮改简历并给出修改意见 | 牛客 思维导图（待更新） 复习资料1. Go 语言综合 Go 语言快速入门 | jaywcjlove Go And BlockChain Study | Github Go by Example Go by Example 中文版 《Go 语言实战》读书笔记 | 飞雪无情 The Go Programming Language 摘要 | Kumu’s Blog Web Go Web Examples 数据库 Go database/sql tutorial mgo | Rich MongoDB driver for Go mongo-go-driver | Github MongoDB Go Driver Documentation 社区/博客 Go 语言中文网 Golang 中国 飞雪无情的博客 Tony Bai | 东软工程师-白明 工具/框架 Awesome Go | Github Gopm Registry | Download Go packages by version dep - Go dependency management tool | Github govendor | Github gin | Github Gin Gonic | The fastest full-featured web framework for Golang Gin Web Framework 文章 Go 1.12 中值得关注的几个变化 | Tony Bai 初窥 Go Module | Tony Bai Hello，Go module proxy | Tony Bai Go 与 SOAP | Tony Bai YAML 入门：以创建一个 Kubernetes deployment 为例 | Tony Bai 一步步打造基于 Kubeadm 的高可用 Kubernetes 集群 - 第一部分 | Tony Bai 2. KVM博客园 KVM - 介绍 KVM - 安装 KVM - CPU、内存虚拟化 KVM - 存储虚拟化 KVM - 网络虚拟化 世民谈云计算 KVM 介绍（1）：简介及安装 KVM 介绍（2）：CPU 和内存虚拟化 KVM 介绍（3）：I/O 全虚拟化和半虚拟化 KVM 介绍（4）：I/O 设备直接分配和 SR-IOV KVM 介绍（5）：libvirt 介绍 KVM 介绍（6）：Nova 通过 libvirt 管理 QEMU/KVM 虚拟机 KVM 介绍（7）：使用 libvirt 做 QEMU/KVM 快照和 Nova 实例的快照 KVM 介绍（8）：使用 libvirt 迁移 QEMU/KVM 虚拟机和 Nova 虚拟机 其他 KVM 学习笔记 | Kumu’s Blog rsync 备份备忘 | Kumu’s Blog 3. Docker 利用 Docker 运行 MongoDB | 全栈渐进之路 如何优雅的关闭容器 | Kumu’s Blog 4. Kubernetes kubernetes.io Docker 和 Kubernetes 从听过到略懂：给程序员的旋风教程 | 1 Byte Docker 和 Kubernetes 从听过到略懂：给程序员的旋风教程 | DockerOne.io Dynamically Expand Volume with CSI and Kubernetes | kubernetes.io 5. 数据库MySQL mysql-tutorial | Github 21分钟 MySQL 基础入门 | 小弟调调 MySQL 教程 | W3Cschool MongoDB MongoDB University MongoDB 教程 | W3Cschool 利用 Docker 运行 MongoDB | 全栈渐进之路 Linux 自动定时备份 MongoDB | 全栈渐进之路 MongoDB 资料大全 | 阿里云栖社区 怎样学 MongoDB | 知乎 MongoDB 教程 | 极客学院 MongoDB 快速入门教程 | 博客园 简明 MongoDB 入门教程 | SegmentFault MongoDB 教程 | MongoDB 中文网 6. 电子书 ebook【C/C++/Linux/Go】 | Github 7. Linuxize 系列文章 Install MySQL on CentOS 7 | Linuxize How to List Installed Packages on CentOS | Linuxize How To Install Atom Text Editor on CentOS 7 | Linuxize How to Enable the EPEL repository on CentOS | Linuxize How to Extract (Unzip) Tar Gz File | Linuxize How to Install Go on CentOS 7 | Linuxize How to Install TeamViewer on CentOS 7 | Linuxize How to Add and Delete Users on CentOS 7 | Linuxize How to Install Go on Ubuntu 18.04 | Linuxize 面试题目1. 腾讯算法 1000个苹果，放到10个框里，怎么样能够保证任意数量的苹果都可以被表示出来？ 参考这里，按位表示，模拟二进制 2. 字节跳动计组 计算机组成原理—-为什么计算机中要使用补码？| CSDN TCP/IP TCP 流量控制和拥塞控制 | 博客园 TCP 拥塞控制和 TCP 流量控制 | CSDN TCP 之 Nagle 算法 &amp;&amp; 延迟 ACK | 博客园 TCP/IP 学习笔记（六）Nagle算法 | CSDN 算法解决思路：最小堆 面试题-100万个数据前100大的数据 | CSDN 海量数据处理 - 10亿个数中找出最大的10000个数（top K问题）| CSDN 看图轻松理解最小(大)堆 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）2020 届互联网秋季校园招聘汇总 (2019年秋)近期复习合集Linux Shell 脚本面试25问golang面试题golang面试题","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://abelsu7.top/tags/面试/"},{"name":"春招","slug":"春招","permalink":"https://abelsu7.top/tags/春招/"}]},{"title":"CentOS 7 安装 MySQL 5.7","slug":"centos7-install-mysql57","date":"2019-02-15T16:25:55.000Z","updated":"2019-09-01T13:04:11.015Z","comments":true,"path":"2019/02/16/centos7-install-mysql57/","link":"","permalink":"https://abelsu7.top/2019/02/16/centos7-install-mysql57/","excerpt":"摘自 CentOS 7 下 Yum 安装 MySQL 5.7 | Zhanming’s blog","text":"摘自 CentOS 7 下 Yum 安装 MySQL 5.7 | Zhanming’s blog 1. 配置 yum 源下载并安装 MySQL 源安装包： &gt; sudo yum localinstall https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm 检查 yum 源是否安装成功： &gt; sudo yum repolist enabled | grep &quot;mysql.*-community.*&quot; mysql-connectors-community/x86_64 MySQL Connectors Community 95 mysql-tools-community/x86_64 MySQL Tools Community 84 mysql57-community/x86_64 MySQL 5.7 Community Server 327 2. yum 安装 MySQL&gt; sudo yum install mysql-community-server 3. 启动 MySQL&gt; sudo systemctl enable mysqld &gt; sudo systemctl start mysqld &gt; sudo systemctl status mysqld ● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2019-02-16 00:41:07 CST; 2 days ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Main PID: 29143 (mysqld) Tasks: 31 Memory: 193.2M CGroup: /system.slice/mysqld.service └─29143 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid Feb 16 00:41:06 localhost.localdomain systemd[1]: Starting MySQL Server... Feb 16 00:41:07 localhost.localdomain systemd[1]: Started MySQL Server. 4. 修改 root 初始密码MySQL 5.7 启动后，会在/var/log/mysqld.log文件中为用户root生成一个随机的初始密码。使用以下命令查看初始密码： &gt; grep &#39;temporary password&#39; /var/log/mysqld.log 2019-02-15T16:29:45.738097Z 1 [Note] A temporary password is generated for root@localhost: jHsg&lt;YlYu5id 登录 MySQL 并修改密码： &gt; mysql -u root -p Enter password: mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass4!&#39;; MySQL 5.7 默认安装了密码安全检查插件（validate_password），默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不少于 8 位。 通过 MySQL 环境变量可以查看密码策略的相关信息： mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;; +--------------------------------------+--------+ | Variable_name | Value | +--------------------------------------+--------+ | validate_password_check_user_name | OFF | | validate_password_dictionary_file | | | validate_password_length | 8 | | validate_password_mixed_case_count | 1 | | validate_password_number_count | 1 | | validate_password_policy | MEDIUM | | validate_password_special_char_count | 1 | +--------------------------------------+--------+ 7 rows in set (0.01 sec) 指定密码校验策略： &gt; sudo vi /etc/my.cnf [mysqld] # 添加如下键值对, 0=LOW, 1=MEDIUM, 2=STRONG validate_password_policy=0 禁用密码策略： &gt; sudo vi /etc/my.cnf [mysqld] # 禁用密码校验策略 validate_password = off 重启 MySQL 服务，使配置生效： sudo systemctl restart mysqld 5. 添加远程登录用户MySQL 默认只允许root用户在本地登录。如果要从其他机器上连接 MySQL，必须允许root用户从远程登录，或者添加一个允许远程连接的账户。以下命令将添加一个新用户admin，并允许其从远程登录： mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;%&#39; IDENTIFIED BY &#39;secret&#39; WITH GRANT OPTION; 如果需要修改权限允许root远程登录，则先以root用户登录 MySQL，再进行如下操作： mysql&gt; USE mysql; Database changed mysql&gt; SELECT User, Host -&gt; FROM user; +-----------+---------------+ | Host | User | +-----------+---------------+ | % | admin | | localhost | mysql.session | | localhost | mysql.sys | | localhost | root | +-----------+---------------+ 4 rows in set (0.02 sec) mysql&gt; UPDATE user -&gt; SET Host = &#39;%&#39; -&gt; WHERE User = &#39;root&#39;; Query OK, 1 row affected (0.04 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql&gt; SELECT User, Host -&gt; FROM user; +-----------+---------------+ | Host | User | +-----------+---------------+ | % | admin | | % | root | | localhost | mysql.session | | localhost | mysql.sys | +-----------+---------------+ 4 rows in set (0.00 sec) 6. 配置默认编码为 UTF-8MySQL 默认编码为latin1，查看字符集： mysql&gt; SHOW VARIABLES LIKE &#39;character%&#39;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | latin1 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | latin1 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 在配置文件/etc/my.cnf中将其修改为utf8： &gt; vim /etc/my.cnf [mysqld] # 在myslqd下添加如下键值对 character_set_server=utf8 init_connect=&#39;SET NAMES utf8&#39; 重启 MySQL，使配置生效： &gt; sudo systemctl restart mysqld 再次查看字符集： mysql&gt; SHOW VARIABLES LIKE &#39;character%&#39;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 7. 开启防火墙端口&gt; sudo firewall-cmd --zone=public --add-port=3306/tcp --permanent &gt; sudo firewall-cmd --reload 参考文章 CentOS 7 下 Yum 安装 MySQL 5.7 | Zhanming’s blog A Quick Guide to Using the MySQL Yum Repository | MySQL Documentation MySQL 5.7 安装与配置（YUM）| CSDN Centos 7 安装 MySQL | 简书 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFS解决 CentOS 7 tracker CPU 占用率 100%CentOS 7 安装配置 VNCCentOS 7 安装配置 oh-my-zsh浅析数据库缓冲池与SQL查询成本在CentOS上使用certbot为nginx添加https证书","categories":[{"name":"数据库","slug":"数据库","permalink":"https://abelsu7.top/categories/数据库/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"MySQL","slug":"MySQL","permalink":"https://abelsu7.top/tags/MySQL/"}]},{"title":"5 分钟 Docker 笔记 5：存储","slug":"docker-5mins-notes-5","date":"2019-02-15T07:35:43.000Z","updated":"2019-09-01T13:04:11.160Z","comments":true,"path":"2019/02/15/docker-5mins-notes-5/","link":"","permalink":"https://abelsu7.top/2019/02/15/docker-5mins-notes-5/","excerpt":"Bind Mount 与 Data Volume、共享数据、Volume 生命周期管理 《每天5分钟玩转Docker容器技术》","text":"Bind Mount 与 Data Volume、共享数据、Volume 生命周期管理 《每天5分钟玩转Docker容器技术》 第 6 章 Docker 存储6.1 Docker 的两类存储资源Docker 为容器提供了两种存放数据的资源： 由 Storage Driver 管理的镜像层和容器层 Data Volume 6.1.1 Storage Driver先来回顾一下 Docker 镜像的分层结构： 容器由最上面一个可写的容器层，以及若干只读的镜像层组成，容器的数据就存放在这些层中。这样的分层结构最大的特性是 Copy-on-Write： 新数据会直接存放在最上面的容器层 修改现有数据会先从镜像层将数据复制到容器层，修改后的数据直接保存在容器层中，镜像层保持不变 如果多个层中有命名相同的文件，用户只能看到最上面那层中的文件 分层结构使镜像和容器的创建、共享以及分发变得非常高效，而这些都要归功于 Docker Storage Driver。正是 storage driver 实现了多层数据的堆叠并为用户提供一个单一的合并之后的统一视图。 Docker 会默认优先使用 Linux 发行版默认的 Storage Driver。 Docker 安装时会根据当前系统的配置选择默认的 driver。默认 driver 具有最好的稳定性，因为默认 driver 在发行版上经过了严格的测试。 运行docker info可查看 Storage Driver 的相关信息： [root@localhost ~]# docker info Containers: 3 Running: 0 Paused: 0 Stopped: 3 Images: 4 Server Version: 18.09.2 Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbce runc version: 09c8266bf2fcf9519a651b04ae54c967b9ab86ec init version: fec3683 Security Options: seccomp Profile: default Kernel Version: 3.10.0-957.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 6 Total Memory: 7.487GiB Name: localhost.localdomain ID: ZUUO:D7MX:3YFL:D67V:Y3DR:B57B:JAVB:IN7B:ZMWO:Q2SN:YNP4:TXP5 Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false Product License: Community Engine 6.1.2 Data VolumeData Volume 本质上是 Docker Host 文件系统中的目录或文件，能够直接被 mount 到容器的文件系统中。 Data Volume 有以下特点： Data Volume 是目录或文件，而非没有格式化的磁盘（块设备） 容器可以读写 volume 中的数据 volume 数据可以被永久的保存，即使使用它的容器已经被销毁 在具体使用中应遵循这样的原则： 无状态的数据存放在数据层中，作为镜像一部分； 有状态的数据存放在 Data Volume 中，因为这是需要持久化的数据，并且应该与镜像分开存放。 在具体使用上，Docker 提供了两种类型的 volume：bind mount 和 Docker managed volume。 bind mountbing mount 是将 host 上已存在的目录或文件 mount 到容器。 例如 Docker host 上有目录$HOME/htdocs： 通过-v将其 mount 到 httpd 容器： 参数-v的格式为&lt;host_path&gt;:&lt;container_path&gt;，原有的同名目录会被隐藏起来，这与 Linux 系统中的mount命令的行为是一致的。 bind mount 可以让 host 与容器共享数据，这在管理上是非常方便的。 另外，使用 bind mount 时还可以指定数据的读写权限，默认是可读可写，可指定为只读： ro设置了只读权限。在容器中是无法对 bind mount 数据进行修改的，只有 host 有权修改数据，提高了安全性。 除了 bind mount 目录，还可以单独指定一个文件： 使用 bind mount 单个文件的场景是：只需要向容器添加文件，不希望覆盖整个目录。 使用单一文件有一点要注意：host 中的源文件必须要存在，不然会当作一个新目录 bind mount 给容器。 bind mount 的使用直观高效，易于理解，但它也有不足的地方：bind mount 需要指定 host 文件系统的特定路径，这就限制了容器的可移植性，当需要将容器迁移到其他 host，而该 host 没有要 mount 的数据或者数据不在相同的路径时，操作会失败。 移植性更好的方式是 docker managed volume。 docker managed volumedocker managed volume 与 bind mount 在使用上的最大区别是不需要指定 mount 源，指明 mount point 就行了。 以 httpd 容器为例： [root@localhost ~]# docker run -d -p 80:80 -v /usr/local/apache2/htdocs httpd 2e973f7246b72d60c42e0a124d8bcb4e8ba053c4eb946de6c6d2ec5d2fb29cdd 上述命令通过-v告诉 Docker 需要一个 data volume，并将其 mount 到/usr/local/apache2/htdocs。 执行docker inspect命令： [root@localhost ~]# docker inspect 2e97 ... &quot;Mounts&quot;: [ { &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;bb76558c26ec96b8f2fd9aced58105495b610119520dbe84c3f83bc347bc2209&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/bb76558c26ec96b8f2fd9aced58105495b610119520dbe84c3f83bc347bc2209/_data&quot;, &quot;Destination&quot;: &quot;/usr/local/apache2/htdocs&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; } ], ... 可以看到Source就是该 Volume 在 host 上的目录。每当容器申请一个 docker managed volume 时，Docker 都会在/var/lib/docker/volumes下生成一个目录，这个目录就是 mount 源。查看该 volume 下的文件内容： [root@localhost ~]# ls /var/lib/docker/volumes/bb76558c26ec96b8f2fd9aced58105495b610119520dbe84c3f83bc347bc2209/_data index.html 总结一下 docker managed volume 的创建过程： 容器启动时，简单的告诉 docker “我需要一个 volume 存放数据，帮我 mount 到目录 /abc“。 docker 在/var/lib/docker/volumes中生成一个随机目录作为 mount 源 如果/abc已经存在，则将数据复制到 mount 源 将 volume mount 到/abc 还可以通过docker volume命令查看 docker managed volume，不过看不到 bing mount，而且也无法知道 volume 对应的容器： [root@localhost ~]# docker volume ls DRIVER VOLUME NAME local bb76558c26ec96b8f2fd9aced58105495b610119520dbe84c3f83bc347bc2209 bing mount 和 docker managed volume 对比相同点：都是 host 文件系统中的某个路径 不同点： bind mount docker managed volume volume 位置 可任意指定 /var/lib/docker/volumes/… 对已有 mount point 影响 隐藏并替换为 volume 原有数据复制到 volume 是否支持单个文件 支持 不支持，只能是目录 权限控制 可设置为只读，默认为读写权限 无控制，均为读写权限 移植性 移植性弱，与 host path 绑定 移植性强，无需指定 host 目录 6.2 共享数据6.2.1 容器与 host 共享数据bing mount 与 docker managed volume 均可实现在容器与 host 之间共享数据。 用 bind mount 来共享数据非常简单：直接将要共享的目录 mount 到容器。 而对与 docker managed volume，由于 volume 位于 host 中的目录，是在容器启动时才生成，所以需要使用docker cp将共享数据拷贝到 volume 中： 6.2.2 容器之间共享数据第一种方法是将共享数据放在 bind mount 中，然后将其 mount 到多个容器。 另一种在容器之间共享数据的方式是使用 volume container。 6.2.3 使用 volume container 共享数据volume container 是专门为其他容器提供 volume 的容器。它提供的卷可以是 bind mount，也可以是 docker managed volume。下面我们创建一个 volume container： 将容器命名为vc_data。这里执行的是docker create命令，这是因为 volume container 的作用只是提供数据，它本身不需要处于运行状态。容器 mount 了两个 volume： bing mount，存放 web server 的静态文件 docker managed volume，存放一些实用工具 其他容器可以通过--volumes-from使用vc_data这个 volume container： volume container 的特点如下： 与 bind mount 相比，不必为每一个容器指定 host path，所有的 path 都在 volume container 中定义好了，容器只需要与 volume container 关联，这样就实现了容器与 host 的解耦 使用 volume container 的容器其 mount point 是一致的，有利于配置的规范和标准化，但也带来一定的局限，使用时需要综合考虑。 6.2.4 data-packed volume container之前的例子中 volume container 的数据还是在 host 上，其实还可以将数据打包到镜像中，然后通过 docker managed volume 共享。通常我们称这种容器为 data-packed volume container。 首先使用下面的 Dockerfile 构建镜像： FROM busybox:latest ADD htdocs /usr/local/apache2/htdocs VOLUME /usr/local/apache2/htdocs 之后构建新镜像 datapacked： 用新镜像创建 data-packed volume container： 因为在 Dockerfile 中已经使用了VOLUME指令，这里就不需要指定 volume 的 mount point 了。启动 httpd 容器并使用 data-packed volume container： 容器能够正确读取 volume 中的数据。data-packed volume container 是自包含的，不依赖 host 提供数据，具有很强的移植性，非常适合只使用静态数据的场景，比如应用的配置信息、web server 的静态文件等。 6.3 volume 生命周期管理6.3.1 volume 备份因为 volume 实际上是 host 文件系统中的目录和文件，所以 volume 的备份实际上是对文件系统的备份。 所有的本地镜像都存在 host 的/myregistry目录中，我们要做的就是定期备份这个目录。 6.3.2 volume 恢复volume 的恢复也很简单，如果数据损坏了，直接用之前备份的数据拷贝到/myregistry就可以了。 6.3.3 volume 迁移如果想使用更新版本的 Registry，就涉及到数据迁移： docker stop当前 Registry 容器 启动新版本容器并 mount 原有 volume： docker run -d -p 5000:5000 -v /myregistry:/var/lib/registry registry:latest 在启用新容器前要确认新版本的默认数据路径是否发生变化。 6.3.4 volume 销毁Docker 不会销毁 bind mount。删除 bind mount 数据的工作只能由 host 负责。 对于 docker managed volume，在执行docker rm删除容器时可以加上-v参数，Docker 会将容器使用到的 volume 一并删除，但前提是没有容器 mount 该 volume。 如果在删除容器时没有带-v，就会产生孤儿 volume： 可以使用docker volome rm删除这些孤儿 volume： 如果想批量删除孤儿 volume，可以使用以下命令： docker volume rm $(docker volume ls -q) 6.4 小结本章包括以下内容： Docker 为容器提供了两种存储资源：数据层和 data volume 数据层包括镜像层和容器层，由 storage driver 管理 Data Volume 有两种类型：bind mount 和 docker managed volume bing mount 可以实现容器与 host 之间、容器与容器之间共享数据 volume container 是一种具有更好移植性的容器间数据共享方案，特别是 data-packed volume container volume 生命周期管理包括备份、恢复、迁移和销毁 Data Volume 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Linux 内核笔记 1：绪论影响力数学之美：不能再凑了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"}]},{"title":"5 分钟 Docker 笔记 4：网络","slug":"docker-5mins-notes-4","date":"2019-02-13T12:03:52.000Z","updated":"2019-09-01T13:04:11.143Z","comments":true,"path":"2019/02/13/docker-5mins-notes-4/","link":"","permalink":"https://abelsu7.top/2019/02/13/docker-5mins-notes-4/","excerpt":"三种默认的网络模式、容器间的通信方式、容器与外部网络互连 《每天5分钟玩转Docker容器技术》","text":"三种默认的网络模式、容器间的通信方式、容器与外部网络互连 《每天5分钟玩转Docker容器技术》 第 5 章 Docker 网络5.1 none 和 host 网络的适用场景Docker 网络从覆盖范围可分为单个 host 上的容器网络和跨多个 host 的网络，本章将主要讨论前一种，即单个 host 上的容器网络。 Docker 安装时会自动在 host 上创建三个网络，可以用docker network ls命令查看： 5.1.1 none 网络顾名思义，none 网络就是什么都没有的网络。挂在 none 网络下的容器除了 lo，没有其他任何网卡。容器创建时，可以通过--network=none指定使用 none 网络： 这种封闭的网络同时也意味着隔离，一些对安全性要求高并且不需要联网的应用可以使用 none 网络。 5.1.2 host 网络连接到 host 网络的容器共享 Docker host 的网络栈，容器的网络配置与 host 完全一样。可以通过--network=host指定使用 host 网络： 在容器中可以看到 host 的所有网卡，并且连 hostname 也是 host 的。 直接使用 Docker host 的网络最大的好处就是性能，如果容器对网络传输效率有较高要求，则可以选择 host 网络。当然不便之处就是牺牲一些灵活性，比如要考虑端口冲突问题，Docker host 上已经使用的端口就不能再用了。 Docker host 的另一个用途是让容器可以直接配置 host 网络。比如某些跨 host 的网络解决方案，其本身也是以容器方式运行的，这些方案需要对网络进行配置，比如管理 iptables。 5.2 默认的 bridge 网络Docker 安装时会创建一个名为 docker0 的 Linux bridge。如果不指定--network，那么创建的容器默认都会挂到docker0上： 当前docker0上没有任何其他网络设备，下面创建一个容器看看有什么变化： 一个新的网络接口veth28c57df被挂到了docker0上，veth28c57df就是新创建容器的虚拟网卡。之后来看容器的网络配置： 容器有一个网卡eth0@if34。实际上eth0@if34和veth28c57df是一对 veth pair。veth pair 是一种成对出现的特殊网络设备，可以把它们想象成由一根虚拟网线连接起来的一对网卡，网卡的一头eth0@if34在容器中，另一头veth28c57df挂在网桥docker0上，其效果就是将eth0@if34也挂在了docker0上。 我们还可以看到，eth0@if34已经配置了 IP 172.17.0.2。通过docker network inspect bridge查看 bridge 网络的配置信息： 易知，bridge 网络配置的 subnet 就是172.17.0.0/16，并且网关是172.17.0.1。这个网关正是docker0的 IP 地址： 最后，当前容器网络拓扑结构如下图所示： 容器创建时，docker 会自动从172.17.0.0/16中分配一个 IP，这里使用 16 位的掩码可以保证有足够多的 IP 地址可供容器使用。 5.3 user-defined 自定义容器网络除了 none, host, bridge 这三个自动创建的网络，用户也可以根据业务需要创建 user-defined 网络。 Docker 提供三种 user-defined 网络驱动：bridge, overlay 和 macvlan。overlay 和 macvlan 用于创建跨主机的网络，后面的章节将单独讨论。 可通过 bridge 驱动创建类似前面默认的 bridge 网络： 查看一下当前 host 的网络结构变化： 可以看到新增了一个网桥br-eaed97dc9a77，这里eaed97dc9a77就是新建 bridge 网络my_net的短ID。 执行docker network inspect查看一下my_net的配置信息： 这里172.18.0.0/16是 Docker 自动分配的 IP 网段。 也可以自己指定 IP 网段，只需在创建网段时指定--subnet和--gateway参数： 这里创建了新的 bridge 网络my_net2，网段为172.22.16.0/24，网关为172.22.16.1。与之前一样，网关在my_net2对应的网桥br-5d863e9f78b6上： 容器要使用新的网络，需要在启动时通过--network指定： 到目前为止，容器的 IP 都是 Docker 自动从 subnet 中分配的。除此之外，我们还可以通过--ip参数来指定容器使用静态 IP 地址： 只有使用--subnet创建的网络才能指定静态 IP，否则 Docker 将会报错。 当前 docker host 的网络拓扑如下： 5.4 理解容器之间的连通性推荐阅读理解容器之间的连通性 - 每天5分钟玩转 Docker 容器技术（34） 5.5 容器间通信的三种方式容器之间可通过 IP，Docker DNS Server 或 joined 容器三种方式通信。 5.5.1 IP 通信两个容器要能通信，必须要有属于同一个网络的网卡。满足这个条件后，容器就可以通过 IP 交互了。具体做法是在容器创建时通过--network指定相应的网络，或者通过docker network connect将现有容器加入到指定网络。 5.5.2 Docker DNS Server从 Docker 1.10 版本开始，docker daemon 实现了一个内嵌的 DNS server，使容器可以直接通过容器名通信： docker run -it --network=my_net2 --name=bbox1 busybox docker run -it --network=my_net2 --name=bbox2 busybox 然后，bbox2就可以直接 ping 到bbox1了： 使用 docker DNS 有个限制：只能在 user-defined 网络中使用，默认的 bridge 网络是无法使用 DNS 的。 5.5.3 joined 容器joined 容器是另一种实现容器间通信的方式。 它可以使两个或多个容器共享一个网络栈，共享网卡和配置信息，joined 容器之间可以通过127.0.0.1直接通信。 joined 容器非常适合以下场景： 不同容器中的程序希望通过 loopback 高效快速地通信，比如 web server 与 app server。 希望监控其他容器的网络流量，比如运行在独立容器中的网络监控程序。 5.6 容器如何访问外部世界容器默认就能访问外网（容器网络以外的网络），这是通过网桥的 NAT（网络地址转换）实现的。 具体参考容器如何访问外部世界？- 每天5分钟玩转 Docker 容器技术（36） 5.7 外部世界如何访问容器外部网络通过端口映射访问到容器内部。 Docker 可将容器对外提供服务的端口映射到 host 的某个端口，外网通过该端口访问容器。容器启动时通过-p参数映射端口： 容器启动后，可通过docker ps或docker port查看动态映射到 host 的端口。 除了映射动态端口，也可以在-p中指定映射到 host 某个特定端口，例如可将容器的 80 端口映射到 host 的 8080 端口： 每一个映射的端口，host 都会启动一个docker-proxy进程来处理访问容器的流量： 以0.0.0.0:32773-&gt;80/tcp为例： docker-proxy监听 host 的 32773 端口 当 curl 访问10.0.2.15:32773时，docker-proxy转发给容器172.17.0.2:80 httpd 容器响应请求并返回结果 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Linux 内核笔记 1：绪论影响力数学之美：不能再凑了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"}]},{"title":"5 分钟 Docker 笔记 3：容器","slug":"docker-5mins-notes-3","date":"2019-02-13T06:23:54.000Z","updated":"2019-09-01T13:04:11.132Z","comments":true,"path":"2019/02/13/docker-5mins-notes-3/","link":"","permalink":"https://abelsu7.top/2019/02/13/docker-5mins-notes-3/","excerpt":"运行容器、容器常用操作、容器资源限制、实现容器的底层技术 《每天5分钟玩转Docker容器技术》","text":"运行容器、容器常用操作、容器资源限制、实现容器的底层技术 《每天5分钟玩转Docker容器技术》 第 4 章 Docker 容器4.1 运行容器4.1.1 如何运行容器docker run是启动容器的方法。例如： &gt; docker run ubuntu pwd / 容器启动时执行pwd，返回的/是容器中的当前目录。 执行docker ps或docker container ls可以查看 Docker Host 中当前运行的容器，添加-a参数会显示所有状态的容器。 若想让容器保持运行状态而不占用终端窗口，可以加上-d参数，以后台方式启动容器： docker run --name &quot;my_http_server&quot; -d httpd 4.1.2 两种进入容器的方法我们经常需要进到容器里去做一些工作，比如查看日志、调试、启动其他进程等。有两种方法进入容器：attach 和 exec。 docker attach通过docker attach可以连接到容器启动命令的终端，例如： 这里通过 “长ID” attach 到了容器的启动命令终端，之后看到的是echo每隔一秒打印的信息。 可通过Ctrl+P然后Ctrl+Q组合键退出 attach 终端 docker exec通过docker exec进入相同的容器： 说明如下： -it以交互模式打开 pseudo-TTY，执行 bash，其结果就是打开了一个 bash 终端 进入到容器中，容器的 hostname 就是其 “短ID” 可以像在普通 Linux 中一样执行命令。ps -elf显示了容器启动进程while以及当前的bash进程 执行exit退出容器，回到 docker host docker exec -it &lt;container&gt; bash|sh是执行 exec 最常用的方式 attach VS exec主要区别如下： attach 直接进入容器启动命令的终端，不会启动新的进程 exec 则是在容器中打开新的终端，并且可以启动新的进程 如果想直接在终端中查看启动命令的输出，用 attach；其他情况则使用 exec。 当然，如果只是为了查看启动命令的输出，可以使用docker logs命令： -f作用与tail -f类似，能够持续打印输出。 4.1.3 运行容器的最佳实践容器按用途分类按用途容器大致可分为两类：服务类容器和工具类容器。 服务类容器以 daemon 的形式运行，对外提供服务。比如 web server，数据库等。通过-d以后台方式启动这类容器是非常合适的。如果要排查问题，可以通过exec -it进入容器。 工具类容器通常给能我们提供一个临时的工作环境，通常以run -it方式运行。执行exit退出终端，同时容器停止。 工具类容器多使用基础镜像，例如 busybox、debian、ubuntu 等。 容器运行小结容器运行的相关知识点： 当 CMD 或 Entrypoint 或docker run命令行指定的命令运行结束时，容器停止。 通过-d参数在后台启动容器。 通过exec -it可进入容器并执行命令。 指定容器的三种方法： 短ID（长ID 前 12 位） 长ID 容器名称。可通过--name为容器命名 容器按用途可分为两类： 服务类的容器 工具类的容器 4.2 容器常用操作4.2.1 stop/start/restart通过docker stop可以停止运行的容器。 容器在 docker host 中实际是一个进程。docker stop命令本质上是向该进程发送一个 SIGTERM 信号。如果想快速停止容器，可使用docker kill命令，其作用是向容器进程发送 SIGKILL 信号。 对于处于停止状态的容器，可以通过docker start重新启动。 docker start会保留容器的第一次启动时的所有参数。 docker restart可以重启容器，其作用就是依次执行docker stop和docker start。 容器可能会因某种错误而停止运行。对于服务类容器，我们通常希望在这种情况下容器能够自动重启。启动容器时设置--restart就可以达到这个效果： docker run -d --restart=always httpd --restart=always意味着无论容器因何种原因退出（包括正常退出），就立即重启。该参数的形式还可以是--restart=on-failure:3，意思是如果启动进程退出代码非 0，则重启容器，最多重启3次。 4.2.2 pause/unpause有时我们只是希望暂时让容器暂停工作一段时间，比如要对容器的文件系统打个快照，或者 docker host 需要使用 CPU，这时可以执行docker pause。 处于暂停状态的容器不会占用 CPU 资源，直到通过docker unpause恢复运行。 4.2.3 rm/rmi使用 docker 一段时间后，host 上可能会有大量已经退出了的容器。这些容器依然会占用 host 的文件系统资源，如果确认不会再重启此类容器，可以通过docker rm删除。 docker rm一次可指定多个容器。如果希望批量删除所有已经退出的容器，可以执行如下命令： docker rm -v $(docker ps -aq -f status=exited) docker rm是删除容器，而docker rmi则是删除镜像。 4.2.4 一张图搞懂容器所有操作 有两点需要补充： 1) 可以先创建容器，稍后再启动： &gt; docker create httpd &gt; docker start 989e12e4d8ea docker create创建的容器处于 Created 状态 docker start将以后台方式启动容器。docker run命令实际上是docker create和docker start命令的组合 2) 只有当容器的启动进程退出时，--restart才生效。 退出包括正常退出或者非正常退出。这里举了两个例子：启动进程正常退出或发生 OOM，此时 docker 会根据--restart的策略判断是否需要重启容器。但如果容器是因为执行docker stop或docker kill退出，则不会自动重启。 4.3 容器资源限制4.3.1 限制容器对内存的使用与操作系统类似，容器可使用的内存包括两部分：物理内存和 swap。Docker 通过下面两组参数来控制容器内存的使用量： -m或--memory：设置内存的使用限额，例如100M、2G --memory-swap：设置 内存+swap 的使用限额 例如执行如下命令： docker run -m 200M --memory-swap=300M ubuntu 其含义是允许该容器最多使用 200M 的内存和 100M 的 swap。默认情况下，上面两组参数为 -1，即对容器内存和 swap 的使用没有限制。 可使用progrium/stress镜像来实验一下，该镜像可用于对容器执行压力测试。执行如下命令： docker run -it -m 200M --memory-swap=300M progrium/stress --vm 1 --vm-bytes 280M 其中： --vm 1：启动 1 个内存工作线程 --vm-bytes 280M：每个线程分配 280M 内存 注意：如果在启动容器时只指定-m而不指定--memory-swap，那么--memory-swap默认为-m的两倍。 4.3.2 限制容器对 CPU 的使用没有限制默认设置下，所有容器可以平等地使用 host CPU 资源并且没有限制。 Docker 可以通过-c或--cpu-shares设置容器使用 CPU 的权重。如果不指定，默认值为 1024。 与内存限额不同，通过-c设置的 cpu share 并不是 CPU 资源的绝对数量，而是一个相对的权重值。某个容器最终能分配到的 CPU 资源取决于它的 cpu share 占所有容器 cpu share 总和的比例。 即：通过 cpu share 可以设置容器使用 CPU 的优先级。 例如在 host 中启动了两个容器： docker run --name &quot;container_A&quot; -c 1024 ubuntu docker run --name &quot;container_B&quot; -c 512 ubuntu container_A 的 cpu share 1024，是 container_B 的两倍。当两个容器都需要 CPU 资源时，container_A 可以得到的 CPU 是 container_B 的两倍。 这种按权重分配 CPU 只会发生在 CPU 资源紧张的情况下。如果 container_A 处于空闲状态，这时，为了充分利用 CPU 资源，container_B 也可以分配到全部可用的 CPU。 4.3.3 限制容器的 Block IOBlock IO 是另一种可以限制容器使用的资源。Block IO 指的是磁盘的读写，docker 可通过设置权重、限制 bps 和 iops 的方式控制容器读写磁盘的带宽。 目前 Block IO 限额只对 direct IO（不使用文件缓存）有效 block IO 权重默认情况下，所有容器能平等地读写磁盘，可以通过设置--blkio-weight参数来改变容器 block IO 的优先级。 --blkio-weight与--cpu-shares类似，设置的是相对权重值，默认为 500。在下面的例子中，container_A 读写磁盘的带宽是 container_B 的两倍： docker run -it --name container_A --blkio-weight 600 ubuntu docker run -it --name container_B --blkio-weight 300 ubuntu 限制 bps 和 iops bps：byte per second，每秒读写的数据量 iops：io per second，每秒 IO 的次数 可以通过以下参数控制容器的 bps 和 iops： --device-read-bps：限制读某个设备的 bps --device-write-bps：限制写某个设备的 bps --device-read-iops：限制读某个设备的 iops --device-write-iops：限制写某个设备的 iops 例如以下命令将限制容器写/dev/sda的速率为 30MB/s： docker run -it --device-write-bps /dev/sda:30MB ubuntu 4.4 实现容器的底层技术在容器的底层实现技术中，cgroup 和 namespace 是最重要的两种技术。cgroup 实现资源限额， namespace 实现资源隔离。 4.4.1 cgroupcgroup 全称 Control Group。Linux 操作系统通过 cgroup 可以设置进程使用 CPU、内存 和 IO 资源的限额。之前提到的--cpu-shares、-m、--device-write-bps实际上就是在配置 cgroup，可以在 host 的/sys/fs/cgroup中找到它。 例如，启动一个容器，设置--cpu-shares=512： 查看容器 ID： 在/sys/fs/cgroup/cpu/docker目录中，Linux 会为每个容器创建一个 cgroup 目录，以容器的长ID命名： 目录中包含所有与 cpu 相关的 cgroup 配置，文件cpu.shares保存的就是--cpu-shares的配置，值为 512。 同样的，/sys/fs/cgroup/memory/docker和/sys/fs/cgroup/blkio/docker中保存的是内存以及 Block IO 的 cgroup 配置。 4.4.2 namespaceLinux 实现容器间资源隔离的技术是 namespace。namespace 管理着 host 中全局唯一的资源，并可以让每个容器都觉得只有自己在使用它。 Linux 使用了六种 namespace，分别对应六种资源：Mount、UTS、IPC、PID、Network 和 User。 MountMount namespace 让容器看上去拥有整个文件系统。 容器有自己的/目录，可以执行 mount 和 umount 命令。当然这些操作只在当前容器中生效，不会影响到 host 和其他容器。 UTS简单的说，UTS namespace 让容器有自己的 hostname。 默认情况下，容器的 hostname 是它的短ID，可以通过-h或--hostname参数设置： IPCIPC namespace 让容器拥有自己的共享内存和信号量（semaphore）来实现进程间通信，而不会与 host 和其他容器的 IPC 混在一起。 PID容器在 host 中以进程的形式运行。例如当前 host 中运行了两个容器： 通过ps axf可以查看容器进程： 所有容器的进程都挂在 dockerd 进程下，同时也可以看到容器自己的子进程。 如果我们进入到某个容器，ps就只能看到自己的进程了： 而且进程的 PID 不同于 host 中对应进程的 PID，容器中 PID=1 的进程当然也不是 host 的 init 进程。也就是说：容器拥有自己独立的一套 PID，这就是 PID namespace 提供的功能。 NetworkNetwork namespace 让容器拥有自己独立的网卡、IP、路由等资源。 UserUser namespace 让容器能够管理自己的用户，host 不能看到容器中创建的用户。 4.5 容器小结下面是容器的常用操作命令： create：创建容器 run：运行容器 pause：暂停容器 unpause：取消暂停继续运行容器 stop：发送 SIGTERM 停止容器 kill：发送 SIGKILL 快速停止容器 start：启动容器 restart：重启重启 attach：attach 到容器启动进程的终端 exec：在容器中启动新进程，通常使用-it参数 logs：显示容器启动进程的控制台输出，使用-f参数持续打印 rm：从磁盘中删除容器 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Linux 内核笔记 1：绪论影响力数学之美：不能再凑了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"}]},{"title":"终端窗口多开神器 Tmux","slug":"tmux-quick-start","date":"2019-02-12T16:43:38.000Z","updated":"2019-11-19T15:14:27.069Z","comments":true,"path":"2019/02/13/tmux-quick-start/","link":"","permalink":"https://abelsu7.top/2019/02/13/tmux-quick-start/","excerpt":"tmux 相关文章收集，待更新…","text":"tmux 相关文章收集，待更新… Ctrl-b+z：最大化当前面板 Ctrl-b+[：进入滚屏模式，按q退出 Ctrl-b+o：下一个面板 Ctrl-b+Ctrl-o：旋转所有面板 :resize-pane -R 20 参考文章 tmux | Github Getting started with Tmux | Linuxize 终端利器-tmux | 枯木 Tmux 快速教程 | Jeswang’s Blog tmux 指南 | 小土刀 A Gentle Introduction to tmux | Hacker Noon Tmux 使用手册 | 路易斯 十分钟学会 tmux | 猫哥_kaiye - 编程笔记 tmux 快捷键调整窗口大小 | 刘朝圳 4 款很酷的终端复用器 | Linux 中国 tmux 2.9 配置变更 | Xuanwo’s Blog Tmux 使用教程 | 阮一峰的网络日志 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"},{"name":"tmux","slug":"tmux","permalink":"https://abelsu7.top/tags/tmux/"}]},{"title":"CentOS 7 安装 glances","slug":"glances-monitor-on-linux","date":"2019-02-12T16:26:29.000Z","updated":"2019-09-01T13:04:11.240Z","comments":true,"path":"2019/02/13/glances-monitor-on-linux/","link":"","permalink":"https://abelsu7.top/2019/02/13/glances-monitor-on-linux/","excerpt":"Glances 相关文章收集","text":"Glances 相关文章收集 yum 安装 pipsudo yum install epel-release sudo yum install python-pip sudo yum clean all 升级 pippip install --upgrade pip pip 安装 glancespip install glances 运行 glancesglances Glances 官网 Glances 官方文档 如何在 Ubuntu 上使用 Glances 监控系统 | Linux 中国 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFS本周文章汇总解决 CentOS 7 tracker CPU 占用率 100%CentOS 7 安装配置 VNC在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"Glances","slug":"Glances","permalink":"https://abelsu7.top/tags/Glances/"},{"name":"监控工具","slug":"监控工具","permalink":"https://abelsu7.top/tags/监控工具/"}]},{"title":"Java 笔记 4：接口、lambda 表达式与内部类","slug":"core-java-notes-4","date":"2019-02-10T13:49:07.000Z","updated":"2019-09-01T13:04:11.088Z","comments":true,"path":"2019/02/10/core-java-notes-4/","link":"","permalink":"https://abelsu7.top/2019/02/10/core-java-notes-4/","excerpt":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》","text":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》 未完待续~ 接口、lambda 表达式与内部类1. 接口1.1 接口概念接口（interface）技术主要用来描述类具有什么功能，而并不给出每个功能的具体实现。 一个类可以实现（implement）一个或多个接口，并在需要接口的地方，随时使用实现了相应接口的对象。 在 Java 程序设计语言中，接口不是类，而是对类的一组需求描述，这些类要遵从接口描述的统一格式进行定义。 public interface Comparable { int compareTo(Object other); } 接口中的所有方法都会自动的属于 public。因此，在接口中声明方法时，不必提供关键字 public。 除此之外，有些接口可能包含多个方法。在接口中还可以定义常量。然而，接口绝不能包含有实例域。 要将类声明为实现某个接口，需要使用关键字 implements： class Employee implements Comparable 1.2 接口的特性接口不是类，尤其不能使用 new 运算符实例化一个接口： x = new Comparable(...); // ERROR 然而，尽管不能构造接口的对象，却能声明接口的变量： Comparable x; // OK 接口变量必须引用实现了接口的类对象： x = new Employee(...); // OK provided Employee implements Comparable 类似的，可以使用instanceof检查一个对象是否实现了某个特定的接口： if (anObject instanceof Comparable) {...} 与建立类的继承关系一样，接口也可以被扩展。 与接口中的方法都自动的被设置为 public 一样，接口中的域将被自动设为 public static final。 1.3 接口与抽象类使用抽象类表示通用属性存在这样一个问题：每个类只能扩展于一个类；但每个类可以实现多个接口。 Java 的设计者选择了不支持多继承（multiple inheritance），其主要原因是多继承会让语言本身变得非常复杂，效率也会降低。 事实上，接口可以提供多重继承的大多数好处，同时还能避免多重继承的复杂性和低效性。 1.4 静态方法在 Java SE 8中，允许在接口中增加静态方法。目前为止，通常的做法都是将静态方法放在伴随类中。在标准库中，你会看到成对出现的接口和实用工具类，如Collection/Collections或Path/Paths。 1.5 默认方法可以为接口方法提供一个默认实现，必须用 default 修饰符标记： public interface Comparable&lt;T&gt; { default int compareTo(T other) { return 0; } // By default, all elements are the same } 1.6 解决默认方法冲突如果先在一个接口中将一个方法定义为默认方法，然后又在超类或另一个接口中定义了同样的方法，就会发生冲突。Java 解决默认方法冲突有以下两个规则： 超类优先：如果超类提供了一个具体方法，同名而且有相同参数类型的默认方法会被忽略 接口冲突：如果一个超接口提供了一个默认方法，另一个接口提供了一个同名而且参数类型相同的方法，必须覆盖这个方法来解决冲突 2. 接口示例2.1 接口与回调回调（callback）是一种常见的程序设计模式。在回调中，可以指出某个特定时间发生时应该采取的动作。 例如，java.swing包中有一个 Timer 定时器类，它需要知道调用哪一个方法，并要求传递的对象所属的类实现了java.awt.event包的 ActionListener 接口： package timer; /** @version 1.01 2015-05-12 @author Cay Horstmann */ import java.awt.*; import java.awt.event.*; import java.util.*; import javax.swing.*; import javax.swing.Timer; // to resolve conflict with java.util.Timer public class TimerTest { public static void main(String[] args) { ActionListener listener = new TimePrinter(); // construct a timer that calls the listener // once every 10 seconds Timer t = new Timer(10000, listener); t.start(); JOptionPane.showMessageDialog(null, &quot;Quit program?&quot;); System.exit(0); } } class TimePrinter implements ActionListener { public void actionPerformed(ActionEvent event) { System.out.println(&quot;At the tone, the time is &quot; + new Date()); Toolkit.getDefaultToolkit().beep(); } } 2.2 Comparator 接口假设我们希望按长度递增的顺序对字符串进行排序，Arrays.sort方法还有第二个版本，有一个数组和一个比较器（comparator）作为参数，比较器是实现了 Comparator 接口的类的实例： public interface Comparator&lt;T&gt; { int compare(T first, T second); } 要按长度比较字符串，可以如下定义一个实现 Comparator 的类： class LengthComparator implements Comparator&lt;String&gt; { public int compare(String first, String second) { return first.length() - second.length(); } } 具体完成比较时，需要建立一个实例： Comparator&lt;String&gt; comp = new LengthComparator(); if (comp.compare(words[i], words[j]) &gt; 0) ... 2.3 对象克隆 略 3. lambda 表达式 略 4. 内部类🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序后端开发 - Java开发环境配置 - 入门篇影响力","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"Java 笔记 3：继承、泛型与反射","slug":"core-java-notes-3","date":"2019-02-05T17:51:15.000Z","updated":"2019-09-01T13:04:11.085Z","comments":true,"path":"2019/02/06/core-java-notes-3/","link":"","permalink":"https://abelsu7.top/2019/02/06/core-java-notes-3/","excerpt":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》","text":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》 继承、泛型与反射1. 类、超类和子类1.1 定义子类关键字 extends 表示继承： public class Manager extends Employee { .... } 在 Java 中，所有的继承都是公有继承，而没有 C++ 中的私有继承和保护继承。 关键字 extends 表明正在构造的新类派生于一个已存在的类。已存在的类称为超类（superclass）、基类（base class）或父类（parent class），新类称为子类（subclass）、派生类（derived class）或孩子类（child class）。 子类比超类封装了更多的数据，拥有更多的功能。 1.2 覆盖方法可以在子类中提供一个新的方法来覆盖（override）超类中的同名方法： public double getSalary() { double baseSalary = super.getSalary(); return baseSalary + bonus; } super 不是一个对象的引用，不能将 super 赋给另一个对象变量，它只是一个指示编译器调用超类方法的特殊关键字。 1.3 子类构造器public Manager(String name, double salary, int year, int month, int day) { super(name, salary, year, month, day); bonus = 0; } 如果子类的构造器没有显式地调用超类的构造器， 则将自动地调用超类默认（没有参数) 的构造器。 如果超类没有不带参数的构造器， 并且在子类的构造器中又没有显式地调用超类的其他构造器，则 Java 编译器将报错。 1.4 继承层次继承并不仅限于一个层次，由一个公共超类派生出来的所有类的集合被称为继承层次（inheritance hierarchy）。在继承层次中，从某个特定类到其祖先的路径被称为该类的继承链（inheritance chain）。 一个祖先类可以拥有多个子孙继承链。另外，Java 不支持多继承。 1.5 多态在 Java 中，is-a 规则表明子类的每个对象也是超类的对象。它的另一种表述法是置换法则，即程序中出现超类对象的任何地方都可以用子类对象置换。 1.6 理解方法调用 略 1.7 阻止继承：final 类和方法有时候，可能希望阻止人们利用某个类定义子类。不允许扩展的类被称为 final 类。 public final class Executive extends Manager { ... } 类中的特定方法也可以被声明为 final，这样一来子类就不能覆盖这个方法。 final 类中的所有方法自动成为 final 方法。 public class Employee { public final String getName() { return name; } } 将方法或类声明为 final 的主要目的是：确保它们不会在子类中改变语义。 1.8 强制类型转换对象引用的转换语法与数值表达式的类型转换类似： Manager boss = (Manager) staff[0]; 需要注意的是： 只能在继承层次内进1行类型转换 再将超类转换成子类之前，应该使用instanceof进行检查 1.9 抽象类使用 abstract 关键字修饰类中的抽象方法： // no implementation required public abstract String getDescription(); 为了提高程序的清晰度，包含一个或多个抽象方法的类本身必须被声明为抽象的： public abstract class Person { ... public abstract String getDescription(); } 除了抽象方法之外，抽象类还可以包含具体数据和具体方法。 抽象方法充当着占位的角色，它们的具体实现在子类中 类即使不包含抽象方法，也可以将类声明为抽象类 抽象类不能被实例化 1.10 控制可见性的访问修饰符在有些时候，人们希望超类中的某些方法允许被子类访问，或允许子类的方法访问超类的某个域。为此，需要将这些方法或域声明为 protected。 下面归纳一下 Java 用于控制可见性的 4 个访问修饰符： 仅对本类可见：private 对所有类可见：public 对本包和所有子类可见：protected 对本包可见：默认，不需要修饰符 2. Object：所有类的超类Object 类是 Java 中所有类的始祖，在 Java 中每个类都是由它扩展而来的： 在 Java 中，只有基本类型（primitive types）不是对象，例如数值、字符和布尔类型的值。而所有的数组类型都扩展了 Object 类 可以使用 Object 类型的变量引用任何类型的对象： Object obj = new Employee(&quot;Abel Su&quot;, 35000); 当然，Object 类型的变量只能用于作为各种值的通用持有者。要想对其中的内容进行具体的操作，还需要清楚对象的原始数据类型，并进行相应的类型转换： Employee e = (Employee) obj; 2.1 equals 方法Object 类中的equals方法用于检测一个对象是否等于另外一个对象。在 Object 类中，这个方法将判断两个对象是否具有相同的引用。 在子类中定义equals方法时，首先调用超类的equals。如果检测失败，对象就不可能相等。如果超类中的域都相等，就需要比较子类中的实例域。 2.2 相等测试与继承// java.util.Arrays // 如果两个数组长度相同，并且在对应的位置上数据元素也均相同，则返回 true static boolean equals(type[] a, type[] b) // java.util.Objects // 如果 a 和 b 都为 null，返回 true；如果只有其中之一为 null，则返回 false；否则返回 a.equals(b) static boolean equals(Object a, Object b) 2.3 hashCode 方法散列码（hash code）是由对象导出的一个整型值。散列码是没有规律的，如果 x 和 y 是两个不同的对象，那么x.hashCode()和y.hashCode()基本上不会相同。 字符串的散列码是由内容导出的 由于 hashCode 方法定义在 Object 类中，因此每个对象都有一个默认的散列码，其值为对象的存储地址。 2.4 toString 方法在 Object 中还有一个重要的方法，就是toString方法，它用于返回表示对象值的字符串。例如 Point 类的toString方法将返回下面的字符串： java.awt.Point[x=10,y=20] 绝大多数（但不是全部）的 toString 方法都遵循这样的格式：类的名字，随后是一对方括号括起来的赋值。最好通过getClass().getName()获得类名的字符串。 随处可见 toString 方法的主要原因是：只要对象与一个字符串通过操作符+连接起来，Java 编译器就会自动的调用 toString 方法，以便获得这个对象的字符串描述。 3. 泛型数组列表ArrayList 是一个采用类型参数（type parameter）的泛型类（generic class）： ArrayList&lt;Employee&gt; staff = new ArrayList&lt;Employee&gt;(); 在 Java SE 7 中，可以省去右边的类型参数： ArrayList&lt;Employee&gt; staff = new ArrayList&lt;&gt;(); 使用 add 方法可以将元素添加到数组列表中： staff.add(new Employee(&quot;Abel Su&quot;, ...)); staff.add(new Employee(&quot;Harry Potter&quot;, ...)); 数组列表管理着对象引用的一个内部数组。最终，数组的全部空间有可能被用尽。如果调用 add 且内部数组已经满了，数组列表就将自动的创建一个更大的数组，并将所有的对象从较小的数组中拷贝到较大的数组中。 如果已经清楚或能够估计出数组可能存储的元素数量，就可以在填充数组之前调用ensureCapacity方法： staff.ensureCapacity(100); 这个方法调用将分配一个包含 100 个对象的内部数组。然后调用 100 次 add, 而不用重新分配空间。 另外，还可以把初始容量传递给 ArrayList 构造器： ArrayList&lt;Employee&gt; staff = new ArrayList&lt;&gt;(100); size方法将返回数组列表中包含的实际元素数目。 一旦能够确认数组列表的大小不再发生变化，就可以调用trimToSize方法，该方法会将存储区域的大小调整为当前元素数量所需要的存储空间数目，垃圾回收器（GC）将回收多余的存储空间。 3.1 访问数组列表元素使用get和set方法实现访问或改变数组元素的操作，而不能使用类似数组中的[]语法格式。 void set(int index, E obj) E get(int index) void add(int index, E obj) E remove(int index) // 删除一个元素，并将后面的元素向前移动。被删除的元素由返回值返回。 3.2 类型化与原始数组列表的兼容性假设有下面这个遗留下来的类： public class EmployeeDB { public void update(ArrayList list) { ... } public ArrayList find(String query) { ... } } 可以将一个类型化的数组列表传递给 update 方法，而并不需要进行任何类型转换。 4. 对象包装器与自动装箱有时，需要将 int 这样的基本类型转换为对象。所有的基本类型都有一个与之对应的类，这些类称为包装器（wrapper）。这些对象包装器类拥有很明显的名字：Integer、Long、Float、Double、Short、Byte、Character、Void 和 Boolean（前 6 个类派生于公共的超类 Number）。 对象包装器类是不可变的，即一旦构造了包装器，就不允许更改包装在其中的值 对象包装器是 final 的，因此不能定义它们的子类 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); 由于每个值分别包装在对象中，所以 ArrayList 的效率远远低于 int[] 数组。因此，应该用它构造小型集合，此时程序员操作的方便性要比执行效率更加重要。 有一个很有用的特性，从而便于添加 int 类型的元素到 ArrayList 中，调用list.add(3)将自动变换成： list.add(Integer.valueOf(3)); 这种变换被称为自动装箱（autoboxing）。 相反的，当将一个 Integer 对象赋给一个 int 值时，将会自动拆箱，编译器会将int n = list.get(i)翻译成： int n = list.get(i).intValue(); 装箱和拆箱是编译器认可的，而不是虚拟机。编译器在生成类的字节码时， 插人必要的方法调用。虚拟机只是执行这些字节码。 5. 参数数量可变的方法用户也可以自己定义可变参数的方法，并将参数指定为任意类型， 甚至是基本类型： public static double max(double... values) { double largest = Double.NEGATIVE_INFINITY; for (double v : values) { if (v &gt; largest) { largest = v; } } return largest; } 然后就可以调用该方法： double m = max(3.1, 40.4, -5); 编译器会将new double[]{3.1, 40.4, -5}传递给max方法。 6. 枚举类public enum Size { SMALL, MEDIUM, LARGE, EXTRA_LARGE }; ... String s_small = Size.SMALL.toString(); Size s = Enum.valueOf(Size.class, &quot;SMALL&quot;); Size[] values = Size.values(); int pos = Size.MEDIUM.ordinal(); // 返回枚举常量的位置 7. 反射能够分析类能力的程序称为反射（reflective）。反射机制的功能十分强大，可以用来： 在运行时分析类的能力 在运行时查看对象 实现通用的数组操作代码 利用 Method 对象，这个对象类似于 C++ 中的函数指针 7.1 Class 类在程序运行期间，Java 运行时系统始终为所有的对象维护一个被称为运行时的类型标识。 这个信息跟踪着每个对象所属的类。虚拟机利用运行时类型信息选择相应的方法执行。 Object 类中的getClass()方法将会返回一个 Class 类型的实例： Employee e; ... Class cl = e.getClass(); 最常用的 Class 方法是getName()，这个方法将返回类的名字： System.out.println(e.getClass().getName() + &quot; &quot; + e.getName()); ------- Employee Harry Hacker 如果类在一个包中，包的名字也会作为类名的一部分，如java.util.Random 还可以调用静态方法forName(className)获得类名对应的 Class 对象： String className = &quot;java.util.Random&quot;; Class cl = Class.forName(className); 获得 Class 类对象的第三种方法非常简单：如果 T 是任意的 Java 类型（或 void 关键字)，T.class将代表匹配的类的对象： Class cl1 = Random.class; // if you import java.util.*; Class cl2 = int.class; Class cl3 = Double[].class; 虚拟机为每个类型管理一个 Class 对象。因此，可以利用==运算符实现两个类对象比较的操作： if (e.getClass() == Employee.class) ... 另一个很有用的方法newInstance()可以用来动态的创建一个类的实例： String s = &quot;java.util.Random&quot;; Object m = Class.forName(s).newInstance(); 7.2 捕获异常try { String name = ...; // get class name Class cl = Class.forName(name); // might throw exception do something with cl } catch (Exception e) { e.printStackTrace(); } 7.3 利用反射分析类的能力反射机制最重要的内容——检查类的结构。 package reflection; import java.util.*; import java.lang.reflect.*; /** * This program uses reflection to print all features of a class. * @version 1.1 2004-02-21 * @author Cay Horstmann */ public class ReflectionTest { public static void main(String[] args) { // read class name from command line args or user input String name; if (args.length &gt; 0) name = args[0]; else { Scanner in = new Scanner(System.in); System.out.println(&quot;Enter class name (e.g. java.util.Date): &quot;); name = in.next(); } try { // print class name and superclass name (if != Object) Class cl = Class.forName(name); Class supercl = cl.getSuperclass(); String modifiers = Modifier.toString(cl.getModifiers()); if (modifiers.length() &gt; 0) System.out.print(modifiers + &quot; &quot;); System.out.print(&quot;class &quot; + name); if (supercl != null &amp;&amp; supercl != Object.class) System.out.print(&quot; extends &quot; + supercl.getName()); System.out.print(&quot;\\n{\\n&quot;); printConstructors(cl); System.out.println(); printMethods(cl); System.out.println(); printFields(cl); System.out.println(&quot;}&quot;); } catch (ClassNotFoundException e) { e.printStackTrace(); } System.exit(0); } /** * Prints all constructors of a class * @param cl a class */ public static void printConstructors(Class cl) { Constructor[] constructors = cl.getDeclaredConstructors(); for (Constructor c : constructors) { String name = c.getName(); System.out.print(&quot; &quot;); String modifiers = Modifier.toString(c.getModifiers()); if (modifiers.length() &gt; 0) System.out.print(modifiers + &quot; &quot;); System.out.print(name + &quot;(&quot;); // print parameter types Class[] paramTypes = c.getParameterTypes(); for (int j = 0; j &lt; paramTypes.length; j++) { if (j &gt; 0) System.out.print(&quot;, &quot;); System.out.print(paramTypes[j].getName()); } System.out.println(&quot;);&quot;); } } /** * Prints all methods of a class * @param cl a class */ public static void printMethods(Class cl) { Method[] methods = cl.getDeclaredMethods(); for (Method m : methods) { Class retType = m.getReturnType(); String name = m.getName(); System.out.print(&quot; &quot;); // print modifiers, return type and method name String modifiers = Modifier.toString(m.getModifiers()); if (modifiers.length() &gt; 0) System.out.print(modifiers + &quot; &quot;); System.out.print(retType.getName() + &quot; &quot; + name + &quot;(&quot;); // print parameter types Class[] paramTypes = m.getParameterTypes(); for (int j = 0; j &lt; paramTypes.length; j++) { if (j &gt; 0) System.out.print(&quot;, &quot;); System.out.print(paramTypes[j].getName()); } System.out.println(&quot;);&quot;); } } /** * Prints all fields of a class * @param cl a class */ public static void printFields(Class cl) { Field[] fields = cl.getDeclaredFields(); for (Field f : fields) { Class type = f.getType(); String name = f.getName(); System.out.print(&quot; &quot;); String modifiers = Modifier.toString(f.getModifiers()); if (modifiers.length() &gt; 0) System.out.print(modifiers + &quot; &quot;); System.out.println(type.getName() + &quot; &quot; + name + &quot;;&quot;); } } } 7.4 在运行时使用反射分析对象ObjectAnalyzer.java： package objectAnalyzer; import java.lang.reflect.AccessibleObject; import java.lang.reflect.Array; import java.lang.reflect.Field; import java.lang.reflect.Modifier; import java.util.ArrayList; public class ObjectAnalyzer { private ArrayList&lt;Object&gt; visited = new ArrayList&lt;&gt;(); /** * Converts an object to a string representation that lists all fields. * @param obj an object * @return a string with the object&#39;s class name and all field names and * values */ public String toString(Object obj) { if (obj == null) return &quot;null&quot;; if (visited.contains(obj)) return &quot;...&quot;; visited.add(obj); Class cl = obj.getClass(); if (cl == String.class) return (String) obj; if (cl.isArray()) { String r = cl.getComponentType() + &quot;[]{&quot;; for (int i = 0; i &lt; Array.getLength(obj); i++) { if (i &gt; 0) r += &quot;,&quot;; Object val = Array.get(obj, i); if (cl.getComponentType().isPrimitive()) r += val; else r += toString(val); } return r + &quot;}&quot;; } String r = cl.getName(); // inspect the fields of this class and all superclasses do { r += &quot;[&quot;; Field[] fields = cl.getDeclaredFields(); AccessibleObject.setAccessible(fields, true); // get the names and values of all fields for (Field f : fields) { if (!Modifier.isStatic(f.getModifiers())) { if (!r.endsWith(&quot;[&quot;)) r += &quot;,&quot;; r += f.getName() + &quot;=&quot;; try { Class t = f.getType(); Object val = f.get(obj); if (t.isPrimitive()) r += val; else r += toString(val); } catch (Exception e) { e.printStackTrace(); } } } r += &quot;]&quot;; cl = cl.getSuperclass(); } while (cl != null); return r; } } ObjectAnalyzerTest.java： package objectAnalyzer; import java.util.ArrayList; /** * This program uses reflection to spy on objects. * @version 1.12 2012-01-26 * @author Cay Horstmann */ public class ObjectAnalyzerTest { public static void main(String[] args) { ArrayList&lt;Integer&gt; squares = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;= 5; i++) squares.add(i * i); System.out.println(new ObjectAnalyzer().toString(squares)); } } 7.5 使用反射编写泛型数组代码package arrays; import java.lang.reflect.*; import java.util.*; /** * This program demonstrates the use of reflection for manipulating arrays. * @version 1.2 2012-05-04 * @author Cay Horstmann */ public class CopyOfTest { public static void main(String[] args) { int[] a = { 1, 2, 3 }; a = (int[]) goodCopyOf(a, 10); System.out.println(Arrays.toString(a)); String[] b = { &quot;Tom&quot;, &quot;Dick&quot;, &quot;Harry&quot; }; b = (String[]) goodCopyOf(b, 10); System.out.println(Arrays.toString(b)); System.out.println(&quot;The following call will generate an exception.&quot;); b = (String[]) badCopyOf(b, 10); } /** * This method attempts to grow an array by allocating a new array and copying all elements. * @param a the array to grow * @param newLength the new length * @return a larger array that contains all elements of a. However, the returned array has * type Object[], not the same type as a */ public static Object[] badCopyOf(Object[] a, int newLength) // not useful { Object[] newArray = new Object[newLength]; System.arraycopy(a, 0, newArray, 0, Math.min(a.length, newLength)); return newArray; } /** * This method grows an array by allocating a new array of the same type and * copying all elements. * @param a the array to grow. This can be an object array or a primitive * type array * @return a larger array that contains all elements of a. */ public static Object goodCopyOf(Object a, int newLength) { Class cl = a.getClass(); if (!cl.isArray()) return null; Class componentType = cl.getComponentType(); int length = Array.getLength(a); Object newArray = Array.newInstance(componentType, newLength); System.arraycopy(a, 0, newArray, 0, Math.min(length, newLength)); return newArray; } } 7.6 调用任意方法java.lang.reflect.Method： public Object invoke(Object implicitParameter, Object[] explicitParameters) // 调用这个对象所描述的方法，传递给定参数，并返回方法的返回值 // 对于静态方法，把 null 作为隐式参数传递 MethodTableTest.java： package methods; import java.lang.reflect.*; /** * This program shows how to invoke methods through reflection. * @version 1.2 2012-05-04 * @author Cay Horstmann */ public class MethodTableTest { public static void main(String[] args) throws Exception { // get method pointers to the square and sqrt methods Method square = MethodTableTest.class.getMethod(&quot;square&quot;, double.class); Method sqrt = Math.class.getMethod(&quot;sqrt&quot;, double.class); // print tables of x- and y-values printTable(1, 10, 10, square); printTable(1, 10, 10, sqrt); } /** * Returns the square of a number * @param x a number * @return x squared */ public static double square(double x) { return x * x; } /** * Prints a table with x- and y-values for a method * @param from the lower bound for the x-values * @param to the upper bound for the x-values * @param n the number of rows in the table * @param f a method with a double parameter and double return value */ public static void printTable(double from, double to, int n, Method f) { // print out the method as table header System.out.println(f); double dx = (to - from) / (n - 1); for (double x = from; x &lt;= to; x += dx) { try { double y = (Double) f.invoke(null, x); System.out.printf(&quot;%10.4f | %10.4f%n&quot;, x, y); } catch (Exception e) { e.printStackTrace(); } } } } 8. 继承的技巧 将公共操作和域放在超类 不要使用受保护的域 使用继承实现 “is-a” 关系 除非所有继承方法都有意义，否则不要使用继承 在覆盖方法时，不要改变预期的行为 使用多态，而非类型信息 不要过多的使用反射 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序后端开发 - Java开发环境配置 - 入门篇影响力","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"Java 笔记 2：对象与类","slug":"core-java-notes-2","date":"2019-01-18T07:24:47.000Z","updated":"2019-09-01T13:04:11.081Z","comments":true,"path":"2019/01/18/core-java-notes-2/","link":"","permalink":"https://abelsu7.top/2019/01/18/core-java-notes-2/","excerpt":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》","text":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》 对象与类1. 面向对象程序设计（OOP）概述面向对象程序设计（OOP）是当今主流的程序设计范型，它已经取代了 20 世纪 70 年代的「结构化」过程化程序设计开发技术。Java 是完全面向对象的。 1.1 类类 类（class）是构造对象的模板或蓝图，由类构造（construct）对象的过程称为创建类的实例（instance）。 封装 封装（encapsulation，有时称为数据隐藏）是与对象有关的一个重要概念，它将数据和行为组合在一个包中，并对对象的使用者隐藏了数据的实现方式。 对象中的数据称为实例域（instance field），操纵数据的过程称为方法（method）。对于每个特定的类实例（对象）都有一组特定的实例域值，这些值的集合就是这个对象的当前状态（state）。 实现封装的关键在于绝对不能让类中的方法直接访问其他类的实例域。程序仅通过对象的方法与对象数据进行交互。 继承 可以通过扩展一个类来建立另外一个新的类，在扩展一个已有的类时，扩展后的新类具有所扩展的类的全部属性和方法，这个过程称为继承（inheritance）。 在 Java 中，所有的类都源自于超类 Object。 1.2 对象对象的三个主要特性： 对象的行为（behavior）：可以对对象施加哪些方法 对象的状态（state）：当施加方法时，对象如何响应 对象的标识（identity）：如果辨别具有相同行为与状态的不同对象 1.3 识别类识别类的简单规则是在分析问题的过程中寻找名词，而方法对应着动词。 1.4 类之间的关系在类之间，最常见的关系有： 依赖（uses-a）：应该尽可能的将相互依赖的类减至最少，即让类之间的耦合度最小 聚合（has-a）：聚合关系意味着类 A 的对象包含类 B 的对象 继承（is-a）：用于表示特殊与一般之间的关系 表达类关系的 UML 符号 2. 使用预定义类2.1 对象与对象变量要想使用对象，首先要构造对象，并指定其初始状态，然后对对象应用方法。 使用对象变量之前必须首先初始化。可以用新构造的对象初始化这个变量： Date deadline = new Date(); 也可以让这个变量引用一个已经存在的对象： Date birthday = new Date(); Date deadline = birthday; 现在，这两个变量将引用同一个对象： 引用同一个对象的对象变量 注意：一个对象变量并没有实际包含一个对象，而仅仅引用一个对象！ 在 Java 中，任何对象变量的值都是对存储在另外一个地方的一个对象的引用。new 操作符的返回值也是一个引用。 可以显示的将对象变量设置为 null，表明这个对象变量目前没有引用任何对象： deadline = null; ... if (deadline != null) { System.out.println(deadline); } 局部变量不会自动的初始化为 null，而必须通过调用 new 或将它们设置为 null 进行初始化。 为了易于理解，可以将 Java 的对象变量看作 C++ 的对象指针。例如： int id; // Java 实际上，等同于： int* id; // C++ 在 Java 中的 null 引用对应 C++ 中的 NULL 指针。如果把一个变量的值赋给另一个变量，两个变量就指向同一个日期，即它们是同一个对象的指针。 所有的 Java 对象都存储在堆中。当一个对象包含另一个对象变量时，这个变量依然包含着指向另一个堆对象的指针。另外，在 Java 中，必须使用 clone 方法获得对象的完整拷贝。 2.2 Java 类库中的 LocalDate 对象Java 标准类库中的 Date 类的实例有一个状态，即特定的时间点。时间使用距离一个固定时间点的毫秒数（可正可负）来表示，这个点就是所谓的纪元（epoch）。它是 UTC 时间1970 年 1 月 1 日 00:00:00。 UTC 是 Coordinated Universal Time 的缩写，与 GMT（Greenwich Mean Time，格林威治时间）一样，是一种具有实践意义的科学标准时间。 Java 的类库设计者决定将保存时间与给时间点命名分开，所以标准 Java 类库分别包含了两个类：一个是用来表示时间点的 Date 类，另一个是用来表示日历表示法的 LocalDate 类。 LocalDate now = LocalDate.now(); LocalDate newYearsEve = LocalDate.of(1999, 12, 31); int year = newYearsEve.getYear(); // 1999 int month = newYearsEve.getMonth(); // 12 int day = newYearsEve.getDay(); // 31 新日期对象也可以通过计算获得： LocalDate aThousandDaysLater = newYearsEve.plusDays(1000); year = aThousandDaysLater.getYear(); // 2002 month = aThousandDaysLater.getMonth(); // 09 day = aThousandDaysLater.getDay(); // 26 2.3 更改器与访问器方法更改对象状态的方法称为更改器方法（mutator method），只访问对象而不修改对象的方法称为访问器方法（accessor method）。 import java.time.*; /** * @author Cay Horstmann * @version 1.5 2015-05-08 */ public class CalendarTest { public static void main(String[] args) { LocalDate date = LocalDate.now(); int month = date.getMonthValue(); int today = date.getDayOfMonth(); date = date.minusDays(today - 1); // Set to start of month DayOfWeek weekday = date.getDayOfWeek(); int value = weekday.getValue(); // 1 = Monday, ... 7 = Sunday System.out.println(&quot;Mon Tue Wed Thu Fri Sat Sun&quot;); for (int i = 1; i &lt; value; i++) System.out.print(&quot; &quot;); while (date.getMonthValue() == month) { System.out.printf(&quot;%3d&quot;, date.getDayOfMonth()); if (date.getDayOfMonth() == today) System.out.print(&quot;*&quot;); else System.out.print(&quot; &quot;); date = date.plusDays(1); if (date.getDayOfWeek().getValue() == 1) System.out.println(); } if (date.getDayOfWeek().getValue() != 1) System.out.println(); } } ------ Mon Tue Wed Thu Fri Sat Sun 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18* 19 20 21 22 23 24 25 26 27 28 29 30 31 3. 用户自定义类要想创建一个完整的 Java 程序，应该将若干类组合在一起，其中只有一个类有main方法。 3.1 Employee 类import java.time.*; /** * This program tests the Employee class. * * @author Cay Horstmann * @version 1.12 2015-05-08 */ public class EmployeeTest { public static void main(String[] args) { // fill the staff array with three Employee objects Employee[] staff = new Employee[3]; staff[0] = new Employee(&quot;Carl Cracker&quot;, 75000, 1987, 12, 15); staff[1] = new Employee(&quot;Harry Hacker&quot;, 50000, 1989, 10, 1); staff[2] = new Employee(&quot;Tony Tester&quot;, 40000, 1990, 3, 15); // raise everyone&#39;s salary by 5% for (Employee e : staff) e.raiseSalary(5); // print out information about all Employee objects for (Employee e : staff) System.out.println(&quot;name=&quot; + e.getName() + &quot;,salary=&quot; + e.getSalary() + &quot;,hireDay=&quot; + e.getHireDay()); } } class Employee { private String name; private double salary; private LocalDate hireDay; public Employee(String n, double s, int year, int month, int day) { name = n; salary = s; hireDay = LocalDate.of(year, month, day); } public String getName() { return name; } public double getSalary() { return salary; } public LocalDate getHireDay() { return hireDay; } public void raiseSalary(double byPercent) { double raise = salary * byPercent / 100; salary += raise; } } ------ name=Carl Cracker,salary=78750.0,hireDay=1987-12-15 name=Harry Hacker,salary=52500.0,hireDay=1989-10-01 name=Tony Tester,salary=42000.0,hireDay=1990-03-15 3.2 多个源文件的使用在上面的示例中，一个源文件包含了两个类。许多程序员习惯于将每一个类存在一个单独的源文件中。例如，将 Employee 类存放在文件Employee.java中， 将 EmployeeTest 类存放在文件EmployeeTest.java中。 这种情况就有两种编译源程序的方法： &gt; javac Employee*.java # or &gt; javac EmployeeTest.java 虽然第二种方法并没有显式的编译Employee.java，但当 Java 编译器发现EmployeeTest.java使用了 Employee 类时会查找名为Employee.class的文件。如果没有找到，就会自动搜索Employee.java，然后对它进行编译。更重要的是，如果Employee.java版本较已有的Employee.class文件版本新，Java 编译器就会自动的重新编译这个文件。 3.3 剖析 Employee 类Employee 类包含 1 个构造器、4 个方法以及 3 个实例域： // 构造器 public Employee(String n, double s, int year, int month, int day) // 方法 public String getName() public double getSalary() public LocalDate getHireDay() public void raiseSalary(double byPercent) // 实例域 private String name; private double salary; private LocalDate hireDay; 3.4 从构造器开始先来看看 Employee 类的构造器： public Employee(String n, double s, int year, int month, int day) { name = n; salary = s; hireDay = LocalDate.of(year, month, day); } 可以看到，构造器与类同名。在构造 Employee 类的对象时，构造器会运行，以便将实例域初始化为所希望的状态。 构造器总是伴随着 new 操作符的执行被调用，而不能对一个已经存在的对象调用构造器，来达到重新设置实例域的目的。 3.5 隐式参数与显式参数方法用于操作对象以及存取它们的实例域。例如： public void raiseSalary(double byPercent) { double raise = salary * byPercent / 100; salary += raise; } 将调用这个方法的对象的 salary 实例域设置为新值。看下面这个调用： number007.raiseSalary(5); 具体将执行下列指令： double raise = number007.salary * 5 / 100; number007.salary += raise; raiseSalary 方法有两个参数。第一个参数称为隐式（implicit）参数，是出现在方法名前的 Emploee 类对象number007。第二个参数是位于方法名后面括号中的数值，是一个显式（explicit）参数。 在每一个方法中，关键字 this 表示隐式参数。如果需要的话，可以使用下列方式编写 raiseSalary 方法： public void raiseSalary(double byPercent) { double raise = this.salary * byPercent / 100; this.salary += raise; } 这样可以将实例域与局部变量明显的区分开来。 3.6 封装的优点public String getName() { return name; } public double getSalary() { return salary; } public LocalDate getHireDay() { return hireDay; } 这些都是典型的访问器方法。由于它们只返回实例域值，因此又称为域访问器。 当需要获得或设置实例域值的时候，应该提供以下三项内容： 一个私有的数据域 一个公有的域访问器方法 一个公有的域更改器方法 这样做有下列明显的好处： 可以改变内部实现，除了该类的方法之外，不会影响其他代码 更改器方法可以执行错误检查，然而直接对域进行赋值将不会进行这些处理 3.7 基于类的访问权限方法可以访问所调用对象的私有数据，还可以访问其所属类的所有对象的私有数据。 3.8 私有方法在实现一个类时，由于公有数据非常危险，所以应该将所有的数据域都设置为私有的。 在 Java 中，要实现一个私有的方法，只需将关键字 public 改为 private 即可。 3.9 final 实例域可以将实例域定义为 final，构建对象时必须初始化这样的域。也就是说，必须确保在每一个构造器执行之后，这个域的值被设置，并且在后面的操作中，不能再对它进行修改。 class Employee { private final String name; ... } final 修饰符大都应用于基本（primitive）类型域，或不可变（immutable）类的域。例如，String 类就是一个不可变的类。 4. 静态域与静态方法4.1 静态域如果将域定义为 static，每个类中只有一个这样的域，而每一个对象对于所有的实例域却都有自己的一份拷贝。例如，假定需要给每一个雇员赋予唯一的标识码。这里给 Employee 类添加一个实例域id和一个静态域nextId： class Employee { private static int nextId = 1; private int id; } 现在，每一个 Employee 对象都有一个自己的id域，但这个类的所有实例将共享一个nextId域。即使没有一个 Employee 对象，静态域nextId也存在。它属于类，而不属于任何独立的对象。 在绝大多数的面向对象程序设计语言中，静态域也被称为类域。 4.2 静态常量例如，在 Math 类中定义了一个静态常量PI： public class Math { ... public static final double PI = 3.14159265358979323846; ... } 另一个多次使用的静态常量是System.out： public class System { ... public static final PrintStream out = ...; } 4.3 静态方法静态方法是一种不能向对象实施操作的方法。例如，Math 类的pow方法就是一个静态方法： Math.pow(x, a); 可以认为静态方法是没有 this 参数的方法，另外静态方法可以访问自身类中的静态域。 4.4 工厂方法静态方法还有另外一种常见的用途，类似 LocalDate 和 NumberFormat 的类使用静态工厂方法（factory method）来构造对象： NumberFormat currencyFormatter = NumberFormat.getCurrencylnstance(); NumberFormat percentFormatter = NumberFormat.getPercentlnstance(); double x = 0.1; System.out.println(currencyFormatter.format(x)); // prints $0.10 System.out.println(percentFomatter.format(x)); // prints 10% 之所以 NumberFormat 类不利用构造器完成这些操作，是因为： 无法命名构造器。构造器名字必须与类名相同，但是这里希望得到的货币实例和百分比实例采用不同的名字。 当使用构造器时，无法改变所构造的对象类型。而 Factory 方法将返回一个 DecimalFormat 类对象，这是 NumberFormat 的子类。 4.5 main 方法main 方法也是一个静态方法，它不对任何对象进行操作。 事实上，在启动程序时还没有任何一个对象。静态的 main 方法将执行并创建程序所需要的对象。 5. 方法参数按值调用（call by name）表示方法接收的是调用者提供的值，而按引用调用（call by reference）表示方法接收的是调用者提供的变量地址。 Java 程序设计语言总是采用按值调用。 6. 对象构造Java 提供了多种编写构造器的机制。 6.1 重载如果多个方法有相同的名字、不同的参数，编译器必须挑选出具体执行那个方法，这种特征叫做重载（overloading）。 StringBuilder messages = new StringBuilder(); StringBuilder todoList = new StringBuilder(&quot;To do:\\n&quot;); 如果编译器找不到匹配的参数，就会产生编译时错误，这个过程被称为重载解析（overloading resolution）。 6.2 默认域初始化如果在构造器中没有显式的给域赋予初值，那么就会被自动的赋给默认值：数值为0，布尔值为 false，对象引用为 null。 6.3 无参数的构造器public Employee() { name = &quot;&quot;; salary = 0; hireDay = LocalDate.now(); } 如果在编写一个类时没有编写构造器， 那么系统就会提供一个无参数构造器。这个构造器将所有的实例域设置为默认值。 如果类中提供了至少一个构造器， 但是没有提供无参数的构造器， 则在构造对象时如果没有提供参数就会被视为不合法。 6.4 显式域初始化初始值不一定是常量值，可以调用方法对域进行初始化： class Employee { private static int nextId; private int id = assignId(); ... private static int assignId() { int r = nextId; nextId++; return r; } ... } 6.5 参数名public Employee(String aName, double aSalary) { name = aName; salary = aSalary; } 当参数变量和实例域同名时，可以通过 this 访问实例域： public Employee(String name, double salary) { this.name = name; this.salary = salary; } 6.6 调用另一个构造器如果构造器的第一个语句形如this(...)，这个构造器将调用同一个类的另一个构造器： public Employee(double s) { // calls Employee(String, double) this(&quot;Employee #&quot; + nextId, s); nextId++; } 采用这种方式使用 this 关键字非常有用，这样对公共的构造器代码部分只编写一次即可。 6.7 初始化块之前已经提到两种初始化数据域的方法： 在构造器中设置值 在声明中赋值 事实上，Java 还有第三种机制，称为初始化块（initialization block）。在一个类的声明中，可以包含多个代码块。只要构造类的对象，这些块就会被执行。 class Employee { private static int nextId; private int id; private String name; private double salary; // object initialization block { id = nextId; nextId++; } public Employee(String n, double s) { name = n; salary = s; } public Employee() { name = &quot;&quot;; salary = 0; } ... } 6.8 对象析构与 finalize 方法由于 Java 有自动的 GC，不需要人工回收内存，所以 Java 不支持析构器。 可以为任何一个类添加 finalize 方法，它将在垃圾回收器清除对象之前调用。 7. 包Java 允许使用包（package）将类组织起来。标准的 Java 类库分布在多个包中，包括 java.lang、java.util、java.net 等。标准的 Java 包具有一个层次结构，如同硬盘的目录嵌套一样，所有标准的 Java 包都处于 java 和 javax 包层次中。 使用包的主要原因是确保类名的唯一性，建议将公司的因特网域名以逆序的形式作为包名，并且对于不同的项目使用不同的子包，例如com.horstmann.corejava。 7.1 类的导入java.time.LocalDate today = java.time.LocalDate.now(); // or import java.util.LocalDate; // or import java.util.*; 7.2 静态导入import 语句不仅可以导入类，还增加了导入静态方法和静态域的功能： import static java.lang.System.*; ... out.println(&quot;Hello, world!&quot;); // i.e., System.out exit(0); // i.e., System.exit 7.3 将类放入包中要想将一个类放入包中，就必须将包的名字放在源文件的开头，定义类的代码之前。 如果没有在源文件中放置 package 语句， 这个源文件中的类就被放置在一个默认包 (defaulf package) 中。默认包是一个没有名字的包。 需要将包中的文件放到与完整的包名匹配的子目录中，编译器将类文件也放在相同的目录结构中。 编译器在编译源文件的时候不检查目录结构。如果包与目录不匹配，虚拟机就找不到类。 7.4 包作用域当没有将类定义为 public 时，默认只有同一个包中的其他类才可以访问该类。 8. 类路径采用-classpath或-cp选项指定类路径： java -classpath /home/usr/classdir:.:/home/user/archieves/archive.jar MyProg 9. 文档注释JDK 中包含了一个很有用的工具 javadoc，它可以由源文件生成一个 HTML 文档，以专用的定界符/**...*/标记。 javadoc -d docDirectory nameOfPackage javadoc -d docDirectory nameOfPackage1 nameOfPackage2 ... // 文件在默认包中 javadoc -d docDirectory *.java 10. 类设计技巧 一定要保证数据私有 一定要对数据初始化 不要在类中使用过多的基本类型 不是所有的域都需要独立的域访问器和域更改器 将职责过多的类进行分解 类名和方法名要能够体现它们的职责 优先使用不可变的类 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序后端开发 - Java开发环境配置 - 入门篇影响力","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"CentOS 7 安装 Docker CE","slug":"install-docker-ce-on-centos7","date":"2019-01-10T08:56:33.000Z","updated":"2019-09-01T13:04:11.399Z","comments":true,"path":"2019/01/10/install-docker-ce-on-centos7/","link":"","permalink":"https://abelsu7.top/2019/01/10/install-docker-ce-on-centos7/","excerpt":"翻译自 Get Docker CE for CentOS | Docker Docs，以 Docker 官方文档 为准","text":"翻译自 Get Docker CE for CentOS | Docker Docs，以 Docker 官方文档 为准 安装前的准备系统要求 官方推荐使用 CentOS 7 的维护版本，已经归档的版本不受支持或未经测试 需要启用centos-extrasrepository。在 CentOS 7 中这个仓库是默认启用的，如果之前有将其禁用，则需要重新启用 推荐使用overlay2作为 Docker 的存储驱动 卸载旧版本旧版本的 Docker 在 CentOS 中的包名为docker或docker-engine。如果之前安装了 Docker 的旧版本，需要先卸载旧版 Docker 及相关依赖： &gt; sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 若yum提示卸载成功或没有找到相关包，即可进行下一步操作。 注意：/var/lib/docker/目录下的内容，包括镜像、容器、卷组、网络等文件将被保留。Docker CE 的新包名为docker-ce。 安装 Docker CE有以下三种方法安装 Docker CE，可根据实际需要选择： 建立 Docker 仓库：安装过程及后续的更新方便，Docker 官方推荐。 下载 RPM 包手动安装：手动管理更新。适合离线环境。 通过安装脚本自动安装：适合测试及开发环境。 方法 1：建立 Docker 仓库 在首次安装 Docker CE 前需要建立 Docker repository，之后可通过仓库安装并更新 Docker。 建立仓库1.安装所需软件包。yum-utils提供了yum-config-manager工具，存储驱动devicemapper则依赖于device-mapper-persistent-data和lvm2： &gt; sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 2.使用以下命令建立stable版本的 repository： &gt; sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 3.可选：启用edge和test仓库。这些仓库包含在docker.repo文件中，但默认是禁用的。可以将它们与stable仓库共同启用。 &gt; sudo yum-config-manager --enable docker-ce-edge &gt; sudo yum-config-manager --enable docker-ce-test 使用带--disable参数的yum-config-manager命令即可禁用edge或test仓库，使用--enable参数则会重新启用。例如下面的命令将禁用edge仓库： &gt; sudo yum-config-manager --disable docker-ce-edge 从 Docker17.06版本开始，stable仓库的 releases 也会推送至edge及test仓库中。点击此处查看 Docker 官方关于stable和edge的说明。 安装 Docker CE1.使用以下命令安装最新版 Docker CE： &gt; sudo yum install docker-ce 如果提示是否接受 GPG 密钥，则需验证密钥指纹是否符合下面的内容，若符合即可点击 accept 继续安装： 060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35 如果启用了多个 Docker 仓库，并且在yum install或yum update命令中没有指明版本，则会安装所有仓库中版本号最新的 Docker。 2.要安装指定版本的 Docker CE，则需要从仓库中列出所有可用的版本，再根据需要选择安装： &gt; yum list docker-ce --showduplicates | sort -r docker-ce.x86_64 18.09.0.ce-1.el7.centos docker-ce-stable 此时安装包名的格式为docker-ce-&lt;VERSION STRING&gt;。例如安装18.03.0版本的 Docker CE： &gt; sudo yum install docker-ce-18.03.0.ce 此时 Docker 应该已经安装完成，但还没有启动。新的用户组docker也已创建，目前为空。 3.启动 Docker： &gt; sudo systemctl start docker 4.运行hello-world镜像以验证 Docker 是否正确安装： &gt; sudo docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 升级 Docker CE如需升级 Docker CE，则可根据上述安装教程，选择安装最新版docker-ce，即可完成升级。 方法 2：下载 RPM 包手动安装安装 Docker CE如果无法使用 Docker 仓库，可以下载.rpm安装包手动安装 Docker CE。 1.前往https://download.docker.com/linux/centos/7/x86_64/stable/Packages/，下载对应版本的 RPM 安装包。 2.使用yum命令安装 RPM 包： &gt; sudo yum install /path/to/package.rpm 3.启动 Docker： &gt; sudo systemctl start docker 4.运行hello-world镜像以验证 Docker 是否正确安装： &gt; sudo docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 升级 Docker CE如需升级，则可下载新版本的 RPM 安装包，使用yum upgrade命令升级： &gt; sudo yum -y upgrade /path/to/package.rpm 方法 3：通过安装脚本自动安装通过 Docker 提供的一键安装脚本可以在开发环境中快速安装 Docker CE，且无需交互。get.docker.com 及 test.docker.com 分别对应edge和test版本，脚本源码存放在 docker-install 仓库 中。 Docker 官方不推荐在生产环境中使用安装脚本 下面的示例将使用 get.docker.com 提供的脚本安装 Docker CE 的最新发布版本。如果要安装最新测试版本，只需将脚本替换为 test.docker.com，并将下面示例命令中的get替换为test： &gt; curl -fsSL https://get.docker.com -o get-docker.sh &gt; sudo sh get-docker.sh &lt;output truncated&gt; 如果需要让非root用户使用 Docker，则使用以下命令将用户添加至docker用户组： &gt; sudo usermod -aG docker your-user 注销并重新登录，即可生效。之后启动 Docker： &gt; sudo systemctl start docker 运行hello-world镜像以验证 Docker 是否正确安装： &gt; sudo docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 卸载 Docker CE1. 卸载 Docker 安装包&gt; sudo yum remote docker-ce 2. 删除相关文件主机上的镜像、容器、卷组以及自定义的配置文件需要手动删除： &gt; sudo rm -rf /var/lib/docker 参考资料 Get Docker CE for CentOS | Docker Docs Post-installation steps for Linux | Docker Docs Docker Docs 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFS微服务编排与容器调度微服务学习资料汇总解决 CentOS 7 tracker CPU 占用率 100%在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"}]},{"title":"Java 笔记 1：Java 的基本程序设计结构","slug":"core-java-notes","date":"2019-01-09T03:03:51.000Z","updated":"2019-09-01T13:04:11.098Z","comments":true,"path":"2019/01/09/core-java-notes/","link":"","permalink":"https://abelsu7.top/2019/01/09/core-java-notes/","excerpt":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》","text":"摘自 《Java 核心技术（卷 Ⅰ）》 《Java 核心技术（卷 Ⅰ）》 Java 的基本程序设计结构1. Hello Worldpublic class FirstSample { public static void main(String[] args) { System.out.println(&quot;We will not use &#39;Hello, World!&#39;&quot;); } } 2. 注释使用//或/* */。第 3 种注释以/**开始，以*/结束，可以用来自动生成文档： /** * This is the first sample program in Core Java Chapter 3 * @version 1.01 1997-03-22 * @author Gary Cornell */ public class FirstSample { public static void main(String[] args) { System.out.println(&quot;We will not use &#39;Hello, World!&#39;&quot;); } } 在 Java 中，/* */注释不能嵌套。 3. 数据类型Java 是一种强类型语言，必须为每一个变量声明一种类型。在 Java 中一共有 8 种基本类型（primitive type）：4 种整型、2 种浮点类型、1 种字符类型char和 1 种用于表示真值的boolean类型。 3.1 整型Java 提供了如下 4 种整型： int 类型的正数部分正好超过 20 亿 类型 存储需求 取值范围 byte 1 字节 -128 ~ 127 short 2 字节 -32768 ~ 32767 int 4 字节 -231 ~ 231-1 long 8 字节 -263 ~ 263-1 整型的范围与运行 Java 代码的机器无关 长整型数值有一个后缀L 十六进制数值有一个前缀0x或0X 八进制数值有一个前缀0，例如010对应八进制中的8 从 Java 7 开始，加上前缀0b或0B就可以写二进制数 从 Java 7 开始，还可以为数字字面量加下划线，如1_000_000表示一百万。这些下划线只是为了让人更易读，Java 编译器会把它们去除掉。 Java 没有任何无符号（unsigned）类型 3.2 浮点类型浮点类型用于表示有小数部分的数值。在 Java 中有两种浮点类型： 类型 存储需求 取值范围 有效数字 float 4 字节 大约 ±3.402 823 47E+38F 6~7 位 double 8 字节 大约 ±1.797 693 134 862 315 70E+308 15 位 double 表示这种类型的数值精度是 float 类型的两倍，也称双精度数值。绝大部分应用程序都采用 double 类型 float 类型的数值有一个后缀F或f。没有后缀F的浮点数值默认为 double 类型。也可以在浮点数值后面添加后缀D或d 有三个用于表示溢出和出错情况的特殊浮点数值： 正无穷大Double.POSITIVE_INFINITY 负无穷大Double.NEGATIVE_INFINITY NaN（不是一个数字）Double.NaN 不能检测一个特定值是否等于Double.NaN，因为所有“非数值”的值都认为是不相同的。可以使用Double.isNaN方法： if (x == Double.NaN) // is never true if (Double.isNaN(x)) // check whether x is &quot;Not a Number&quot; 浮点数值不适用于无法接收舍入误差的场景。例如，以下命令将打印出0.8999999999999999而不是0.9，这种舍入误差的主要原因是浮点数值采用二进制系统表示，而在二进制系统中无法精确的表示分数1/10： System.out.println(2.0 - 1.1); ------ 0.8999999999999999 如果在数值计算中不允许有任何舍入误差，就应该使用 BigDecimal 类。 3.3 char 类型char 类型的字面量值要用单引号括起来。例如：&#39;A&#39;是编码值为 65 所对应的字符常量，它与&quot;A&quot;不同，&quot;A&quot;是包含一个字符 A 的字符串。 char 类型可以表示为十六进制，其范围从\\u0000到\\uffff。 转义序列 名称 Unicode 值 \\b 退格 \\u0008 \\t 制表 \\u0009 \\n 换行 \\u000a \\r 回车 \\u000d \\” 双引号 \\u0022 \\’ 单引号 \\u0027 \\\\ 反斜杠 \\u005c 特别注意： Unicode 转义序列会在解析代码之前得到处理 更隐秘的，一定要当心注释中的\\u，例如// Look inside c:\\users 3.4 Unicode 和 char 类型 码点（code point）是指与一个编码表中的某个字符对应的代码值。在 Unicode 标准中，码点采用十六进制书写，并加上前缀U+，例如U+0041就是拉丁字母 A 的码点。 在 Java 中，char 类型描述了 UTF-16 编码中的一个代码单元。 3.5 boolean 类型boolean（布尔）类型有两个值：false 和 true，用来判定逻辑条件。 整型值和布尔值之间不能进行相互转换。 4. 变量在 Java 中，每个变量都有一个类型，变量名必须是一个以字母开头并由字母或数字构成的序列。 可以使用 Character 类的isJavaIdentifierStart和isJavaIdentifierPart方法来检查那些 Unicode 字符属于 Java 中的字母。另外，不要在代码中使用$字符，它只用在 Java 编译器或其他工具生成的名字中。 4.1 变量初始化 在 Java 中，变量的声明尽可能的靠近变量第一次使用的地方，这是一种良好的程序编写风格。 声明一个变量后，必须使用赋值语句对变量进行显式初始化，使用未初始化的变量编译器会报错： int vacationDays; System.out.println(vacationDays); // ERROR--variable not initialized 4.2 常量关键字 final 用来指示常量： final double PI = 3.14; final 表示这个变量只能被赋值一次，一旦被赋值之后，就不能够再更改了。习惯上，常量名使用全大写。 在 Java 中，经常希望某个常量可以在一个类中的多个方法使用，通常将这些常量称为类常量，可以使用关键字 static final 来修饰： public class Main { public static final double CM_PER_INCH = 2.54; public static void main(String[] args) { double paperWidth = 8.5; double paperHeight = 11; System.out.println(&quot;Paper size in centimeters: &quot; + paperWidth * CM_PER_INCH + &quot; by &quot; + paperHeight * CM_PER_INCH); } } ------ Paper size in centimeters: 21.59 by 27.94 类常量的定义位于main方法的外部。因此，在同一个类的其他方法中也可以使用这个常量。而且，如果一个常量被声明为 public，那么其他类的方法也可以使用这个常量。 5. 运算符当参与/运算的两个操作数都是整数时，表示整数除法；否则，表示浮点除法。 另外，整数被 0 除将会产生一个异常，而浮点数被 0 除将会得到无穷大或 NaN 结果。 如果将一个类标记为 strictfp，那么这个类中的所有方法都要使用严格的浮点计算。 5.1 数学函数与常量在 Math 类中，包含了各种各样的数学函数： import static java.lang.Math.*; // 开方、乘幂、取余 sqrt(x); pow(x, a); floorMod(x, y); // 三角函数 sin(a); cos(a); tan(a); atan(a); atan2(y, x); // 指数及对数 exp(a); log(a); log10(a); // 常量近似值 Math.PI; Math.E; 5.2 数值类型之间的转换高精度数值类型转换为低精度数值类型，可能会发生精度损失。 数值类型之间的合法转换 如果两个操作数中有一个是 double 类型，另一个操作数就会转换为 double 类型 否则，如果其中一个操作数是 float 类型，另一个操作数将会转换为 float 类型 否则，如果其中一个操作数是 long 类型，另一个操作数将会转换为 long 类型 否则，两个操作数都将被转换为 int 类型 5.3 强制类型转换强制类型转换通过截断小数部分将浮点值转换为整型： double x = 9.997; int nx = (int) x; // x = 9 如果想对浮点数进行舍入运算，那就需要使用Math.round()方法： double x = 9.997; int nx = (int) Math.round(x); // x = 10 如果试图将一个数值从一种类型强制转换为另一种类型，而又超出了目标类型的表示范围，结果就会截断成一个完全不同的值。例如，(byte) 300的实际值为 44。 5.4 结合赋值和运算符x += 4; x += 3.5; // 将发生强制类型转换，等价于 (int)(x + 3.5) 5.5 自增与自减运算符int n = 12; n++; 由于这些运算符会改变变量的值，所以它们的操作数不能是数值。例如，4++就不是一个合法的语句。 后缀和前缀形式都会使变量值加 1 或减 1，但用在表达式中，二者就有区别了。前缀形式会先完成加 1，而后缀形式会使用变量原来的值： int m = 7; int n = 7; int a = 2 * ++m; // now a is 16, m is 8 int b = 2 * n++; // now b is 14, n is 8 5.6 关系和 boolean 运算符逻辑运算符&amp;&amp;和||是按照「短路」方式来求值的：如果第一个操作数已经能够确定表达式的值，第二个操作数就不必计算了。如果用&amp;&amp;运算符合并两个表达式，就可以利用这一点来避免错误： x != 0 &amp;&amp; 1 / x &gt; x + y // no division by 0 另外，Java 支持三元操作符? :： x &lt; y ? x : y 会返回 x 和 y 中较小的一个。 5.7 位运算符处理整型类型时，可以直接对组成整型数值的各个位完成操作，这意味着可以使用掩码技术得到整数中的各个位： &amp; (&quot;and&quot;) | (&quot;or&quot;) ^ (&quot;XOr&quot;) ~ (&quot;not&quot;) 利用&amp;并结合使用适当的 2 的幂，可以把其他位掩掉，而只保留其中的某一位。另外，&amp;和|运算符不采用「短路」方式来求值。 另外，还有&gt;&gt;和&lt;&lt;运算符将位模式左移或右移： int fourthBitFromRight = (n &amp; (1 &lt;&lt; 3)) &gt;&gt; 3; 最后，&gt;&gt;&gt;运算符会用 0 填充高位，这与&gt;&gt;不同，它会用符号位填充高位，不存在&lt;&lt;&lt;运算符。 可以用Integer.toBinaryString()方法将整型类型转换类二进制字符串。 移位运算符的右操作数要完成模 32 的运算（除非左操作数是 long 类型，在这种情况下需要对右操作数模 64）。例如，1 &lt;&lt; 35的值等同于1 &lt;&lt; 3的值即为 8。 5.8 括号与运算符级别同一个级别的运算符按照从左到右的次序进行计算（除了右结合运算符）。 运算符 结合性 [] . ()函数调用 从左向右 ! ~ ++ -- +一元 -一元 ()强制类型转换 new 从右向左 * / % 从左向右 + - 从左向右 &lt;&lt; &gt;&gt; &gt;&gt;&gt; 从左向右 &lt; &lt;= &gt; &gt;= instanceof 从左向右 == != 从左向右 &amp; 从左向右 ^ 从左向右 l 从左向右 &amp;&amp; 从左向右 ll 从左向右 ?: 从右向左 = += -= *= /= %= &amp;= != ^= &lt;&lt;= &gt;&gt;= &gt;&gt;&gt;= 从右向左 5.9 枚举类型有时候，变量的取值只在一个有限的集合内。这时可以自定义枚举类型。枚举类型包括有限个命名的值： enum Size { SMALL, MEDIUM, LARGE, EXTRA_LARGE } Size s = Size.MEDIUM; Size 类型的变量只能存储这个类型声明中给定的某个枚举值，或者 null 值。null 表示这个变量没有设置任何值。 6. 字符串Java 字符串就是 Unicode 字符序列。例如，串Java\\u2122由 5 个 Unicode 字符J、a、v、a、和™组成。Java 没有内置的字符串类型，而是在标准 Java 类库中提供了一个预定义类 String。每个用双引号括起来的字符串都是 String 类的一个实例： String e = &quot;&quot;; // an empty string String greeting = &quot;Hello&quot;; 6.1 子串String greeting = &quot;Hello&quot;; String s = greeting.substring(0, 3); System.out.println(s); ------ Hel 字符串s.substring(a, b)的长度为b-a。 6.2 拼接Java 语言允许使用+号拼接两个字符串。另外如果需要把多个字符串放在一起，用一个定界符分隔，可以使用静态 join 方法： String all = String.join(&quot; / &quot;, &quot;S&quot;, &quot;M&quot;, &quot;L&quot;, &quot;XL&quot;); System.out.println(s); ------ S / M / L / XL 6.3 不可变字符串String 类没有提供用于修改字符串的方法，所以在 Java 文档中将 String 类对象称为不可变字符串。虽然通过拼接来创建新字符串的效率确实不高，但是不可变字符串却有一个优点：编译器可以让字符串共享。 可以想象将各种字符串存放在公共的存储池中，字符串变量指向存储池中相应的位置。如果复制一个字符串变量，原始字符串与复制的字符串共享相同的字符。 6.4 检测字符串是否相等 一定不要使用==运算符检测两个字符串是否相等，==只能确定两个字符串是否放置在同一个位置上。 s.equals(t); s.equalsIgnoreCase(t); 6.5 空串与 Null 串空串&quot;&quot;是长度为 0 的字符串。可以调用以下代码检查一个字符串是否为空： if (str.length() == 0) if (str.equals(&quot;&quot;)) 空串是一个 Java 对象，有自己的串长度（0）和内容（空）。不过，String 变量还可以存放一个特殊的值，名为 null，表示目前没有任何对象与该变量关联。要检查一个字符串是否为空，可以使用以下条件： if (str == null) 有时要检查一个字符串既不是 null 也不为空串，这种情况下就需要使用以下条件： if (str != null &amp;&amp; str.length() != 0) 6.6 码点与代码单元Java 字符串由 char 值序列组成。 length()方法将返回采用 UTF-16 编码表示的给定字符串所需要的代码单元数量： String greeting = &quot;Hello&quot;; int n = greeting.length(); // is 5. 想要得到实际的长度，即码点数量，可以调用： int cpCount = greeting.codePointCount(0, greeting.length()); 调用s.charAt(n)将返回位置 n 的代码单元，n 介于0和s.length()-1之间，例如： char first = greeting.charAt(0); // first is &#39;H&#39; char last = greeting.charAt(4); // last is &#39;o&#39; 要想得到第 i 个码点，则使用下列语句： int index = greeting.offsetByCodePoints(0, i); int cp = greeting.codePointAt(index); 6.7 String APIJava 中的 String 类包含了 50 多个方法，最常用的如下： char charAt(int index) // 返回给定位置的代码单元 int codePointAt(int index) // 返回从给定位置开始的码点 int offsetByCodePoints(int startIndex, int cpCount) // 返回从 startIndex 代码点开始，位移 cpCount 后的码点索引 int compareTo(String other) // 按照字典顺序，如果字符串位于 other 之前，返回一个负数 IntStream codePoints() // 将这个字符串的码点作为一个流返回 new String(int[] codePoints, int offset, int count) // 用数组中从 offset 开始的 count 个码点构造一个字符串 boolean equals(Object other) // 如果字符串与 other 相等，返回 true boolean equalsIgnoreCase(String other) // 如果字符串与 other 相等（忽略大小写），返回 true boolean startsWith(String prefix) boolean endsWith(String suffix) // 如果字符串以 suffix 开头或结尾，则返回 true int indexOf(String str) int indexOf(String str, int fromIndex) int indexOf(int cp) int indexOf(int cp, int fromIndex) // 返回与字符串 str 或代码点 cp 匹配的第一个字串的开始位置 int lastIndexOf(String str) int lastIndexOf(String str, int fromIndex) int lastIndexOf(int cp) int lastIndexOf(int cp, int fromIndex) // 返回与字符串 str 或代码点 cp 匹配的最后一个子串的开始位置 int length() // 返回字符串的长度 int codePointCount(int startIndex, int endIndex) // 返回 startIndex 和 endIndex-1 之间的代码点数量 String replace(CharSequence oldString, CharSequence newString) String substring(int beginIndex) String substring(int beginIndex, int endIndex) String toLowerCase() String toUpperCase() String trim() String join(CharSequence delimiter, CharSequence... elements) 6.8 构建字符串有些时候，需要由较短的字符串构建字符串，采用字符串连接的方式达到此目的的效率比较低。每次连接字符串，都会构建一个新的 String 对象，既耗时又浪费空间。使用 StringBuilder 类可以避免这个问题发生。 如果需要用许多小段的字符串构建一个字符串，首先构建一个空的字符串构建器： StringBuilder builder = new StringBuilder(); 当每次需要添加一部分内容时，就调用append方法： builder.append(ch); // appends a single character builder.append(str); // appends a string 在需要构建字符串时调用toString方法，就可以得到一个 String 对象，其中包含了构建器中的字符序列： String completedString = builder.toString(); 重要方法如下： StringBuilder() // 构造一个空的字符串构建器 int length() // 返回构建器或缓冲器中的代码单元数量 StringBuilder append(String str) // 追加一个字符串并返回 this StringBuilder append(char c) // 追加一个代码单元并返回 this StringBuilder appendCodePoint(int cp) // 追加一个代码点，并将其转换为一个或两个代码单元并返回 this void setCharAt(int i, char c) // 将第 i 个代码单元设置为 c StringBuilder insert(int offset, String str) // 在 offset 位置插入一个字符串并返回 this StringBuilder insert(int offset, Char c) // 在 offset 位置插入一个代码单元并返回 this StringBuilder delete(int startIndex, int endIndex) // 删除偏移量从 startIndex 到 endIndex-1 的代码单元并返回 this String toString() // 返回一个与构建器或缓冲器内容相同的字符串 7. 输入输出7.1 读取输入要想通过控制台进行输入，首先需要构造一个 Scanner 对象，并与标准输入流 System.in 关联，Scanner 类定义在java.util包中： import java.util.*; /** * This program demonstrates console input. * @version 1.10 2004-02-10 * @author Cay Horstmann */ public class InputTest { public static void main(String[] args) { Scanner in = new Scanner(System.in); // get first input System.out.print(&quot;What is your name? &quot;); String name = in.nextLine(); // get second input System.out.print(&quot;How old are you? &quot;); int age = in.nextInt(); // display output on console System.out.println(&quot;Hello, &quot; + name + &quot;. Next year, you&#39;ll be &quot; + (age + 1)); } } 常用方法如下： Scanner (InputStream in) // 用给定的输入流创建一个 Scanner 对象 String nextLine() // 读取输入的下一行内容 String next() // 读取输入的下一个单词（以空格分隔） int nextInt() double nextDouble() boolean hasNext() // 检测输入中是否还有其他单词 boolean hasNextInt() boolean hasNextDouble() 7.2 格式化输出Java 沿用了 C 语言库函数中的printf方法，例如： System.out.printf(&quot;%8.2f&quot;, x); 会使用 8 个字符的宽度和小数点后两个字符的精度打印x。 每一个以%字符开始的格式说明符都用相应的参数替换，格式说明符尾部的转换符将指示被格式化的数值类型：f表示浮点数，s表示字符串，d表示十进制整数。 用于 printf 的转换符如下所示： 转换符 类型 举例 d 十进制整数 159 x 十六进制整数 9f o 八进制整数 237 f 定点浮点数 15.9 e 指数浮点数 1.59e+01 g 通用浮点数 — a 十六进制浮点数 0x1.fccdp3 s 字符串 Hello c 字符 H b 布尔 True h 散列码 42628b2 Tx 日期时间 已经过时，应改为java.time类 % 百分号 % n 与平台有关的行分隔符 — 另外，还可以给出控制格式化输出的各种标志： 用于 printf 的标志 可以使用静态的String.format方法创建一个格式化的字符串，而不打印输出： String string = String.format(&quot;Hello, %s, Next year, you&#39;ll be %d&quot;, name, age); printf 方法中还有关于日期与时间的格式化选项。格式包括两个字母，以t开始，以下表中的任意字母结束： 日期和时间的转换符 日期和时间的转换符（续） 7.3 文件输入与输出要想对文件进行读取，就需要用一个 File 对象来构造一个 Scanner 对象。如果文件名中包含反斜杠\\符号，就要使用转义字符\\\\： Scanner in = new Scanner(Paths.get(&quot;C:\\\\Users\\\\abel1\\\\IdeaProjects\\\\CoreJava\\\\src\\\\myfile.txt&quot;), &quot;UTF-8&quot;); ... in.close(); 要想写入文件，就需要构造一个 PrintWriter 对象。在构造器中，只需要提供文件名。如果文件不存在，则会自动创建该文件： PrintWriter out = new PrintWriter(&quot;myfile.txt&quot;, &quot;UTF-8&quot;); ... out.close(); 注意：可以构造一个带有字符串参数的 Scanner，但这个 Scanner 将字符串解释为数据，而不是文件名。例如： Scanner in = new Scanner(&quot;myfile.txt&quot;); // ERROR? 这个 scanner 会将参数作为包含 10 个字符的数据：m、y、f等。 当指定一个相对文件名时，文件位于 Java 虚拟机启动路径的相对位置。可以使用下面的调用方式找到路径的位置： String dir = System.getProperty(&quot;user.dir&quot;); 如果 Scanner 和 PrintWriter 中指定的文件不存在或无法创建，就会发生异常。在已知有可能出现「输入/输出」异常的情况下，需要在main方法中用throws子句标记： public static void main(String[] args) throws IOException { Scanner in = new Scanner(Path.get(&quot;myfile.txt&quot;), &quot;UTF-8&quot;); ... in.close(); } 常用方法如下： Scanner(File f) // 构造一个从给定文件读取数据的 Scanner Scanner(String data) // 构造一个从给定字符串读取数据的 Scanner PrintWriter(String fileName) // 构造一个将数据写入文件的 PrintWriter。文件名由参数指定 static Path get(String pathname) // 根据指定的路径名构造一个 Path 8. 控制流程8.1 if 条件语句 条件必须用括号括起来 if (condition) { statement } 8.2 while 循环while (condition) { statement } while 循环语句首先检测循环条件。如果希望循环体至少执行一次，则应该将检测条件放到最后： do { statement } while (condition); 例如下面的例子，只要用户回答N，循环就重复执行： import java.util.*; /** * This program demonstrates a &lt;code&gt;do/while&lt;/code&gt; loop. * @version 1.20 2004-02-10 * @author Cay Horstmann */ public class Retirement2 { public static void main(String[] args) { Scanner in = new Scanner(System.in); System.out.print(&quot;How much money will you contribute every year? &quot;); double payment = in.nextDouble(); System.out.print(&quot;Interest rate in %: &quot;); double interestRate = in.nextDouble(); double balance = 0; int year = 0; String input; // update account balance while user isn&#39;t ready to retire do { // add this year&#39;s payment and interest balance += payment; double interest = balance * interestRate / 100; balance += interest; year++; // print current balance System.out.printf(&quot;After year %d, your balance is %,.2f%n&quot;, year, balance); // ask if ready to retire and get input System.out.print(&quot;Ready to retire? (Y/N) &quot;); input = in.next(); } while (input.equalsIgnoreCase(&quot;N&quot;)); } } 8.3 for 循环for 语句的第 1 部分通常用于对计数器初始化；第 2 部分给出每次新一轮循环执行前要检测的循环条件；第 3 部分指示如何更新计数器。 for 语句也可以看作 while 语句的一种简化形式。 for (int i = 10; i &gt; 0; i--) { System.out.println(&quot;Counting down...&quot; + i); } System.out.println(&quot;Blastoff!&quot;); 8.4 switch 语句Scanner in = new Scanner(System.in); System.out.print(&quot;Select an option (1, 2, 3, 4) &quot;); int choice = in.nextInt(); switch (choice) { case 1: // do something break; case 2: // do something break; case 3: // do something break; case 4: // do something break; default: // bad input break; } 如果在某个 case 分支语句的末尾没有 break 语句，那么就会接着执行下一个 case 分支语句，这种情况很容易引发错误。可以在编译代码时加上-Xlint:fallthrough选项： javac -Xlint:fallthrough Test.java 这样一来，如果某个分支最后缺少一个 break 语句，编译器就会给出一个警告信息。 如果确实是想使用这种“直通式”（fallthrough）行为，可以为其外围方法加一个标注@SuppressWarnings(&quot;fallthrough&quot;)，这样就不会对这个方法生成警告了。 case 标签可以是： 类型为 char、byte、short 或 int 的常量表达式 枚举常量 从 Java SE 7 开始，还可以是字符串字面量 String input = ...; switch (input.toLowerCase()) { case &quot;yes&quot;: // OK since Jave SE 7 ... break; ... } 8.5 中断控制流程语句不带标签的 break 语句用于退出当前循环语句。另外，Java 还提供了一种带标签的 break 语句，用于跳出多重嵌套的循环语句： Scanner in = new Scanner(System.in); int n; read_data: while (...) { // this loop statement is tagged with the label ... for (...) { // this inner loop is not labeled System.out.print(&quot;Enter a number &gt;=0: &quot;); n = in.nextInt(); if (n &lt; 0) { // should never happen - can&#39;t go on break read_data; // break out of read_data loop } ... } } // this statement is executed immediately after the labeled break if (n &lt; 0) { // check for bad situation // deal with bad situation } else { // carry out normal processing } 如果输入有误，通过执行带标签的 break 跳转到带标签的语句块末尾。对于任何使用 break 语句的代码都需要检测循环是正常结束，还是由 break 跳出。 事实上，可以将标签应用到任何语句中，甚至是 if 语句或者块语句。另外需要注意，break 只能跳出语句块，而不能跳入语句块： label: { ... if (condition) break label; // exits block ... } // jumps here when the break statement executes 最后，还有一个 continue 语句，它将中断正常的控制流程，并将控制转移到最内层循环的首部。例如： Scanner in = new Scanner(System.in); while (sum &lt; goal) { System.out.print(&quot;Enter a number: &quot;); n = in.nextInt(); if (n &lt; 0) continue; sum += n; // not executed if n &lt; 0 } 如果n &lt; 0，则 continue 语句越过了当前循环体的剩余部分，立刻跳到循环首部sum &lt; goal。 如果将 continue 语句用于 for 循环中，就可以跳到 for 循环的更新部分： for (count = 1; count &lt;= 100; count++) { System.out.print(&quot;Enter a number, -1 to quit: &quot;); n = in.nextInt(); if (n &lt; 0) continue; sum += n; // not executed if n &lt; 0 } 如果n &lt; 0，则会跳到count++语句。 还有一种带标签的 continue 语句，将跳到与标签匹配的循环首部。 9. 大数值如果基本的整数和浮点数精度不能满足需求，可以使用java.math包中的两个很有用的类：BigInteger 和 BigDecimal，这两个类可以处理任意长度数字序列的数值。 import java.math.BigInteger; import java.math.BigDecimal; 使用静态的valueOf()方法可以将普通的数值转化为大数值： BigInteger a = BigInteger.valueOf(100); 不能直接使用算数运算符（如+、*）来处理大数值，而需要使用大数值类中的 add 和 multiply 方法： import java.math.BigInteger; public class Main { public static void main(String[] args) { BigInteger a = BigInteger.valueOf(Long.MAX_VALUE); BigInteger b = BigInteger.valueOf(Long.MAX_VALUE); BigInteger sum = a.add(b); BigInteger product = a.multiply(b); System.out.printf(&quot;%d + %d = %d\\n&quot;, a, b, sum); System.out.printf(&quot;%d * %d = %d&quot;, a, b, product); } } ------ 9223372036854775807 + 9223372036854775807 = 18446744073709551614 9223372036854775807 * 9223372036854775807 = 85070591730234615847396907784232501249 Process finished with exit code 0 BigInteger 常用方法如下： BigInteger add(BigInteger other) BigInteger subtract(BigInteger other) BigInteger multiply(BigInteger other) BigInteger divide(BigInteger other) BigInteger mod(BigInteger other) int compareTo(BigInteger other) // 如果与另一个大整数 other 相等则返回 0，大于返回正数，小于返回负数 static BigInteger valueOf(long x) // 返回值等于 x 的大整数 BigDecimal 常用方法如下： BigDecimal add(BigDecimal other) BigDecimal subtract(BigDecimal other) BigDecimal multiply(BigDecimal other) BigDecimal divide(BigDecimal other RoundingMode mode) // 要想计算商，必须给出舍入方式。RoundingMode.HALF_UP 即为四舍五入 int compareTo(BigDecimal other) // 如果与另一个大实数 other 相等则返回 0，大于返回正数，小于返回负数 static BigDecimal valueOf(long x) static BigDecimal valueOf(long x, int scale) // 返回值为 x 或 x/10^scale 的一个大实数 10. 数组在声明数组变量时，需要指出数组类型和数组变量名，可以使用 new 运算符创建数组： int[] a = new int[100]; 创建一个数字数组时，所有元素都初始化为0。boolean 数组的元素会初始化为false。对象数组的元素则初始化为一个特殊值null，表示这些元素还未存放任何对象。 一旦创建了数组，就不能再改变它的大小。如果经常需要在运行过程中扩展数组的大小，就应该使用另一种数据结构——数组列表（ArrayList）。 10.1 for each 循环for each 循环可以用来依次处理数组中的每个元素而不必为指定下标值而分心： for (variable : collection) { statement } collection 这一集合表达式必须是一个数组或者是一个实现了 Iterable 接口的类对象（例如 ArrayList）。 有个更简单的方式打印数组中的所有值，即利用 Arrays 类的toString方法： import java.util.Arrays; ... System.out.println(Arrays.toString(a)); 10.2 数组初始化以及匿名数组Java 提供了一种创建数组对象并同时赋予初始值的简化书写形式： int[] smallPrimes = {2, 3, 5, 7, 11, 13}; 还可以初始化一个匿名的数组，这种表示法将创建一个数组并利用括号中提供的值进行初始化，数组的大小就是初始值个数。使用这种语法可以在不创建新变量的情况下重新初始化一个数组： smallPrimes = new int [] {17, 19, 23, 29, 31, 37}; 10.3 数组拷贝在 Java 中，允许将一个数组变量拷贝给另一个数组变量。这时，两个变量将引用同一个数组： 拷贝一个数组变量 import java.io.PrintWriter; import java.util.Arrays; import java.util.Scanner; public class Main { public static void main(String[] args) { Scanner in = new Scanner(System.in); PrintWriter out = new PrintWriter(System.out); int[] smallPrimes = new int[]{2, 3, 5, 7, 11, 13}; out.println(&quot;smallPrimes: &quot; + Arrays.toString(smallPrimes)); int[] luckyNumbers = smallPrimes; out.println(&quot;luckyNumbers: &quot; + Arrays.toString(luckyNumbers)); luckyNumbers[5] = 12; out.println(&quot;After Change:&quot;); out.println(&quot;smallPrimes: &quot; + Arrays.toString(smallPrimes)); out.println(&quot;luckyNumbers: &quot; + Arrays.toString(luckyNumbers)); in.close(); out.close(); } } ------ smallPrimes: [2, 3, 5, 7, 11, 12] luckyNumbers: [2, 3, 5, 7, 11, 12] After Change: smallPrimes: [0, 0, 0, 0, 0, 0] luckyNumbers: [0, 0, 0, 0, 0, 0] 如果希望将一个数组的所有值拷贝到一个新的数组中，就要使用 Arrays 类的copyOf方法： int[] copiedLuckyNumbers = Arrays.copyOf(luckNumbers.length); 第 2 个参数是新数组的长度，这个方法通常用来增加数组的大小： luckyNumbers = Arrays.copyOf(luckyNumbers, 2 * luckyNumbers.length); 如果数组元素是数值型，那么多余的元素将被赋值为 0。如果是布尔型，则将赋值为 false。相反，如果长度小于原始数组的长度，则只拷贝最前面的数据元素。 10.4 命令行参数每一个 Java 应用程序都有一个带String[] args参数的 main 方法。这个参数表明 main 方法将接收一个字符串数组，也就是命令行参数。例如： public class Message { public static void main(String[] args) { if (args.length == 0 || args[0].equals(&quot;-h&quot;)) { System.out.print(&quot;Hello,&quot;); } else if (args[0].equals(&quot;-g&quot;)) { System.out.print(&quot;Goodbye,&quot;); } // print the other command-line arguments for (int i = 1; i &lt; args.length; i++) { System.out.print(&quot; &quot; + args[i]); } System.out.println(&quot;!&quot;); } } 如果使用下面的命令运行程序： java Message -g cruel world 则 args 数组将包含以下内容： args[0]: &quot;-g&quot; args[1]: &quot;cruel&quot; args[2]: &quot;world&quot; 程序将输出以下信息： Goodbye, cruel world! 10.5 数组排序要想对数值型数组进行排序，可以使用 Arrays 类中的sort方法。Arrays.sort()使用了优化的快速排序算法： int[] a = new int[10000]; ... Arrays.sort(a); 下面的程序用到了数组，它将产生一个抽彩游戏中的随机数组合： import java.util.Arrays; import java.util.Scanner; /** * This program demonstrates array manipulation. * * @author Cay Horstmann * @version 1.20 2004-02-10 */ public class LotteryDrawing { public static void main(String[] args) { Scanner in = new Scanner(System.in); System.out.print(&quot;How many numbers do you need to draw? &quot;); int k = in.nextInt(); System.out.print(&quot;What is the highest number you can draw? &quot;); int n = in.nextInt(); // fill an array with numbers 1 2 3 ... n int[] numbers = new int[n]; for (int i = 0; i &lt; numbers.length; i++) { numbers[i] = i + 1; } // draw k numbers and put them into a second array int[] result = new int[k]; for (int i = 0; i &lt; result.length; i++) { // make a random index between 0 and n - 1 int r = (int) (Math.random() * n); // pick the element at the random location result[i] = numbers[r]; // move the last element into the random location numbers[r] = numbers[n - 1]; n--; } // print the sorted array Arrays.sort(result); System.out.println(&quot;Bet the following combination. It&#39;ll make you rich!&quot;); for (int r : result) { System.out.println(r); } } } ------ How many numbers do you need to draw? 6 What is the highest number you can draw? 49 Bet the following combination. It&#39;ll make you rich! 2 7 8 17 34 38 数组类 Arrays 的常用方法如下： static String toString(type[] a) static type copyOf(type[] a, int length) static type copyOfRange(type[] a, int start, int end) // 包含 start, 不包含 end static void sort(type[] a) // 采用优化的快速排序 static int binarySearch(type[] a, type v) static int binarySearch(type[] a, int start, int end, type v) // 二分查找值 v。成功则返回下标值，否则返回一个负数 static void fill(type[] a, type v) // a 与 v 数据元素类型相同 static boolean equals(type[] a, type[] b) // 如果两个数组大小相同、下标相同的元素都对应相等，则返回 true 10.6 多维数组在 Java 中，声明一个二维数组相当简单： double[][] balance = new double[NYEARS][NRATES]; 如果知道数组元素，也可以不调用 new，直接使用简化形式对多维数组进行初始化： int[][] magicSquare = { {16, 3, 2, 13}, {5, 10, 11, 8}, {9, 6, 7, 12}, {4, 15, 14, 1} }; for each 循环语句不能自动处理二维数组的每一个元素。它是按照行，也就是一维数组处理的。要想访问二维数组magicSquare的所有元素，需要使用两个嵌套的循环： for (int[] row : magicSquare) { for (int value : row) { System.out.println(value); } } 另外，要想快速的打印一个二维数组的数据元素列表，可以调用 Arrays 类的deepToString方法： System.out.println(Arrays.deepToString(magicSquare)); 10.7 不规则数组Java 实际上没有多维数组，只有一维数组。多维数组被解释为「数组的数组」。 一个二维数组 下面是一个使用数组来打印杨辉三角的例子： /** * This program demonstrates a triangular array. * @version 1.20 2004-02-10 * @author Cay Horstmann */ public class LotteryArray { public static void main(String[] args) { final int NMAX = 10; // allocate triangular array int[][] odds = new int[NMAX + 1][]; for (int n = 0; n &lt;= NMAX; n++) odds[n] = new int[n + 1]; // fill triangular array for (int n = 0; n &lt; odds.length; n++) for (int k = 0; k &lt; odds[n].length; k++) { /* * compute binomial coefficient n*(n-1)*(n-2)*...*(n-k+1)/(1*2*3*...*k) */ int lotteryOdds = 1; for (int i = 1; i &lt;= k; i++) lotteryOdds = lotteryOdds * (n - i + 1) / i; odds[n][k] = lotteryOdds; } // print triangular array for (int[] row : odds) { for (int odd : row) System.out.printf(&quot;%4d&quot;, odd); System.out.println(); } } } ------ 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 1 5 10 10 5 1 1 6 15 20 15 6 1 1 7 21 35 35 21 7 1 1 8 28 56 70 56 28 8 1 1 9 36 84 126 126 84 36 9 1 1 10 45 120 210 252 210 120 45 10 1 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序后端开发 - Java开发环境配置 - 入门篇影响力","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"Docker 笔记 1：Docker 基础与搭建第一个 Docker 应用栈","slug":"docker-notes","date":"2019-01-08T14:55:55.000Z","updated":"2019-09-01T13:04:11.171Z","comments":true,"path":"2019/01/08/docker-notes/","link":"","permalink":"https://abelsu7.top/2019/01/08/docker-notes/","excerpt":"摘自 《Docker 容器与容器云（第2版）》 《Docker 容器与容器云（第2版）》","text":"摘自 《Docker 容器与容器云（第2版）》 《Docker 容器与容器云（第2版）》 1. 从容器到容器云1.1 云计算平台经典云计算架构包括 IaaS（Infrastructure as a Service，基础设施即服务）、PaaS（Platform as a Service，平台即服务）、SaaS（Software as a Service，软件即服务）三层服务，如下图所示。 云平台经典架构 1.2 容器技术生态系统 容器技术生态系统 可以看出，容器技术生态系统自上而下分别覆盖了 IaaS 层和 PaaS 层所涉及的各类问题，包括资源调度、编排、部署、监控、配置管理、存储网络管理、安全、容器化应用支撑平台等。容器技术主要带来了以下几点好处： 持续部署与测试：容器消除了线上线下的环境差异，保证了应用生命周期的环境一致性和标准化。 跨云平台支持：越来越多的云平台都已支持容器，用户无需担心受到云平台的捆绑。 环境标准化和版本控制：可使用 Git 等工具对容器镜像进行版本控制。相比基于代码的版本控制来说，还能够对整个应用运行环境实现版本控制，一旦出现故障可以快速回滚。相比以前的虚拟机镜像，容器压缩和备份速度更快，镜像启动也像启动一个普通进程一样快速。 高资源利用率与隔离：容器没有管理程序的额外开销，与底层共享操作系统，性能更优，负载更低。同时，容器拥有不错的资源隔离与限制能力，可以精确的对应用分配 CPU、内存等资源，保证应用之间不会相互影响。 容器跨平台性与镜像：容器在原有 Linux 容器的基础上进行大胆革新，为容器设定了一整套标准化的配置方法，将应用及其依赖的运行环境打包成镜像，大大提高了容器的跨平台性。 易于理解且易用：Docker 的英文原意是处理集装箱的码头工人，标志是鲸鱼运送一大堆集装箱，集装箱就是容器。容器的易用性加速了容器标准化的步伐。 应用镜像仓库：Docker 官方构建了一个镜像仓库，已经累积了成千上万的镜像，所有人都可以自由的下载微服务组件，为开发者提供了巨大便利。 1.3 从容器到容器云容器云以容器为资源分割和调度的基本单位，封装整个软件运行时环境，为开发者和系统管理员提供用于构建、发布和运行分布式应用的平台。 当容器云专注于资源共享与隔离、容器编排与部署时，它更接近传统的 IaaS 当容器云渗透到应用支撑与运行时环境时，它更接近传统的 PaaS 容器云并不仅限于 Docker，基于 rkt 容器的 CoreOS 项目也是容器云。Docker 最初发布时只是一个单机下的容器管理工具，随后 Docker 公司发布了 Compose、Machine、Swarm 等编排部署工具，并收购了 Socketplane 解决集群化后的网络问题。 除了 Docker 公司之外，业界许多云计算厂商也对基于 Docker 的容器云做了巨大的投入。例如 Fleet、Flynn、Deis 以及目前成为事实主流标准的 Kubernetes，都是基于 Docker 技术构建的广为人知的容器云。 2. Docker 基础2.1 Docker 的安装安装 Docker 的基本要求如下： 只支持 64 位 CPU 架构的计算机，目前不支持 32 位 CPU 建议系统的 Linux 内核版本为3.10及以上 Linux 内核需开启 cgroups 和 namespace 功能 安装过程可参考 CentOS 7 安装 Docker CE。 2.2 Docker 操作参数解读 docker命令的执行一般都需要 root 权限，因为 Docker 的命令行工具docker与 Docker daemon 是同一个二进制文件，而 Docker daemon 负责接收并执行来自docker的命令，它的运行需要 root 权限。同时，从 Docker 0.5.2 版本开始，Docker daemon 默认绑定一个 UNIX Socket 来代替原有的 TCP 端口，该 UNIX Socket 默认是属于 root 用户的。 用户在使用 Docker 时，需要使用 Docker 命令行工具docker与 Docker daemon 建立通信。Docker daemon 是 Docker 守护进程，负责接收并分发执行 Docker 命令。可以使用docker或docker help命令获取docker的命令清单： &gt; docker Usage: docker [OPTIONS] COMMAND A self-sufficient runtime for containers Options: --config string Location of client config files (default &quot;/root/.docker&quot;) -D, --debug Enable debug mode -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (&quot;debug&quot;|&quot;info&quot;|&quot;warn&quot;|&quot;error&quot;|&quot;fatal&quot;) (default &quot;info&quot;) --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default &quot;/root/.docker/ca.pem&quot;) --tlscert string Path to TLS certificate file (default &quot;/root/.docker/cert.pem&quot;) --tlskey string Path to TLS key file (default &quot;/root/.docker/key.pem&quot;) --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Management Commands: config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumes 例如可以使用docker start --help命令来获取子命令start的详细信息： &gt; docker start --help Usage: docker start [OPTIONS] CONTAINER [CONTAINER...] Start one or more stopped containers Options: -a, --attach Attach STDOUT/STDERR and forward signals --detach-keys string Override the key sequence for detaching a container -i, --interactive Attach container&#39;s STDIN 推荐阅读： docker专题(2)：docker常用管理命令（上）| Sean’s Notes docker专题(2)：docker常用管理命令（下）| Sean’s Notes 根据命令的用途，可将 Docker 子命令进行如下分类： Docker 子命令分类 从docker命令的使用出发，可以梳理出如下的命令结构图： Docker 命令结构图 下面选择每个功能分类中常用的子命令进行用法和操作参数的解读。 1. Docker 环境信息docker info命令用于检查 Docker 是否正确安装。如果 Docker 正确安装，该命令会输出 Docker 的配置信息： &gt; docker info Containers: 33 Running: 20 Paused: 0 Stopped: 13 Images: 23 Server Version: 18.06.1-ce Storage Driver: overlay2 ... Kernel Version: 4.15.0-38-generic Operating System: Ubuntu 18.04.1 LTS ... docker info命令一般结合docker version命令使用，两者结合能够提取到足够详细的 Docker 环境信息： &gt; docker version Client: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:24:56 2018 OS/Arch: linux/amd64 Experimental: false Server: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:21 2018 OS/Arch: linux/amd64 Experimental: false 2. 容器生命周期管理容器生命周期管理涉及容器启动、停止等功能。 docker run 命令docker run命令使用方法如下： docker run [OPTIONS] IMAGE [COMMAND] [ARG...] docker run命令用来基于特定的镜像创建一个容器，并依据选项来控制该容器： &gt; docker run ubuntu echo &quot;Hello Docker&quot; Hello Docker 该命令从 ubuntu 镜像启动一个容器，并执行echo命令打印 Hello Docker。执行完echo命令后，容器将停止运行。docker run命令启动的容器会随机分配一个容器 IDCONTAINER ID，用以标识该容器。 root@ubuntu:~&gt; docker run -i -t --name mytest ubuntu:latest /bin/bash root@eb9dda25b0fe:/&gt; 上例中，docker run命令启动一个容器，并为它分配一个伪终端执行/bin/bash命令，用户可以在该伪终端与容器进行交互。其中： -i：表示使用交互模式，始终保持输入流开放 -t：表示分配一个伪终端，一般两个参数结合时使用-it --name：可以指定启动的容器的名字。若无此选项，Docker 将为容器随机分配一个名字 -c：用于给运行在容器中的所有进程分配 CPU 的 shares 值，这是一个相对权重，实际处理速度还与宿主机的 CPU 有关 -m：用于限制为容器中所有进程分配的内存总量，以 B、K、M、G 为单位 -v：用于挂载一个 volume，可以用多个-v参数同时挂载多个 volume。volume 的格式为[host-dir]:[container-dir]:[rw|ro] -p：用于将容器的端口暴露给宿主机的端口，其常用格式为hostPort:containerPort。这样外部主机就可以通过宿主机暴露的端口来访问容器内的应用 docker start/stop/restart 命令对于已经存在的容器，可以通过docker start/stop/restart命令来启动、停止和重启，一般利用CONTAINER ID标识来确定具体容器，某些情况下也使用容器名来确定容器。 docker start命令使用-i选项来开启交互模式，并始终保持输入流开放。使用-a选项来附加标准输入、输出或错误输出。此外，docker stop和docker restart命令使用-t选项来设定容器停止前的等待时间。 3. Docker registryDocker registry 是存储容器镜像的仓库，用户可以通过 Docker client 与 Docker registry 进行通信，以此来完成镜像的搜索、下载和上传等相关操作。 Docker Hub 是 Docker 公司官方提供的镜像仓库，提供镜像的公有与私有存储服务，是目前最主要的镜像来源。除此之外，用户还可以自行搭建私有服务器来实现镜像仓库功能。 docker pull 命令用于从 Docker registry 中拉取 image 或 repository： docker pull [OPTIONS] NAME[:TAG @DIGEST] 使用示例如下： # 从官方 Hub 拉取 ubuntu:latest 镜像 &gt; docker pull ubuntu # 从官方 Hub 拉取指明 &quot;ubuntu 16.04&quot; tag 的镜像 &gt; docker pull ubuntu:16.04 # 从特定的仓库拉取 ubuntu 镜像 &gt; docker pull SEL/ubuntu # 从其他服务器拉取镜像 &gt; docker pull 10.10.103.215:5000/sshd docker push 命令用于将本地的 image 或 repository 推送到 Docker Hub 的公共或私有镜像库，以及私有服务器： docker push [OPTIONS] NAME[:TAG] 使用示例如下： &gt; docker push SEL/ubuntu 4. 镜像管理用户可以在本地保存镜像资源，为此 Docker 提供了相应的管理子命令。 docker images 命令通过docker images命令可以列出主机上的镜像，默认只列出最顶层的镜像。使用-a选项可以显示所有镜像： docker images [OPTIONS] [REPOSITORY[:TAG]] 使用示例如下： &gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 16.04 b0ef3016420a 11 days ago 117MB influxdb latest 623f651910b3 7 weeks ago 238MB memcached latest 8230c836a4b3 7 weeks ago 62.2MB mongo 3.2 fb885d89ea5c 7 weeks ago 300MB mist/mailmock latest 95c29bda552f 7 weeks ago 299MB mist/docker-socat latest f00ed0eed13f 7 weeks ago 7.8MB mistce/logstash v3-3-1 0f90a36d12c8 2 months ago 730MB mistce/api v3-3-1 4a21b676352f 2 months ago 705MB mistce/nginx v3-3-1 4f55dd9b39e0 2 months ago 109MB mistce/gocky v3-3-1 ee93caf66f70 2 months ago 440MB mistce/elasticsearch-manage v3-3-1 10a48b9ea0e1 2 months ago 65.8MB mistce/ui v3-3-1 b8fdbe0ccb23 2 months ago 626MB ubuntu-with-vi-dockerfile latest 74ba87f80b96 2 months ago 169MB ubuntu-with-vi latest 9d2fac08719d 2 months ago 169MB ubuntu latest ea4c82dcd15a 2 months ago 85.8MB centos latest 75835a67d134 3 months ago 200MB hello-world latest 4ab4c602aa5e 4 months ago 1.84kB elasticsearch 5.6.10 73e6fdf8bd4f 4 months ago 486MB mistce/landing v3-3-1 b0e433749aa9 5 months ago 532MB kibana 5.6.10 bc661616b61c 5 months ago 389MB hello-world &lt;none&gt; 2cb0d9787c4d 6 months ago 1.85kB traefik v1.5 fde722950ccf 9 months ago 49.7MB mist/swagger-ui latest 0b5230f1b6c4 10 months ago 24.8MB rabbitmq 3.6.6-management c74093aa9895 22 months ago 179MB 上例中，从REPOSITORY属性可以判断出镜像是来自于官方镜像、私人仓库还是私有服务器。 docker rmi/rm 命令docker rmi命令用于删除镜像，docker rm命令用于删除容器。它们可以同时删除多个镜像或容器，也可以按条件来删除： docker rm [OPTIONS] CONTAINER [CONTAINER...] docker rmi [OPTIONS] IMAGE [IMAGE...] 使用docker rmi命令删除镜像时，如果已有基于该镜像启动的容器存在，则无法直接删除，需要首先删除启动的容器。当然，这两个子命令都提供了-f选项，可以强制删除存在容器的镜像或启动中的容器。 5. 容器运维操作作为 Docker 的核心，容器的操作是重中之重，Docker 也为用户提供了丰富的容器运维操作命令。 docker attach 命令docker attach命令可以连接到正在运行的容器，观察该容器的运行情况，或与容器的主进程进行交互： docker attach [OPTIONS] CONTAINER docker inspect 命令docker inspect命令可以查看镜像和容器的详细信息，默认会列出全部信息，可以通过--format参数来指定输出的模板格式，以便输出特定信息： docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...] 具体示例如下： &gt; docker inspect --format=&#39;{{.NetworkSettings.IPAddress}}&#39; ee36 172.17.0.8 docker ps 命令docker ps命令可以查看容器的相关信息，默认只显示正在运行的容器的信息。可以查看到的信息包括CONTAINER ID、NAMES、IMAGE、STATUS、容器启动后执行的COMMAND、创建时间CREATED和绑定开启的端口PORTS： docker ps [OPTIONS] docker ps命令常用的选项有-a和-l。-a选项可以查看所有容器，包括停止的容器。-l选项则只查看最新创建的容器，包括不在运行中的容器。 &gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8befe85aa9b2 ubuntu &quot;/bin/bash&quot; 4 minutes ago Exited (0) 4 minutes ago elegant_hawking eb9dda25b0fe ubuntu:latest &quot;/bin/bash&quot; About an hour ago Exited (0) About an hour ago mytest 33be0880de8a ubuntu &quot;echo &#39;Hello Docker&#39;&quot; About an hour ago Exited (0) About an hour ago loving_neumann 9dbd65001cc2 ubuntu &quot;echo hello&quot; About an hour ago Exited (0) About an hour ago zealous_mendeleev ee10555e84be hello-world &quot;/hello&quot; About an hour ago Exited (0) About an hour ago friendly_mestorf 4219345c98a0 ubuntu-with-vi-dockerfile &quot;/bin/bash&quot; 2 months ago Exited (0) 2 months ago ecstatic_wilson 7257b9828da4 centos &quot;/bin/bash&quot; 2 months ago Exited (0) 2 months ago hopeful_chaplygin 26119a6e11bd centos &quot;/bin/bash&quot; 2 months ago Exited (0) 2 months ago brave_khorana f48bc1339340 ubuntu-with-vi &quot;/bin/bash&quot; 2 months ago Exited (127) 2 months ago agitated_hugle 1abe6e7341ca ubuntu &quot;/bin/bash&quot; 2 months ago Exited (0) 2 months ago laughing_leavitt 5c5eabb13be4 hello-world &quot;/hello&quot; 2 months ago Exited (0) 2 months ago eloquent_wiles 8f2f6854078c 2cb0d9787c4d &quot;/hello&quot; 4 months ago Exited (0) 4 months ago goofy_sinoussi &gt; docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8befe85aa9b2 ubuntu &quot;/bin/bash&quot; 6 minutes ago Exited (0) 6 minutes ago elegant_hawking 6. 其他子命令docker commit 命令docker commit命令可以将一个容器固化为一个新的镜像： docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 提交保存时，只能选用正在运行的容器来制作新的镜像。在制作特定镜像时，直接使用docker commit命令只是一个临时性的辅助命令，不推荐使用。官方建议通过docker build命令结合 Dockerfile 来创建和管理镜像。 docker events/history/logs 命令docker events/history/logs 这 3 个命令用于查看 Docker 的系统日志信息。docker events命令会打印出实时的系统事件。docker history命令会打印出指定镜像的历史版本信息，即构建该镜像的每一层镜像的命令记录。docker logs命令会打印出容器中进程的运行日志： docker events [OPTIONS] docker history [OPTIONS] IMAGE docker logs [OPTIONS] CONTAINER 2.3 搭建第一个 Docker 应用栈Docker 的设计理念是希望用户能够保证一个容器只运行一个进程，即只提供一种服务。通常情况下，用户需要利用多个容器，分别提供不同的服务，并在不同容器间互连通信，最后形成一个 Docker 集群，以实现特定的功能。 基于 Docker 集群构建的应用称为 Docker App Stack，即 Docker 应用栈。 以下示例将在单台机器上利用 Docker 自带的命令行工具，搭建一个 Docker 应用栈，利用多个容器来组成一个特定的应用。 在开始搭建过程前，需要对所要搭建的应用栈进行简单的设计和描述：我们将搭建一个包含 6 个节点的 Docker 应用栈，其中包括 1 个代理节点、2 个 Web 应用节点、1 个主数据库节点及 2 个从数据库节点。应用栈具体结构如下图所示： Docker 应用栈结构图 如图所示，HAProxy 是负载均衡代理节点。Redis 是非关系型的数据库，它由一个主数据库节点和两个从数据库节点组成。App 是应用，这里将使用 Python 语言、基于 Django 架构设计一个访问数据库的基础 Web 应用。 1. 获取应用栈各节点所需镜像在搭建过程中，可以从 Docker Hub 获取现有可用的镜像，在这些镜像的基础上启动容器，按照需求进行修改来实现既定的功能。 &gt; docker pull ubuntu &gt; docker pull django &gt; docker pull haproxy &gt; docker pull redis &gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE haproxy latest d23194a3929a 40 hours ago 72MB redis latest 5d2989ac9711 12 days ago 95MB ubuntu latest 1d9c17228a9e 12 days ago 86.7MB django latest eb40dcf64078 2 years ago 436MB 2. 应用栈容器节点互联鉴于在同一主机下搭建容器应用栈的环境，只需要完成容器互联来实现容器间的通信即可，可以采用docker run命令的--link选项建立容器间的互联关系。使用示例如下： &gt; docker run --link redis:redis --name console ubuntu bash 上例将在 ubuntu 镜像上启动一个容器，并命名为console，同时将新启动的console容器连接到名为redis的容器上。 通过--link选项来建立容器间的连接，不但可以避免容器的 IP 和端口暴露到外网所导致的安全问题，还可以防止容器在重启后 IP 地址变化导致的访问失效，原理类似于 DNS 的域名和地址映射。 回到应用栈的搭建，应用栈各节点的连接信息如下： 启动redis-master容器节点 两个redis-slave容器节点启动时要连接到redis-master上 两个 App 容器节点启动时要连接到redis-master上 HAProxy 容器节点启动时要连接到两个 App 节点上 综上所述，容器的启动顺序为： redis-master --&gt; redis-slave --&gt; APP --&gt; HAProxy 此外，为了能够从外网访问应用栈，并通过 HAProxy 节点来访问应用栈中的 App，在启动 HAProxy 容器节点时，需要利用-p参数暴露端口给主机，即可从外网访问搭建的应用栈。以下是整个应用栈的搭建流程示例。 3. 应用栈容器节点启动# 启动 Redis 容器 &gt; docker run -it --name redis-master redis /bin/bash &gt; docker run -it --name redis-slave1 --link redis-master:master redis /bin/bash &gt; docker run -it --name redis-slave2 --link redis-master:master redis /bin/bash # 启动 Django 容器，即应用 &gt; docker run -it --name APP1 --link redis-master:db -v ~/Projects/Django/App1:/usr/src/app django /bin/bash &gt; docker run -it --name APP2 --link redis-master:db -v ~/Projects/Django/App2:/usr/src/app django /bin/bash # 启动 HAProxy 容器 &gt; docker run -it --name HAProxy --link APP1:APP1 --link APP2:APP2 -p 6301:6301 -v ~/Projects/HAProxy:/tmp haproxy /bin/bash 启动的容器信息可以通过docker ps命令查看： &gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 733e71e16ac5 haproxy &quot;/docker-entrypoint.…&quot; 30 seconds ago Up 29 seconds 0.0.0.0:6301-&gt;6301/tcp HAProxy 3f91ac2a23a6 django &quot;/bin/bash&quot; 47 seconds ago Up 46 seconds APP2 e94c7ff2c319 django &quot;/bin/bash&quot; 3 minutes ago Up 3 minutes APP1 5e7994e6ad59 redis &quot;docker-entrypoint.s…&quot; 5 minutes ago Up 4 minutes 6379/tcp redis-slave2 6fac6db730c3 redis &quot;docker-entrypoint.s…&quot; 8 minutes ago Up 8 minutes 6379/tcp redis-slave1 936c426faa29 redis &quot;docker-entrypoint.s…&quot; 8 minutes ago Up 8 minutes 6379/tcp redis-master 至此，所有搭建应用栈所需容器的启动工作已经完成。 4. 应用栈容器节点的配置Redis Master 主数据库容器节点的配置Redis Master 主数据库容器节点启动后，我们需要在容器中添加 Redis 的启动配置文件，以启动 Redis 数据库。 由于容器的轻量化设计，其中缺乏相应的文本编辑命令工具，这时可以利用 volume 来实现文件的创建。在容器启动时，利用-v参数挂载 volume，在主机和容器之间共享数据，就可以直接在主机上创建和编辑相关文件。 在利用 Redis 镜像启动容器时，镜像中已经集成了 volume 的挂载命令，通过docker inspect命令查看redis-master所挂载 volume 的情况： &gt; docker inspect --format &quot;{{.Mounts}}&quot; redis-master [{volume a77509a99df7d7a9d78313c1a1bb19619bac98fedadd78dbab17f072a49a905c /var/lib/docker/volumes/a77509a99df7d7a9d78313c1a1bb19619bac98fedadd78dbab17f072a49a905c/_data /data local true }] 可以发现，该 volume 在主机中的目录为/var/lib/docker/volumes/a77509a99df7d7a9d78313c1a1bb19619bac98fedadd78dbab17f072a49a905c/_data，在容器中的目录为/data。进入主机目录创建 Redis 的启动配置文件： &gt; cd /var/lib/docker/volumes/a77509a99df7d7a9d78313c1a1bb19619bac98fedadd78dbab17f072a49a905c/_data &gt; cp &lt;your-own-redis-dir&gt;/redis.conf redis.conf &gt; vim redis.conf 对于 Redis 主数据库，需要修改模板文件中的如下几个参数： daemonize yes pidfile /var/run/redis.pid protected-mode no # 关闭保护模式 在主机创建好启动配置文件后，切换到容器中的 volume 目录，并复制redis.conf到 Redis 的执行工作目录，然后启动 Redis 服务器： &gt; cd /data &gt; cp redis.conf /usr/local/bin/ &gt; cd /usr/local/bin/ &gt; redis-server redis.conf Redis Slave 从数据库容器节点的配置与redis-master容器节点类似，在启动redis-slave容器节点后，首先需要查看 volume 信息，然后将redis.conf复制到对应的目录中。不同的是，对于 Redis 从数据库，需要修改如下几个参数： daemonize yes pidfile /var/run/redis.pid protected-mode no # 关闭保护模式 replicaof master 6379 # 之前是 slaveof replicaof参数的使用格式为replicaof &lt;masterip&gt; &lt;masterport&gt; 在主机修改好redis.conf配置文件后，切换到容器中的/data目录，并复制配置文件到 Redis 的执行工作目录，然后启动 Redis 服务器： &gt; cd /data &gt; cp redis.conf /usr/local/bin/ &gt; cd /usr/local/bin/ &gt; redis-server redis.conf 594:C 10 Jan 2019 23:10:43.936 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 594:C 10 Jan 2019 23:10:43.936 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=594, just started 594:C 10 Jan 2019 23:10:43.936 # Configuration loaded 同理，可以完成对另一个 Redis Slave 容器节点的配置。至此，便完成了所有 Redis 数据库容器节点的配置。 Redis 数据库容器节点的测试 完成 Redis Master 和 Redis Slave 容器节点的配置以及服务器的启动后，可以通过启动redis-cli来测试数据库。 首先，在redis-master容器内，启动redis-cli，并存储一个数据： &gt; redis-cli 127.0.0.1:6379&gt; info replication # Replication role:master connected_slaves:2 slave0:ip=172.17.0.3,port=6379,state=online,offset=1260,lag=0 slave1:ip=172.17.0.4,port=6379,state=online,offset=1260,lag=0 master_replid:295c948cc1bbdf21eb49fdd8417ba5b4b76fc32b master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1260 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1260 127.0.0.1:6379&gt; set master 936c OK 127.0.0.1:6379&gt; get master &quot;936c&quot; 随后，在redis-slave1和redis-slave2两个容器中，分别启动redis-cli并查询先前在redis-master数据库中存储的数据： &gt; redis-cli 127.0.0.1:6379&gt; info replication # Replication role:slave master_host:master master_port:6379 master_link_status:up master_last_io_seconds_ago:3 master_sync_in_progress:0 slave_repl_offset:1330 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:295c948cc1bbdf21eb49fdd8417ba5b4b76fc32b master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1330 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:127 repl_backlog_histlen:1204 127.0.0.1:6379&gt; get master &quot;936c&quot; 可以看到redis-master主数据库中的数据已经自动同步到了两个从数据库中。至此，应用栈的数据库部分已搭建完成，并通过测试。 APP 容器节点（ Django）的配置Django 容器启动后，需要利用 Django 框架，开发一个简单的 Web 程序。 为了访问数据库，需要在容器中安装 Python 语言的 Redis 支持包： &gt; pip install redis 安装完成后，验证 Redis 支持包是否安装成功： &gt; python Python 3.4.5 (default, Dec 14 2016, 18:54:20) [GCC 4.9.2] on linux Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; import redis &gt;&gt;&gt; print(redis.__file__) /usr/local/lib/python3.4/site-packages/redis/__init__.py 如果没有报错，就说明已经可以使用 Python 语言来调用 Redis 数据库。接下来开始创建 Web 程序。以APP1为例，首先在容器的 volume 目录/usr/src/app/下创建 APP： # 在容器内 &gt; cd /usr/src/app/ &gt; mkdir dockerweb &gt; cd dockerweb/ &gt; django-admin.py startproject redisweb &gt; ls redisweb &gt; cd redisweb &gt; ls manage.py redisweb &gt; python manage.py startapp helloworld &gt; ls helloworld manage.py redisweb 在容器内创建好 APP 后，切换到主机的 volume 目录~/Projects/Django/App1，进行相应的编辑来配置 APP： # 在主机内 &gt; cd ~/Projects/Django/App1 &gt; ls dockerweb 可以看到，在容器内创建的 APP 文件在主机的 volume 目录下同样可见。之后修改helloworld应用的视图文件views.py： &gt; cd dockerweb/redisweb/helloworld &gt; ls admin.py __init__.py models.py views.py apps.py migrations tests.py &gt; vim views.py 为了简化设计，只要求完成 Redis 数据库信息输出，以及从 Redis 数据库存储和读取数据的结果输出。viwes.py文件如下： from django.shortcuts import render from django.http import HttpResponse # Create your views here. import redis def hello(request): str = redis.__file__ str += &quot;&lt;br&gt;&quot; r = redis.Redis(host=&quot;db&quot;, port=6379, db=0) info = r.info() str += (&quot;Set Hi &lt;br&gt;&quot;) r.set(&#39;Hi&#39;, &#39;HelloWorld-APP1&#39;) str += (&quot;Get Hi: %s &lt;br&gt;&quot; % r.get(&#39;Hi&#39;)) str += (&quot;Redis Info: &lt;br&gt;&quot;) str += (&quot;Key: Info Value&quot;) for key in info: str += (&quot;%s: %s &lt;br&gt;&quot; % (key, info[key])) return HttpResponse(str) 完成views.py文件修改后，接下来修改redisweb项目的配置文件setting.py，并添加新建的helloworld应用： &gt; cd ../redisweb/ &gt; ls __init__.py __pycache__ settings.py urls.py wsgi.py &gt; vim settings.py 在settings.py文件中的INSTALLED_APPS选项下添加 helloworld，并修改ALLOWED_HOSTS： # SECURITY WARNING: don&#39;t run with debug turned on in production! DEBUG = True ALLOWED_HOSTS = [&#39;*&#39;] # Application definition INSTALLED_APPS = [ &#39;django.contrib.admin&#39;, &#39;django.contrib.auth&#39;, &#39;django.contrib.contenttypes&#39;, &#39;django.contrib.sessions&#39;, &#39;django.contrib.messages&#39;, &#39;django.contrib.staticfiles&#39;, &#39;helloworld&#39; ] 此处为了演示方便将ALLOWED_HOSTS设置为[&#39;*&#39;]即允许所有连接，在实际开发环境中请勿按此设置。另外在生产环境中还需将DEBUG选项设置为False。 最后，修改redisweb项目的 URL 模式文件urls.py，它将设置访问应用的 URL 模式，并为 URL 模式调用视图函数之间的映射表： &gt; vim urls.py 在urls.py文件中，引入 helloworld 应用的hello视图，并为hello视图添加一个urlpatterns变量。urls.py文件内容如下： from django.conf.urls import url from django.contrib import admin from helloworld.views import hello urlpatterns = [ url(r&#39;^admin/&#39;, admin.site.urls), url(r&#39;^helloworld$&#39;, hello), ] 在主机下修改完成这几个文件后，需要再次进入APP1容器，在目录/usr/src/app/dockerweb/redisweb下完成项目的生成： &gt; python manage.py makemigrations No changes detected &gt; python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying sessions.0001_initial... OK &gt; python manage.py createsuperuser Username (leave blank to use &#39;root&#39;): admin Email address: admin@gmail.com Password: Password (again): Superuser created successfully. 旧版本的 Django 使用syncdb命令来同步数据库并创建admin账户。在新版 Django 中syncdb命令已被移除，使用createsuperuser命令创建管理员账户。 至此，APP1容器的所有配置已经完成，另一个APP2容器配置也是同样的过程，这样就完成了应用栈 APP 部分的全部配置。 在启动 APP 的 Web 服务器时，可以指定服务器的端口和 IP 地址。为了通过 HAProxy 容器节点接受外网所有的公共 IP 地址访问，实现负载均衡，需要指定服务器的 IP 地址和端口。对于APP1使用 8001 端口，而APP2则使用 8002 端口。同时，都使用0.0.0.0地址。以APP1为例，启动服务器的过程如下： &gt; python manage.py runserver 0.0.0.0:8001 Performing system checks... System check identified no issues (0 silenced). January 11, 2019 - 03:35:58 Django version 1.10.4, using settings &#39;redisweb.settings&#39; Starting development server at http://0.0.0.0:8001/ Quit the server with CONTROL-C. [11/Jan/2019 03:37:01] &quot;GET /helloworld HTTP/1.1&quot; 200 3999 [11/Jan/2019 03:37:14] &quot;GET /admin/ HTTP/1.1&quot; 200 2779 ... HAProxy 容器节点的配置在完成了数据库和 APP 部分的应用栈部署后，最后部署一个 HAProxy 负载均衡代理的容器节点，所有对应用栈的访问将通过它来实现负载均衡。 首先，将 HAProxy 的启动配置文件复制进容器中。在主机的 volume 目录~/Projects/HAProxy下，执行以下命令： &gt; cd ~/Projects/HAProxy &gt; vim haproxy.cfg 其中，haproxy.cfg配置文件的内容如下： global log 127.0.0.1 local0 # 日志输入配置，所有日志都记录在本机，通过 local0 输出 maxconn 4096 # 最大连接数 chroot /usr/local/sbin # 改变当前工作目录 daemon # 以后台形式运行 HAProxy 实例 nbproc 4 # 启动 4 个 HAProxy 实例 pidfile /usr/local/sbin/haproxy.pid # pid 文件位置 defaults log 127.0.0.1 local3 # 日志文件的输出定向 mode http # { tcp|http|health } 设定启动实例的协议类型 option dontlognull # 保证 HAProxy 不记录上级负载均衡发送过来的用于检测状态没有数据的心跳包 option redispatch # 当 serverId 对应的服务器挂掉后，强制定向到其他健康&gt;的服务器 retries 2 # 重试 2 次连接失败就认为服务器不可用，主要通过后面的 check 检查 maxconn 2000 # 最大连接数 balance roundrobin # balance 有两个可用选项：roundrobin 和 source，其中,roundrobin 表示 # 轮询，而 source 表示 HAProxy 不采用轮询的策略，而是把来自某个 IP 的请求转发给一个固定 IP 的后端 timeout connect 5000ms # 连接超时时间 timeout client 50000ms # 客户端连接超时时间 timeout server 50000ms # 服务器端连接超时时间 listen redis_proxy bind 0.0.0.0:6301 stats enable stats uri /haproxy-stats server APP1 APP1:8001 check inter 2000 rise 2 fall 5 # 你的均衡节点 server APP2 aPP2:8002 check inter 2000 rise 2 fall 5 随后，进入到容器的 volume 目录/tmp下，将 HAProxy 的启动配置文件复制到 HAProxy 的工作目录中： # 在容器中 &gt; cd /tmp &gt; cp haproxy.cfg /usr/local/sbin/ &gt; cd /usr/local/sbin/ &gt; ls haproxy haproxy.cfg 接下来利用该配置文件来启动 HAProxy 代理： &gt; haproxy -f haproxy.cfg 另外，如果修改了配置文件的内容，需要先结束所有的 HAProxy 进程，并重新启动代理。Docker 镜像为了精简体积，本身并没有安装ps、killall等进程管理命令，需要手动在容器中安装： &gt; apt-get update &gt; apt-get install procps # ps、pkill &gt; apt-get install psmisc # killall &gt; killall haproxy 至此，完成了 HAProxy 容器节点的全部部署，同时也完成了整个 Docker 应用栈的部署。 应用栈访问测试参考结构图可知，整个应用栈群的访问是通过 HAProxy 代理节点来进行的。HAProxy 在启动时通过-p 6301:6301参数，映射了容器访问的端口到主机上，因此可在其他主机上通过本地主机的 IP 地址和端口来访问搭建好的应用栈。 首先在本地主机上进行测试。在浏览器中访问http://172.17.0.7:6301/helloworld，可以查看来自 APP1 或 APP2 的页面内容，具体访问到的 APP 容器节点会由 HAProxy 代理进行均衡分配。其中，172.17.0.7为 HAProxy 容器的 IP 地址。 访问 APP1 容器节点 访问 APP2 容器节点 本地测试通过后，尝试在其他主机上通过应用栈入口主机的 IP 地址和暴露的 6301 端口来访问该应用栈，即访问http://116.56.129.153:6301/helloworld，可看到来自 APP1 或 APP2 容器节点的页面，访问http://116.56.129.153:6301/haproxy-stats则可看到 HAProxy 的后台管理页面及统计数据。其中，116.56.129.153为 宿主机的 IP 地址。 其他主机访问本地主机 HAProxy 后台管理页面 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Linux 内核笔记 1：绪论在Django中使用migrate初始化数据库数据使用Django+Vue.js快速构建项目","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Redis","slug":"Redis","permalink":"https://abelsu7.top/tags/Redis/"},{"name":"Django","slug":"Django","permalink":"https://abelsu7.top/tags/Django/"},{"name":"HAProxy","slug":"HAProxy","permalink":"https://abelsu7.top/tags/HAProxy/"}]},{"title":"《深度实践 KVM》笔记","slug":"explore-kvm-notes-1","date":"2019-01-08T14:27:04.000Z","updated":"2019-09-01T13:04:11.219Z","comments":true,"path":"2019/01/08/explore-kvm-notes-1/","link":"","permalink":"https://abelsu7.top/2019/01/08/explore-kvm-notes-1/","excerpt":"摘自 《深度实践 KVM》 《深度实践 KVM》","text":"摘自 《深度实践 KVM》 《深度实践 KVM》 更新中~ 🚩推荐阅读（由hexo文章推荐插件驱动）虚拟化相关资料收集半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述影响力数学之美：不能再凑了","categories":[{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/categories/KVM/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"KVM","slug":"KVM","permalink":"https://abelsu7.top/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"},{"name":"QEMU","slug":"QEMU","permalink":"https://abelsu7.top/tags/QEMU/"}]},{"title":"《CentOS 7 系统管理与运维实战》笔记","slug":"centos7-notes","date":"2019-01-08T14:18:48.000Z","updated":"2019-09-01T13:04:11.022Z","comments":true,"path":"2019/01/08/centos7-notes/","link":"","permalink":"https://abelsu7.top/2019/01/08/centos7-notes/","excerpt":"摘自 《CentOS 7系统管理与运维实战》 《CentOS 7系统管理与运维实战》","text":"摘自 《CentOS 7系统管理与运维实战》 《CentOS 7系统管理与运维实战》 更新中~ 1. 预备知识1.1 Linux 版本问题Linux 的内核版本Linux 内核由 C 语言编写，符合 POSIX 标准。但是 Linux 内核并不能称为操作系统，内核只提供基本的设备驱动、文件管理、资源管理等功能，是 Linux 操作系统的核心组件。 Linux 内核版本有稳定版和开发版两种，内核版本号一般由 3 组数字组成，比如 2.6.18 内核版本： 第 1 组数字2表示目前发布的内核主版本 第 2 组数字6表示稳定版本，如为奇数则表示开发中版本 第 3 组数字18表示修改的次数 前两组数字用于描述内核系列，可以通过uname -r查看当前使用的内核版本。 Linux 的发行版本点击查看常见的 Linux 发行版 1.2 CentOS 之于 LinuxCentOS 简介CentOS (Community Enterprise Operating System) 最初是由一个社区主导的操作系统，其来源于另一个最重要的发行版 RHEL (Red Hat Enterprise Linux)。由于 CentOS 是免费的且得到社区的大力支持，因此得到了市场的青睐。 2014 年初，CentOS 和 Red Hat 共同宣布，CentOS 将加入 Red Hat。目前 CentOS 由红帽公司和社区共同维护。 CentOS 7 的最新改进相比与 CentOS 6，CentOS 7 的主要改进之处在于： 内核版本更新为 3.10.0：新版本的内核将对 swap 内存空间进行压缩，显著提高了 I/O 性能；优化 KVM 虚拟化支持；开启固态硬盘和机械硬盘框架，同时使用将会提速；更新和改进了图形、音频驱动等 文件系统方面：默认支持 XFS 文件系统，并更新了 KVM，使其可以支持 ext4 和 XFS 快照 网络方面：支持 Firewalld（动态防火墙）；更新了高性能网络驱动等 支持 Linux 容器 使用 Systemd 替换 SysVinit 2. 安装 CentOS 72.1 系统分区磁盘分区Linux 系统的磁盘分区类型包括： 主分区：可以直接用来存放数据，但一个硬盘上的主分区最多只能有 4 个。 扩展分区：扩展分区也是一种主分区，但不能用来存放数据。可以在扩展分区之上再划分可以存放数据的逻辑分区。 逻辑分区：逻辑分区是在扩展分区基础上建立的，可以用来存放数据。 明确了分区类型的概念之后，安装 CentOS 时还需要制订一个分区方案。在 Windows 系统中，不同的分区被 C、D、E 等盘符替代。但在 Linux 系统中没有盘符的概念，不同的分区被挂载在不同的目录下，目录称为挂载点。只要进入挂载点目录就进入了相应的分区，这样做的好处是用户可以根据需求为某个目录单独扩展空间。 一个最简单的分区方案如下： 引导分区 /boot：创建一个约 300MB~500MB 的分区挂载到/boot目录下，这个分区主要用来存放系统引导时使用的文件。 交换分区 swap：这个分区没有挂载点，大小通常为内存的 2 倍。系统运行时，当物理内存不足时，系统会将内存中不常用的数据存放到 swap 中，即 swap 此时被当作虚拟内存。 根分区 /：根分区的挂载点是/，这个目录是系统的起点，可以将剩余的空间都分到这个分区中。 家目录 /home：用户的家目录，可根据实际需求划分适当容量的分区空间。 静态分区的缺点和逻辑卷管理简介对于普通用户而言，直接对硬盘分区然后挂载这种使用静态分区的方法几乎没有什么问题。但对于某些特定的生产环境而言，这种方法弊大于利。 例如要求不间断运行的数据库中心，这类服务会随着时间增加而逐渐占用大量硬盘空间。如果使用静态分区方案，这类服务会在硬盘空间耗尽后自动停止，即使运维工程师及早发现，也会在更换硬盘时停止服务。因此这类要求不间断运行的服务，最好不要使用静态分区方案。 为了防止需要不间断运行的服务因硬盘空间耗尽而停止，应该采用更加先进的逻辑卷管理（Logical Volume Manager，LVM）方案。LVM 先将硬盘分区转化为物理卷 PV，然后将 PV 组成卷组 VG，然后在卷组的基础上再划分逻辑卷 LV，最后就可以使用逻辑卷来存放数据。 使用 LVM 有以下优点： 可以解决硬盘空间不足，需要停止服务迁移数据的问题。扩容过程是在线进行的，无需停止服务。即使卷组中没有剩余空间，也可以向卷组添加新物理卷为卷组扩容。 当硬盘空间不足时，可以添加更大的硬盘，从而将卷组中那些容量较小的硬盘移出卷组，这个过程也可以在线进行，无需关闭服务。 可以为逻辑卷添加快照卷，利用这一功能可实现数据备份等操作，而无需担心数据的一致性受到影响。 2.2 安装 CentOS 7 安装 CentOS 7 可搜索网上教程，此处略 2.3 Linux 运行级别如果想切换到命令模式，可在进入系统后在终端输入init 3，即可完成运行级别的转变。Linux 运行级别如下表所示： 级别 说明 0 停机 1 单用户模式 2 多用户模式 3 完全多用户模式，服务器一般运行在此级别 4 一般不用，仅在一些特殊情况下使用 5 X11 模式，一般发行版的默认运行级别，可以启动图形桌面系统 6 重新启动 2.4 Linux 目录结构 推荐阅读 Unix 目录结构的来历 | 阮一峰 Linux 的启动流程 | 阮一峰 比起Windows，怎样解读Linux的文件系统与目录结构？| 高效开发运维 Linux 目录结构 | 程序猿 Linux 的目录类似树形结构，任何目录、文件和设备都在根目录/之下。 UNIX 中的树形目录结构 Linux 常见目录如下： 路径 说明 / 根目录，文件系统的最顶端。 /bin 存放系统所需的重要命令。另外 /usr/bin 也存放了一些系统命令，这些命令对应的文件都是可执行的。 /boot 存放 Linux 启动时内核及引导系统程序所需的核心文件。内核文件和 grub 系统引导管理器都位于此目录。 /dev 存放 Linux 系统下的设备文件。访问该目录下的某个文件相当于访问某个硬件设备，常用的是挂载光驱。 /etc 一般存放系统的配置文件，作为一些软件启动默认配置文件的读取目录，例如 /etc/fstab 存放系统分区信息。 /home 系统默认的用户主目录，可以用 HOME 环境变量表示当前用户的主目录。 /lib 主要存放动态链接库.so文件，在 64 位系统中还有 /lib64 目录。类似的目录有 /usr/lib、usr/local/lib 等。 /lost_found 存放一些当系统意外崩溃或意外关机时产生的文件碎片。 /mnt 用于存放挂载存储设备的目录，如光驱、共享存储等。 /proc 存放操作系统运行时的运行信息，如进程信息、内核信息、网络信息等。此目录的内容存在于内存中，实际不占用磁盘空间。如 /proc/cpuinfo 存放 CPU 的相关信息。 /root Linux 超级权限用户 root 的主目录。 /sbin 存放一些系统管理命令，一般只能由 root 用户执行。大多数命令普通用户无权限执行，类似 /sbin/ifconfig，不过使用绝对路径也可执行。类似的目录有 /usr/sbin、/usr/local/sbin。 /tmp 临时文件目录，任何人都可以访问。系统软件或用户运行程序时产生的临时文件都存放在这里。此目录数据需要定期清除。此目录空间不宜过小。 /usr 应用程序存放目录，如命令、帮助文件等。安装 Linux 软件包会默认安装到 /usr/local 目录下，例如 /usr/share/fonts 存放系统字体，/usr/share/man 存放帮助文档，/usr/include 存放软件的头文件等。/usr/local 目录建议单独分区并设置较大的磁盘空间。 /var 这个目录的内容是经常变动的，/var/log 用于存放系统日志，/var/lib 存放系统库文件等。 /sys 目录与/proc类似，是一个虚拟的文件系统，主要记录与系统核心相关的信息，如系统当前已经载入的模块信息等。类似的，这个目录实际不占用磁盘空间。 3. CentOS 7 网络管理技能3.2 网络管理命令3.2.1 pingping 用来测试目标主机或域名是否可达。 &gt; ping abelsu7.top &gt; ping 192.168.3.100 &gt; ping -c 3 192.168.3.100 # -c 指定次数 &gt; ping -c 3 -i 0.01 192.168.3.100 # -i 指定间隔 3.2.2 ifconfigifconfig 命令用于查看、配置、启用或禁用指定网络接口。语法如下： &gt; ifconfig interface [[-net -host] address [parameters]] 例如： &gt; ifconfig docker0 docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:77ff:fefe:d330 prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:77:fe:d3:30 txqueuelen 0 (Ethernet) RX packets 5607 bytes 2293055 (2.1 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6232 bytes 10143929 (9.6 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 输出信息说明： 第 1 行：UP 表示此网络接口为启用状态，RUNNING 表示网卡设备已连接，MULTICAST 表示支持组播，MTU 为数据包最大传输单元 第 2 行：依次为网卡 IP、子网掩码、广播地址 第 3 行：IPv6 地址 第 4 行：Ethernet（以太网）表示连接类型，ether为网卡 MAC 地址 第 5 行：接收数据包个数、大小统计 第 6 行：异常接受包的数量，如丢包量、错误等 第 7 行：发送数据包个数、大小统计信息 第 8 行：异常发送包的数量，如丢包量、错误等 设置 IP 地址使用以下命令： &gt; ifconfig eno1 192.168.100.100 netmask 255.255.255.0 &gt; ifconfig eno1 hw ether 00:0c:29:0b:07:77 # 更改网卡的 MAC 地址 &gt; ifconfig eno1 192.168.100.170/24 UP &gt; ifconfig eno1 down 在 CentOS 和 RHEL 中使用命令ifup和ifdown加网络接口名，可以启用、禁用对应的网络接口。 3.2.3 routeroute 命令用于查看或编辑计算机的 IP 路由表，语法如下： &gt; route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default gateway 0.0.0.0 UG 100 0 0 enp5s0 116.56.129.0 0.0.0.0 255.255.255.0 U 100 0 0 enp5s0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 192.168.122.0 0.0.0.0 255.255.255.0 U 0 0 0 virbr0 # 添加一条路由：发往 192.168.60.0 网段的全部要经过网关 192.168.19.1 &gt; route add -net 192.168.60.0 netmask 255.255.255.0 gw 192.168.19.1 # 删除一条路由，删除的时候不需要指明网关 &gt; route del -net 192.168.60.0 netmask 255.255.255.0 3.2.4 scpscp 命令可以将本地文件传送到远程主机或从远程主机拉取文件到本地。常用参数如下： -P：指定远程连接端口 -q：把进度参数关掉 -r：递归的复制整个文件夹 -V：Verbose。打印排错信息方便问题定位 # 将本地文件传送至远程主机 192.168.3.100 的 /usr 路径下 &gt; scp -P 12345 myfile root@192.168.3.100:/usr # 拉取远程主机文件至本地路径 &gt; scp -P 12345 root@192.168.3.100:/etc/hosts ./ # 使用参数 -r 传送目录 &gt; scp -r -P 12345 root@192.168.3.100:/usr/local/apache2 ./ # 将本地目录传送至远程主机指定目录 &gt; scp -r apache2 root@192.168.3.100:/data 3.2.5 rsyncrsync 是 Linux 系统下常用的数据镜像备份工具，用于在不同的主机之间同步文件。 除了单个文件，rsync 还可以镜像保存整个目录树和文件系统，支持增量同步，并保持文件原有的属性（如权限、时间戳等）。 另外，rsync 的数据传输过程是加密的，可以保证数据的安全性。 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"运维","slug":"运维","permalink":"https://abelsu7.top/tags/运维/"}]},{"title":"《快学 Go 语言》笔记","slug":"quickgo-notes","date":"2019-01-04T02:05:15.000Z","updated":"2019-09-01T13:04:11.631Z","comments":true,"path":"2019/01/04/quickgo-notes/","link":"","permalink":"https://abelsu7.top/2019/01/04/quickgo-notes/","excerpt":"快学 Go 语言 - 老钱 | 知乎专栏《快学 Go 语言》最新内容大全代码在线运行 - 在线工具","text":"快学 Go 语言 - 老钱 | 知乎专栏《快学 Go 语言》最新内容大全代码在线运行 - 在线工具 更新中… 目录 目录 1. 预备知识 Go 语言的「元团队」 Hello World 设置 GOPATH 环境变量 2. 变量 定义变量的三种方式 全局变量和局部变量 变量与常量 指针类型 Go 语言基础类型大全 3. 分支与循环 if else 语句 switch 语句 for 循环 循环控制 4. 数组 数组变量的定义 数组的访问 数组的下标越界检查 数组赋值 数组的遍历 5. 切片 切片的创建 切片的初始化 空切片 切片的赋值 切片的遍历 切片的追加 切片的域是只读的 切片的切割 数组变切片 copy 函数 切片的扩容点 6. 字典 字典的创建 字典的读写 字典 key 不存在会怎么样？ 字典的遍历 线程安全 字典变量里存的是什么？ 7. 字符串 按字节遍历 按字符 rune 遍历 字符串的内存表示 字符串是只读的 字符串的切割 字节切片和字符串的相互转换 8. 结构体 结构体类型的定义 结构体变量的创建 零值结构体和 nil 结构体 结构体的内存大小 结构体的拷贝 结构体中的数组和切片 结构体的参数传递 结构体方法 结构体的指针方法 内嵌结构体 匿名内嵌结构体 Go 语言的结构体没有多态性 9. 接口 空接口 接口变量的本质 用接口来模拟多态 接口的组合继承 接口变量的赋值 指向指针的接口变量 10. 错误和异常 错误接口 错误处理首体验 体验 Redis 的错误处理 异常与捕捉 多个 defer 语句 11. 协程 协程的启动 子协程异常退出 协程的本质 设置线程数 协程的应用 12. 通道 创建通道 读写通道 读写阻塞 关闭通道 通道写安全 多路通道 非阻塞读写 通道内部结构 13. 并发与安全 线程不安全的字典 线程安全的字典 避免锁复制 使用匿名锁字段 使用读写锁 14. 魔术变性指针 unsafe.Pointer 指针的加减运算 切片的内部结构 字符串与切片的高效转换 深入接口变量的赋值 15. 反射 反射的目标 reflect.kind 反射的基础代码 reflect.Type reflect.Value Go 语言官方的反射三大定律 16. 包管理 GOPATH 和 Vendor 系统包路径 全局管理 GOPATH 友好的包路径 编写第一个模块 替换导入包名 无名导入 go get/build/install 局部管理 Vendor 1. 预备知识 摘自《快学 Go 语言》第 1 课 —— Hello World Go 语言的「元团队」很多著名的计算机语言都是那么一两个人业余时间捣鼓出来的，但是 Go 语言是 Google 养着一帮团队打造出来的。这个团队非常豪华，它被称之为 Go Team，成员之一就有大名鼎鼎的 Unix 操作系统的创造者 Ken Thompson，C 语言就是他和已经过世的 Dennis Ritchie 一起发明的。 图中翘着二郎腿的谢顶老头就是 Ken Thompson Hello Worldpackage main import &quot;fmt&quot; func main() { fmt.Println(&quot;hello world!&quot;) } 直接运行源文件main.go： &gt; go run main.go 编译二进制文件： &gt; go build main.go 设置 GOPATH 环境变量环境变量 GOPATH 指向一个目录，以后我们下载的第三方包和我们自己开发的程序代码包都要放在这个目录里面，它就是 Go 语言的工作目录。 当你在源码里使用import语句导入一个包时，编译器都会来 GOPATH 目录下面寻找这个包。 Mac 和 Linux 用户的 GOPATH 通常设置为~/go。将下面环境变量的设置命令追加到~/.bashrc或~/.zshrc的文件末尾，然后重启终端： &gt; export GOPATH=~/go 在 Go 语言的早期版本中，还需要用户设置 GOROOT 环境变量,指代 Go 语言开发包的目录，类似于 Java 语言里面的JAVA_HOME环境变量。不过后来 Go 取消了 GOROOT 的设置，也就是说用户可以不必再操心这个环境变量了，当它不存在就行。 2. 变量 摘自《快学 Go 语言》第 2 课 —— 变量什么的最讨厌了 定义变量的三种方式package main import &quot;fmt&quot; func main() { var s1 int = 42 // 显式定义，可读性最强 var s2 = 42 // 编译器自动推导变量类型 s3 := 42 // 自动推导类型 + 赋值 fmt.Println(s1, s2, s3) } ------------- 42 42 42 如果一个变量很重要，建议使用第一种显式声明类型的方式来定义，比如全局变量的定义就比较偏好第一种定义方式。 如果要使用一个不那么重要的局部变量，就可以使用第三种，比如循环下标变量。 var关键字无法直接写进循环条件的初始化语句中。 for i:=0; i&lt;10; i++ { doSomething() } 如果在第一种声明变量的时候不赋初值，编译器就会自动赋予相应类型的「零值」，不同类型的零值不尽相同，比如字符串的零值不是nil，而是空串，整型的零值就是0，布尔类型的零值是false。 package main import &quot;fmt&quot; func main() { var i int fmt.Println(i) } ----------- 0 全局变量和局部变量局部变量定义在函数内部，函数调用结束就随之消亡。全局变量则定义在函数外部，在程序运行期间会一直存在。 package main import &quot;fmt&quot; var globali int = 24 func main() { var locali int = 42 fmt.Println(globali, locali) } --------------- 24 42 首字母大写的全局变量：公开的全局变量 首字母小写的全局变量：内部的全局变量 内部的全局变量只有当前包内的代码可以访问，外面包的代码是不能看见的。另外，Go 语言没有静态变量。 变量与常量常量关键字const用来定义常量，可以是全局常量也可以是局部常量，大小写规则与变量一致。常量必须初始化，因为它无法二次赋值。不可以对常量进行修改，否则编译器会报错。 package main import &quot;fmt&quot; const globali int = 24 func main() { const locali int = 42 fmt.Println(globali, locali) } --------------- 24 42 指针类型Go 语言被称为互联网时代的 C 语言，它延续使用了 C 语言的指针类型。指针符号*和取地址符&amp;在功能和使用上同 C 语言几乎一模一样。同 C 语言一样，指针还支持二级指针、三级指针，不过在日常应用中很少遇到。 package main import &quot;fmt&quot; func main() { var value int = 42 var p1 *int = &amp;value var p2 **int = &amp;p1 var p3 ***int = &amp;p2 fmt.Println(p1, p2, p3) fmt.Println(*p1, **p2, ***p3) } ---------- 0xc4200160a0 0xc42000c028 0xc42000c030 42 42 42 指针变量本质上就是一个整型变量，里面存储的值是另一个变量的内存地址。*和&amp;符号都只是它的语法糖，是用来在形式上方便使用和理解指针的。*操作符存在两次内存读写，第一次获取指针变量的值，也就是内存地址，然后再去拿这个内存地址所在的变量内容。 指针变量 如果普通变量是一个储物箱，那么指针变量就是另一个储物箱，这个储物箱里存放了普通变量所在储物箱的钥匙。通过多级指针来读取变量值就好比在玩一个解密游戏。 Go 语言基础类型大全package main import &quot;fmt&quot; func main() { // 有符号整数，可以表示正负 var a int8 = 1 // 1 字节 var b int16 = 2 // 2 字节 var c int32 = 3 // 4 字节 var d int64 = 4 // 8 字节 fmt.Println(a, b, c, d) // 无符号整数，只能表示非负数 var ua uint8 = 1 var ub uint16 = 2 var uc uint32 = 3 var ud uint64 = 4 fmt.Println(ua, ub, uc, ud) // int 类型，在32位机器上占4个字节，在64位机器上占8个字节 var e int = 5 var ue uint = 5 fmt.Println(e, ue) // bool 类型 var f bool = true fmt.Println(f) // 字节类型 var j byte = &#39;a&#39; fmt.Println(j) // 字符串类型 var g string = &quot;abcdefg&quot; fmt.Println(g) // 浮点数 var h float32 = 3.14 var i float64 = 3.141592653 fmt.Println(h, i) } ------------- 1 2 3 4 1 2 3 4 5 5 true abcdefg 3.14 3.141592653 97 另外还有几个不太常用的数据类型： 复数类型：complex64和complex128 Unicode 字符类型：rune 指针类型：uinitptr 3. 分支与循环 摘自《快学 Go 语言》第 3 课 —— 分支与循环 程序 = 数据结构 + 算法 上面的等式并不是什么严格的数学公式，它只是对一般程序的简单认知： 数据结构是内存数据关系的静态表示，算法是数据结构从一个状态变化到另一个状态需要执行的机器指令序列； 数据结构是静态的，算法是动态的； 数据结构是状态，算法是状态的变化。 if else 语句Go 语言没有三元操作符a &gt; b ? a : b，另外分支与循环语句的条件也不需要用括号括起来。 package main import &quot;fmt&quot; func main() { fmt.Println(sign(max(min(24, 42), max(24, 42)))) } func max(a int, b int) int { if a &gt; b { return a } return b } func min(a int, b int) int { if a &lt; b { return a } return b } func sign(a int) int { if a &gt; 0 { return 1 } else if a &lt; 0 { return -1 } else { return 0 } } ------------ 1 switch 语句switch 语句有两种匹配模式：一种是变量值匹配，另一种是表达式匹配。 package main import &quot;fmt&quot; func main() { fmt.Println(prize1(60)) fmt.Println(prize2(60)) } // 值匹配 func prize1(score int) string { switch score / 10 { case 0, 1, 2, 3, 4, 5: return &quot;差&quot; case 6, 7: return &quot;及格&quot; case 8: return &quot;良&quot; default: return &quot;优&quot; } } // 表达式匹配 func prize2(score int) string { // 注意 switch 后面什么也没有 switch { case score &lt; 60: return &quot;差&quot; case score &lt; 80: return &quot;及格&quot; case score &lt; 90: return &quot;良&quot; default: return &quot;优&quot; } } for 循环Go 语言虽然没有提供 while 和 do while 语句，不过这两个语句都可以使用 for 循环的形式来模拟。平时使用 while 语句来写死循环while (true) {}，Go 语言可以这么写： package main import &quot;fmt&quot; func main() { for { fmt.Println(&quot;hello world!&quot;) } } 或者： package main import &quot;fmt&quot; func main() { for true { fmt.Println(&quot;hello world!&quot;) } } for 什么条件也不带的，相当于 loop 语句。for 带一个条件的，相当于 while 语句。for 带三个条件的就是普通的 for 语句。 package main import &quot;fmt&quot; func main() { for i := 0; i &lt; 10; i++ { fmt.Println(&quot;hello world!&quot;) } } 循环控制Go 语言支持 continue 和 break 语句来控制循环，除此之外还支持 goto 语句。 4. 数组 摘自《快学 Go 语言》第 4 课 —— 低调的数组 Go 语言里面的数组其实很不常用，这是因为数组是定长静态的，一旦定义好长度就无法更改，而且不同长度的数组属于不同的类型，之间不能相互转换与赋值，用起来多有不便。 切片 (slice) 是动态的数组，是可以扩充内容增加长度的数组。当切片长度不变时，用起来和普通数组一样。当长度不同时，它们也属于相同的类型，之间可以相互赋值。这就决定了数组的应用领域都广泛的被切片取代了。 在切片的底层实现中，数组是切片的基石，是切片的特殊语法隐藏了内部的细节，让用户不能直接看到内部隐藏的数组。可以说切片是数组的一个包装。 数组变量的定义只声明类型，不赋初值，这时编译器会给数组默认赋上「零值」。 package main import &quot;fmt&quot; func main() { var a [9]int fmt.Println(a) } ------------ [0 0 0 0 0 0 0 0 0] 另外三种变量定义形式如下，效果都是一样的的： package main import &quot;fmt&quot; func main() { var a = [9]int{1, 2, 3, 4, 5, 6, 7, 8, 9} var b [10]int = [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} c := [8]int{1, 2, 3, 4, 5, 6, 7, 8} fmt.Println(a) fmt.Println(b) fmt.Println(c) } --------------------- [1 2 3 4 5 6 7 8 9] [1 2 3 4 5 6 7 8 9 10] [1 2 3 4 5 6 7 8] 数组的访问使用下标访问数组中的元素： package main import &quot;fmt&quot; func main() { var squares [9]int for i := 0; i &lt; len(squares); i++ { squares[i] = (i + 1) * (i + 1) } fmt.Println(squares) } -------------------- [1 4 9 16 25 36 49 64 81] 数组的下标越界检查Go 语言会对数组访问下标越界进行编译器检查： package main import &quot;fmt&quot; func main() { var a = [5]int{1,2,3,4,5} a[101] = 255 fmt.Println(a) } ----- ./main.go:7:3: invalid array index 101 (out of bounds for 5-element array) 而当数组下标是变量时，Go 会在编译后的代码中插入下标越界检查的逻辑，在运行时也会提示数组下标越界。所以数组的下标访问效率是要打折扣的，比不上 C 语言的数组访问性能。 package main import &quot;fmt&quot; func main() { var a = [5]int{1,2,3,4,5} var b = 101 a[b] = 255 fmt.Println(a) } ------------ panic: runtime error: index out of range goroutine 1 [running]: main.main() /Users/qianwp/go/src/github.com/pyloque/practice/main.go:8 +0x3d exit status 2 数组赋值同样的子元素类型并且是同样长度的数组才可以相互赋值，否则就是不同的数组类型，不能赋值。数组的赋值本质上是一种浅拷贝操作，赋值的两个数组变量的值不会共享。 package main import &quot;fmt&quot; func main() { var a = [9]int{1, 2, 3, 4, 5, 6, 7, 8, 9} var b [9]int b = a a[0] = 12345 fmt.Println(a) fmt.Println(b) } -------------------------- [12345 2 3 4 5 6 7 8 9] [1 2 3 4 5 6 7 8 9] 从上面代码的运行结果中可以看出赋值后的两个数组并没有共享内部元素。如果数组的长度很大，那么拷贝操作是有一定的开销的，使用的时候要多加注意。 数组的遍历数组除了可以使用下标进行遍历之外，还可以使用range关键字来进行遍历。range遍历提供了下面两种形式： package main import &quot;fmt&quot; func main() { var a = [5]int{1,2,3,4,5} for index := range a { fmt.Println(index, a[index]) } for index, value := range a { fmt.Println(index, value) } } ------------ 0 1 1 2 2 3 3 4 4 5 0 1 1 2 2 3 3 4 4 5 5. 切片 摘自《快学 Go 语言》第 5 课 —— 神奇的切片 学过 Java 语言的人会比较容易理解切片，因为它的内部结构非常类似于 ArrayList，ArrayList 的内部实现也是一个数组。当数组容量不够需要扩容时，就会换新的数组，还需要将老数组的内容拷贝到新数组。ArrayList 内部有两个非常重要的属性capacity和length。capacity表示内部数组的总长度，length表示当前已经使用的数组的长度。length永远不能超过capacity。 Go 语言中的切片 上图中的一个切片变量包含三个域，分别是底层数组的指针、切片的长度length和切片的容量capacity。切片支持 append 操作可以将新内容追加到底层数组，也就是填充上图中的灰色格子。如果格子满了，切片就需要扩容，底层的数组就会更换。 切片的创建切片的创建有多种方式，先来看最通用的创建方法，那就是内置的 make 函数： package main import &quot;fmt&quot; func main() { var s1 []int = make([]int, 5, 8) var s2 []int = make([]int, 8) // 满容切片 fmt.Println(s1) fmt.Println(s2) } ------------- [0 0 0 0 0] [0 0 0 0 0 0 0 0] 使用 make 函数创建切片，需要提供三个参数：切片的类型、切片的长度和容量。其中第三个参数是可选的，如果不声明切片的容量，那么长度和容量相等，也就是说切片是满容的。 切片和普通变量一样，也可以使用类型自动推导，省区类型定义以及var关键字： package main import &quot;fmt&quot; func main() { var s1 = make([]int, 5, 8) s2 := make([]int, 8) fmt.Println(s1) fmt.Println(s2) } ------------- [0 0 0 0 0] [0 0 0 0 0 0 0 0] 切片的初始化使用 make 函数创建的切片内容是「零值切片」，也就是内部数组的元素都是零值。Go 语言还提供了另一种创建切片的语法，允许我们给它赋初值，使用这种方式创建的切片是满容的： package main import &quot;fmt&quot; func main() { var s []int = []int{1,2,3,4,5} // 满容的 fmt.Println(s, len(s), cap(s)) } --------- [1 2 3 4 5] 5 5 Go 语言提供了内置函数len()和cap()可以直接获得切片的长度和容量属性。 空切片在创建切片时，还有两个非常特殊的情况需要考虑，那就是容量和长度都是零的切片，叫做「空切片」。这个不同与之前提到的「零值切片」。 package main import &quot;fmt&quot; func main() { var s1 []int var s2 []int = []int{} var s3 []int = make([]int, 0) fmt.Println(s1, s2, s3) fmt.Println(len(s1), len(s2), len(s3)) fmt.Println(cap(s1), cap(s2), cap(s3)) } ----------- [] [] [] 0 0 0 0 0 0 上面三种形式创建的切片都是「空切片」，不过在内部结构上这三种形式还是有所差异的，准确来说第一种应该称为「nil 切片」，但是二者形式上几乎一模一样，用起来差不多没有区别，所以初级用户暂时可以不必区分。 切片的赋值切片的赋值是一次浅拷贝操作，拷贝的是切片变量的三个域。拷贝前后两个变量共享底层数组，对一个切片的修改会影响另一个切片的内容。 package main import &quot;fmt&quot; func main() { var s1 = make([]int, 5, 8) // 切片的访问和数组差不多 for i := 0; i &lt; len(s1); i++ { s1[i] = i + 1 } var s2 = s1 fmt.Println(s1, len(s1), cap(s1)) fmt.Println(s2, len(s2), cap(s2)) // 尝试修改切片内容 s2[0] = 255 fmt.Println(s1) fmt.Println(s2) } -------- [1 2 3 4 5] 5 8 [1 2 3 4 5] 5 8 [255 2 3 4 5] [255 2 3 4 5] 从上面的输出可以看到赋值的两切片共享了底层数组。 切片的遍历切片在遍历的语法上和数组是一样的，除了支持下标遍历外，那就是使用 range 关键字。 package main import &quot;fmt&quot; func main() { var s = []int{1,2,3,4,5} for index := range s { fmt.Println(index, s[index]) } for index, value := range s { fmt.Println(index, value) } } -------- 0 1 1 2 2 3 3 4 4 5 0 1 1 2 2 3 3 4 4 5 切片的追加之前有提到切片是动态的数组，其长度是可以变化的，可以通过追加操作来改变切片的长度。 切片每一次追加后都会形成新的切片变量，如果底层数组没有扩容，那么追加前后的两个切片变量就共享底层数组；如果底层数组扩容了，那么追加前后的底层数组是分离的不共享的。 如果底层数组是共享的，那么一个切片的内容变化就会影响到另一个切片，这点需要特别注意。 package main import &quot;fmt&quot; func main() { var s1 = []int{1,2,3,4,5} fmt.Println(s1, len(s1), cap(s1)) // 对满容的切片进行追加会分离底层数组 var s2 = append(s1, 6) fmt.Println(s1, len(s1), cap(s1)) fmt.Println(s2, len(s2), cap(s2)) // 对非满容的切片进行追加会共享底层数组 var s3 = append(s2, 7) fmt.Println(s2, len(s2), cap(s2)) fmt.Println(s3, len(s3), cap(s3)) } -------------------------- [1 2 3 4 5] 5 5 [1 2 3 4 5] 5 5 [1 2 3 4 5 6] 6 10 [1 2 3 4 5 6] 6 10 [1 2 3 4 5 6 7] 7 10 正是因为切片追加后是新的切片变量，所以 Go 编译器禁止追加了切片后不使用这个新的切片变量，以避免用户以为追加操作的返回值和原切片变量是同一个变量。 package main import &quot;fmt&quot; func main() { var s1 = []int{1,2,3,4,5} append(s1, 6) fmt.Println(s1) } -------------- ./main.go:7:8: append(s1, 6) evaluated but not used 如果真的不需要使用这个新的变量，可以将 append 的结果赋值给下划线变量_。 下划线变量_是 Go 语言特殊的内置变量，它就像一个黑洞，可以将任意变量赋值给它，但是却不能读取这个特殊变量。 package main import &quot;fmt&quot; func main() { var s1 = []int{1,2,3,4,5} _ = append(s1, 6) fmt.Println(s1) } ---------- [1 2 3 4 5] 还需要注意的是追加虽然会导致底层数组发生扩容、更换的新的数组，但是旧数组并不会立即被销毁被回收，因为老切片还指向着旧数组。 切片的域是只读的 需要仔细思考 我们刚才说切片的长度是可以变化的，为什么又说切片是只读的呢？这不是矛盾么。这是为了提醒读者注意切片追加后形成了一个新的切片变量，而老的切片变量的三个域其实并不会改变，改变的只是底层的数组。这里说的是切片的「域」是只读的，而不是说切片是只读的。切片的「域」就是组成切片变量的三个部分，分别是底层数组的指针、切片的长度和切片的容量。 切片的切割切片的切割可以类比字符串的子串，它并不是要把切片割断，而是从母切片中拷贝一个子切片出来，子切片和母切片共享底层数组。 package main import &quot;fmt&quot; func main() { var s1 = []int{1,2,3,4,5,6,7} // start_index 和 end_index，不包含 end_index // [start_index, end_index) var s2 = s1[2:5] fmt.Println(s1, len(s1), cap(s1)) fmt.Println(s2, len(s2), cap(s2)) } ------------ [1 2 3 4 5 6 7] 7 7 [3 4 5] 3 5 上面的输出需要特别注意的是：既然切割前后共享底层数据，那为什么容量不一样呢？下图可以解释这个问题。 切片的切割 可以注意到子切片的内部数据指针指向了数组的中间位置，而不再是数组的开头了。子切片容量的大小是从中间的位置开始直到切片末尾的长度，母子切片依旧共享底层数组。 子切片语法上要提供起始和结束位置，这两个位置都是可选的。不提供起始位置，默认就是从母切片的初始位置开始（不是底层数组的初始位置）。不提供结束位置，默认就结束到母切片尾部（是长度线，不是容量线）。 package main import &quot;fmt&quot; func main() { var s1 = []int{1, 2, 3, 4, 5, 6, 7} var s2 = s1[:5] var s3 = s1[3:] var s4 = s1[:] fmt.Println(s1, len(s1), cap(s1)) fmt.Println(s2, len(s2), cap(s2)) fmt.Println(s3, len(s3), cap(s3)) fmt.Println(s4, len(s4), cap(s4)) } ----------- [1 2 3 4 5 6 7] 7 7 [1 2 3 4 5] 5 7 [4 5 6 7] 4 4 [1 2 3 4 5 6 7] 7 7 上面的s1[:]与普通的切片赋值没有区别，同样是共享底层数组，同样是浅拷贝。另外，Go 语言中切片的下标不支持负数。 数组变切片对数组进行切割可以转换成切片。切片将原数组作为内部底层数组，也就是说修改了原数组会影响到新切片，对切片的修改也会影响到原数组。 package main import &quot;fmt&quot; func main() { var a = [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} var b = a[2:6] fmt.Println(b) a[4] = 100 fmt.Println(b) } ------- [3 4 5 6] [3 4 100 6] copy 函数Go 语言还内置了一个 copy 函数，用来进行切片的深拷贝。不过其实也没那么深，只是深到底层的数组而已。如果数组里面装的是指针，比如[]*int类型，那么指针指向的内容还是共享的。 func copy(dst, src []T) int copy 函数不会因为原切片和目标切片的长度问题而额外分配底层数组的内存，它只负责拷贝数组的内容，从原切片拷贝到目标切片，拷贝的量是原切片和目标切片长度的较小值min(len(src), len(dst))，函数返回的是拷贝的实际长度。 package main import &quot;fmt&quot; func main() { var s = make([]int, 5, 8) for i:=0;i&lt;len(s);i++ { s[i] = i+1 } fmt.Println(s) var d = make([]int, 2, 6) var n = copy(d, s) fmt.Println(n, d) } ----------- [1 2 3 4 5] 2 [1 2] 切片的扩容点当比较短的切片扩容时，系统会多分配 100% 的空间，也就是说分配的数组容量是切片长度的 2 倍。但当切片长度超过 1024 时，扩容策略调整为多分配 25% 的空间，这是为了避免空间的过多浪费。 package main import &quot;fmt&quot; func main() { s1 := make([]int, 6) s2 := make([]int, 1024) s1 = append(s1, 1) s2 = append(s2, 2) fmt.Println(len(s1), cap(s1)) fmt.Println(len(s2), cap(s2)) } ------------------------------------------- 7 12 1025 1344 6. 字典 摘自《快学 Go 语言》第 6 课 —— 字典 数组切片让我们具备了可以操作一块连续内存的能力，它是对同质元素的统一管理。而字典则赋予了不连续不同类的内存变量的关联性，它表达的是一种因果关系，字典的 key 是因，字典的 value 是果。 指针、数组切片和字典都是容器型变量。字典比数组切片在使用上要简单很多，但是内部结构却非常复杂。 字典的创建在创建字典时，必须要给 key 和 value 指定类型。创建字典也可以使用 make 函数： package main import &quot;fmt&quot; func main() { var m map[int]string = make(map[int]string) fmt.Println(m, len(m)) } ---------- map[] 0 使用 make 函数创建的字典是空的，长度为零，内部没有任何元素。如果需要给字典提供初始化的元素，就需要使用另一种创建字典的方式： package main import &quot;fmt&quot; func main() { var m map[int]string = map[int]string{ 90: &quot;优秀&quot;, 80: &quot;良好&quot;, 60: &quot;及格&quot;, // 注意这里逗号不可缺少，否则会报语法错误 } fmt.Println(m, len(m)) } --------------- map[90:优秀 80:良好 60:及格] 3 字典变量同样支持类型推导，上面的变量定义可以简写成： var m = map[int]string { 90: &quot;优秀&quot;, 80: &quot;良好&quot;, 60: &quot;及格&quot;, } 如果提前知道字典内部键值对的数量，那么还可以给 make 函数传递一个整数值，通知运行时提前分配好相应的内存，这样可以避免字典在长大的过程中要经历的多次扩容操作： var m = make(map[int]string, 16) 字典的读写字典可以使用中括号[]来读写内部元素，使用 delete 函数来删除元素： package main import &quot;fmt&quot; func main() { var fruits = map[string]int { &quot;apple&quot;: 2, &quot;banana&quot;: 5, &quot;orange&quot;: 8, } // 读取元素 var score = fruits[&quot;banana&quot;] fmt.Println(score) // 增加或修改元素 fruits[&quot;pear&quot;] = 3 fmt.Println(fruits) // 删除元素 delete(fruits, &quot;pear&quot;) fmt.Println(fruits) } ----------------------- 5 map[apple:2 banana:5 orange:8 pear:3] map[orange:8 apple:2 banana:5] 字典 key 不存在会怎么样？删除操作时，如果对应的 key 不存在，delete 函数会静默处理。读操作时，如果 key 不存在，也不会抛出异常，它会返回 value 类型对应的零值。 可以通过字典的特殊语法来判断对应的 key 是否存在： package main import &quot;fmt&quot; func main() { var fruits = map[string]int { &quot;apple&quot;: 2, &quot;banana&quot;: 5, &quot;orange&quot;: 8, } var score, ok = fruits[&quot;durin&quot;] if ok { fmt.Println(score) } else { fmt.Println(&quot;durin not exists&quot;) } fruits[&quot;durin&quot;] = 0 score, ok = fruits[&quot;durin&quot;] if ok { fmt.Println(score) } else { fmt.Println(&quot;durin still not exists&quot;) } } ------------- durin not exists 0 字典的下标读取可以返回两个值，使用第二个返回值都表示对应的 key 是否存在。它只是 Go 语言提供的语法糖，内部并没有太多的玄妙。 正常的函数调用可以返回多个值，但是并不具备这种“随机应变”的特殊能力 —— 「多态返回值」。 字典的遍历字典的遍历提供了以下两种方式：一种是需要携带 value，另一种是只需要 key，需要使用到 Go 语言的 range 关键字： package main import &quot;fmt&quot; func main() { var fruits = map[string]int { &quot;apple&quot;: 2, &quot;banana&quot;: 5, &quot;orange&quot;: 8, } for name, score := range fruits { fmt.Println(name, score) } for name := range fruits { fmt.Println(name) } } ------------ orange 8 apple 2 banana 5 apple banana orange 然而，Go 语言的字典并没有提供例如keys()或values()这样的方法，意味着如果要获取 key 列表，就得自己循环一下： package main import &quot;fmt&quot; func main() { var fruits = map[string]int { &quot;apple&quot;: 2, &quot;banana&quot;: 5, &quot;orange&quot;: 8, } var names = make([]string, 0, len(fruits)) var scores = make([]int, 0, len(fruits)) for name, score := range fruits { names = append(names, name) scores = append(scores, score) } fmt.Println(names, scores) } ---------- [apple banana orange] [2 5 8] 注意：遍历的时候，直接得到的 value 是拷贝过后的，会影响性能。在遍历中，使用map[key]的方式可以直接用索引获取数据，速度要比使用 value 快将近一倍，但要注意指针安全的问题。 线程安全Go 语言的内置字典不是线程安全的，如果需要线程安全，必须使用锁来控制。 字典变量里存的是什么？字典变量里存的只是一个地址指针，这个指针指向字典的头部对象。所以字典变量占用的空间是一个字，也就是一个指针的大小，64 位机器是 8 字节，32 位机器是 4 字节。 字典变量中的地址指针 可以使用 unsafe 包提供的Sizeof函数来计算一个变量的大小： package main import ( &quot;fmt&quot; &quot;unsafe&quot; ) func main() { var m = map[string]int{ &quot;apple&quot;: 2, &quot;pear&quot;: 3, &quot;banana&quot;: 5, } fmt.Println(unsafe.Sizeof(m)) } ------ 8 7. 字符串 摘自《快学 Go 语言》第 7 课 —— 字符串 字符串通常有两种设计，一种是「字符」串，一种是「字节」串。「字符」串中的每个字都是定长的，而「字节」串中每个字是不定长的。Go 语言里的字符串是「字节」串，英文字符占用 1 个字节，非英文字符占多个字节。这意味着无法通过位置来快速定位出一个完整的字符来，而必须通过遍历的方式来逐个获取单个字符。 我们所说的字符通常是指 unicode 字符，一个 unicode 字符通常用 4 个字节来表示，对应的 Go 语言中的字符 rune 占 4 个字节。 在 Go 语言的源码中可以看到，rune 类型是一个衍生类型，它在内存里面使用int32类型的 4 个字节存储。 type rune int32 字节 byte 和字符 rune 的关系 其中 codepoint 是每个「字」的实际偏移量。Go 语言的字符串采用 utf-8 编码，中文汉字通常需要占用 3 个字节，英文只需要 1 个字节。len()函数得到的是字节的数量，通过下标来访问字符串得到的是「字节」。 按字节遍历字符串可以通过下标来访问内部字节数组具体位置上的字节，字节是 byte 类型： package main import &quot;fmt&quot; func main() { var s = &quot;嘻哈china&quot; for i:=0;i&lt;len(s);i++ { fmt.Printf(&quot;%x &quot;, s[i]) } } ----------- e5 98 bb e5 93 88 63 68 69 6e 61 按字符 rune 遍历package main import &quot;fmt&quot; func main() { var s = &quot;嘻哈china&quot; for codepoint, runeValue := range s { fmt.Printf(&quot;%d %d &quot;, codepoint, int32(runeValue)) } } ----------- 0 22075 3 21704 6 99 7 104 8 105 9 110 10 97 对字符串进行 range 遍历，每次迭代出两个变量codepoint和runeValue，codepoint 表示字符起始位置，runeValue表示对应的 unicode 编码（类型是 rune）。 字符串的内存表示 字符串的内存结构 字符串的内存结构不仅包含前面提到的字节数组，编译器还为它分配了头部字段来存储 长度信息 和 指向底层字节数组的指针，如上图所示，结构非常类似于切片，区别是头部少了一个容量字段。 字符串是只读的可以使用下标来读取字符串指定位置的字节，但是无法修改这个位置上的字节内容。如果尝试使用下标赋值，编译器在语法上直接拒绝： package main func main() { var s = &quot;hello&quot; s[0] = &#39;H&#39; } -------- ./main.go:5:7: cannot assign to s[0] 字符串的切割字符串在内存形式上比较接近于切片，它也可以像切片一样进行切割来获取子串。子串和母串共享底层字节数组。 package main import &quot;fmt&quot; func main() { var s1 = &quot;hello world&quot; var s2 = s1[3:8] fmt.Println(s2) } ------- lo wo 字节切片和字符串的相互转换在使用 Go 语言进行网络编程时，经常需要将来自网络的字节流转换成内存字符串，同时也需要将内存字符串转换成网络字节流。Go 语言直接内置了字节切片和字符串的相互转换语法： package main import &quot;fmt&quot; func main() { var s1 = &quot;hello world&quot; var b = []byte(s1) // 字符串转字节切片 var s2 = string(b) // 字节切片转字符串 fmt.Println(b) fmt.Println(s2) } -------- [104 101 108 108 111 32 119 111 114 108 100] hello world 注意：字节切片和字符串的底层字节数组不是共享的，底层字节数组会被拷贝。这是因为字节切片的底层数组内容是可以修改的，而字符串的底层字节数组是只读的，如果共享了，就会导致字符串的只读属性不再成立。 8. 结构体 摘自《快学 Go 语言》第 8 课 —— 结构体 Go 语言结构体里面装的是基础类型、数组、切片、字典以及其他类型结构体等。 Go 语言中的结构体 结构体类型的定义结构体和其它高级语言里的「类」比较相似： type Circle struct { x int y int Radius int } 需要特别注意的是结构体内部变量的大小写，首字母大写是公开变量，首字母小写是内部变量，分别相当于类成员变量的 public 和 private 类别。内部变量只有属于同一个 package 的代码才能直接访问。 结构体变量的创建最常见的创建形式是「KV 形式」，通过显式指定结构体内部字段的名称和初始值来初始化结构体，没有指定初值的字段会自动初始化为相应类型的「零值」： package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func main() { var c1 Circle = Circle{ x: 100, y: 100, Radius: 50, } var c2 Circle = Circle{ Radius: 50, } var c3 Circle = Circle{} fmt.Printf(&quot;%+v\\n&quot;, c1) fmt.Printf(&quot;%+v\\n&quot;, c2) fmt.Printf(&quot;%+v\\n&quot;, c3) } ---------- {x:100 y:100 Radius:50} {x:0 y:0 Radius:50} {x:0 y:0 Radius:0} 结构体的第二种创建形式是不指定字段名称来顺序字段初始化，需要显式提供所有字段的初值，一个都不能少。这种形式称之为「顺序形式」： package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func main() { var c Circle = Circle{100, 100, 50} fmt.Printf(&quot;%+v\\n&quot;, c) } ------- {x:100 y:100 Radius:50} 结构体变量和普通变量都有指针形式，使用取地址符&amp;就可以得到结构体的指针类型： package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func main() { var c *Circle = &amp;Circle{100, 100, 50} fmt.Printf(&quot;%+v\\n&quot;, c) } ----------- &amp;{x:100 y:100 Radius:50} 结构体变量创建的第三种形式是使用全局的new()函数来创建一个「零值」结构体，所有字段都被初始化为相应类型的零值： package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func main() { var c *Circle = new(Circle) fmt.Printf(&quot;%+v\\n&quot;, c) } ---------- &amp;{x:0 y:0 Radius:0} 第四种创建形式也是零值初始化： package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func main() { var c Circle fmt.Printf(&quot;%+v\\n&quot;, c) } ---------- {x:0 y:0 Radius:0} 三种零值初始化形式对比： var c1 Circle = Circle{} var c2 Circle var c3 *Circle = new(Circle) 零值结构体和 nil 结构体nil 结构体是指结构体指针变量没有指向一个实际存在的内存。这样的指针变量只会占用 1 个指针的存储空间，也就是一个机器字的内存大小。 var c *Circle = nil 而零值结构体则会实际占用内存空间，只不过每个字段都是零值。 结构体的内存大小Go 语言的 unsafe 包提供了获取结构体内存占用的函数Sizeof()： package main import &quot;fmt&quot; import &quot;unsafe&quot; type Circle struct { x int y int Radius int } func main() { var c Circle = Circle{Radius: 50} fmt.Println(unsafe.Sizeof(c)) } ------- 24 64 位机器上每个 int 类型都是 8 字节。而 32 位机器上，Circle 结构体就只会占用 12 字节。 结构体的拷贝结构体之间可以相互赋值，本质上是一次浅拷贝操作，拷贝了结构体内部的所有字段。 结构体指针之间也可以相互赋值，本质上也是一次浅拷贝操作，不过它拷贝的仅仅是指针地址值，结构体的内容是共享的。 package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func main() { var c1 Circle = Circle{Radius: 50} var c2 Circle = c1 fmt.Printf(&quot;%+v\\n&quot;, c1) fmt.Printf(&quot;%+v\\n&quot;, c2) c1.Radius = 100 fmt.Printf(&quot;%+v\\n&quot;, c1) fmt.Printf(&quot;%+v\\n&quot;, c2) var c3 *Circle = &amp;Circle{Radius: 50} var c4 *Circle = c3 fmt.Printf(&quot;%+v\\n&quot;, c3) fmt.Printf(&quot;%+v\\n&quot;, c4) c3.Radius = 100 fmt.Printf(&quot;%+v\\n&quot;, c3) fmt.Printf(&quot;%+v\\n&quot;, c4) } ---------------------- {x:0 y:0 Radius:50} {x:0 y:0 Radius:50} {x:0 y:0 Radius:100} {x:0 y:0 Radius:50} &amp;{x:0 y:0 Radius:50} &amp;{x:0 y:0 Radius:50} &amp;{x:0 y:0 Radius:100} &amp;{x:0 y:0 Radius:100} 通过观察 Go 语言的底层源码，可以发现所有的 Go 语言内置的高级数据结构都是由结构体来完成的。 结构体中的数组和切片之前分析了数组与切片在内存形式上的区别：数组只有「体」，切片除了「体」之外，还有「头」部。切片的头部和内容体是分离的，使用指针关联起来。 package main import &quot;fmt&quot; import &quot;unsafe&quot; type ArrayStruct struct { value [10]int } type SliceStruct struct { value []int } func main() { var as = ArrayStruct{[...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}} var ss = SliceStruct{[]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}} fmt.Println(unsafe.Sizeof(as), unsafe.Sizeof(ss)) } ------------- 80 24 注意代码中的数组初始化使用了[...]语法糖，表示让编译器自动推导数组的长度。 结构体的参数传递函数调用时参数传递结构体变量，值传递涉及到结构体字段的浅拷贝，指针传递则会共享结构体内容，只拷贝指针地址，规则上和赋值是等价的： package main import &quot;fmt&quot; type Circle struct { x int y int Radius int } func expandByValue(c Circle) { c.Radius *= 2 } func expandByPointer(c *Circle) { c.Radius *= 2 } func main() { var c = Circle{Radius: 50} expandByValue(c) fmt.Println(c) expandByPointer(&amp;c) fmt.Println(c) } --------- {0 0 50} {0 0 100} 结构体方法package main import ( &quot;fmt&quot; &quot;math&quot; ) type Circle struct { x int y int Radius int } // 面积 func (c Circle) Area() float64 { return math.Pi * float64(c.Radius) * float64(c.Radius) } // 周长 func (c Circle) Circumference() float64 { return 2 * math.Pi * float64(c.Radius) } func main() { var c = Circle{Radius: 50} fmt.Println(c.Area(), c.Circumference()) // 指针变量调用方法形式上是一样的 var pc = &amp;c fmt.Println(pc.Area(), pc.Circumference()) } ----------- 7853.981633974483 314.1592653589793 7853.981633974483 314.1592653589793 Go 语言不喜欢类型的隐式转换，所以需要将整型显式转换成浮点型 Go 语言结构体方法里面也没有self和this这样的关键字来指代当前的对象 Go 语言的方法名称也分首字母大小写，它的权限规则和字段一样，首字母大写就是公开方法，首字母小写就是内部方法，只有归属与同一个包的代码才可以访问 结构体的值类型和指针类型访问内部字段和方法在形式上是一样的，都是使用句点.操作符 结构体的指针方法结构体的值方法无法改变结构体内部状态。例如，使用下面的方法无法扩大 Circle 的半径： func (c Circle) expand() { c.Radius *= 2 } 这是因为参数传递是值传递，复制了一份结构体内容。要想修改结构体内部状态，就必须要使用结构体的指针方法： func (c *Circle) expand() { c.Radius *= 2 } 通过指针访问内部的字段需要 2 次内存读取操作，第一步是取得指针地址，第二步是读取地址的内容，它比值访问要慢。但是在方法调用时，指针传递可以避免结构体的拷贝操作，结构体比较大时，这种性能的差距就会比较明显。 还有一些特殊的结构体不允许被复制，比如结构体内部包含有锁时，这时就必须使用它的指针形式来定义方法，否则会发生一些莫名其妙的问题。 内嵌结构体结构体作为一种变量它可以放进另外一个结构体作为一个字段来使用，这种内嵌结构体的形式在 Go 语言里称之为「组合」： package main import &quot;fmt&quot; type Point struct { x int y int } func (p Point) show() { fmt.Println(p.x, p.y) } type Circle struct { loc Point Radius int } func main() { var c = Circle{ loc: Point{ x: 100, y: 100, }, Radius: 50, } fmt.Printf(&quot;%+v\\n&quot;, c) fmt.Printf(&quot;%+v\\n&quot;, c.loc) fmt.Printf(&quot;%d %d\\n&quot;, c.loc.x, c.loc.y) c.loc.show() } ---------------- {loc:{x:100 y:100} Radius:50} {x:100 y:100} 100 100 100 100 匿名内嵌结构体还有一种特殊的内嵌结构体形式，内嵌的结构体不提供名称。这时外面的结构体将直接继承内嵌结构体所有的内部字段和方法，匿名的结构体字段将会自动获得以结构体类型的名字命名的字段名称： package main import &quot;fmt&quot; type Point struct { x int y int } func (p Point) show() { fmt.Println(p.x, p.y) } type Circle struct { Point // 匿名内嵌结构体 Radius int } func main() { var c = Circle{ Point: Point{ x: 100, y: 100, }, Radius: 50, } fmt.Printf(&quot;%+v\\n&quot;, c) fmt.Printf(&quot;%+v\\n&quot;, c.Point) fmt.Printf(&quot;%d %d\\n&quot;, c.x, c.y) // 继承了字段 fmt.Printf(&quot;%d %d\\n&quot;, c.Point.x, c.Point.y) c.show() // 继承了方法 c.Point.show() } ------- {Point:{x:100 y:100} Radius:50} {x:100 y:100} 100 100 100 100 100 100 100 100 这里的继承仅仅是形式上的语法糖，c.show()转换成二进制代码后和c.Point.show()是等价的，c.x和c.Point.x也是等价的。 Go 语言的结构体没有多态性Go 语言不是面向对象语言在于它的结构体明确不支持多态，外结构体的方法不能覆盖内部结构体的方法。 多态是指父类定义的方法可以调用子类实现的方法，不同的子类有不同的实现，从而给父类的方法带来了多样的不同行为。 package main import &quot;fmt&quot; type Fruit struct{} func (f Fruit) eat() { fmt.Println(&quot;eat fruit&quot;) } func (f Fruit) enjoy() { fmt.Println(&quot;smell first&quot;) f.eat() fmt.Println(&quot;clean finally&quot;) } type Apple struct { Fruit } func (a Apple) eat() { fmt.Println(&quot;eat apple&quot;) } type Banana struct { Fruit } func (b Banana) eat() { fmt.Println(&quot;eat banana&quot;) } func main() { var apple = Apple{} var banana = Banana{} apple.enjoy() banana.enjoy() } ---------- smell first eat fruit clean finally smell first eat fruit clean finally 可以看到，enjoy方法调用的eat方法还是 Fruit 自己的eat方法，它没能被外面的结构体方法覆盖掉，这意味着面向对象的代码习惯不能直接用到 Go 语言中。 9. 接口 摘自《快学 Go 语言》第 9 课 —— 接口 接口是一个对象的对外能力的展现，我们使用一个对象时，往往不需要知道一个对象的内部复杂实现，通过它暴露出来的接口，就知道了这个对象具备哪些能力以及如何使用这个能力。 Go 语言的接口类型非常特别，它的作用和 Java 语言的接口一样，但是在形式上有很大的差别。Java 语言需要在类的定义上显式实现了某些接口，才可以说这个类具备了接口定义的能力。但是 Go 语言的接口是隐式的，只要结构体上定义的方法在形式上（名称、参数和返回值）和接口定义的一样，那么这个结构体就自动实现了这个接口，我们就可以使用这个接口变量来指向结构体对象。 package main import &quot;fmt&quot; // 可以闻 type Smellable interface { smell(s string) } // 可以吃 type Eatable interface { eat(s string) } // 苹果既可以闻又可以吃 type Apple struct { name string } func (a Apple) smell(s string) { fmt.Println(s + &quot; can smell&quot;) } func (a Apple) eat(s string) { fmt.Println(s + &quot; can eat&quot;) } // 花只可以闻 type Flower struct { name string } func (f Flower) smell(s string) { fmt.Println(s + &quot; can smell&quot;) } func main() { var s1 Smellable var s2 Eatable var apple = Apple{ name: &quot;Apple&quot;, } var flower = Flower{ name: &quot;Flower&quot;, } s1 = apple s1.smell(apple.name) s1 = flower s1.smell(flower.name) s2 = apple s2.eat(apple.name) } -------------------- apple can smell flower can smell apple can eat Apple 结构体同时实现了Smellable和Eatable这两个接口，而 Flower 结构体只实现了Smellable接口。可以看到在 Go 语言中，无需使用类似于 Java 语言的 implements 关键字，结构体和接口就自动产生了关联。 空接口如果一个接口里面没有定义任何方法，那么它就是空接口，任意结构体都隐式的实现了空接口。 Go 语言为了避免用户重复定义，自己内置了一个名为interface{}的空接口。空接口里没有方法，所以它也不具备任何能力，其作用相当于 Java 的 Object 类型，可以容纳任意对象，是一个万能容器。比如一个字典的 key 是字符串，但是希望 value 可以容纳任意类型的对象，类似于 Java 语言的 Map 类型，这时候就可以使用空接口类型interface{}。 package main import &quot;fmt&quot; func main() { var user = map[string]interface{}{ &quot;age&quot;: 30, &quot;address&quot;: &quot;Guangdong Guangzhou&quot;, &quot;married&quot;: true, } fmt.Println(user) // 类型转换语法 var age = user[&quot;age&quot;].(int) var address = user[&quot;address&quot;].(string) var married = user[&quot;married&quot;].(bool) fmt.Println(age, address, married) } ------------- map[age:30 address:Guangdong Guangzhou married:true] 30 Guangdong Guangzhou true 因为 user 字典变量的类型是map[string]interface{}，从这个字典中直接读取得到的 value 类型是interface{}，所以需要通过类型转换才能得到期望的变量。 接口变量的本质可以将 Go 语言中的接口看成一个特殊的容器：这个容器只能容纳一个对象，只有实现了这个接口类型的对象才可以放进去。 Go 语言中的接口变量 查看 Go 语言的源码发现，接口变量也是由结构体来定义的。这个结构体包含两个指针字段，所以接口变量的内存占用是 2 个机器字： package main import &quot;fmt&quot; import &quot;unsafe&quot; func main() { var s interface{} fmt.Println(unsafe.Sizeof(s)) var arr = [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} fmt.Println(unsafe.Sizeof(arr)) s = arr fmt.Println(unsafe.Sizeof(s)) } ---------- 16 80 16 用接口来模拟多态接口是一种特殊的容器，可以容纳多种不同的对象。那么只要这些对象都同样实现了接口定义的方法，再将容纳的对象替换成另一个对象，就可以模拟实现多态： package main import ( &quot;fmt&quot; ) type Fruitable interface { eat() } type Fruit struct { Name string // 属性变量 Fruitable // 匿名内嵌接口变量 } func (f Fruit) want() { fmt.Printf(&quot;I like &quot;) f.eat() // 外结构体会自动继承匿名内嵌变量的方法 } type Apple struct{} func (a Apple) eat() { fmt.Println(&quot;eating apple&quot;) } type Banana struct{} func (b Banana) eat() { fmt.Println(&quot;eating banana&quot;) } func main() { var f1 = Fruit{&quot;Apple&quot;, Apple{}} var f2 = Fruit{&quot;Banana&quot;, Banana{}} f1.want() f2.want() } --------- I like eating apple I like eating banana 使用这种方式模拟多态本质上是通过组合属性变量 Name 和接口变量 Fruitable 来做到的。属性变量是对象的数据，而接口变量是对象的功能，将它们组合到一块就形成了一个完整的多态性结构体。 接口的组合继承接口的定义也支持组合继承： type Smellable interface { smell() } type Eatable interface { eat() } type Fruitable interface { Smellable Eatable } 这时 Fruitable 接口就自动包含了smell()和eat()两个方法，和下面的定义是等价的： type Fruitable interface { smell() eat() } 接口变量的赋值变量的赋值本质上是一次内存浅拷贝：切片的赋值是拷贝了切片头，字符串的赋值是拷贝了字符串的头部，而数组的赋值则是直接拷贝了整个数组。 package main import &quot;fmt&quot; type Rect struct { Width int Height int } func main() { var a interface{} var r = Rect{50, 50} a = r var rx = a.(Rect) r.Width = 100 r.Height = 100 fmt.Println(rx) } ------ {50 50} 可以根据上面的输出结果推断出结构体的内存发生了复制，这是因为赋值a = r和类型转换rx = a.(Rect)两者都发生了数据内存的赋值——浅拷贝。 指向指针的接口变量将上面的例子改成指针，将接口变量指向结构体指针，就会得到不一样的结果： package main import &quot;fmt&quot; type Rect struct { Width int Height int } func main() { var a interface{} var r = Rect{50, 50} a = &amp;r // 指向了结构体指针 var rx = a.(*Rect) r.Width = 100 r.Height = 100 fmt.Println(rx) } ------- &amp;{100 100} 可以看到指针变量 rx 指向的内存和变量 r 的内存是同一份，因为在类型转换的过程中只发生了指针变量的内存复制，而指针变量指向的内存是共享的。 10. 错误和异常 摘自《快学 Go 语言》第 10 课 —— 错误和异常 错误接口Go 语言规定凡是实现了错误接口的对象都是错误对象，这个错误接口只定义了一个方法： type error interface { Error() string } 编写一个错误对象很简单：写一个结构体，然后挂在Error方法里： package main import &quot;fmt&quot; type SomeError struct { Reason string } func (s SomeError) Error() string { return s.Reason } func main() { var err error = SomeError{&quot;something happened&quot;} fmt.Println(err) } --------------- something happened Go 语言内置了一个通用错误类型，在 errors 包里面。这个包还提供了一个New()函数来方便的创建一个通用错误： var err = errors.New(&quot;something happened&quot;) 还可以使用 fmt 包提供的Errorf函数来给错误字符串定制一些参数： var thing = &quot;something&quot; var err = fmt.Errorf(&quot;%s happened&quot;, thing) 错误处理首体验在 Java 语言中，如果遇到 I/O 问题通常会抛出IOException类型的异常。然而在 Go 语言中，它不会抛出异常，而是以返回值的形式来通知上层逻辑来处理错误。 package main import ( &quot;fmt&quot; &quot;os&quot; ) func main() { // 打开文件 var f, err = os.Open(&quot;quick.go&quot;) if err != nil { // 文件不存在、权限等原因 fmt.Println(&quot;open file failed reason: &quot; + err.Error()) return } // 推迟到函数尾调用，确保文件会关闭 defer f.Close() // 存储文件内容 var content = []byte{} // 临时的缓冲，按块读取，一次最多读取 100 字节 var buf = make([]byte, 100) for { // 读文件，将读到的内容填充到缓冲 n, err := f.Read(buf) if n &gt; 0 { // 将读到的内容聚合起来 content = append(content, buf[:n]...) } if err != nil { // 遇到流结束或者其它错误 break } } // 输出文件内容 fmt.Println(string(content)) } ------- package main import &quot;os&quot; import &quot;fmt&quot; ..... 体验 Redis 的错误处理首先需要使用go get指令下载 redis 包： go get github.com/go-redis/redis 下面实现一个小功能：获取 Redis 中两个整数值，然后相乘，再存入 Redis 中： package main import &quot;fmt&quot; import &quot;strconv&quot; import &quot;github.com/go-redis/redis&quot; func main() { // 定义客户端对象，内部包含一个连接池 var client = redis.NewClient(&amp;redis.Options{ Addr: &quot;localhost:6379&quot;, }) // 定义三个重要的整数变量值，默认都是零 var val1, val2, val3 int // 获取第一个值 valstr1, err := client.Get(&quot;value1&quot;).Result() if err == nil { val1, err = strconv.Atoi(valstr1) if err != nil { fmt.Println(&quot;value1 not a valid integer&quot;) return } } else if err != redis.Nil { fmt.Println(&quot;redis access error reason:&quot; + err.Error()) return } // 获取第二个值 valstr2, err := client.Get(&quot;value2&quot;).Result() if err == nil { val2, err = strconv.Atoi(valstr2) if err != nil { fmt.Println(&quot;value1 not a valid integer&quot;) return } } else if err != redis.Nil { fmt.Println(&quot;redis access error reason:&quot; + err.Error()) return } // 保存第三个值 val3 = val1 * val2 ok, err := client.Set(&quot;value3&quot;, val3, 0).Result() if err != nil { fmt.Println(&quot;set value error reason:&quot; + err.Error()) return } fmt.Println(ok) } ------ OK Go 语言中不轻易使用异常语句，所以对于任何可能出错的地方都需要判断返回值的错误信息 字符串的零值是空串而不是 nil，需要通过返回值的错误信息来判断。redis.Nil就是客户端专门为 key 不存在这种情况而定义的错误对象 异常与捕捉Go 语言提供了 panic 和 recover 全局函数让我们可以抛出异常、捕获异常，类似于 try、throw、catch语句，但是又很不一样。比如 panic 函数可以抛出任意对象： package main import &quot;fmt&quot; var negErr = fmt.Errorf(&quot;negative number&quot;) func main() { fmt.Println(fact(5)) fmt.Println(fact(10)) fmt.Println(fact(15)) fmt.Println(fact(-20)) } func fact(a int) int { if a &lt;= 0 { panic(negErr) } var result = 1 for i := 1; i &lt;= a; i++ { result *= i } return result } ------- 120 3628800 1307674368000 panic: negative number goroutine 1 [running]: main.fact(0xffffffffffffffec, 0x1) C:/Users/abel1/go/src/hello/quickgo.go:16 +0x7e main.main() C:/Users/abel1/go/src/hello/quickgo.go:11 +0x15e Process finished with exit code 2 上面的代码抛出了negErr，直接导致了程序崩溃，程序最后打印了异常堆栈信息。下面我们可以使用 recover 函数来保护它，需要结合 defer 语句一起使用，这样可以确保recover()逻辑在程序异常时也可以得到调用： package main import &quot;fmt&quot; var negErr = fmt.Errorf(&quot;negative number&quot;) func main() { defer func() { if err := recover(); err != nil { fmt.Println(&quot;error catched&quot;, err) } }() fmt.Println(fact(5)) fmt.Println(fact(10)) fmt.Println(fact(15)) fmt.Println(fact(-20)) } func fact(a int) int { if a &lt;= 0 { panic(negErr) } var result = 1 for i := 1; i &lt;= a; i++ { result *= i } return result } ------- 120 3628800 1307674368000 error catched negative number Process finished with exit code 0 可以看到程序成功捕获了异常，并且不再崩溃，但异常点后面的逻辑也不会再继续执行了， 我们经常还需要对recover()返回的结果进行判断，以挑选出我们愿意处理的异常对象类型。对于那些不愿意处理的，可以选择再次抛出，让上层来处理： defer func() { if err := recover(); err != nil { if err == negErr { fmt.Println(&quot;error catched&quot;, err) } else { panic(err) // rethrow } } }() Go 语言官方表态不要轻易使用 panic recover，除非你真的无法预料中间可能会发生的错误，或者它能非常显著地简化你的代码。除非逼不得已，否则不要使用它。 多个 defer 语句有时我们需要在一个函数里使用多次 defer 语句。例如拷贝文件，需要同时打开源文件和目标文件，那就需要调用两次defer f.Close： package main import ( &quot;fmt&quot; &quot;os&quot; ) func main() { fsrc, err := os.Open(&quot;source.txt&quot;) if err != nil { fmt.Println(&quot;open source file failed&quot;) return } defer fsrc.Close() fdes, err := os.Open(&quot;target.txt&quot;) if err != nil { fmt.Println(&quot;open target file failed&quot;) return } defer fdes.Close() fmt.Println(&quot;do something here&quot;) } ------ open source file failed Process finished with exit code 0 需要注意的是 defer 语句的执行顺序和代码编写的顺序是相反的，也就是说最先 defer 的语句最后执行。 package main import &quot;fmt&quot; import &quot;os&quot; func main() { fsrc, err := os.Open(&quot;source.txt&quot;) if err != nil { fmt.Println(&quot;open source file failed&quot;) return } defer func() { fmt.Println(&quot;close source file&quot;) fsrc.Close() }() fdes, err := os.Open(&quot;target.txt&quot;) if err != nil { fmt.Println(&quot;open target file failed&quot;) return } defer func() { fmt.Println(&quot;close target file&quot;) fdes.Close() }() fmt.Println(&quot;do something here&quot;) } -------- do something here close target file close source file Process finished with exit code 0 11. 协程 摘自《快学 Go 语言》第 11 课 —— 千军万马跑协程 协程与通道 Go 语言里协程被称为goroutine，通道被称为channel。 协程的启动Go 语言里创建一个协程非常简单：使用go关键词加上一个函数调用就可以了。 Go 语言会启动一个新的协程，函数调用将成为这个协程的入口。 package main import ( &quot;fmt&quot; &quot;time&quot; ) func main() { fmt.Println(&quot;run in main goroutine&quot;) go func() { fmt.Println(&quot;run in child goroutine&quot;) go func() { fmt.Println(&quot;run in grand child goroutine&quot;) go func() { fmt.Println(&quot;run in grand grand child goroutine&quot;) }() }() }() time.Sleep(time.Second) fmt.Println(&quot;main goroutine will quit&quot;) } ------ run in main goroutine run in child goroutine run in grand child goroutine run in grand grand child goroutine main goroutine will quit Process finished with exit code 0 在 Go 语言里只有一个主协程，其它都是它的子协程，子协程之间是平行关系。 子协程异常退出子协程的异常退出会将异常传播到主协程，直接会导致主协程也跟着挂掉，进而导致程序崩溃。 为了保护子协程的安全，通常我们会在协程的入口函数开头增加recover()语句来恢复协程内部发生的异常，阻断它传播到主协程导致程序崩溃： package main import ( &quot;fmt&quot; &quot;time&quot; ) func main() { fmt.Println(&quot;run in main goroutine&quot;) go func() { fmt.Println(&quot;run in child goroutine&quot;) go func() { fmt.Println(&quot;run in grand child goroutine&quot;) go func() { fmt.Println(&quot;run in grand grand child goroutine&quot;) defer func() { if err := recover(); err != nil { // log error fmt.Println(&quot;wtf error happen!&quot;) } }() panic(&quot;wtf&quot;) }() }() }() time.Sleep(time.Second) fmt.Println(&quot;main goroutine will quit&quot;) } ------ run in main goroutine run in child goroutine run in grand child goroutine run in grand grand child goroutine wtf error happen! main goroutine will quit Process finished with exit code 0 协程的本质Go 语言中的协程有如下特点： 一个进程内部可以运行多个线程，而每个线程又可以运行多个协程 线程要负责对协程进行调度，保证每个协程都有机会得到执行 当一个协程睡眠时，它要将线程的运行权让给其他协程来运行，而不能持续霸占这个线程 同一个线程内部最多只会有一个协程正在运行 同一个线程内部最多只会有一个协程正在运行 线程的调度是由操作系统负责的，调度算法运行在内核态。而协程的调用是由 Go 语言的运行时负责的，调度算法运行在用户态。 Go 语言协程的三种状态 协程可以简化为三种状态： 运行态：同一个线程中最多只会存在一个处于运行态的协程 就绪态：就绪态的协程是指那些具备了运行能力但是还没有得到运行机会的协程，它们随时会被调度到运行态 休眠态：休眠态的协程还不具备运行能力，它们是在等待某些条件的发生，比如 I/O 操作的完成、睡眠时间的结束等 操作系统对线程的调度是抢占式的，也就是说单个线程的死循环不会影响其它线程的执行，每个线程的连续运行受到时间片的限制。 Go 语言运行时对协程的调度并不是抢占式的。如果单个协程通过死循环霸占了线程的执行权，那这个线程就没有机会去运行其它协程了，可以说这个线程假死了。 每个线程都会包含多个就绪态的协程形成了一个就绪队列。Go 语言运行时调度器采用了work-stealing算法，当某个线程空闲时，也就是该线程上所有的协程都在休眠（或者一个协程都没有），它就会去其它线程的就绪队列上去偷一些协程来运行。正常情况下，运行时会尽量平均分配工作任务。 设置线程数默认情况下，Go 运行时会将线程数会被设置为机器 CPU 逻辑核心数。同时它内置的runtime包提供了GOMAXPROCS(n int)函数允许我们动态调整线程数。 如果参数n &lt;=0，就不会产生修改效果，等价于读取当前的线程数 package main import ( &quot;fmt&quot; &quot;runtime&quot; ) func main() { // 读取默认的线程数 fmt.Println(runtime.GOMAXPROCS(0)) // 设置线程数为 10 runtime.GOMAXPROCS(10) // 读取当前的线程数 fmt.Println(runtime.GOMAXPROCS(0)) } ------ 4 10 Process finished with exit code 0 获取当前的协程数量可以使用 runtime 包提供的NumGoroutine()方法： package main import ( &quot;fmt&quot; &quot;runtime&quot; &quot;time&quot; ) func main() { fmt.Println(runtime.NumGoroutine()) for i := 0; i &lt; 10; i++ { go func() { for { time.Sleep(time.Second) } }() } fmt.Println(runtime.NumGoroutine()) } ------ 1 11 Process finished with exit code 0 协程的应用在日常互联网应用中，Go 语言的协程主要应用在 HTTP API 应用、消息推送系统、聊天系统等。 12. 通道 摘自《快学 Go 语言》第 12 课 —— 神秘的地下通道 不同的并行协程之间交流的方式有两种，一种是通过共享变量，另一种是通过队列。 Go 语言鼓励使用队列的形式来交流，它单独为协程之间的队列数据交流定制了特殊的语法——通道。 协程与通道 通道是协程的输入和输出。作为协程的输出，通道是一个容器，它可以容纳数据。作为协程的输入，通道是一个生产者，它可以向协程提供数据。 通道作为容器是有限定大小的，满了就写不进去，空了就读不出来。 通道还有它自己的类型，它可以限定进入通道的数据的类型。 创建通道创建通道只有一种语法，那就是make全局函数，提供第一个类型参数限定通道可以容纳的数据类型，再提供第二个整数参数作为通道的容器大小。 // 缓冲型通道，里面只能放整数 var bufferedChannel = make(chan int, 1024) // 非缓冲型通道 var unbufferedChannel = make(chan int) 大小参数是可选的，如果不填，那这个通道的容量为零，叫做「非缓冲型通道」。 非缓冲型通道必须确保有协程正在尝试读取当前通道，否则写操作就会阻塞直到有其它协程来从通道中读东西。 非缓冲型通道总是处于既满又空的状态。与之对应的有限定大小的通道就是缓冲型通道。 在 Go 语言里不存在无界通道，每个通道都是有限定最大容量的 读写通道Go 语言为通道的读写设计了特殊的箭头语法糖&lt;-，把箭头写在通道变量的右边就是写通道，把箭头写在通道的左边就是读通道。需要注意的是，一次只能读写一个元素。 package main import &quot;fmt&quot; func main() { var ch chan int = make(chan int, 4) for i := 0; i &lt; cap(ch); i++ { ch &lt;- i // 写通道 } for len(ch) &gt; 0 { fmt.Printf(&quot;current len: %d, cap: %d\\n&quot;, len(ch), cap(ch)) var value int = &lt;-ch // 读通道 fmt.Printf(&quot;value: %d\\n&quot;, value) } } ------ current len: 4, cap: 4 value: 0 current len: 3, cap: 4 value: 1 current len: 2, cap: 4 value: 2s current len: 1, cap: 4 value: 3 Process finished with exit code 0 通道作为容器，可以像切片一样，使用cap()和len()全局函数获得通道的容量和当前内部的元素个数。 通道一般作为不同的协程交流的媒介，不过在同一个协程里也是可以使用的 读写阻塞通道满了，写操作就会阻塞，协程就会进入睡眠，直到有其它协程读通道挪出了空间，协程才会被唤醒。如果有多个协程的写操作都阻塞了，一个读操作只会唤醒一个协程。 通道空了，读操作就会阻塞，协程也会进入睡眠，直到有其它协程写通道装进了数据才会被唤醒。如果有多个协程的读操作阻塞了，一个写操作也只会唤醒一个协程。 package main import ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot; ) func send(ch chan int) { for { var value = rand.Intn(100) ch &lt;- value fmt.Printf(&quot;send %d\\n&quot;, value) } } func recv(ch chan int) { for { value := &lt;-ch fmt.Printf(&quot;recv %d\\n&quot;, value) time.Sleep(time.Second) } } func main() { var ch = make(chan int, 1) // 子协程循环读 go recv(ch) // 主协程循环写 send(ch) } ------ send 81 send 87 recv 81 recv 87 send 47 recv 47 send 59 ... 关闭通道Go 语言的通道不但支持读写操作，还支持关闭。读取一个已经关闭的通道会立即返回通道类型的「零值」，而写入一个已经关闭的通道会抛出异常。 如果通道里的元素是整型的，读操作不能通过返回值来确定通道是否关闭 package main import &quot;fmt&quot; func main() { var ch = make(chan int, 4) ch &lt;- 1 ch &lt;- 2 close(ch) value := &lt;-ch fmt.Println(value) value = &lt;-ch fmt.Println(value) value = &lt;-ch fmt.Println(value) } ------ 1 2 0 Process finished with exit code 0 还可以使用for range语法取代箭头操作符&lt;-来遍历通道。当通道空了，循环会暂停阻塞。当通道关闭时，阻塞停止，循环也跟着结束了。当循环结束时，我们就知道通道已经关闭了。 package main import &quot;fmt&quot; func main() { var ch = make(chan int, 4) ch &lt;- 1 ch &lt;- 2 close(ch) // for range 遍历通道 for value := range ch { fmt.Println(value) } } ------ 1 2 Process finished with exit code 0 如果将上面关闭通道的语句注释掉，使用for range语法遍历通道就会报错： package main import &quot;fmt&quot; func main() { var ch = make(chan int, 4) ch &lt;- 1 ch &lt;- 2 // close(ch) // for range 遍历通道 for value := range ch { fmt.Println(value) } } ------ 1 2 fatal error: all goroutines are asleep - deadlock! goroutine 1 [chan receive]: main.main.func1(0xc00007e000) C:/Users/abel1/go/src/hello/quickgo.go:13 +0xa1 main.main() C:/Users/abel1/go/src/hello/quickgo.go:17 +0xa1 Process finished with exit code 2 通道如果没有显式关闭，当它不再被程序使用的时候，会自动关闭被垃圾回收掉。不过优雅的程序应该将通道看成资源，显式关闭每个不再使用的资源是一种良好的习惯 通道写安全写通道时一定要确保通道没有被关闭，否则会抛出异常： package main import &quot;fmt&quot; // 写通道 func send(ch chan int) { i := 0 for { i++ ch &lt;- i } } // 读通道 func recv(ch chan int) { value := &lt;-ch fmt.Println(value) value = &lt;-ch fmt.Println(value) close(ch) } func main() { var ch = make(chan int, 4) go recv(ch) send(ch) } ------ 1 2 panic: send on closed channel goroutine 1 [running]: main.send(0xc00007e000) C:/Users/abel1/go/src/hello/quickgo.go:10 +0x4b main.main() C:/Users/abel1/go/src/hello/quickgo.go:26 +0x6d Process finished with exit code 2 确保通道写安全的最好方式是由负责写通道的协程自己来关闭通道，读通道的协程不要去关闭通道： package main import &quot;fmt&quot; func send(ch chan int) { ch &lt;- 1 ch &lt;- 2 ch &lt;- 3 ch &lt;- 4 close(ch) } func recv(ch chan int) { for v := range ch { fmt.Println(v) } } func main() { var ch = make(chan int, 1) go send(ch) recv(ch) } ------ 1 2 3 4 Process finished with exit code 0 这样可以应对单写多读的场景。不过在多写单读的场景下，任意一个读写通道的协程都不可以随意关闭通道，否则会导致其它写通道协程抛出异常。 这个时候就需要使用内置sync包提供的WaitGroup对象，使用计数来等待指定事件完成，即等待所有的写通道协程都结束运行后才关闭通道： package main import ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot; ) func send(ch chan int, wg *sync.WaitGroup) { defer wg.Done() // 计数值减 1 i := 0 for i &lt; 4 { i++ ch &lt;- i } } func recv(ch chan int) { for value := range ch { fmt.Println(value) } } func main() { var ch = make(chan int, 4) var wg = new(sync.WaitGroup) wg.Add(2) // 增加计数值 go send(ch, wg) // 写 go send(ch, wg) // 写 go recv(ch) // Wait() 阻塞等待所有的写通道协程结束 // 待计数值变成零，Wait() 才会返回 wg.Wait() // 关闭通道 close(ch) time.Sleep(time.Second) } ------ 1 2 3 4 1 2 3 4 Process finished with exit code 0 多路通道当消费者有多个消费来源时，只要有一个来源生产了数据，消费者就可以读这个数据进行消费。这时候可以将多个来源通道的数据汇聚到目标通道，然后统一在目标通道进行消费。 package main import ( &quot;fmt&quot; &quot;time&quot; ) // 每隔一段时间产生一个数 func send(ch chan int, gap time.Duration) { i := 0 for { i++ ch &lt;- i time.Sleep(gap) } } // 将多个原通道内容拷贝到单一的目标通道 func collect(source chan int, target chan int) { for v := range source { target &lt;- v } } // 从目标通道消费数据 func recv(ch chan int) { for v := range ch { fmt.Printf(&quot;receive %d\\n&quot;, v) } } func main() { var ch1 = make(chan int) // 原通道 1 var ch2 = make(chan int) // 原通道 2 var ch3 = make(chan int) // 目标通道 go send(ch1, time.Second) go send(ch2, 2*time.Second) go collect(ch1, ch3) go collect(ch2, ch3) recv(ch3) } ------ receive 1 receive 1 receive 2 receive 2 receive 3 receive 4 receive 3 receive 5 receive 6 receive 4 receive 7 receive 8 receive 5 receive 9 receive 10 receive 6 ... 但是这种形式比较繁琐：一来需要单独编写collect()汇聚函数，二来一旦多路通道的规模很大，就需要为每一种消费来源都单独启动一个汇聚协程。好在 Go 语言为这种使用场景提供了「多路复用」语法糖——select语句，它可以同时管理多个通道的读写：如果所有通道都不能读写，它就整体阻塞，只要有一个通道可以读写，它就会继续： package main import ( &quot;fmt&quot; &quot;time&quot; ) // 每隔一段时间产生一个数 func send(ch chan int, gap time.Duration) { i := 0 for { i++ ch &lt;- i time.Sleep(gap) } } // 从目标通道消费数据 func recv(ch1 chan int, ch2 chan int) { for { select { case v := &lt;-ch1: fmt.Printf(&quot;recv %d from ch1\\n&quot;, v) case v := &lt;-ch2: fmt.Printf(&quot;recv %d from ch2\\n&quot;, v) } } } func main() { var ch1 = make(chan int) var ch2 = make(chan int) go send(ch1, time.Second) go send(ch2, time.Second * 2) recv(ch1, ch2) } ------ recv 1 from ch2 recv 1 from ch1 recv 2 from ch1 recv 2 from ch2 recv 3 from ch1 recv 4 from ch1 recv 3 from ch2 recv 5 from ch1 recv 6 from ch1 recv 4 from ch2 recv 7 from ch1 ... 可以观察到向ch2写数据的生产者go send(ch2, time.Second * 2)要更慢一些。 上面是多路复用select语句的读通道形式，下面是它的写通道形式，只要有一个通道能写进去，它就会打破阻塞： select { case ch1 &lt;- v: fmt.Printf(&quot;Send %d to ch1\\n&quot;, v) case ch2 &lt;- v: fmt.Printf(&quot;Send %d to ch2\\n&quot;, v) } 关于如何在多路复用时关闭通道，可以参考 多路复用 channel 的时候，如何优雅的关闭通道 | Go 语言中文网 非阻塞读写前面讲的读写都是阻塞读写，Go 语言还提供了通道的非阻塞读写：当通道空时，读操作不会阻塞，当通道满时，写操作也不会阻塞。 非阻塞读写需要依靠select语句的default分支。当select语句所有通道都不可读写时，如果定义了default分支，那就会执行default分支逻辑，这样就起到了不阻塞的效果。 下面演示一个单生产者多消费者的场景。生产者同时向两个通道写数据，写不进去就丢弃： package main import ( &quot;fmt&quot; &quot;time&quot; ) func send(ch1 chan int, ch2 chan int) { i := 0 for { i++ select { case ch1 &lt;- i: fmt.Printf(&quot;send ch1 %d\\n&quot;, i) case ch2 &lt;- i: fmt.Printf(&quot;send ch2 %d\\n&quot;, i) default: } } } func recv(ch chan int, gap time.Duration, name string) { for v := range ch { fmt.Printf(&quot;receive %s %d\\n&quot;, name, v) time.Sleep(gap) } } func main() { // 无缓冲通道 var ch1 = make(chan int) var ch2 = make(chan int) // 两个消费者的休眠时间不一样，名称不一样 go recv(ch1, time.Second, &quot;ch1&quot;) go recv(ch2, time.Second * 2, &quot;ch2&quot;) send(ch1, ch2) } ------ send ch1 429 send ch2 430 receive ch1 429 receive ch2 430 send ch1 10062541 receive ch1 10062541 send ch2 20457524 receive ch2 20457524 send ch1 20467243 receive ch1 20467243 send ch1 30294965 receive ch1 30294965 send ch2 40021595 receive ch2 40021595 send ch1 40041927 receive ch1 40041927 send ch1 49448528 receive ch1 49448528 send ch2 58807676 receive ch2 58807676 ... 可以看到很多数据被丢弃了，消费者读到的数据是不连续的。 将select语句里面的default分支去掉，再运行一次： send ch2 1 send ch1 2 receive ch1 2 receive ch2 1 receive ch1 3 send ch1 3 receive ch2 4 send ch2 4 receive ch1 5 send ch1 5 receive ch1 6 send ch1 6 receive ch2 7 send ch2 7 receive ch1 8 send ch1 8 receive ch1 9 send ch1 9 receive ch2 10 ... 可以看到消费者读到的数据都连续了，写通道又恢复为阻塞的。 select语句的default分支非常关键，它决定了通道读写操作是否阻塞 通道内部结构 Go 语言中通道的内部结构 Go 语言的通道内部结构是一个循环数组，通过读写偏移量来控制元素发送和接收。它为了保证线程安全，内部会有一个全局锁来控制并发。对于发送和接收操作都会有一个队列来容纳处于阻塞状态的协程。Go 语言中通道的源码位于$GOROOT/src/runtime/chan.go： type hchan struct { qcount uint // 通道有效元素个数 dataqsiz uint // 通道容量，循环数组总长度 buf unsafe.Pointer // 数组地址 elemsize uint16 // 内部元素的大小 closed uint32 // 是否已关闭，0 或者 1 elemtype *_type // 内部元素类型信息 sendx uint // 循环数组的写偏移量 recvx uint // 循环数组的读偏移量 recvq waitq // 阻塞在读操作上的协程队列 sendq waitq // 阻塞在写操作上的协程队列 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex // 全局锁 } 这个循环队列和 Java 语言内置的ArrayBlockingQueue结构如出一辙，所以可以从这个数据结构中得出结论：队列在本质上是使用共享变量加锁的方式来实现的，共享变量才是并行交流的本质。 13. 并发与安全 摘自《快学 Go 语言》第 13 课 —— 并发与安全 并发编程不同的协程共享数据的方式除了通道之外还有就是共享变量。虽然 Go 语言官方推荐使用通道的方式来共享数据，但是通过变量来共享才是基础，因为通道在底层也是通过共享变量的方式来实现的。通道的内部数据结构包含一个数组，对通道的读写就是对内部数组的读写。 并发环境下共享读写变量必须使用锁来控制数据结构的安全。Go 语言内置了sync包，里面包含了我们平时需要经常使用的互斥锁对象sync.Nutex。 Go 语言内置的字典不是线程安全的，可以使用互斥锁对象来保护字典，让它变成线程安全的 线程不安全的字典 Go 语言从1.9版本之后自带线程安全的字典sync.map，主要操作有：Store、LoadOrStore、Load、Delete、Range Go 语言内置了数据结构「竞态检查」工具来帮我们检查程序中是否存在线程不安全的代码。关于 Go 语言的竞态检测器，可以参考 Go 的竞态检测器 | Go 语言中文网。例如下面这段代码： package main import &quot;fmt&quot; func write(d map[string]int) { d[&quot;fruit&quot;] = 2 } func read(d map[string]int) { fmt.Println(d[&quot;fruit&quot;]) } func main() { d := map[string]int{} go read(d) write(d) } 读、写分别是两个协程，存在明显的安全隐患，运行竞态检查指令go run -race quickgo.go观察输出结果： C:\\Users\\abel1\\go\\src\\hello&gt;go run -race quickgo.go ================== WARNING: DATA RACE Read at 0x00c000052240 by goroutine 6: runtime.mapaccess1_faststr() C:/Go/src/runtime/map_faststr.go:12 +0x0 main.read() C:/Users/abel1/go/src/hello/quickgo.go:10 +0x64 Previous write at 0x00c000052240 by main goroutine: runtime.mapassign_faststr() C:/Go/src/runtime/map_faststr.go:190 +0x0 main.main() C:/Users/abel1/go/src/hello/quickgo.go:6 +0x8f Goroutine 6 (running) created at: main.main() C:/Users/abel1/go/src/hello/quickgo.go:15 +0x60 ================== ================== WARNING: DATA RACE Read at 0x00c0000422f8 by goroutine 6: main.read() C:/Users/abel1/go/src/hello/quickgo.go:10 +0x77 Previous write at 0x00c0000422f8 by main goroutine: main.main() C:/Users/abel1/go/src/hello/quickgo.go:6 +0xa4 Goroutine 6 (running) created at: main.main() C:/Users/abel1/go/src/hello/quickgo.go:15 +0x60 ================== 2 Found 2 data race(s) exit status 66 竞态检查工具是基于运行时代码检查，而不是通过代码静态分析来完成的。这意味着那些没有机会运行到的代码逻辑中如果存在安全隐患，它是检查不出来的。 线程安全的字典让字典变的线程安全，就需要使用互斥锁对字典的所有读写操作进行保护： package main import ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot; ) type SafeDict struct { data map[string]int mutex *sync.Mutex } func NewSafeDict(data map[string]int) *SafeDict { return &amp;SafeDict{ data: data, mutex: &amp;sync.Mutex{}, } } func (d *SafeDict) Len() int { d.mutex.Lock() defer d.mutex.Unlock() return len(d.data) } func (d *SafeDict) Put(key string, value int) (int, bool) { d.mutex.Lock() defer d.mutex.Unlock() old_value, ok := d.data[key] d.data[key] = value return old_value, ok } func (d *SafeDict) Get(key string) (int, bool) { d.mutex.Lock() defer d.mutex.Unlock() old_value, ok := d.data[key] return old_value, ok } func (d *SafeDict) Delete(key string) (int, bool) { d.mutex.Lock() defer d.mutex.Unlock() old_value, ok := d.data[key] if ok { delete(d.data, key) } return old_value, ok } func write(d *SafeDict, key string, value int) { d.Put(key, value) } func read(d *SafeDict, key string) { fmt.Println(d.Get(key)) } func main() { d := NewSafeDict(map[string]int{ &quot;apple&quot;: 2, &quot;peach&quot;: 3, }) go read(d, &quot;peach&quot;) write(d, &quot;peach&quot;, 10) time.Sleep(time.Second) } ------ 10 true Process finished with exit code 0 再次使用竞态检查工具运行上面的代码，发现没有之前的警告输出，说明Get()和Put()方法已经做到了协程安全，但是还不能说明Delete()方法是否安全，因为它没有机会得到运行。 避免锁复制需要注意的是，sync.Mutex是一个结构体对象，这个对象在使用的过程中要避免被复制（浅拷贝）。复制将会导致锁被「分裂」了，起不到保护的作用。所以在平时的使用中要尽量使用它的指针类型。 使用匿名锁字段我们知道外部结构体可以自动继承匿名内部结构体的所有方法。如果将锁字段匿名，就可以简化代码： package main import &quot;fmt&quot; import &quot;sync&quot; type SafeDict struct { data map[string]int *sync.Mutex } func NewSafeDict(data map[string]int) *SafeDict { return &amp;SafeDict{data, &amp;sync.Mutex{}} } func (d *SafeDict) Len() int { d.Lock() defer d.Unlock() return len(d.data) } func (d *SafeDict) Put(key string, value int) (int, bool) { d.Lock() defer d.Unlock() old_value, ok := d.data[key] d.data[key] = value return old_value, ok } func (d *SafeDict) Get(key string) (int, bool) { d.Lock() defer d.Unlock() old_value, ok := d.data[key] return old_value, ok } func (d *SafeDict) Delete(key string) (int, bool) { d.Lock() defer d.Unlock() old_value, ok := d.data[key] if ok { delete(d.data, key) } return old_value, ok } func write(d *SafeDict) { d.Put(&quot;banana&quot;, 5) } func read(d *SafeDict) { fmt.Println(d.Get(&quot;banana&quot;)) } func main() { d := NewSafeDict(map[string]int{ &quot;apple&quot;: 2, &quot;pear&quot;: 3, }) go read(d) write(d) } 使用读写锁日常应用中，大多数并发数据结构都是读多写少的，对于读多写少的场合，可以将互斥锁换成读写锁，可以有效提升性能。读写锁sync.RWMutex提供了四个常用方法，分别是：写加锁Lock()、写释放锁Unlock()、读加锁RLock()和读释放锁RUnlock()。 写锁是排他锁，加写锁时会阻塞其它协程再加读锁和写锁。读锁是共享锁，加读锁还可以允许其它协程再加读锁，但是会阻塞加写锁。另外，读写锁在写并发高的情况下性能退化为普通的互斥锁 将上面代码中SafeDict的互斥锁改造成读写锁： package main import &quot;fmt&quot; import &quot;sync&quot; type SafeDict struct { data map[string]int *sync.RWMutex } func NewSafeDict(data map[string]int) *SafeDict { return &amp;SafeDict{data, &amp;sync.RWMutex{}} } func (d *SafeDict) Len() int { d.RLock() defer d.RUnlock() return len(d.data) } func (d *SafeDict) Put(key string, value int) (int, bool) { d.Lock() defer d.Unlock() old_value, ok := d.data[key] d.data[key] = value return old_value, ok } func (d *SafeDict) Get(key string) (int, bool) { d.RLock() defer d.RUnlock() old_value, ok := d.data[key] return old_value, ok } func (d *SafeDict) Delete(key string) (int, bool) { d.Lock() defer d.Unlock() old_value, ok := d.data[key] if ok { delete(d.data, key) } return old_value, ok } func write(d *SafeDict) { d.Put(&quot;banana&quot;, 5) } func read(d *SafeDict) { fmt.Println(d.Get(&quot;banana&quot;)) } func main() { d := NewSafeDict(map[string]int{ &quot;apple&quot;: 2, &quot;pear&quot;: 3, }) go read(d) write(d) } 14. 魔术变性指针 摘自《快学 Go 语言》第 14 课 —— 魔术变性指针 使用 Go 语言内置的unsafe包可以直接操纵指定内存地址的内存。 unsafe.PointerPointer代表着变量的内存地址，可以将任意变量的地址转换成Pointer类型，也可以将Pointer类型转换成任意的指针类型，它是不同指针类型之间互转的中间类型。另外，Pointer本身也是一个整型的值。 type Pointer int 指针的加减运算在 Go 语言中，编译器禁止Pointer类型直接进行加减运算。如果要进行运算，需要将Pointer类型转换为uintptr类型进行加减，然后再将uintptr转换成Pointer类型。uintptr其实也是一个整型： type uintptr int package main import ( &quot;fmt&quot; &quot;unsafe&quot; ) type Rect struct { Width int Height int } func main() { var r = Rect{50, 50} // *Rect =&gt; Pointer =&gt; *int =&gt; int var width = *(*int)(unsafe.Pointer(&amp;r)) // *Rect =&gt; Pointer =&gt; uintptr =&gt; Pointer =&gt; *int =&gt; int var height = *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;r)) + uintptr(8))) fmt.Println(width, height) } ------ 50 50 Process finished with exit code 0 上面的代码使用unsafe包来读取结构体的内容，下面尝试修改结构体的值： package main import ( &quot;fmt&quot; &quot;unsafe&quot; ) type Rect struct { Width int Height int } func main() { var r = Rect{50, 50} // *Rect =&gt; Pointer =&gt; *int =&gt; int var pwidth = (*int)(unsafe.Pointer(&amp;r)) // *Rect =&gt; Pointer =&gt; uintptr =&gt; Pointer =&gt; *int =&gt; int var pheight = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;r)) + unsafe.Offsetof(r.Height))) *pwidth = 100 *pheight = 200 fmt.Println(r.Width, r.Height) } ------ 100 200 Process finished with exit code 0 注意可以使用unsafe.Offsetof(r.Height)替换uintptr(8)，直接得到字段在结构体内的偏移量。 切片的内部结构Go 语言的切片分为切片头和内部数组两部分，使用unsafe包来验证一下切片的内部数据结构： package main import &quot;fmt&quot; import &quot;unsafe&quot; func main() { // head = {address, 10, 10} // body = [1,2,3,4,5,6,7,8,9,10] var s = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} var address = (**[10]int)(unsafe.Pointer(&amp;s)) var len = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(8))) var cap = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(16))) fmt.Println(address, *len, *cap) var body = **address for i := 0; i &lt; *len; i++ { fmt.Printf(&quot;%d &quot;, body[i]) } } ------ 0xc000044400 10 10 1 2 3 4 5 6 7 8 9 10 Process finished with exit code 0 需要注意的是address是一个二级指针变量： 字符串与切片的高效转换字节切片和字符串之间的转换需要复制内存，而unsafe包则提供了另一种高效的转换方法，让转换前后的字符串和字节切片共享内部存储： 字符串和字节切片的不同点在于头部，字符串的头部 2 个int字节，切片的头部 3 个int字节 package main import &quot;fmt&quot; import &quot;unsafe&quot; func main() { fmt.Println(bytes2str(str2bytes(&quot;hello&quot;))) } func str2bytes(s string) []byte { var strhead = *(*[2]int)(unsafe.Pointer(&amp;s)) var slicehead [3]int slicehead[0] = strhead[0] slicehead[1] = strhead[1] slicehead[2] = strhead[1] return *(*[]byte)(unsafe.Pointer(&amp;slicehead)) } func bytes2str(bs []byte) string { return *(*string)(unsafe.Pointer(&amp;bs)) } ------ hello Process finished with exit code 0 注意：通过这种方式转换得到的字节切片切记不能修改，因为其底层字节数组是共享的，修改会破坏字符串的只读规则。另外只可以用作临时的局部变量，因为被共享的字节数组随时可能会被回收 深入接口变量的赋值 可参考原文，此处略 接口类型和结构体类型似乎是两个不同的世界。只有接口类型之间的赋值和转换会共享数据，其它情况都会复制数据。其它情况包括结构体之间的赋值，结构体转接口，接口转结构体。 不同接口变量之间的转换本质上只是调整了接口变量内部的类型指针，数据指针并不会发生改变。 15. 反射 摘自《快学 Go 语言》第 15 课 —— 反射 反射的目标 获取变量的类型信息：例如这个类型的名称、占用字节数、所有的方法列表、所有的内部字段结构、底层存储类型等 动态修改变量的内部字段值：例如 JSON 的反序列化 reflect.kindGo 语言的reflect包定义了十几种内置的「元类型」，每一种元类型都有一个整数编号，这个编号使用reflect.Kind类型表示。不同的结构体是不同的类型，但是它们都是同一个元类型Struct。包含不同子元素的切片也是不同的类型，但是它们都是同一个元类型Slice。 $GOROOT/src/reflect/type.go中部分源码如下： // A Kind represents the specific kind of type that a Type represents. // The zero Kind is not a valid kind. type Kind uint const ( Invalid Kind = iota // 不存在的无效类型 Bool Int Int8 Int16 Int32 Int64 Uint Uint8 Uint16 Uint32 Uint64 Uintptr // 指针的整数类型，对指针进行整数运算时使用 Float32 Float64 Complex64 Complex128 Array // 数组类型 Chan // 通道类型 Func // 函数类型 Interface // 接口类型 Map // 字典类型 Ptr // 指针类型 Slice // 切片类型 String // 字符串类型 Struct // 结构体类型 UnsafePointer // unsafe.Pointer 类型 ) 反射的基础代码reflect包提供了两个基础反射方法，分别是TypeOf()和ValueOf()方法，分别用于获取变量的类型和值： func TypeOf(v interface{}) Type func ValueOf(v interface{}) Value 对结构体变量进行反射： package main import ( &quot;fmt&quot; &quot;reflect&quot; ) type Rect struct { Width int Height int } func main() { var s int = 42 fmt.Println(reflect.TypeOf(s)) fmt.Println(reflect.ValueOf(s)) var r = Rect{200, 100} fmt.Println(reflect.TypeOf(r)) fmt.Println(reflect.ValueOf(r)) } ------ int 42 main.Rect {200 100} Process finished with exit code 0 这两个方法的参数是interface{}类型，所以调用时编译器首先会将目标变量转换成interface{}类型。接口类型包含两个指针，一个指向类型，一个指向值。上面两个方法的作用就是将接口变量进行解剖从而分离出类型和值。 TypeOf()方法返回变量的类型信息得到的是一个类型为reflect.Type的变量 ValueOf()方法返回变量的值信息得到的是一个类型为reflect.Value的变量 reflect.Type它是一个接口类型，里面定义了非常多的方法用于获取和这个类型相关的一切信息： type Type interface { ... Method(i int) Method // 获取挂在类型上的第 i&#39;th 个方法 ... NumMethod() int // 该类型上总共挂了几个方法 Name() string // 类型的名称 PkgPath() string // 所在包的名称 Size() uintptr // 占用字节数 String() string // 该类型的字符串形式 Kind() Kind // 元类型 ... Bits() // 占用多少位 ChanDir() // 通道的方向 ... Elem() Type // 数组，切片，通道，指针，字典(key)的内部子元素类型 Field(i int) StructField // 获取结构体的第 i&#39;th 个字段 ... In(i int) Type // 获取函数第 i&#39;th 个参数类型 Key() Type // 字典的 key 类型 Len() int // 数组的长度 NumIn() int // 函数的参数个数 NumOut() int // 函数的返回值个数 Out(i int) Type // 获取函数 第 i&#39;th 个返回值类型 common() *rtype // 获取类型结构体的共同部分 uncommon() *uncommonType // 获取类型结构体的不同部分 } 所有的类型结构体都包含一个共同的部分信息，这部分信息使用rtype结构体描述，rtype实现了Type接口的所有方法： // 基础类型 rtype 实现了 Type 接口 type rtype struct { size uintptr // 占用字节数 ptrdata uintptr hash uint32 // 类型的hash值 ... kind uint8 // 元类型 ... } // 切片类型 type sliceType struct { rtype elem *rtype // 元素类型 } // 结构体类型 type structType struct { rtype pkgPath name // 所在包名 fields []structField // 字段列表 } ... reflect.Value不同于reflect.Type的复杂，reflect.Value是一个非常简单的结构体： type Value struct { typ *rtype // 变量的类型结构体 ptr unsafe.Pointer // 数据指针 flag uintptr // 标志位 } 来看一个简单的例子： package main import ( &quot;fmt&quot; &quot;reflect&quot; ) func main() { type SomeInt int var s SomeInt = 42 var t = reflect.TypeOf(s) var v = reflect.ValueOf(s) // reflect.ValueOf(s).Type() 等价于 reflect.TypeOf(s) fmt.Println(t == v.Type()) fmt.Println(v.Kind() == reflect.Int) // 元类型 // 将 Value 还原成原来的变量 var is = v.Interface() fmt.Println(is.(SomeInt)) } ------ true true 42 Process finished with exit code 0 Value结构体虽然简单，但是其附带的方法非常多，主要是用来方便用户读写ptr字段指向的数据内存。使用Value结构体提供的方法要比unsafe包更加简单直接： func (v Value) SetLen(n int) // 修改切片的 len 属性 func (v Value) SetCap(n int) // 修改切片的 cap 属性 func (v Value) SetMapIndex(key, val Value) // 修改字典 kv func (v Value) Send(x Value) // 向通道发送一个值 func (v Value) Recv() (x Value, ok bool) // 从通道接受一个值 // Send 和 Recv 的非阻塞版本 func (v Value) TryRecv() (x Value, ok bool) func (v Value) TrySend(x Value) bool // 获取切片、字符串、数组的具体位置的值进行读写 func (v Value) Index(i int) Value // 根据名称获取结构体的内部字段值进行读写 func (v Value) FieldByName(name string) Value // 将接口变量装成数组，一个是类型指针，一个是数据指针 func (v Value) InterfaceData() [2]uintptr // 根据名称获取结构体的方法进行调用 // Value 结构体的数据指针 ptr 可以指向方法体 func (v Value) MethodByName(name string) Value ... Go 语言官方的反射三大定律 Reflection goes from interface value to reflection object. Reflection goes from reflection object to interface value. To modify a reflection object, the value must be settable. 第一条定律的意思是反射将接口变量转换成反射对象Type和Value： func TypeOf(v interface{}) Type func ValueOf(v interface{}) Value 第二条定律的意思是可以通过反射对象Value还原成原先的接口变量，指的就是Value结构体提供的Interface方法： func (v Value) Interface() interface{} 注意：v.Interface得到的是一个接口变量，还需要经过一次造型才能还原成原先的变量 第三条定律的意思是值类型的变量不可以通过反射来修改，因为在反射之前，传参的时候需要将值变量转换成接口变量，值内容会被浅拷贝，所以reflect包直接禁止了通过反射来修改值类型的变量： package main import &quot;reflect&quot; func main() { var s int = 42 var v = reflect.ValueOf(s) v.SetInt(43) } ------ panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignable(0x82) C:/Go/src/reflect/value.go:234 +0x15e reflect.Value.SetInt(0x47b4a0, 0xc00004c000, 0x82, 0x2b) C:/Go/src/reflect/value.go:1472 +0x36 main.main() C:/Users/abel1/go/src/hello/routine.go:8 +0xc7 Process finished with exit code 2 可以看到当尝试通过反射来修改整型变量时，程序直接抛出了异常。而通过反射来修改指针变量指向的值还是可行的： panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignable(0x82) C:/Go/src/reflect/value.go:234 +0x15e reflect.Value.SetInt(0x47b4a0, 0xc00004c000, 0x82, 0x2b) C:/Go/src/reflect/value.go:1472 +0x36 main.main() C:/Users/abel1/go/src/hello/routine.go:8 +0xc7 Process finished with exit code 2 ------ 43 Process finished with exit code 0 结构体也是值类型，也必须通过指针类型来修改。下面尝试使用反射来动态修改结构体内部字段的值： package main import &quot;fmt&quot; import &quot;reflect&quot; type Rect struct { Width int Height int } func SetRectAttr(r *Rect, name string, value int) { var v = reflect.ValueOf(r) var field = v.Elem().FieldByName(name) field.SetInt(int64(value)) } func main() { var r = Rect{50, 100} SetRectAttr(&amp;r, &quot;Width&quot;, 100) SetRectAttr(&amp;r, &quot;Height&quot;, 200) fmt.Println(r) } ----- {100 200} Process finished with exit code 0 16. 包管理 GOPATH 和 Vendor 摘自《快学 Go 语言》第 16 课 —— 包管理 GOPATH 和 Vendor 系统包路径Go 语言有很多内置包，内置包的使用需要用户手工import进来。Go 语言的内置包都是已经编译好的「包对象」，使用时编译器不需要进行二次编译： // go sdk 安装路径 &gt; go env GOROOT /usr/local/go &gt; go env GOOS darwin &gt; go env GOARCH amd64 &gt; ls /usr/local/go/darwin_amd64 total 22264 drwxr-xr-x 4 root wheel 136 11 3 05:11 archive -rw-r--r-- 1 root wheel 169564 11 3 05:06 bufio.a -rw-r--r-- 1 root wheel 177058 11 3 05:06 bytes.a drwxr-xr-x 7 root wheel 238 11 3 05:11 compress drwxr-xr-x 5 root wheel 170 11 3 05:11 container -rw-r--r-- 1 root wheel 93000 11 3 05:06 context.a drwxr-xr-x 21 root wheel 714 11 3 05:11 crypto -rw-r--r-- 1 root wheel 24002 11 3 05:02 crypto.a ... 全局管理 GOPATHGo 语言的GOPATH路径下存放了全局的第三方依赖包，当我们在代码里面import某个第三方包时，编译器都会到GOPATH路径下面来寻找。 &gt; go env GOPATH /Users/qianwp/go GOPATH下有三个重要的子目录，分别是： src：存放第三方包的源代码 pkg：存放编译好的第三方包对象 bin：存放第三方包提供的二进制可执行文件 当我们导入第三方包时，编译器优先寻找已经编译好的包对象，如果没有包对象，就会去源码目录寻找相应的源码来编译。使用包对象的编译速度会明显快于使用源码 友好的包路径可以使用go get指令直接去相应的网站上拉取包代码，默认使用 HTTPS 协议下载代码仓库，可以使用-insecure参数切换到 HTTP 协议。 import &quot;github.com/go-redis/redis&quot; import &quot;golang.org/x/net&quot; import &quot;gopkg.in/mgo.v2&quot; import &quot;myhost.com/user/repo&quot; // 个人提供的仓库 编写第一个模块现在尝试编写第一个 Go 语言算法模块mathy，提供两个方法：Fib用来计算斐波那契数，Fact用来计算阶乘： &gt; mkdir -p $GOPATH/src/github.com/abelsu7/mathy &gt; cd $GOPATH/src/github.com/abelsu7/mathy 然后创建mathy.go文件： package mathy // 函数名大写，其它的包才可以看的见 func Fib(n int) int64 { if n &lt;= 1 { return 1 } var s = make([]int64, n+1) s[0] = 1 s[1] = 1 for i := 2; i &lt;= n; i++ { s[i] = s[i-1] + s[i-2] } return s[n] } func Fact(n int) int64 { if n &lt;= 1 { return 1 } var s int64 = 1 for i := 2; i &lt;= n; i++ { s *= int64(i) } return s } 之后去其他的任意空目录下编写main.go文件来使用mathy，但是不能在当前目录，因为同一个目录只能有同一个包名： package main import ( &quot;fmt&quot; &quot;github.com/abelsu7/mathy&quot; ) func main() { fmt.Println(mathy.Fib(10)) fmt.Println(mathy.Fact(10)) } ------ 89 3628800 Process finished with exit code 0 将代码推送到 Github 上，之后在任意 GO 语言环境下使用go get github.com/abelsu7/mathy即可将代码拉取到$GOPATH/src/目录下。 替换导入包名import pmathy &quot;github.com/pyloque/mathy&quot; import omathy &quot;github.com/other/mathy&quot; 无名导入Go 语言还支持一种罕见的导入语法可以将其它包的所有类型变量都导入到当前的文件中，在使用相关类型变量时可以省去包名前缀： package main import &quot;fmt&quot; import . &quot;github.com/pyloque/mathy&quot; func main() { fmt.Println(Fib(10)) fmt.Println(Fact(10)) } go get/build/installGo 提供了三个比较的常用的指令go get、go build、go install用来进行全局的包管理。 go build：仅编译。如果当前包里有main包，就会生成二进制文件。如果没有main包，则仅仅用来检查编译是否可以通过，编译完成后会丢弃所有临时包对象。如果指定-i参数，则会将编译成功的第三方依赖包对象安装到$GOPATH/pkg目录 go install：先编译，再安装。将编译成的包对象安装到$GOPATH的pkg目录中，将编译成的可执行文件安装到$GOPATH的bin目录中。如果指定-i参数，还会安装编译成功的第三方依赖包对象 go get：下载代码、编译和安装。安装内容包括包对象和可执行文件，但是不包括依赖包 使用go run指令时如果发现程序启动了很久，就可以考虑先执行go build -i指令，将编译成功的依赖包都安装到$GOPATH/pkg，这样再次运行go run指令就会快很多 局部管理 Vendor多版本依赖有一个专业的名称叫「钻石型」依赖。 钻石型依赖 为了解决这个问题，Go 1.6 引入了 Vendor 机制，就是在当前项目的目录下增加vendor子目录，将自己项目依赖的所有第三方包放到vendor目录里。这样当你导入第三方包的时候，优先去vendor目录里找你需要的第三方包。如果没有，再去$GOPATH全局路径下找。 使用 Vendor 有一个限制，那就是你不能将 Vendor 里面依赖的类型暴露到外面去，Vendor 里面的依赖包提供的功能仅限于当前项目使用，这就是 Vendor 的「隔离沙箱」。正是因为这个沙箱才使得项目里可以存在因为依赖传递导致的同一个依赖包的多个版本 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"}]},{"title":"重启或关闭 Linux 系统的 6 个终端命令","slug":"6-commands-to-shutdown-linux","date":"2019-01-03T13:42:07.000Z","updated":"2019-09-01T13:04:10.979Z","comments":true,"path":"2019/01/03/6-commands-to-shutdown-linux/","link":"","permalink":"https://abelsu7.top/2019/01/03/6-commands-to-shutdown-linux/","excerpt":"重启或关闭 Linux 系统是诸多风险操作之一，务必慎之又慎。 Linux 系统在重启或关闭之前，会通知所有已登录的用户和进程。如果在命令中加入了时间参数，系统还将拒绝新的用户登入请求。","text":"重启或关闭 Linux 系统是诸多风险操作之一，务必慎之又慎。 Linux 系统在重启或关闭之前，会通知所有已登录的用户和进程。如果在命令中加入了时间参数，系统还将拒绝新的用户登入请求。 推荐阅读： 查看系统/服务器正常运行时间的 11 个方法 | 2daygeek Tuptime 一款为 Linux 系统保存历史记录、统计运行时间工具 | 2daygeek 下面将依次介绍以下命令 shutdown、halt、poweroff、reboot：用于休眠、重启或关机 init：initialization 的简称，是系统启动的第一个进程 systemctl：systemd 是 Linux 系统和服务器的管理程序 shutdown 命令shutdown命令用于重启或关闭本地/远程的 Linux 设备，并提供了多个选项。如果定义了时间参数，则系统会在关机的 5 分钟前创建/run/nologin文件，以确保后续的登录请求会被拒绝。 通用语法如下： &gt; shutdown [OPTION] [TIME] [MESSAGE] 运行以下命令则会立即关闭 Linux 设备。-h now表示立刻杀死所有进程，并关闭系统： -h：如果不特指-halt选项，则等价于-poweroff选项 &gt; shutdown -h now 另外我们可以使用带有-halt选项的shutdown命令立即关闭设备： -H、--halt：停止设备运行 &gt; shutdown --halt now # 或者 &gt; shutdown -H now 还可以使用带有poweroff选项的shutdown命令： -P、--poweroff：切断电源（默认） &gt; shutdown --poweroff now # 或者 &gt; shutdown -P now 如果没有使用时间选项运行以下命令，则命令会在一分钟之后执行： [root@centos-1~] &gt; shutdown -h Shutdown scheduled for Mon 2018-10-08 06:42:31 EDT, use &#39;shutdown -c&#39; to cancel. [root@centos-2~] &gt; Broadcast message from root@centos-1 (Mon 2018-10-08 06:41:31 EDT): The system is going down for power-off at Mon 2018-10-08 06:42:31 EDT! 若要取消关机计划，则可使用shutdown -c： [root@centos-1~] &gt; shutdown -c Broadcast message from root@centos-1 (Mon 2018-10-08 06:39:09 EDT): The system shutdown has been cancelled at Mon 2018-10-08 06:40:09 EDT! 同样的，其他登录用户都能在中断中看到如下的广播消息： [root@centos-2~] &gt; Broadcast message from root@centos-1 (Mon 2018-10-08 06:41:35 EDT): The system shutdown has been cancelled at Mon 2018-10-08 06:42:35 EDT! 如果想在指定时间（例如N秒）后执行重启或关机操作，则可添加时间参数，并可以为所有登录用户添加自定义广播消息。例如，我们将在五分钟后重启设备： [root@centos-1~] &gt; shutdown -r +5 &quot;To activate the latest Kernel&quot; Shutdown scheduled for Mon 2018-10-08 07:13:16 EDT, use &#39;shutdown -c&#39; to cancel. [root@centos-2~] &gt; Broadcast message from root@vps.2daygeek.com (Mon 2018-10-08 07:08:16 EDT): To activate the latest Kernel The system is going down for reboot at Mon 2018-10-08 07:13:16 EDT! 运行以下命令则会立即杀死所有进程并重启系统： &gt; shutdown -r now reboot 命令reboot命令同样可以重启或关闭本地/远程的 Linux 设备。 执行不带任何参数的reboot命令以重启 Linux 设备： &gt; reboot 执行带-p参数的reboot命令以关闭 Linux 设备电源： -p、--poweroff：调用halt或poweroff命令，切断设备电源 &gt; reboot -p 执行带-f参数的reboot命令以强制重启 Linux 设备（类似按压机器上的电源键）： -f、--force：立刻强制终端，切断电源或重启 &gt; reboot -f init 命令init进程是 Linux 系统启动的第一个进程。 它会检查/etc/inittab文件并决定 Linux 的运行级别。同时，允许用户在 Linux 设备上执行关机或重启操作。级别范围为0~6，共七个运行等级。 推荐阅读：如何检查 Linux 上所有运行的服务 | 2daygeek 执行以下命令关闭系统： 0：停机 - 关闭系统 &gt; init 0 执行以下命令重启设备： 6：重启 - 重启设备 &gt; init 6 halt 命令halt命令用来切断电源或关闭本地/远程 Linux 设备。它会中断所有进程并关闭 CPU： &gt; halt poweroff 命令poweroff命令同样用来切断电源或关闭本地/远程 Linux 设备。poweroff很像halt，但不同的是它可以关闭设备硬件：poweroff会给主板发送 ACPI 指令，主板再将信号发送给电源并切断电源： &gt; poweroff systemctl 命令systemd 是一款适用于所有主流 Linux 发行版的全新 init 系统和系统管理器，它是内核启动的第一个进程，并持有序号为1的进程 PID。 推荐阅读：chkservice – 一款终端下系统单元管理工具 | 2daygeek systemd是一切进程的父进程，Fedora 15 是第一个适配安装 systemd（替代 upstart）的 Linux 发行版。 systemctl是命令行下管理 systemd 守护进程和服务的主要工具。常用命令包括：start、restart、stop、enable、disable、reload和status。 systemd 使用.service文件而不是 SysV init 使用的 bash 脚本。systemd 将所有守护进程归于自身的 Linux cgroups 用户组下，可以浏览/cgroup/systemd文件查看该系统的层次等级。 &gt; systemctl halt &gt; systemctl poweroff &gt; systemctl reboot &gt; systemctl suspend &gt; systemctl hibernate 参考文章 重启和关闭 Linux 系统的 6 个终端命令 | Linux 中国 6 Commands To Shutdown And Reboot The Linux System From Terminal | 2daygeek 查看系统/服务器正常运行时间的 11 个方法 | 2daygeek Tuptime 一款为 Linux 系统保存历史记录、统计运行时间工具 | 2daygeek 如何检查 Linux 上所有运行的服务 | 2daygeek chkservice – 一款终端下系统单元管理工具 | 2daygeek 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"},{"name":"终端","slug":"终端","permalink":"https://abelsu7.top/tags/终端/"}]},{"title":"解决 VS Code 中 golang.org 被墙导致的 Go 插件安装失败问题","slug":"go-vscode-plugin","date":"2018-12-28T08:58:51.000Z","updated":"2019-09-01T13:04:11.275Z","comments":true,"path":"2018/12/28/go-vscode-plugin/","link":"","permalink":"https://abelsu7.top/2018/12/28/go-vscode-plugin/","excerpt":"Google 在今年一月发布了golang.org 的镜像站golang.google.cn，中国大陆可直接访问。详情参见 Hello, 中国! | The Go Blog","text":"Google 在今年一月发布了golang.org 的镜像站golang.google.cn，中国大陆可直接访问。详情参见 Hello, 中国! | The Go Blog 微软官方开发的 Go for Visual Studio Code 插件为Go 语言 提供了丰富的支持。在VS Code 中首次打开 Go 工作区后，VS Code 会自动检测当前开发环境为 Go 并推荐安装上述插件。 然而 Go 插件的安装并不顺利：输出窗口的安装信息提示其中一些依赖工具安装失败： Installing github.com/mdempsky/gocode FAILED Installing github.com/ramya-rao-a/go-outline FAILED Installing github.com/acroca/go-symbols FAILED Installing golang.org/x/tools/cmd/guru FAILED Installing golang.org/x/tools/cmd/gorename FAILED Installing github.com/stamblerre/gocode FAILED Installing github.com/ianthehat/godef FAILED Installing github.com/sqs/goreturns FAILED Installing golang.org/x/lint/golint FAILED 9 tools failed to install. 手动使用go get -v github.com/mdempsky/gocode等命令同样提示网络连接失败。 失败原因原因其实很简单：golang.org 在国内由于一些众所周知的原因无法直接访问，而go get在获取gocode、go-def、golint等插件依赖工具的源码时，需要从golang.org 上拉取部分代码至GOPATH，自然就导致了最后这些依赖于golang.org 代码的依赖工具安装失败。 解决办法解决也并不复杂：先通过git clone命令手动将依赖工具的源码拉取至GOPATH的对应路径，再通过go install命令安装依赖工具。 以 Windows 为例，首先进入%GOPATH%\\src\\目录，并创建golang.org\\x。 之后进入%GOPATH%\\src\\golang.org\\x，使用下列命令下载插件依赖工具的源码： git clone https://github.com/golang/tools.git tools git clone命令执行完毕后，所需的工具源码就都保存在tools目录中。 最后进入%GOPATH%目录，根据之前的安装失败提示信息安装对应的依赖工具： go install github.com/mdempsky/gocode go install github.com/ramya-rao-a/go-outline go install github.com/acroca/go-symbols go install golang.org/x/tools/cmd/guru go install golang.org/x/tools/cmd/gorename go install github.com/stamblerre/gocode go install github.com/ianthehat/godef go install github.com/sqs/goreturns go install golang.org/x/lint/golint 安装 golint在执行go install命令安装 golint 时，提示信息如下： go install golang.org/x/lint/golint can't load package: package golang.org/x/lint/golint: cannot find package \"golang.org/x/lint/golint\" in any of: C:\\Go\\src\\golang.org\\x\\lint\\golint (from $GOROOT) C:\\Users\\abel1\\go\\src\\golang.org\\x\\lint\\golint (from $GOPATH) 这是因为 golint 的源码在lint下，而不是tools，需要单独拉取 golint 源码。 进入%GOPATH%\\src\\golang.org\\x，执行下列命令拉取 golint 源码： git clone https://github.com/golang/lint 最后回到%GOPATH%，通过go install安装 golint： go install golang.org/x/lint/golint 重启 VS Code 后，插件就可以正常使用了。Now let’s go for Go！ 参考文章 解决 VS Code 中 golang.org 被墙导致的 Go 插件安装失败问题 | 苏易北 解决vscode中golang插件依赖安装失败问题 | 简书 VSCode安装go语言开发环境，go插件问题解决 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://abelsu7.top/tags/VS-Code/"}]},{"title":"学术论文参考文献格式","slug":"paper-ref-format","date":"2018-12-19T02:02:17.000Z","updated":"2019-09-01T13:04:11.602Z","comments":true,"path":"2018/12/19/paper-ref-format/","link":"","permalink":"https://abelsu7.top/2018/12/19/paper-ref-format/","excerpt":"参考文献格式应符合GB7714-1987《文后参考文献著录规则》","text":"参考文献格式应符合GB7714-1987《文后参考文献著录规则》 参考文献的类型根据GB3469-83《文献类型与文献载体代码》规定，各类常用文献以单字母标识： M: 专著 C: 论文集 N: 报纸文章 J: 期刊文章 D: 学位论文 R: 研究报告 S: 标准 P: 专利 A: 专著、论文集中的析出文献 Z: 其他未说明的文献类型 电子文献类型以双字母作为标识： DB: 数据库 CP: 计算机程序 EB: 电子公告 非纸张型载体电子文献，在参考文献标识中同时标明其载体类型： DB/OL: 联机网上的数据库 DB/MT: 磁带数据库 M/CD: 光盘图书 CP/DK: 磁盘软件 J/OL: 网上期刊 EB/OL: 网上电子公告 参考文献常用格式1. 期刊# 应标明年、卷、期，尤其注意区分卷和期 [序号] 主要作者.文献题名[J].刊名，出版年份，卷号(期号)：起止页码. # 例如: [1] 袁庆龙，候文义.Ni-P 合金镀层组织形貌及显微硬度研究[J].太原理工大学学报，2001，32(1)：51-53. 2. 专著# 应标明出版地及所参阅内容在原文献中的位置 [序号] 著者.书名[M].出版地：出版者，出版年：起止页码. # 例如: [2] 刘国钧，王连成.图书馆史研究[M].北京：高等教育出版社，1979：15-18，31. 3. 论文集# 应标明出版信息及起止页码 [序号] 著者.文献题名[C].编者.论文集名.出版地：出版者，出版年：起止页码. # 例如: [3] 孙品一.高校学报编辑工作现代化特征[C].中国高等学校自然科学学报研究会.科技编辑学论文集(2).北京：北京师范大学出版社，1998：10-22. 4. 学位论文# 应标明保存单位及发表年份 [序号] 作者.题名[D].保存地：保存单位，年份. # 例如: [4] 张和生.地质力学系统理论[D].太原：太原理工大学，1998. 5. 报告# 应标明报告会主办单位及年份 [序号] 作者.文献题名[R].报告地：报告会主办单位，年份. # 例如: [5] 冯西桥.核反应堆压力容器的LBB 分析[R].北京：清华大学核能技术设计研究院，1997. 6. 专利文献# 应标明专利所有者及发布日期 [序号] 专利所有者.专利题名[P].专利国别：专利号，发布日期. # 例如: [6] 姜锡洲.一种温热外敷药制备方案[P].中国专利：881056078，1983-08-12. 7. 国际、国家标准# 应标明出版地、出版者及出版年份 [序号] 标准代号，标准名称[S].出版地：出版者，出版年. # 例如: [7] GB/T 16159—1996，汉语拼音正词法基本规则[S].北京：中国标准出版社，1996. 8. 报纸文章# 应标明出版日期及印刷批次 [序号] 作者.文献题名[N].报纸名，出版日期(版次). # 例如: [8] 谢希德.创造学习的思路[N].人民日报，1998-12-25(10). 9. 电子文献# 应标明载体类型及可获得地址 [序号] 作者.电子文献题名[文献类型/载体类型].电子文献的出版或可获得地址，发表或更新的期/引用日期(任选). # 例如: [9] 王明亮.中国学术期刊标准化数据库系统工程的[EB/OL]. 参考文献快速格式化1. 百度学术直接引用/批量引用在百度学术中搜索想要引用的参考文献，点击引用或批量引用即可自动生成引用格式。 在百度学术中直接引用 支持GB/T 7714(国标)、MLA、APA三种格式，在批量引用中可一键复制全部的参考文献引用格式。 2. 参考文献自动生成器 | 笔杆网利用笔杆网提供的参考文献自动生成器检索文章并添加引用格式。 参考文献自动生成器 | 笔杆网 同样支持GB/T 7714(国标)、MLA、APA。 参考文章 关于学术论文的参考文献格式 | 简书 参考文献标准格式 | 知乎 参考文献自动生成器 | 笔杆网 硕士论文参考文献的格式 | 笔杆网 毕业论文参考文献规范格式 | 笔杆网 参考文献常用的书写格式 | 笔杆网 参考文献格式 | peda.net GB7714-1987《文后参考文献著录规则》 GB3469-83《文献类型与文献载体代码》 🚩推荐阅读（由hexo文章推荐插件驱动）历年顶会自动摘要论文合集","categories":[{"name":"写作","slug":"写作","permalink":"https://abelsu7.top/categories/写作/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://abelsu7.top/tags/论文/"},{"name":"参考文献","slug":"参考文献","permalink":"https://abelsu7.top/tags/参考文献/"}]},{"title":"Leetcode 9. 回文数","slug":"leetcode-9-palindrome-number","date":"2018-12-17T08:57:51.000Z","updated":"2019-09-01T13:04:11.481Z","comments":true,"path":"2018/12/17/leetcode-9-palindrome-number/","link":"","permalink":"https://abelsu7.top/2018/12/17/leetcode-9-palindrome-number/","excerpt":"题目描述 判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。Try it on Leetcode","text":"题目描述 判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。Try it on Leetcode 输入示例示例 1 输入: 121 输出: true 示例 2 输入: -121 输出: false 解释: 从右向左读为 121-, 因此不是回文数 示例 3 输入: 10 输出: false 解释: 从右向左读为 01, 因此不是回文数 解题思路：反转一半数字映入脑海的第一个想法是将数字转换为字符串，并检查字符串是否为回文。但是，这需要额外的非常量空间来创建问题描述中所不允许的字符串。 第二个想法是将数字本身反转，然后将反转后的数字与原始数字进行比较，如果它们是相同的，那么这个数字就是回文数。但是，如果反转后的数字大于Integer.MAX_VALUE，就会遇到整数溢出的问题。 按照第二个想法，为了避免数字反转可能导致的溢出问题，可以考虑只反转int数字的一半。如果输入的是回文数，那么其后半部分反转后应该与原始数字的前半部分相同。 Java 实现class Solution { public boolean isPalindrome(int x) { /** * if x &lt; 0 or end up with 0 ( except 0 itself ) * then return false */ if (x &lt; 0 || (x % 10 == 0 &amp;&amp; x != 0)) { return false; } int reverseNumber = 0; while (x &gt; reverseNumber) { reverseNumber = reverseNumber * 10 + x % 10; x /= 10; } return x == reverseNumber || x == reverseNumber / 10; } } Go 实现func isPalindrome(x int) bool { if x &lt; 0 || (x % 10 == 0 &amp;&amp; x != 0) { return false } reverseNumber := 0 for x &gt; reverseNumber { reverseNumber = reverseNumber * 10 + x % 10 x /= 10 } return x == reverseNumber || x == reverseNumber / 10 } 复杂度分析 时间复杂度：$O(\\log_{10}(n))$。对于每次迭代，需要将输入除以10 空间复杂度：$O(1)$ 参考文章 9. Palindrome Number | Leetcode Leetcode 9. 回文数 | 苏易北 题解 - 9. 回文数 | Leetcode力扣 🚩推荐阅读（由hexo文章推荐插件驱动）Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总Java 笔记 5：集合Java 笔记 6：异常、断言和日志检查回文数检查回文数","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://abelsu7.top/tags/Leetcode/"}]},{"title":"Leetcode 292. Nim 游戏","slug":"leetcode-292-nim-game","date":"2018-12-14T09:36:58.000Z","updated":"2019-09-01T13:04:11.477Z","comments":true,"path":"2018/12/14/leetcode-292-nim-game/","link":"","permalink":"https://abelsu7.top/2018/12/14/leetcode-292-nim-game/","excerpt":"题目描述 你和你的朋友，两人一起玩 Nim 游戏：桌子上有一堆石头，每次你们轮流拿掉1-3块石头，你作为先手，拿掉最后一块石头的人获胜。你们是聪明人，每一步都是最优解。编写一个函数，来判断你是否可以在给定石头数量的情况下赢得游戏。Try it on Leetcode","text":"题目描述 你和你的朋友，两人一起玩 Nim 游戏：桌子上有一堆石头，每次你们轮流拿掉1-3块石头，你作为先手，拿掉最后一块石头的人获胜。你们是聪明人，每一步都是最优解。编写一个函数，来判断你是否可以在给定石头数量的情况下赢得游戏。Try it on Leetcode 输入示例Input : 4 Output : false 如果堆中有4块石头，那么你永远不会赢得游戏，因为最后一块石头总是会被你的朋友拿走。 巴什博弈（Bash Game）根据 巴什博奕，若有： n % (m + 1) != 0 则可知先手必胜。 Java 实现class Solution { public boolean canWinNim(int n) { // Bash Game - n % (m + 1) != 0. First will win. return n % 4 != 0; } } 参考文章 292. Nim Game | Leetcode Leetcode 292. Nim 游戏 | 苏易北 🚩推荐阅读（由hexo文章推荐插件驱动）Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总Java 笔记 5：集合Java 笔记 6：异常、断言和日志检查回文数检查回文数","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://abelsu7.top/tags/Leetcode/"}]},{"title":"Leetcode 101. 对称二叉树","slug":"leetcode-101-symmetric-tree","date":"2018-12-13T13:42:51.000Z","updated":"2019-09-01T13:04:11.458Z","comments":true,"path":"2018/12/13/leetcode-101-symmetric-tree/","link":"","permalink":"https://abelsu7.top/2018/12/13/leetcode-101-symmetric-tree/","excerpt":"题目描述 给定一个二叉树，检查它是否是镜像对称的。Try it on Leetcode","text":"题目描述 给定一个二叉树，检查它是否是镜像对称的。Try it on Leetcode 输入示例例如，二叉树[1,2,2,3,4,4,3]是对称的 1 / \\ 2 2 / \\ / \\ 3 4 4 3 但是下面这个1,2,2,null,3,null,3则不是镜像对称的 1 / \\ 2 2 \\ \\ 3 3 树的定义首先，给出我们将要使用的树的节点TreeNode的定义： /** * Definition for a binary tree node. */ public class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } 方法一：递归算法描述如果一个树的左子树和右子树镜像对称，那么这个树就是对称的。 因此，该问题可以转化为：两个树在什么情况下互为镜像？ 如果同时满足下列条件，则两个树互为镜像： 它们的两个根节点具有相同的值 每个树的右子树都与另一个树的左子树镜像对称 Java 实现/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public boolean isSymmetric(TreeNode root) { return isMirror(root, root); } public boolean isMirror(TreeNode t1, TreeNode t2) { if (t1 == null &amp;&amp; t2 == null) return true; if (t1 == null || t2 == null) return false; return (t1.val == t2.val) &amp;&amp; isMirror(t1.right, t2.left) &amp;&amp; isMirror(t1.left, t2.right); } } Go 实现/** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isSymmetric(root *TreeNode) bool { return isMirror(root, root) } func isMirror(t1 *TreeNode, t2 *TreeNode) bool { switch { case t1 == nil &amp;&amp; t2 == nil: return true case t1 == nil || t2 == nil: return false default: return (t1.Val == t2.Val) &amp;&amp; isMirror(t1.Right, t2.Left) &amp;&amp; isMirror(t1.Left, t2.Right) } } 复杂度分析 时间复杂度：由于要遍历整个输入树一次，所以总的运行时间为 $O(N)$，其中 $N$ 是树中节点的数量。 空间复杂度：递归调用的次数受树的高度限制。在最糟糕的情况下，树是线性的，其高度为 $N$。因此，在最糟糕的情况下，由栈上的递归调用造成的空间复杂度为 $O(N)$。 方法二：迭代算法描述除了递归的方法外，还可以利用队列进行迭代。队列中每两个连续的结点应该是相等的，而且它们的子树互为镜像。 最开始，队列中包含的是root和root。该算法的工作原理类似于 BFS，但存在一些关键差异。 每次提取两个节点并比较它们的值。然后将两个节点的左右子节点按相反的顺序插入队列中。当队列为空时，或我们检测到树不对称（即从队列中取出两个不相等的连续节点）时，算法结束。 Java 实现/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public boolean isSymmetric(TreeNode root) { Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;(); q.add(root); q.add(root); while (!q.isEmpty()) { TreeNode t1 = q.poll(); TreeNode t2 = q.poll(); if (t1 == null &amp;&amp; t2 == null) continue; if (t1 == null || t2 == null) return false; if (t1.val != t2.val) return false; q.add(t1.left); q.add(t2.right); q.add(t1.right); q.add(t2.left); } return true; } } 复杂度分析 时间复杂度：$O(N)$，因为要遍历整个输入树一次，其中 $N$ 是树中节点的总数。 空间复杂度：鉴于搜索队列需要额外的空间，在最糟糕的情况下，不得不向队列中插入 $O(N)$ 个节点。因此，空间复杂度为 $O(N)$。 参考文章 101. Symmetric Tree | Leetcode Leetcode 101. 对称二叉树 | 苏易北 题解 - 101. 对称二叉树 | Leetcode力扣 🚩推荐阅读（由hexo文章推荐插件驱动）gops：Go 程序查看和诊断分析工具简介使用 Gogs 自建 Git 服务在 Gin 中使用 swaggo 自动生成 RESTful API 文档使用 upx 压缩 go build 打包的可执行文件转载《Go语言interface底层实现》转载《Go语言interface底层实现》","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Go","slug":"Go","permalink":"https://abelsu7.top/tags/Go/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://abelsu7.top/tags/Leetcode/"},{"name":"二叉树","slug":"二叉树","permalink":"https://abelsu7.top/tags/二叉树/"}]},{"title":"Leetcode 104. 二叉树的最大深度","slug":"leetcode-104-maxdepth-of-binary-tree","date":"2018-12-12T09:59:17.000Z","updated":"2019-09-01T13:04:11.464Z","comments":true,"path":"2018/12/12/leetcode-104-maxdepth-of-binary-tree/","link":"","permalink":"https://abelsu7.top/2018/12/12/leetcode-104-maxdepth-of-binary-tree/","excerpt":"题目描述 给定一个二叉树，找出其最大深度。Try it on Leetcode","text":"题目描述 给定一个二叉树，找出其最大深度。Try it on Leetcode 输入示例 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 给定二叉树[3,9,20,null,null,15,7] 3 / \\ 9 20 / \\ 15 7 返回它的最大深度3。 树的定义首先，给出我们将要使用的树的节点TreeNode的定义： /** * Definition for a binary tree node. */ public class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } 方法一：递归算法描述 DFS 递归求解 最直观的方法是通过递归来解决该问题，上图演示了 DFS（深度优先搜索）策略的求解过程。 Java 实现/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public int maxDepth(TreeNode root) { return root == null ? 0 : Math.max(maxDepth(root.left), maxDepth(root.right)) + 1; } } 复杂度分析 时间复杂度：由于每个结点只访问一次，因此时间复杂度为 $O(N)$，其中N是节点的数量。 空间复杂度：在最糟糕的情况下，树是完全不平衡的。例如每个节点只剩下左子节点，这时递归将会被调用N次（树的高度），因此保持调用栈的存储为 $O(N)$。但在最好的情况下（树是完全平衡的），树的高度为 $\\log(N)$，此时空间复杂度为 $O(\\log(N))$。 方法二：迭代算法描述 迭代的思路是使用 DFS 策略访问每个节点，同时在每次访问时更新最大深度。 所以从包含根节点且相应深度为1的栈开始,然后继续迭代：将当前节点弹出栈并推入子节点。并且每一步都会更新深度。 Java 实现import java.util.LinkedList; import java.util.Queue; import javafx.util.Pair; /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public int maxDepth(TreeNode root) { Queue&lt;Pair&lt;TreeNode, Integer&gt;&gt; stack = new LinkedList&lt;&gt;(); if (root != null) { stack.add(new Pair(root, 1)); } int depth = 0; while (!stack.isEmpty()) { Pair&lt;TreeNode, Integer&gt; current = stack.poll(); root = current.getKey(); int current_depth = current.getValue(); if (root != null) { depth = Math.max(depth, current_depth); stack.add(new Pair(root.left, current_depth + 1)); stack.add(new Pair(root.right, current_depth + 1)); } } return depth; } } 复杂度分析 时间复杂度：$O(N)$ 空间复杂度：$O(N)$ 参考文章 104. Maximum Depth of Binary Tree | Leetcode Leetcode 104. 二叉树的最大深度 | 苏易北 题解 - 104. 二叉树的最大深度 | Leetcode力扣 🚩推荐阅读（由hexo文章推荐插件驱动）Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总Java 笔记 5：集合Java 笔记 6：异常、断言和日志检查回文数检查回文数","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://abelsu7.top/tags/Leetcode/"},{"name":"二叉树","slug":"二叉树","permalink":"https://abelsu7.top/tags/二叉树/"}]},{"title":"Leetcode 118. 杨辉三角","slug":"leetcode-118-pascal-triangle","date":"2018-12-12T01:40:54.000Z","updated":"2019-09-01T13:04:11.472Z","comments":true,"path":"2018/12/12/leetcode-118-pascal-triangle/","link":"","permalink":"https://abelsu7.top/2018/12/12/leetcode-118-pascal-triangle/","excerpt":"题目描述 给定一个非负整数 numRows，生成杨辉三角的前 numRows 行。Try it on Leetcode","text":"题目描述 给定一个非负整数 numRows，生成杨辉三角的前 numRows 行。Try it on Leetcode 输入示例输入: 5 输出: [ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1] ] 解题思路：动态规划 如果能够知道一行杨辉三角，我们就可以根据每对相邻的值轻松地计算出它的下一行。 算法描述首先，初始化整个 triangle 列表，三角形的每一行都以子列表的形式存储。 之后，检查行数为 0 的特殊情况，若为 0 则直接返回 []。 如果 numRows &gt; 0，则用 [1] 作为第一行来初始化 triangle，并按如下方式继续填充： 动态规划填充杨辉三角 复杂度分析 时间复杂度：$O(numRows^2)$ 空间复杂度：$O(numRows^2)$ Java 实现class Solution { public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) { List&lt;List&lt;Integer&gt;&gt; triangle = new ArrayList&lt;&gt;(); // Case 1: if numRows equals zero, then return zero rows. if (0 == numRows) { return triangle; } // Case 2: the first row is always [1]. triangle.add(new ArrayList&lt;&gt;()); triangle.get(0).add(1); // Case 3: if numRows &gt; 1, calculate according to the previous row. for (int curRow = 1; curRow &lt; numRows; curRow++) { List&lt;Integer&gt; row = new ArrayList&lt;&gt;(); List&lt;Integer&gt; preRow = triangle.get(curRow - 1); // The first element is 1. row.add(1); // DP: row[i][j] = row[i-1][j-1] + row[i-1][j] for (int j = 1; j &lt; curRow; j++) { row.add(preRow.get(j-1) + preRow.get(j)); } // The last element is 1. row.add(1); triangle.add(row); } return triangle; } } Python 3 实现class Solution: def generate(self, num_rows): triangle = [] for row_num in range(num_rows): # The first and last row elements are always 1. row = [None for _ in range(row_num+1)] row[0], row[-1] = 1, 1 # Each triangle element is equal to the sum of the elements # above-and-to-the-left and above-and-to-the-right. for j in range(1, len(row)-1): row[j] = triangle[row_num-1][j-1] + triangle[row_num-1][j] triangle.append(row) return triangle 参考文章 118. Pascal’s Triangle | Leetcode Leetcode 118. 杨辉三角 | 苏易北 题解 - 118. 杨辉三角 | Leetcode力扣 🚩推荐阅读（由hexo文章推荐插件驱动）Python 速查使用 pingtop 同时 ping 多台服务器Leetcode 题解 in Golang（不定期更新）Go 语言常用算法及数据结构汇总使用virtualenv创建隔离环境奇异值分解的原理与使用","categories":[{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/categories/算法/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://abelsu7.top/tags/算法/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://abelsu7.top/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://abelsu7.top/tags/Python/"}]},{"title":"获取微信公众号文章封面图片","slug":"extract-wechat-cover","date":"2018-12-05T03:12:19.000Z","updated":"2019-09-01T13:04:11.223Z","comments":true,"path":"2018/12/05/extract-wechat-cover/","link":"","permalink":"https://abelsu7.top/2018/12/05/extract-wechat-cover/","excerpt":"📷图片存起来干啥，留着过年吗？🚴‍没错（理直气壮）！","text":"📷图片存起来干啥，留着过年吗？🚴‍没错（理直气壮）！ 某种程度上，现代生活已经离不开微信了。微信公众号也正在变成一个越来越庞大的内容集散地。 维护过个人公众号的朋友应该知道，在制作新素材时要上传图片作为文章封面，而在用户的手机端只能看到封面图片，并不能直接保存。 但有时我们会看到非常喜欢的封面图片，想存起来又该怎么办呢？例如最近看到为什么程序员需要了解数学？| 纯洁的微笑这篇文章，虽然是篇广告文。。不过封面图片很吸引我，也许以后写文会用得上： 上述文章的封面 想要存图也很简单：直接 PC 端开调试看源码就好。 首先在浏览器中打开文章链接，Ctrl+U 查看源码，Ctrl+F 搜索 var msg，找到如下的匹配字段， 查看源码 其中： msg_title 对应图文标题 msg_desc 对应图文摘要 msg_cdn_url 即为我们需要的封面图片 url cdn_url_1_1 则对应分享至朋友圈时显示的正方形缩略图 其他字段的对应关系此处不再阐述~ 参考文章 获取微信公众号文章封面图的方法 | CSDN 如何获取微信公众号文章封面图？| 红黑联盟 利用链接提取微信公众号信息 | QQ 看点（已过时） 用 awk 或者 sed 取双引号中的值 | CSDN awk 基于固定的字符抽取双引号中的数据 | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）小程序自定义分析功能（上）微信定制你自己的表情包","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"微信","slug":"微信","permalink":"https://abelsu7.top/tags/微信/"}]},{"title":"数值分析笔记 8：例题整理","slug":"math-sample-questions","date":"2018-12-02T13:24:19.000Z","updated":"2019-09-01T13:04:11.529Z","comments":true,"path":"2018/12/02/math-sample-questions/","link":"","permalink":"https://abelsu7.top/2018/12/02/math-sample-questions/","excerpt":"数值分析例题整理","text":"数值分析例题整理 目录 目录 1. 误差与范数 1.1 误差的定义 1.2 应取几位有效数字 1.3 相对误差允许范围 1.4 算术运算的误差估计 1.5 数值稳定性-1 1.6 数值稳定性-2 1.7 函数序列的一致收敛性 1.8 向量范数 1.9 矩阵范数 2. 函数插值方法 2.1 多项式插值定理 2.2 求过给定样点的插值多项式 2.3 $Lagrange$ 线性插值/二次插值 2.4 插值基函数的性质 2.5 三次 $Hermite$ 带导插值-1 2.6 三次 $Hermite$ 带导插值-2 3. 曲线拟合/连续函数逼近 3.1 线性拟合 3.2 二次拟合 3.3 指数模型的线性化拟合 3.4 双曲线模型的线性化拟合 3.5 超定方程组的近似解 3.6 法方程的矩阵形式-1 3.7 法方程的矩阵形式-2 5. 方程组数值解法——直接法 5.1 顺序 $Gauss$ 消去法 5.2 列主元 $Gauss$ 消去法 5.3 直接三角分解法 6. 方程组数值解法——迭代法 6.1 $Jacobi$ 迭代法/$Gauss$-$Seidel$ 迭代法-1 6.2 $Jacobi$ 迭代法/$Gauss$-$Seidel$ 迭代法-2 6.3 迭代法收敛性-1 6.4 迭代法收敛性-2 6.5 严格对角占优矩阵 6.6 收敛速度问题 7. 非线性方程组的数值解法 7.1 二分法 7.2 不动点迭代法 7.3 收敛性基本定理-1 7.4 收敛性基本定理-2 7.5 局部收敛定理 7.6 收敛速度与收敛阶 7.7 $Newton$ 迭代法 7.8 非线性方程组的 $Newton$ 迭代法 8. 矩阵特征值计算 8.1 计算模最大特征值 $\\lambda_1$ 的乘幂法 8.2 计算模最小特征值 $\\lambda_n$ 的反幂法 1. 误差与范数1.1 误差的定义证明：设 $x$ 的非零近似值 x^* 记为规格化形式 x^* = \\pm 10^k \\times 0.a_1a_2\\cdots a_n，其中 $k$ 为整数，$a_1,a_2,\\cdots a_n \\in \\{ 0,1,\\cdots,9; \\ a \\ne 0 \\}$，则 1.如果 x^* 有 $n$ 位有效数字，则 |e_r(x^*)| = \\frac{|x-x^*|}{|x^*|} \\leqslant \\frac{1}{2a_1} \\times 10^{1-n}2.如果 |e_r(x^*)| = \\frac{|x-x^*|}{|x^*|} \\leqslant \\frac{1}{2(a_1+1)} \\times 10^{1-n}则 $x^*$ 至少有 $n$ 位有效数字。 1.2 应取几位有效数字要使 $\\sqrt{20}$ 的近似值的相对误差不超过 $0.1\\%$，问用计算器计算时，应取几位有效数字？ 1.3 相对误差允许范围计算球体积 $V=\\displaystyle{\\frac{4}{3}} \\pi r^3$ 时，为使 $V$ 的相对误差不超过 $0.3\\%$，求半径 $r$ 的相对误差允许范围。 1.4 算术运算的误差估计设 $t=1.21$，$\\mu = 3.65$，$\\upsilon = 9.81$ 均准确到小数点后两位，试估计下列计算的相对误差：$x=t \\mu + \\upsilon$。 1.5 数值稳定性-1分析递推公式 \\begin{cases} y_0 = 28 \\\\ y_n = y_{n-1} - \\displaystyle{\\frac{1}{100}}\\sqrt{783} \\end{cases}\\quad (n=1,2,\\cdots)的数值稳定性，设实际计算时，取 $\\sqrt{783} \\approx 27.982$ 进行近似计算。 1.6 数值稳定性-2试导出计算 $I_n = \\displaystyle{\\int_{0}^{1}}x^ne^x\\mathrm{d}x \\ (n=0,1,2,\\cdots)$ 的递推公式，并讨论其数值稳定性。 1.7 函数序列的一致收敛性证明函数序列 $f_n(x) = \\displaystyle{\\frac{x}{1+n^2x^2}}$ 在 $[0,1]$ 上一致收敛于 $0$，即 $\\lim \\limits_{n \\to \\infty} f_n(x) = 0$。 1.8 向量范数设 $\\pmb{x} = (2,-4,3)^T$，求 \\left \\| \\pmb{x} \\right \\|_1、\\left \\| \\pmb{x} \\right \\|_\\infty、\\left \\| \\pmb{x} \\right \\|_2。 1.9 矩阵范数设 \\pmb{A}=\\begin{bmatrix}1 &-2 \\\\-3 &4 \\end{bmatrix}，求 \\left \\| \\pmb{A} \\right \\|_F、\\left \\| \\pmb{A} \\right \\|_1、\\left \\| \\pmb{A} \\right \\|_\\infty、\\left \\| \\pmb{A} \\right \\|_2。 2. 函数插值方法2.1 多项式插值定理证明：设已知 $[a,b]$ 上的函数 $f$ 在 $n+1$ 个互异节点 $x_i \\in [a,b]$ 上的值 $f_i=f(x_i) \\ (i=0,1,\\cdots,n)$，则存在唯一的次数 $\\leqslant n$ 的多项式 $p_n(x) \\in \\pmb{P}_n$ 满足： p_n(x) = f_i \\quad (i=0,1,\\cdots,n)2.2 求过给定样点的插值多项式求过三个样点 $A(0,1)$，$B(1,2)$，$C(2,3)$ 的插值多项式。 2.3 $Lagrange$ 线性插值/二次插值设已知 $f(x) = e^{-x}$ 的四个函数值如下表所示： \\begin{array}{c|cccc} x & \\quad 0 & 1 & 2 &3 \\\\ \\hline e^{-x} & \\quad 1 & 0.3679 & 0.1353 &0.0498 \\\\ \\end{array}试用 $Lagrange$ 公式的线性插值求 $e^{-1.4}$ 的近似值，用二次插值求 $e^{-2.1}$ 的近似值。 2.4 插值基函数的性质证明：由 $n+1$ 个互异节点 $x_i \\in [a,b]$ 构成的 $n+1$ 个插值基函数 $l_i(x) \\ (i=0,1,\\cdots,n)$ 具有性质： \\sum \\limits_{i=0}^n l_i(x)=1, \\ \\forall x \\in [a,b]2.5 三次 $Hermite$ 带导插值-1对函数 $f(x) = \\ln (x)$，给定： f(1)=0, \\ f(2)=0.693147, \\ f{}'(1)=1, \\ f{}'(2)=0.5试用三次 $Hermite$ 插值多项式 $H_3(x)$ 计算 $f(1.5)$ 的近似值并估计误差。 2.6 三次 $Hermite$ 带导插值-2试用多种解法求一个次数 $\\leqslant 3$ 的插值多项式 $H_3(x)$，满足插值条件： H_3(-1) = -1, \\ H_3(0) = H{}'_3(0) = 0, \\ H_3(1) = 13. 曲线拟合/连续函数逼近3.1 线性拟合已知实验数据如下： \\begin{array}{c|ccccc} \\hline x & \\ 1 & 3 & 4 & 6 & 7 \\\\ \\hline f & \\ -2.1 & -0.9 & -0.6 &0.6 & 0.9 \\\\ \\hline \\end{array}试求其拟合曲线。 3.2 二次拟合设已知实验数据如下表： \\begin{array}{c|ccccc} \\hline x & \\ -2 & -1 & 0 & 1 & 2 \\\\ \\hline f & \\ 0 & 1 & 2 & 1 & 0 \\\\ \\hline \\end{array}试求其二次多项式拟合模型： (1) \\ s(x) = a_0 + a_1x + a_2x^2; \\quad (2) \\ s(x) = a_0 + a_1x^23.3 指数模型的线性化拟合已知离散数据如下（权 $\\rho \\equiv 1$）： \\begin{array}{c|ccccc} \\hline x_j & \\ 1.00 & 1.25 & 1.50 & 1.75 & 2.00 \\\\ \\hline f(x_j) & \\ 5.10 & 5.79 & 6.53 & 7.45 & 8.46 \\\\ \\hline \\end{array}求形如 $s(x) = ae^{bx}$ 的拟合曲线。 3.4 双曲线模型的线性化拟合已知离散数据如下（权 $\\rho \\equiv 1$）： \\begin{array}{c|cccc} \\hline x_j & \\ 1 & 2 & 3 & 4 \\\\ \\hline f(x_j) & \\ 1.95 & 3.05 & 3.55 & 3.85 \\\\ \\hline \\end{array}求形如 $s(x) = \\displaystyle{\\frac{x}{ax+b}}$ 的拟合曲线。 3.5 超定方程组的近似解求下列超定方程组的近似解： \\begin{cases} x_1 - x_2 = 1 \\\\ -x_1 + x_2 = 2 \\\\ 2x_1 - 2x_2 = 3 \\\\ -3x_1 + x_2 = 4 \\end{cases}3.6 法方程的矩阵形式-1已知实验数据如下： \\begin{array}{c|ccccc} \\hline x & \\ 1 & 3 & 4 & 6 & 7 \\\\ \\hline y & \\ -2.1 & -0.9 & -0.6 & 0.6 & 0.9 \\\\ \\hline \\end{array}以法方程的矩阵形式求解。 3.7 法方程的矩阵形式-2已知实验数据如下： \\begin{array}{c|cccc} \\hline x & \\ 1 & 2 & 3 & 4 \\\\ \\hline f & \\ 4 & 10 & 18 & 26 \\\\ \\hline \\end{array}按最小二乘拟合求形如 $s(x)=ax+bx^2$ 的经验公式。 5. 方程组数值解法——直接法5.1 顺序 $Gauss$ 消去法用顺序 $Gauss$ 消去法（消去过程加回代过程）解方程组： \\begin{cases} x_1 + 2x_2 + x_3 = 0 \\\\ 2x_1 + 2x_2 + 3x_3 = 3 \\\\ x_1 + 3x_2 = -2 \\end{cases}5.2 列主元 $Gauss$ 消去法用列主元 $Gauss$ 消去法解方程组，并求系数矩阵行列式值 $\\det \\pmb{A}$： \\begin{cases} -3x_1 + 2x_2 + 6x_3 = 4 \\\\ 10 x_1 - 7 x_2 = 7 \\\\ 5x_1 - x_2 + 5 x_3 = 6 \\end{cases}5.3 直接三角分解法用直接三角分解法解方程组： \\begin{bmatrix} 2 & -3 & -2 \\\\ -1 & 2 & -2 \\\\ 3 & -1 & 4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}= \\begin{bmatrix} 0 \\\\ -1 \\\\ 7 \\end{bmatrix}6. 方程组数值解法——迭代法6.1 $Jacobi$ 迭代法/$Gauss$-$Seidel$ 迭代法-1已知方程组: \\begin{cases} 8x_1 - 3x_2 + 2x_3 = 20 \\\\ 4x_1 + 11x_2 - x_3 = 33 \\\\ 2x_1 + x_2 + 4x_3 = 12 \\end{cases}分别用 $Jacobi$ 迭代法 $Gauss$-$Seidel$ 迭代法 以 $\\pmb{x}^{(0)}=(0,0,0)^T$ 为初始向量，计算其前三个迭代值，并与精确解 $\\pmb{x}^*=(3,2,1)^T$ 比较。 6.2 $Jacobi$ 迭代法/$Gauss$-$Seidel$ 迭代法-2用 $Jacobi$ 迭代法和 $Gauss$-$Seidel$ 迭代法求解方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$，其中： \\pmb{A}=\\begin{bmatrix} 4 & 1 & -1 \\\\ 2 & 5 & 2 \\\\ 1 & 1 & 3 \\end{bmatrix},\\quad \\pmb{b}=\\begin{bmatrix} 5 \\\\ -4 \\\\ 3 \\end{bmatrix}取 $\\pmb{x}^{(0)} = (1,-1,1)^T$，$\\varepsilon = \\displaystyle{\\frac{1}{2}} \\times 10^{-6}$。 6.3 迭代法收敛性-1已知方程组： \\begin{bmatrix} 1 &2 \\\\ 0.3 &1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}使用 $J$ 法和 $GS$ 法求解此方程的收敛性。 6.4 迭代法收敛性-2试证明解下列方程组： \\begin{bmatrix} 1 &2 &-2 \\\\ 1 &1 &1 \\\\ 2 &2 &1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}= \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}的 $J$ 法收敛；而 $GS$ 法发散。 6.5 严格对角占优矩阵设方程组： \\begin{cases} \\ \\ x_1 - 8x_2 \\qquad \\ = -7 \\\\ \\ \\ x_1 \\qquad \\ - 9x_3 = -8 \\\\ 9x_1 - \\ \\ x_2 - x_3 \\ = 7 \\end{cases}试写出解此方程组的收敛的 $J$ 迭代公式和 $GS$ 迭代公式。 6.6 收敛速度问题设方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$，其中 \\pmb{A} = \\begin{bmatrix}3&2\\\\1&2\\end{bmatrix}，\\pmb{b}=\\begin{bmatrix}3\\\\-1\\end{bmatrix}，用下列迭代公式求解： \\pmb{x}^{(k+1)} = \\pmb{x}^{(k)} + \\alpha ( \\pmb{A}\\pmb{x}^{(k)} - \\pmb{b} ) \\quad (k=0,1,\\cdots) 试找出使迭代收敛的实数 $\\alpha$ 的取值范围； 试求出使迭代收敛最快的 $\\alpha$ 值。 7. 非线性方程组的数值解法7.1 二分法设方程 $f(x) = e^x + 10x -2 = 0$，试： 证明它在 $(0,1)$ 内有且只有一个实根 $x^*$； 用二分法求这个实根 $x^*$； 若要求 $|x^* - x_n| &lt; 10^{-6}$，问需二分区间 $[0,1]$ 多少次？ 7.2 不动点迭代法用不动点迭代法求方程 $x^3 + 4x^2 - 10=0$ 在 $[1,2]$ 内的一个实根。 7.3 收敛性基本定理-1证明：设迭代函数 $\\varphi \\in C[a,b]$ 满足条件： 映内性：当 $a \\leqslant x \\leqslant b$ 时，有 $a \\leqslant \\varphi(x) \\leqslant b$； 压缩性：存在常数 $0 &lt; L &lt; 1$，$L$ 称为压缩系数，使得 |\\varphi(x) - \\varphi(\\tilde{x})| \\leqslant L|x - \\tilde{x}|, \\quad \\forall x,\\tilde{x} \\in [a,b]则可得： 函数 $\\varphi$ 在 $[a,b]$ 上存在唯一的不动点 $x^*$； 对任意初值 $x_0 \\in [a,b]$，迭代公式 $x_{k+1}=\\varphi(x_k)$ 收敛于 x^*，即 \\lim \\limits_{k \\to \\infty} x_k = x^*； 迭代值有误差估计式： |x^* - x_k| \\leqslant \\frac{L}{1-L}|x_k - x_{k-1}|, \\\\ |x^* - x_k| \\leqslant \\frac{L^k}{1-L}|x_1 - x_0|.7.4 收敛性基本定理-2用不动点迭代法求解方程： x - \\ln x = 2 \\quad (x > 1)要求相对误差 $\\Delta &lt; 10^{-8}$。 7.5 局部收敛定理对迭代函数 $\\varphi(x) = x + \\lambda(x^2 - 5)$，试找出使迭代公式 $x_{k+1} = \\varphi(x_k) \\ (k=0,1,\\cdots)$ 局部收敛于 $x^*=\\sqrt{5}$ 的 $\\lambda$ 的取值范围。 7.6 收敛速度与收敛阶为使下列形式的迭代公式： x_{k+1} = px_k + q\\frac{a}{x^2} + \\frac{a^2}{x_k^5} \\quad (k=0,1,\\cdots)所产生的序列 $\\{x_k\\}$ 收敛于 $\\sqrt[3]{a}$，并且有尽可能高的收敛阶，试确定其中常数 $p$，$q$，$r$。 7.7 $Newton$ 迭代法用 $Newton$ 迭代法求下列方程的近似根： xe^x - 1 = 07.8 非线性方程组的 $Newton$ 迭代法用 $Newton$ 迭代法解非线性方程组： \\begin{cases} 4x_1^2 + x_2^2 - 4 = 0 \\\\ x_1 + x_2 - \\sin(x_1 - x_2) = 0 \\end{cases}8. 矩阵特征值计算8.1 计算模最大特征值 $\\lambda_1$ 的乘幂法用乘幂法求矩阵 $\\pmb{A}$ 的特征值和特征向量，其中： \\pmb{A} = \\begin{bmatrix} 2 &3 &2 \\\\ 10 &3 &4 \\\\ 3 &6 &1 \\end{bmatrix}.8.2 计算模最小特征值 $\\lambda_n$ 的反幂法用反幂法求矩阵 $\\pmb{A}$ 的特征值和特征向量，其中： \\pmb{A} = \\begin{bmatrix} 2 &10 &3 \\\\ 3 &3 &6 \\\\ 2 &4 &1 \\end{bmatrix}.🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"数值分析笔记 7：矩阵特征值计算","slug":"math-analysis-7","date":"2018-11-27T01:46:28.000Z","updated":"2019-09-01T13:04:11.525Z","comments":true,"path":"2018/11/27/math-analysis-7/","link":"","permalink":"https://abelsu7.top/2018/11/27/math-analysis-7/","excerpt":"矩阵特征值和特征向量、乘幂法、反幂法 《应用数值分析》","text":"矩阵特征值和特征向量、乘幂法、反幂法 《应用数值分析》 目录 目录 7. 矩阵特征值计算 7.1 矩阵特征值和特征向量 7.2 乘幂法 7.2.1 求模最大的特征值的乘幂法 7.2.2 求模最小的特征值的反幂法 7. 矩阵特征值计算7.1 矩阵特征值和特征向量设 $\\pmb{A}$ 是 $n$ 阶方阵，$\\pmb{x}=(x_1,x_2,\\cdots,x_n)^T$ 是 $n$ 维列向量。若有数值 $\\lambda$，使得下面的矩阵方程： \\pmb{A}\\pmb{x} = \\lambda\\pmb{x}有非零解 $\\pmb{x}$，则称数值 $\\lambda$ 为方阵 $\\pmb{A}$ 的特征值，而对应的非零解 $\\pmb{x}$ 称为对应特征值 $\\lambda$ 的特征向量。 将上式变换为： (\\pmb{A} - \\lambda \\pmb{I})\\pmb{x}=\\pmb{0}于是，当且仅当方程的系数矩阵行列式为零时，即 \\det(\\pmb{A} - \\lambda \\pmb{I})=0则方程有非零解。将上式等号左边按 $\\lambda$ 展开，得到 $\\lambda$ 的 $n$ 次多项式，称为 $\\pmb{A}$ 的特征多项式，上式也变成多项式方程： a_n\\lambda^n + a_{n-1}\\lambda^{n-1} + \\cdots + a_1\\lambda + a_0 = 0特征值 $\\lambda$ 即为 $n$ 次多项式方程的解。 7.2 乘幂法7.2.1 求模最大的特征值的乘幂法输入：矩阵 $\\pmb{A}$，精度要求 $\\varepsilon$，迭代次数上限 $N$ 输出：模数最大的特征值 $\\lambda_1$ 及对应的特征向量 $\\pmb{x}$ 算法过程： 任意取一个非零向量 $\\pmb{V}_0=(x_1,x_2,\\cdots,x_n)^T$，迭代次数 $k=0$，向量 $\\pmb{V}$ 中绝对值最大的分量 $m_0$ $\\pmb{U}^{(k)}=\\pmb{A}\\pmb{V}^{(k-1)}$，$m = \\max \\{ \\pmb{U}^{(k)} \\}$，$\\pmb{V}^{(k)}=\\displaystyle{\\frac{1}{m}}\\pmb{U}^{(k)}$，$k=k+1$ 若 $|m-m_0| &lt; \\varepsilon$，则转到 4；若 $k \\geqslant N$，则显示“超出最大迭代次数”，停机；否则，$m_0 = m$，转向 2 $\\lambda_1 = m$，$\\pmb{x} = \\pmb{V}^{(k)}$，输出结果结束 7.2.2 求模最小的特征值的反幂法输入：矩阵 $\\pmb{A}$，精度要求 $\\varepsilon$，迭代次数上限 $N$ 输出：模数最小的特征值 $\\lambda_n$ 及对应的特征向量 $\\pmb{x}$ 算法过程： 任意取一个非零向量 $\\pmb{V}_0=(x_1,x_2,\\cdots,x_n)^T$，迭代次数 $k=0$，向量 $\\pmb{V}$ 中绝对值最大的分量 $m_0$ 将矩阵 $\\pmb{A}$ 作 $LU$ 分解：$\\pmb{A} = \\pmb{L}\\pmb{U}$，得到下三角矩阵 $\\pmb{L}$ 和上三角矩阵 $\\pmb{U}$ 解线性方程组 $\\pmb{L}\\pmb{W}=\\pmb{x}$，得到解 $\\pmb{W} \\in \\pmb{R}^n$。再解线性方程组 $\\pmb{U}\\pmb{Y}=\\pmb{W}$，得到解 $\\pmb{Y} \\in \\pmb{R}^n$。$m \\leftarrow$ 向量 $Y$ 中绝对值最大的分量，$\\pmb{x} \\leftarrow \\displaystyle{\\frac{1}{m}} \\pmb{Y}$，$k \\leftarrow k+1$ 若 $\\left| \\displaystyle{\\frac{1}{m}} - \\displaystyle{\\frac{1}{m_0}} \\right| &lt; \\varepsilon$，且 $|m-m_0| &lt; \\varepsilon$，则转到 5；若 $k \\geqslant N$，则显示“超出最大迭代数”，停机；否则，$m_0 \\leftarrow m$，转回 3 输处模最小的特征值 $\\lambda_n = \\displaystyle{\\frac{1}{m}}$，对应的特征向量 $\\pmb{x} = \\pmb{V}^{(k)}$，算法结束 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"数值分析笔记 6：非线性方程组的数值解法","slug":"math-analysis-6","date":"2018-11-26T01:47:46.000Z","updated":"2019-09-01T13:04:11.524Z","comments":true,"path":"2018/11/26/math-analysis-6/","link":"","permalink":"https://abelsu7.top/2018/11/26/math-analysis-6/","excerpt":"二分法、不动点迭代法、切线法 《应用数值分析》","text":"二分法、不动点迭代法、切线法 《应用数值分析》 目录 目录 6. 非线性方程组的数值解法 6.1 一元非线性方程求根 6.2 二分法 6.3 不动点迭代法及其收敛性理论 6.3.1 不动点迭代法 6.3.2 收敛性基本定理 6.3.3 局部收敛定理 6.4 $Newton$ 迭代法 6.4.1 $Newton$ 迭代公式 6.4.2 $Newton$ 迭代法的收敛性 6.4.3 重根的迭代改善 6.4.4 $Newton$ 迭代法用于求方根 6.4.5 离散 $Newton$ 迭代法：割线法 6.5 非线性方程组的 $Newton$ 迭代法与拟 $Newton$ 迭代法 6.5.1 $Aitken$ 加速方案 6.5.2 拟 $Newton$ 迭代法 6. 非线性方程组的数值解法6.1 一元非线性方程求根对 $f$ 不是 $x$ 的线性函数的方程，统称为非线性方程或一次方程。 方程的解 x^* 满足 f(x^* )\\equiv 0，也称为方程的根、函数的零点、不动点。 若 $f$ 在 $x^*$ 的邻域上可表示为 f(x) = (x-x^*)^m {g}(x), \\quad g(x^*) \\neq 0其中，$m$ 为正整数，则称 x^* 是方程的 $m$ 重根或函数 $f$ 的 $m$ 重零点。$m=1$ 时，称为单重根或单重零点。 若 $x^*$ 是 $f(x)=0$ 的 $m$ 重根，且 $g(x)$ 充分光滑，则可表示为： \\begin{cases} f(x^*)=0,f{}'(x^*)=0,\\cdots,f^{(m-1)}(x^*)=0 \\\\ f^{(m)}(x^*) \\neq 0 \\end{cases}若上式成立，则 $f(x)$ 在点 $x^*$ 处的 $Taylor$ 展开式为： f(x)=\\frac{f^{(m)}(\\xi)}{m!}(x-x^*)^m, \\quad \\xi \\ \\text{在} \\ x \\ \\text{与} \\ x^* \\ \\text{之间}求根思想：把有根区间或隔离区间逐步缩小 6.2 二分法如果方程 $f(x)=0$ 中，$f \\in C[a,b]$，且 $f(a) \\cdot f(b) &lt; 0$，则由二分法产生的序列 $\\{x_n\\}$ 收敛于方程的根 $x^*$，且有误差估计： | x^* - x_n | \\leqslant \\frac{b-a}{2^n}6.3 不动点迭代法及其收敛性理论6.3.1 不动点迭代法将方程改写为等价方程 $x=\\varphi(x)$，从某个取定的初值 $x_0$ 开始，对应上式构建迭代公式： x_{k+1} = \\varphi(x_k) \\quad (k=0,1,\\cdots)这种求根的方法就称为迭代法或函数迭代法，式中的 $\\varphi(x)$ 称为迭代函数。如果 x^* 对函数 $\\varphi(x)$ 满足 x^*=\\varphi(x^*)，则称 x^* 为 $\\varphi(x)$ 的不动点，因此函数迭代法也称为不动点迭代法。 6.3.2 收敛性基本定理设迭代公式中的迭代函数 $\\varphi \\in C[a,b]$ 满足条件： 映内性：当 $a \\leqslant x \\leqslant b$ 时，有 $a \\leqslant \\varphi(x) \\leqslant b$ 压缩性：存在常数 $0&lt;L&lt;1$，$L$ 称为压缩系数，使得： \\left| \\varphi(x) - \\varphi(\\tilde{x}) \\right| \\leqslant L |x-\\tilde{x}|, \\quad \\forall x,\\tilde{x}\\in[a,b]则可得： 函数 $\\varphi$ 在 $[a,b]$ 上存在唯一的不动点 $x^*$； 对任意初值 $x_0 \\in [a,b]$，迭代公式收敛于 x^*，即 \\lim \\limits_{k \\to \\infty} x_k = x^*； 迭代值有误差估计式： \\left| x^* - x_k \\right| \\leqslant \\frac{L}{1-L} |x_k - x_{k-1}|, \\\\ \\left| x^* - x_k \\right| \\leqslant \\frac{L^k}{1-L} | x_1 - x_0 |.6.3.3 局部收敛定理设 x^* 为 $\\varphi$ 的不动点，$\\varphi{}’(x)$ 在 x^* 的某个邻域 $\\Delta$ 上存在、连续且 |\\varphi{}'(x^*)|","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"数值分析笔记 5：线性代数方程组数值解法——迭代法","slug":"math-analysis-5","date":"2018-11-23T09:01:25.000Z","updated":"2019-09-01T13:04:11.522Z","comments":true,"path":"2018/11/23/math-analysis-5/","link":"","permalink":"https://abelsu7.top/2018/11/23/math-analysis-5/","excerpt":"迭代法基本概念和迭代公式、迭代法收敛性理论 《应用数值分析》","text":"迭代法基本概念和迭代公式、迭代法收敛性理论 《应用数值分析》 目录 目录 5. 线性代数方程组数值解法——迭代法 5.1 迭代法基本概念和迭代公式 5.2 $Jacobi$ 迭代法 5.3 $Gauss$-$Seidel$ 迭代法 5.4 迭代法收敛性理论 5.4.1 迭代法收敛性基本定理 5.4.2 迭代法收敛性充分条件 5.4.3 严格占优对角矩阵 5.4.4 收敛速度问题 5. 线性代数方程组数值解法——迭代法5.1 迭代法基本概念和迭代公式解线性代数方程组 \\pmb{A}\\pmb{x}=\\pmb{b}（$\\pmb{A} \\in \\pmb{R}^{n \\times n}$ 非奇异，$\\pmb{b}=(b_1,b_2,\\cdots,b_n)^T \\neq 0$，$\\pmb{x}=(x_1,x_2,\\cdots,x_n)^T$ 为解向量）的迭代法具体做法是，将上述方程组变形为等价形式： \\pmb{x} = \\pmb{F}(\\pmb{x})特别的，这里仅研究其线性的形式： \\pmb{x} = \\pmb{B} \\pmb{x} + \\pmb{f}其中，$\\pmb{B} \\in \\pmb{R}^{n \\times n}$ 非奇异，$\\pmb{f} \\in \\pmb{R}^n$。构造迭代公式： \\pmb{x}^{(k+1)} = \\pmb{B} \\pmb{x}^{k} + \\pmb{f} \\quad (k=0,1,\\cdots) 每一步迭代值 $\\pmb{x}^{(k+1)}$ 仅依赖于前一步迭代值 $\\pmb{x}^{(k)}$，这称为单步迭代 $\\pmb{B}$ 和 $\\pmb{f}$ 与 $k$ 无关，这称为定常情形 $\\pmb{B}$ 称为迭代矩阵 按照迭代公式可产生向量序列 $\\left\\{ \\pmb{x}^{(k)} \\right\\}(k=0,1,\\cdots)$，如果 \\lim \\limits_{k \\to \\infty}\\pmb{x}^{(k)} = \\pmb{x}^*，即序列 \\left\\{ \\pmb{x}^{(k)} \\right\\} 收敛于 \\pmb{x}^* 5.2 $Jacobi$ 迭代法设方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$ 中 $\\pmb{A}=(a_{ij}) \\in \\pmb{R}^{n \\times n}$，$\\pmb{b} = (b_i)\\in \\pmb{R}^{n \\times n}$ 且 $a_{ii} \\neq 0 \\ (i=1,2,\\cdots,n)$ 假设系数矩阵 $A$ 的对角元 $a_{ii} \\neq 0 \\ (i=1,2,\\cdots,n)$，则对角矩阵 $\\pmb{D}=diag(a_{11},a_{22},\\cdots,a_{nn})$ 非奇异。可将矩阵 $\\pmb{A}$ 分解为： \\pmb{A} = \\pmb{D} - \\pmb{L} - \\pmb{U}其中， \\pmb{L}=-\\begin{bmatrix} 0 & & & \\\\ a_{21} &0 & & \\\\ \\vdots &\\vdots &\\ddots & \\\\ a_{n1} &a_{n2} &a_{n3} &0 \\end{bmatrix}, \\pmb{U}=-\\begin{bmatrix} 0 &a_{12} &\\cdots &a_{1n} \\\\ &0 &\\cdots &a_{2n} \\\\ & &\\ddots &\\vdots \\\\ & & &0 \\end{bmatrix}此时原方程组可改写为： \\pmb{x}^{(k+1)}=\\pmb{B}_J\\pmb{x}^{(k)}+\\pmb{f} \\quad (k=0,1,\\cdots)其中， \\pmb{B}_J=\\pmb{D}^{-1}(\\pmb{L}+\\pmb{U}) \\ \\text{或} \\\\ \\pmb{B}_J= \\pmb{I} - \\pmb{D}^{-1}\\pmb{A}, \\\\ \\pmb{f} = \\pmb{D}^{-1} \\pmb{b}则 $Jacobi$ 迭代公式为： \\begin{cases} \\pmb{x}^{(0)} = (x_1^{(0)},x_2^{(0)},\\cdots,x_n^{(0)})^T \\\\ x_i^{(k+1)} = \\left( b_i - \\sum \\limits_{j=1,j \\neq i}^n a_{ij}x_j^{(k)}\\right)/a_{ii} \\end{cases}, \\ i = 1,2,\\cdots,n5.3 $Gauss$-$Seidel$ 迭代法原方程组可改写为： \\pmb{x}^{(k+1)}=\\pmb{B}_{GS}\\pmb{x}^{(k)}+\\pmb{f} \\quad (k=0,1,\\cdots)其中， \\pmb{B}_{GS}=(\\pmb{D}-\\pmb{L})^{-1}\\pmb{U}, \\ \\pmb{f} = (\\pmb{D}-\\pmb{L})^{-1}\\pmb{b}则 $Gauss-Seidel$ 迭代公式为： \\begin{cases} \\pmb{x}^{(0)} = (x_1^{(0)},x_2^{(0)},\\cdots,x_n^{(0)})^T \\\\ x_i^{(k+1)} = \\left( b_i - \\sum \\limits_{j=1}^{i-1}a_{ij}x_j^{(k+1)} - \\sum \\limits_{j=i+1}^{n}a_{ij}x_j^{(k)} \\right)/a_{ii} \\end{cases}, \\ i = 1,2,\\cdots,n5.4 迭代法收敛性理论5.4.1 迭代法收敛性基本定理设方程组为 $\\pmb{x} = \\pmb{B} \\pmb{x} + \\pmb{f}$，对任意的初始向量 $\\pmb{x}^{(0)}$，解此方程组的迭代法 \\pmb{x}^{(k+1)} = \\pmb{B} \\pmb{x}^{k} + \\pmb{f} \\quad (k=0,1,\\cdots)收敛的充分必要条件是迭代矩阵 $\\pmb{B}$ 的谱半径 $\\rho(\\pmb{B}) &lt; 1$ 5.4.2 迭代法收敛性充分条件如果迭代法 $\\pmb{x}^{(k+1)} = \\pmb{B} \\pmb{x}^{k} + \\pmb{f} \\quad (k=0,1,\\cdots)$ 的迭代矩阵 $\\pmb{B}$ 的某一种算子范数 \\left \\| \\pmb{B} \\right \\| < 1，则： 对任意初始向量 $\\pmb{x}^{(0)}$，迭代法收敛； 迭代序列与方程组的解 $x^*$ 存在误差估计式： \\left \\| x^* - x^{(k)} \\right \\| \\leqslant \\frac{\\left \\| \\pmb{B} \\right \\|}{1 - \\left \\| \\pmb{B} \\right \\|}\\left \\| \\pmb{x}^{(k)} - \\pmb{x}^{(k-1)} \\right \\|或 \\left \\| x^* - x^{(k)} \\right \\| \\leqslant \\frac{\\left \\| \\pmb{B} \\right \\|^{(k)}}{1 - \\left \\| \\pmb{B} \\right \\|}\\left \\| \\pmb{x}^{(1)} - \\pmb{x}^{(0)} \\right \\|5.4.3 严格占优对角矩阵设 $\\pmb{A} = (a_{ij}) \\in \\pmb{R}^{n \\times n}$，若满足 | a_{ii} | > \\sum \\limits_{j=1,j \\neq i}^n | a_{ij} | \\quad (i=1,2,\\cdots,n)则称 $\\pmb{A}$ 为严格对角占优矩阵；若满足其中至少有一个严格不等式成立，则称 $\\pmb{A}$ 为弱对角占优矩阵。 定理：若方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$ 中，$\\pmb{A} = (a_{ij}) \\in \\pmb{R}^{n \\times n}$ 为严格对角占优矩阵，或为不可约弱对角占优矩阵，则解此方程组的 $J$ 法和 $GS$ 法均收敛。 5.4.4 收敛速度问题设迭代法收敛，定义 R(\\pmb{B}) = -\\ln \\rho(\\pmb{B})称 $R(\\pmb{B})$ 为迭代法的渐近收敛速度。由定义可知，$R(\\pmb{B})$ 越大，收敛越快，也即 $\\rho(\\pmb{B})(0&lt;\\rho(\\pmb{B})&lt;1)$ 谱半径越小，收敛速度越快。 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"数值分析笔记 4：线性代数方程组数值解法——直接法","slug":"math-analysis-4","date":"2018-11-22T12:11:20.000Z","updated":"2019-09-01T13:04:11.520Z","comments":true,"path":"2018/11/22/math-analysis-4/","link":"","permalink":"https://abelsu7.top/2018/11/22/math-analysis-4/","excerpt":"上/下三角矩阵的回代/前推、顺序/列主元消去、矩阵三角分解 《应用数值分析》","text":"上/下三角矩阵的回代/前推、顺序/列主元消去、矩阵三角分解 《应用数值分析》 目录 目录 4. 线性代数方程组数值解法——直接法 4.1 线性方程组的一般形式/直接法的基本过程 4.1.1 $n$ 阶线性代数方程组的一般形式 4.1.2 上三角方程组与回代过程 4.1.3 下三角方程组与前推过程 4.2 $Gauss$ 消去过程/列主元 $Gauss$ 消去法 4.2.1 $Gauss$ 消去过程 4.2.2 顺序 $Gauss$ 消去法 4.2.3 列主元 $Gauss$ 消去法 4.3 矩阵三角分解：解方程组的直接三角分解法 4. 线性代数方程组数值解法——直接法4.1 线性方程组的一般形式/直接法的基本过程4.1.1 $n$ 阶线性代数方程组的一般形式具有 $n$ 个未知数 $n$ 个方程的 $n$ 阶线性代数方程组的一般形式记为： \\begin{cases} a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n = b_1 \\\\ a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n = b_2 \\\\ \\quad \\ \\vdots \\qquad \\quad \\ \\vdots \\qquad \\qquad \\quad \\ \\ \\vdots \\quad \\quad \\ \\ \\vdots \\\\ a_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nn}x_n = b_n \\end{cases}或写成向量-矩阵形式： \\pmb{A}\\pmb{x}=\\pmb{b}其中， \\pmb{A}= \\begin{bmatrix} a_{11} &a_{12} &\\cdots &a_{1n} \\\\ a_{21} &a_{22} &\\cdots &a_{2n} \\\\ \\vdots &\\vdots & &\\vdots \\\\ a_{n1} &a_{n2} &\\cdots &a_{nn} \\end{bmatrix}, \\pmb{x}= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}, \\pmb{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix}.$\\pmb{A}$ 称为系数矩阵，$\\pmb{x}$ 称为解向量，$\\pmb{b}$ 称为右端常数向量。实际应用中，主要处理实数情形的方程组，即 $\\pmb{A} \\in \\pmb{R}^{n \\times n}$，$\\pmb{b} \\in \\pmb{R}^n$。 根据 $Grammer$（克兰姆）法则，若系数矩阵 $\\pmb{A}$ 非奇异（或者说 $\\pmb{A}$ 的行列式值 $\\det \\pmb{A} \\neq 0$），则方程组存在唯一解： x_i = \\frac{D_i}{D} \\quad (i=1,2,\\cdots,n).其中，$D$ 表示 $\\pmb{A}$ 对应的行列式值 $\\det \\pmb{A}$，$D_i$ 表示在 $D$ 中第 $i$ 列用 $\\pmb{b}$ 替换。 4.1.2 上三角方程组与回代过程假如方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$（$\\pmb{A} \\in \\pmb{R}^{n \\times n}$ 非奇异）已被约化为如下形状的上三角方程组： \\left \\{ \\begin{matrix} a_{11}x_1 &+ &a_{12}x_2 &+ &\\cdots &+ &a_{1n}x_n &= &b_1 \\\\ & &a_{22}x_2 &+ &\\cdots &+ &a_{2n}x_n &= &b_2 \\\\ & & &\\ddots & & &\\vdots & &\\vdots \\\\ & & & & & &a_{nn}x_n &= &b_n \\end{matrix} \\right.则通过回代过程可求解： \\begin{cases} x_n = b_n / a_{nn} \\\\ x_i = (b_i - \\sum \\limits_{j=i+1}^n a_{ij}x_j)/a_{ii} \\quad (i=n-1,\\cdots,2,1) \\end{cases}4.1.3 下三角方程组与前推过程类似的，假如方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$（$\\pmb{A} \\in \\pmb{R}^{n \\times n}$ 非奇异）已被约化为如下形状的下三角方程组： \\left\\{\\begin{matrix} a_{11}x_1 & & & & & & &= &b_1 \\\\ a_{21}x_1 &+ &a_{22}x_1 & & & & &= &b_2 \\\\ \\vdots & &\\vdots & &\\ddots & & & &\\vdots \\\\ a_{n1}x_1 &+ &a_{n2}x_2 &+ &\\cdots &+ &a_{nn}x_n &= &b_n \\end{matrix}\\right.则通过前推过程可求解： \\begin{cases} x_1 = b_1 / a_{11} \\\\ x_i = (b_i - \\sum \\limits_{j=1}^{i-1} a_{ij}x_j)/a_{ii} \\quad (i=2,3,\\cdots,n) \\end{cases}4.2 $Gauss$ 消去过程/列主元 $Gauss$ 消去法4.2.1 $Gauss$ 消去过程 待更新 4.2.2 顺序 $Gauss$ 消去法 待更新 4.2.3 列主元 $Gauss$ 消去法 待更新 4.3 矩阵三角分解：解方程组的直接三角分解法把矩阵 $\\pmb{A}$ 分解成两个三角矩阵 $\\pmb{L}$ 与 $\\pmb{U}$ 的乘积，$\\pmb{A}=\\pmb{L}\\pmb{U}$，消元乘数为： l_{ik}=a_{ik}^{(k)}/a_{kk}^{(k)} \\quad (i=k+1,\\cdots,n)其中，$\\pmb{L}$ 为单位下三角矩阵，$\\pmb{U}$ 为上三角矩阵： \\pmb{L} = \\begin{bmatrix} 1 & & & \\\\ l_{21} &1 & & \\\\ \\vdots &\\vdots &\\ddots & \\\\ l_{n1} &l_{n2} &\\cdots &1 \\end{bmatrix}, \\pmb{U} = \\begin{bmatrix} u_{11} &u_{12} &\\cdots &u_{1n} \\\\ &u_{22} &\\cdots &u_{2n} \\\\ & &\\ddots &\\vdots \\\\ & & &u_{nn} \\end{bmatrix}这样一来，解方程组 $\\pmb{A}\\pmb{x}=\\pmb{b}$ 就转化为解方程组 $\\pmb{L}\\pmb{U}\\pmb{x}=\\pmb{b}$。令其中 $\\pmb{U}\\pmb{x}=\\pmb{y}$，则解方程组 $\\pmb{L}\\pmb{U}\\pmb{x}=\\pmb{b}$ 又相当于依次解两个三角形方程组： \\begin{cases} \\pmb{L}\\pmb{y}=\\pmb{b} \\quad \\text{(下三角方程组)} \\\\ \\pmb{U}\\pmb{x}=\\pmb{y} \\quad \\text{(上三角方程组)} \\end{cases}🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"数值分析笔记 3：曲线拟合/连续函数逼近","slug":"math-analysis-3","date":"2018-11-21T01:28:34.000Z","updated":"2019-09-01T13:04:11.519Z","comments":true,"path":"2018/11/21/math-analysis-3/","link":"","permalink":"https://abelsu7.top/2018/11/21/math-analysis-3/","excerpt":"最小二乘拟合、法方程的矩阵形式 《应用数值分析》","text":"最小二乘拟合、法方程的矩阵形式 《应用数值分析》 目录 目录 3. 曲线拟合/连续函数逼近 3.1 拟合问题与逼近问题 3.2 曲线拟合的（线性）最小二乘法 3.2.1 最小二乘拟合问题的提法 3.2.2 最小二乘解的解法：法方程 3.3 最小二乘的相关问题及例 3.3.1 指数模型与双曲线模型的线性化拟合 3.3.2 算术平均：最小二乘意义下误差最小 3.3.3 超定方程组（矛盾方程组）的最小二乘解 3.3.4 法方程的矩阵形式 3. 曲线拟合/连续函数逼近3.1 拟合问题与逼近问题 最小二乘拟合问题实际上就是针对已知的离散数据的平方逼近问题 插值问题就是针对已知的离散函数点，要求以插值函数在离散点的值与已知离散点的函数值相等为逼近标准的逼近问题 3.2 曲线拟合的（线性）最小二乘法3.2.1 最小二乘拟合问题的提法设 $f$ 是在 $m+1$ 个节点 $x_j\\in [a,b]$ 上给定的离散函数，即给定离散数据 (x_j,f(x_j)) \\quad j=0,1,\\cdots,n要在某个指定空间 $\\Phi$ 中，找出一个函数 s^*(x_j)\\in \\Phi 作为 $f$ 的近似的连续模型，要求 s^* 在 $x_j$ 处的值 s^*(x_j) 与 $f(x_j)$ 的误差 \\delta_j=f(x_j) - s^*(x_j) \\quad (j=0,1,\\cdots,m)的平方和最小，即记 $\\pmb{\\delta}=(\\delta_0,\\delta_1,\\cdots,\\delta_m)^T$，有 \\begin{aligned} \\left \\| \\pmb{\\delta} \\right \\|_2^2 &= \\sum_{j=0}^m \\delta_j^2 \\\\ &= \\sum_{j=0}^m \\left[ f(x_j)-s^*(x_j) \\right]^2 \\\\ &= \\min_{s \\in \\Phi} \\sum_{j=0}^m \\left[ f(x_j)-s(x_j) \\right]^2\\end{aligned}或为了体现数据的重要性不同，引入对应 $[a,b]$ 上不同点 $x_j$ 的权函数值 $\\rho(x_j)&gt;0$，从而将上式改写成更一般的带权形式 \\begin{aligned} \\left \\| \\pmb{\\delta} \\right \\|_2^2 &= \\sum_{j=0}^m \\rho(x_j) \\left[ f(x_j)-s^*(x_j) \\right]^2 \\\\ &= \\min_{s \\in \\Phi} \\sum_{j=0}^m \\rho(x_j) \\left[ f(x_j)-s(x_j) \\right]^2\\end{aligned}这就是最小二乘拟合问题，$s^*(x)$ 称为 $f$ 在 $m+1$ 个节点 $x_j \\ (j=0,1,\\cdots,m)$ 上的最小二乘解，或称为拟合曲线或经验公式或回归线。 通常，在简单情形下，选择 $\\Phi$ 为多项式空间（或其子空间），$\\Phi = P_n = Span\\{1,x,\\cdots,x^n\\}$，这时，若 $s(x) \\in P_n$，则 $s(x)$ 的形式为 s(x) = a_0 + a_1x + \\cdots + a_nx^n在一般情形下，选择 $\\Phi$ 为线性空间 $\\Phi = Span\\{ \\varphi_0(x),\\varphi_1(x),\\cdots,\\varphi_n(x) \\}$，其中 $\\varphi_i(x)$ 是 $[a,b]$ 上已知的线性无关组，这时，若 $s(x)\\in \\Phi$，则有 s(x) = a_0\\varphi_0(x) + a_1\\varphi_1(x) + \\cdots + a_n\\varphi_n(x) = \\sum_{i=0}^n a_i\\varphi_i(x)两式中关于待定参数（也称回归系数）$a_0,a_1,\\cdots,a_n$ 都是一次的，所以 $s(x)$ 是一种线性模型，而上述问题称为线性最小二乘拟合。 3.2.2 最小二乘解的解法：法方程法方程及平方误差 法方程（组）或正则方程（组）可表示如下： \\left[ \\begin{matrix} (\\varphi_0,\\varphi_0) &(\\varphi_0,\\varphi_1) &\\cdots &(\\varphi_0,\\varphi_n) \\\\ (\\varphi_1,\\varphi_0) &(\\varphi_1,\\varphi_1) &\\cdots &(\\varphi_1,\\varphi_n) \\\\ \\vdots &\\vdots & &\\vdots \\\\ (\\varphi_n,\\varphi_0) &(\\varphi_n,\\varphi_1) &\\cdots &(\\varphi_n,\\varphi_n) \\end{matrix} \\right] \\left[ \\begin{matrix} a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_n \\end{matrix} \\right]= \\left[ \\begin{matrix} (\\varphi_0,f) \\\\ (\\varphi_1,f) \\\\ \\vdots \\\\ (\\varphi_n,f) \\end{matrix} \\right]对 s^*(x) 的误差估计，可使用平方误差： \\left \\| f-s^* \\right \\|_2^2 = \\sum_{j=0}^m \\rho_j \\left[ f(x_j)-s^*(x_j) \\right]^2或均方误差： \\left \\| f-s^* \\right \\|_2 = \\sqrt{\\sum_{j=0}^m \\rho_j \\left[ f(x_j)-s^*(x_j) \\right]^2}其中，平方误差还可导出另一种表示形式： \\left \\| f-s^* \\right \\|_2^2 = \\left \\| f \\right \\|_2^2-\\sum_{i=0}^n a_i^*(\\varphi_i,f) 这种表示的优点是，计算平方误差时可以直接利用求解法方程过程中的信息，而无需调用计算 $s^*(x)$ 的子程序。 求最小二乘拟合曲线的主要步骤 根据已知数据求最小二乘拟合曲线有两个主要步骤： 选定拟合模型的形式，即选定空间 $\\Phi$ 的基函数 $\\varphi_0,\\varphi_1,\\cdots,\\varphi_n$ 求最小二乘解 $s^*(x)$，即求出拟合曲线，它转化为求解相应的法方程 二次多项式模型及权函数 $\\rho_j \\equiv 1$ 时对应的法方程 \\begin{bmatrix} \\sum \\limits_{j=0}^m 1 &\\sum \\limits_{j=0}^m x_j &\\sum \\limits_{j=0}^m x_j^2 \\\\ \\sum \\limits_{j=0}^m x_j &\\sum \\limits_{j=0}^m x_j^2 &\\sum \\limits_{j=0}^m x_j^3 \\\\ \\sum \\limits_{j=0}^m x_j^2 &\\sum \\limits_{j=0}^m x_j^3 &\\sum \\limits_{j=0}^m x_j^4 \\end{bmatrix} \\begin{bmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{bmatrix}= \\left[ \\begin{matrix} \\sum \\limits_{j=0}^m f_j \\\\ \\sum \\limits_{j=0}^m x_jf_j \\\\ \\sum \\limits_{j=0}^m x_j^2 f_j \\end{matrix} \\right]3.3 最小二乘的相关问题及例3.3.1 指数模型与双曲线模型的线性化拟合1. 指数模型：$s(x)=ae^{bx}$ 对模型 $s(x)=ae^{bx}$，两边取对数 \\ln{s(x)} = \\ln{a} + bx令 $Y=\\ln{s(x)}$，$A=\\ln{a}$，则上式为 Y = A +bx并将原数据变化为 $(x_j,\\ln{f(x_j)})$ 2. 指数模型：$s(x)=ae^{\\frac{b}{x}}$ 对模型 $s(x)=ae^{\\frac{b}{x}}$，两边取对数 \\ln{s(x)} = \\ln{a} + \\frac{b}{x}令 $Y=\\ln{s(x)}$，$A=\\ln{a}$，$X=\\displaystyle{\\frac{1}{x}}$，则上式为 Y = A +bX并将原数据变化为 $(\\displaystyle{\\frac{1}{x_j}},\\ln{f(x_j)})$ 3. 对数模型：$s(x)=\\displaystyle{\\frac{1}{a+bx}}$ 对模型 $s(x)=\\displaystyle{\\frac{1}{a+bx}}$，取倒数为 $\\displaystyle{\\frac{1}{s(x)}}=a+bx$。令 $Y=\\displaystyle{\\frac{1}{s(x)}}$ ，即有一次拟合模型 Y = a + bx并将原数据变化为 $\\left( x_j, \\displaystyle{\\frac{1}{f(x_j)}} \\right)$ 4. 对数模型：$s(x)=\\displaystyle{\\frac{x}{ax+b}}$ 对模型 $s(x)=\\displaystyle{\\frac{x}{ax+b}}$，取倒数为 $\\displaystyle{\\frac{1}{s(x)}}=a+b\\displaystyle{\\frac{1}{x}}$。令 $Y=\\displaystyle{\\frac{1}{s(x)}}$，$X=\\displaystyle{\\frac{1}{x}}$，即有一次拟合模型 Y = a + bX并将原数据变化为 $\\left( \\displaystyle{\\frac{1}{x_j}}, \\displaystyle{\\frac{1}{f(x_j)}} \\right)$ 3.3.2 算术平均：最小二乘意义下误差最小 取算术平均值是在最小二乘意义下误差达到最小 3.3.3 超定方程组（矛盾方程组）的最小二乘解超定方程组（或称矛盾方程组）即独立方程个数多余未知数个数的方程组，解超定方程组的一种方法是采用最小二乘原理求其近似解。 例如求下列超定方程组的近似解： \\begin{cases} x_1 - x_2 = 1 \\\\ -x_1 + x_2 = 2 \\\\ 2x_1 - 2x_2 = 3 \\\\ -3x_1 + x_2 = 4 \\end{cases}显然，如果方程组中每个方程的左、右两端不相等而是近似，则相差越小，方程组近似解越精确。为此，记各方程左、右两端之差（即误差）为： \\begin{aligned} \\delta_1 &= (x_1 - x_2) - 1 \\\\ \\delta_2 &= (-x_1 + x_2) - 2 \\\\ \\delta_3 &= (2x_1 - 2x_2) - 3 \\\\ \\delta_4 &= (-3x_1 + x_2) - 4 \\end{aligned}按最小二乘原理，作误差平方和： \\begin{aligned} J(x_1, x_2) = \\sum_{j=0}^3 \\delta_j^2 = &(x_1 - x_2 - 1)^2 + (-x_1 + x_2 - 2)^2 + \\\\ &(2x_1 - 2x_2 - 3)^2 + (-3x_1 + x_2 -4)^2 \\end{aligned}求最小值，即令 \\begin{cases} \\displaystyle{\\frac{\\partial J}{\\partial x_1}} = &2(x_1 - x_2 -1) - 2(-x_1 + x_2 -2) + \\\\ &4(2x_1 - 2x_2 - 3) - 6(-3x_1 + x_2 -4) \\\\ &=0 \\\\ \\displaystyle{\\frac{\\partial J}{\\partial x_2}} = &-2(x_1 - x_2 -1) + 2(-x_1 + x_2 -2) - \\\\ &4(2x_1 - 2x_2 - 3) + 2(-3x_1 + x_2 -4) \\\\ &=0 \\end{cases}化简得法方程 \\begin{cases} 15x_1 - 9x_2 = -7 \\\\ -9x_1 + 7x_2 = -1 \\end{cases}解之得超定方程组的近似解 x_1^* = -\\displaystyle{\\frac{29}{12}} \\approx -2.4167，x_2^* = -\\displaystyle{\\frac{39}{12}} \\approx -3.25，它们也称为超定方程的最小二乘解。 3.3.4 法方程的矩阵形式一般的，若对数据 $(x_j,f_j),j=0,1,\\cdots,m$，取最小二乘拟合模型为 s(x) = a_0\\varphi_0(x) + a_1\\varphi_1(x) + \\cdots + a_n\\varphi_n(x)并引入矩阵 $\\pmb{A}$ \\pmb{A} = \\begin{bmatrix} \\varphi_0(x_0) &\\varphi_1(x_0) &\\cdots &\\varphi_n(x_0) \\\\ \\varphi_0(x_1) &\\varphi_1(x_1) &\\cdots &\\varphi_n(x_1) \\\\ \\vdots &\\vdots & &\\vdots \\\\ \\varphi_0(x_m) &\\varphi_1(x_m) &\\cdots &\\varphi_n(x_m) \\end{bmatrix}_{(m+1) \\times (n+1)}向量 $\\pmb{\\alpha}=(a_0,a_1,\\cdots,a_n)^T$，$\\pmb{d}=(f_0,f_1,\\cdots,f_m)^T$，则求最小二乘解的法方程的矩阵形式为 \\pmb{A}^T\\pmb{A}\\pmb{\\alpha}=\\pmb{A}^T\\pmb{d}🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"数值分析笔记 2：函数插值方法","slug":"math-analysis-2","date":"2018-11-19T12:35:20.000Z","updated":"2019-09-01T13:04:11.517Z","comments":true,"path":"2018/11/19/math-analysis-2/","link":"","permalink":"https://abelsu7.top/2018/11/19/math-analysis-2/","excerpt":"多项式插值方法、带导插值 《应用数值分析》","text":"多项式插值方法、带导插值 《应用数值分析》 目录 目录 2. 函数插值方法 2.1 多项式插值的存在唯一性 2.1.1 插值相关定义 2.1.2 插值多项式 2.1.3 插值定理 2.2 $Lagrange$ 插值公式 2.2.1 线性插值 2.2.2 二次插值 2.2.3 $n$ 次 $Lagrange$ 插值 2.2.4 余项公式 2.3 带导插值：$Hermite$ 插值公式 2.3.1 带导插值的提法 2.3.2 带导插值定理 2.3.3 $Hermite$ 插值公式及其余项公式 2.3.4 $Hermite$ 插值的常用情形 2. 函数插值方法2.1 多项式插值的存在唯一性2.1.1 插值相关定义设 $f$ 是定义在 $[a,b]$ 上的实值函数，已知在 $[a,b]$ 上的 $n+1$ 个互异节点 $x_i$ 及其相应函数值 $f_i=f(x_i)$，要求构建近似函数 $p$，使得： p(x_i)=f_i \\quad (i=0,1,\\cdots,n). 插值条件：$p(x_i)=f_i \\quad (i=0,1,\\cdots,n)$ 被插函数：$f$ 插值函数：$p$ 插值节点：$x_i$ 插值区间：$[a,b]$ 2.1.2 插值多项式 p_n(x_i)=a_0+a_1x+\\cdots+a_nx^n2.1.3 插值定理设已知 $[a,b]$ 上的函数 $f$ 在 $n+1$ 个互异节点 $x_i \\in [a,b]$ 上的值 $f_i=f(x_i)(i=0,1,\\cdots,n)$，则存在唯一的次数 $\\leqslant n$ 的多项式 $p_n(x) \\in P_n$ 满足 p_n(x_i)=f_i \\quad (i=0,1,\\cdots,n).2.2 $Lagrange$ 插值公式2.2.1 线性插值线性插值也称为一次插值。已知函数的两个点 $(x_0,f_0)$，$(x_1,f_1)$，必存在唯一的次数 $\\leqslant 1$ 的多项式 $L_1(x)$ 满足： L_1(x_0)=f_0， \\quad L_1(x_1)=f_1不难构造并验证所求的 $L_1(x)$ 就是 L_1(x) = \\frac{x-x_1}{x_0-x_1}f_0+\\frac{x-x_0}{x_1-x_0}f_1称上述等式为线性（一次）插值多项式。记 l_0(x)=\\frac{x-x_1}{x_0-x_1}, \\quad l_1(x)=\\frac{x-x_0}{x_1-x_0}则称 $l_0(x)$，$l_1(x)$ 为线性插值基函数。于是，可知线性插值函数是线性插值基函数 $l_0(x)$，$l_1(x)$ 与函数值 $f_0$，$f_1$ 的线性组合。 L_1(x) = l_0(x) \\cdot f_0 + l_1(x) \\cdot f_12.2.2 二次插值二次插值也称为抛物线插值。已知函数的三个点 $(x_0,f_0)$，$(x_1,f_1)$，$(x_2,f_2)$，根据定理，必存在唯一的次数 $\\leqslant 2$ 的插值多项式 $L_2(x)$ 满足： L_2(x_0)=f_0,\\quad L_2(x_1)=f_1,\\quad L_2(x_2)=f_2采用基函数方法，仿照线性插值，作三个二次插值基函数： l_0(x) = \\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)}, \\\\ l_1(x) = \\frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)}, \\\\ l_2(x) = \\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}.同样，注意到它们的构造规律，并可验证它们具有下列性质： l_0(x_0)=1,\\quad l_0(x_1)=0,\\quad l_0(x_2)=0 \\\\ l_1(x_0)=0,\\quad l_1(x_1)=1,\\quad l_1(x_2)=0 \\\\ l_2(x_0)=0,\\quad l_2(x_1)=0,\\quad l_2(x_2)=1 \\\\于是，通过验证插值条件，可知所求二次插值多项式为： \\begin{aligned} L_2(x)&=l_0(x) \\cdot f_0 + l_1(x) \\cdot f_1 + l_2(x) \\cdot f_2 \\\\ &= \\sum \\limits_{i=0}^2 l_i(x) \\cdot f_i \\end{aligned}称为二次（抛物线）插值多项式。以下还可将线性插值和二次插值推广到一般情形。 2.2.3 $n$ 次 $Lagrange$ 插值已知函数的 $n+1$ 个点 $(x_i,f_i)(i=0,1,\\cdots,n)$，根据定理，必存在唯一的次数 $\\leqslant n$的多项式 $L_n(x)$ 满足： L_n(x_i)=f_i \\quad (i=0,1,\\cdots,n).仍仿照上述基函数方法，由 $n+1$ 个节点 $x_i(i=0,1,\\cdots,n)$ 作 $n+1$ 个 $n$ 次插值基函数： \\begin{aligned} l_i(x)&=\\frac{(x-x_0)\\cdots (x-x_{i-1})(x-x_{i+1})\\cdots (x-x_n)}{(x_i-x_0)\\cdots (x_i-x_{i-1})(x_i-x_{i+1})\\cdots (x_i-x_n)} \\\\ &=\\prod_{\\begin{subarray}{c}j=0\\\\ j \\neq i \\end{subarray}}^n \\frac{x-x_j}{x_i-x_j} \\qquad (i=0,1,\\cdots,n). \\end{aligned}容易验证，它们具有下列性质： \\begin{aligned} &l_0(x_0)=1, \\quad l_0(x_1)=0,\\quad \\cdots,\\quad l_0(x_n)=0 \\\\ &l_1(x_0)=1, \\quad l_1(x_1)=0,\\quad \\cdots,\\quad l_1(x_n)=0 \\\\ &\\quad \\ \\ \\vdots \\qquad \\ \\vdots \\quad \\qquad \\vdots \\qquad \\ \\vdots \\qquad \\qquad \\quad \\ \\vdots \\quad \\quad \\ \\ \\vdots \\\\ &l_n(x_0)=1, \\quad l_n(x_1)=0,\\quad \\cdots,\\quad l_n(x_n)=0 \\\\ \\end{aligned}或采用所谓 $Kronecker$（克罗内克尔）符号 \\delta_{ij}=\\begin{cases} 1, & \\text{当$ i = j $}\\\\ 0, & \\text{当$ i \\neq j $} \\end{cases}基函数的性质可表示为： l_i(x_j)=\\delta_{ij}=\\begin{cases} 1, & \\text{当$ i = j $}\\\\ 0, & \\text{当$ i \\neq j $} \\end{cases}于是，所求的插值多项式为： L_n(x)=\\sum \\limits_{i=0}^n l_i(x) \\cdot f_i或写成紧凑格式： L_n(x)=\\sum \\limits_{i=0}^n \\left( \\prod_{\\begin{subarray}{c}j=0\\\\ j \\neq i \\end{subarray}}^n \\frac{x-x_j}{x_i-x_j} \\right) \\cdot f_i这种由插值基函数 $l_i(x)$ 和函数值样本 $f_i \\ (i=0,1,\\cdots,n)$ 构造的插值函数，便称为 $n$ 次 $Lagrange$ 插值函数，或称为插值多项式的 $Lagrange$ 形式。 理论分析中为了简化形式，常引用记号 \\omega_{n+1}(x)=\\prod_{j=0}^n(x-x_j)并由对数求导法可推导出 \\omega_{n+1}{}'(x_i)=\\prod_{\\begin{subarray}{c}j=0\\\\ j \\neq i \\end{subarray}}^n(x_i-x_j)于是，基函数表示成 l_i(x)=\\frac{\\omega_{n+1}(x)}{(x-x_i)\\omega{}'_{n+1}(x_i)} \\quad (i=0,1,\\cdots,n)2.2.4 余项公式利用插值多项式 $L_n(x)$ 作为 $f(x)$ 的近似函数，在 $[a,b]$ 上有误差（截断误差）： R(x)=f(x)-L_n(x)称为插值多项式的余项。其中，当 $x=x_i \\ (i=0,1,\\cdots,n)$ 时，$R(x_i)=0$。对余项的估计有一个理论的结果： 设 $f \\in C^n[a,b]$，且 $f^{(n+1)}$ 在 $(a,b)$ 内存在，则 $f$ 的 $n$ 次插值多项式 $L_n$ 对任何 $x\\in[a,b]$，有插值余项 R_n(x)=f(x)-L_n(x)=\\frac{1}{(n+1)!}f^{(n+1)}(\\xi)\\omega_{n+1}(x)其中，$\\xi \\in (a,b)$ 且与 $x$ 有关，$\\omega_{n+1}(x)=\\prod \\limits_{i=0}^n(x-x_i)$ 2.3 带导插值：$Hermite$ 插值公式2.3.1 带导插值的提法 如果不仅已知插值节点处的函数值，而且还掌握插值节点处的导数值（1 阶甚至高阶）；或者说，不仅要求在节点处插值多项式与被插函数的值相等（插值条件），而且还要求相应阶的导数值也相等（相切），这就是带导插值，也称 $Hermite$（埃尔米特）插值。 设已知 $f$ 在 $[a,b]$ 上 $n+1$ 个互异节点 $x_i \\in [a,b]$ 处的函数值 $f_i = f(x_i)$ 和 1 阶导数值 $f{}’_i = f{}’(x_i) \\ (i=0,1,\\cdots,n)$，或记为离散数据 (x_i,f_i,f{}'_i) \\quad (i=0,1,\\cdots,n), \\qquad (2.3.1)求作一个次数尽可能低的多项式 $H(x)$，满足插值条件： \\begin{cases} H(x_i)=f_i \\\\ H{}'(x_i)=f{}'_i \\end{cases}\\quad (i=0,1,\\cdots,n)这样的多项式 $H(x)$ 就被称为 $f$ 的带导插值多项式，或称为带导插值多项式的 $Hermite$ 形式。 2.3.2 带导插值定理对已知数据 $(2.3.1)$，存在唯一的次数 $\\leqslant 2n+1$ 的多项式 $H_{2n+1}(x) \\in P_{2n+1}$，满足插值条件： \\begin{cases} H_{2n+1}(x_i)=f_i \\\\ H_{2n+1}{}'(x_i)=f{}'_i \\end{cases}\\quad (i=0,1,\\cdots,n)2.3.3 $Hermite$ 插值公式及其余项公式插值基函数 仿照 $Lagrange$ 插值多项式的做法，用基函数的方法来求插值多项式 $H_{2n+1}(x)$。如果能够由已知插值节点 $x_i \\ (i=0,1,\\cdots,n)$ 作出 $2n+2$ 个 $2n+1$ 次插值基函数 \\alpha_i(x),\\ \\beta_i(x) \\quad (i=0,1,\\cdots,n),且它们具有下列性质： \\alpha_i(x_j)=\\delta_{ij}=\\begin{cases} 1, & \\text{当$i=j$} \\\\ 0, & \\text{当$i\\neq j$} \\end{cases}, \\quad \\alpha{}'_i(x_j)=0 \\beta_i(x_j) = 0, \\quad \\beta{}'_i(x_j)=\\begin{cases} 1, & \\text{当$i=j$} \\\\ 0, & \\text{当$i\\neq j$} \\end{cases}则容易验证，满足插值条件的 $2n+1$ 次 $Hermite$ 插值多项式为： H_{2n+1}(x)=\\sum_{i=0}^n \\left[ \\alpha_i(x) \\cdot f_i + \\beta_i(x) \\cdot f{}'_i \\right]其中插值基函数为： \\alpha_i(x)=[1-2(x-x_i)\\sum_{\\begin{subarray}{c}j=0\\\\ j \\neq i \\end{subarray}}^{n}\\frac{1}{x_i - x_j}]l_i^2(x) \\quad (i=0,1,\\cdots,n) \\beta_i(x)=(x-x_i)l_i^2(x) \\quad (i=0,1,\\cdots,n)余项公式 设函数 $f \\in C^{2n+1}[a,b]$，且 $f^{(2n+2)}$ 在 $(a,b)$ 内存在，则 $f$ 的 $Hermite$ 插值多项式 $H_{2n+1}(x)$ 的余项公式为： R(x)=f(x)-H_{2n+1}(x)=\\frac{f^{(2n+2)}(\\xi)}{(2n+2)!}\\omega_{n+1}^2(x), \\quad \\forall x \\in [a,b].其中，$\\xi = \\xi(x) \\in (a,b)$，$\\omega_{n+1}(x)=\\prod \\limits_{i=0}^n(x-x_i)$。 2.3.4 $Hermite$ 插值的常用情形两个节点 $x_0,x_1$（即 $n=1$） 的三次 $Hermite$ 插值多项式 $H_3(x)$ 是应用中最基本的情形。这时，基函数为： \\begin{aligned} &\\alpha_0(x)=(1+2\\frac{x-x_0}{x_1-x_0})(\\frac{x-x_1}{x_0-x_1})^2, \\\\ &\\alpha_1(x)=(1+2\\frac{x-x_1}{x_0-x_1})(\\frac{x-x_0}{x_1-x_0})^2, \\\\ &\\beta_0(x) = (x-x_0)(\\frac{x-x_1}{x_0-x_1})^2, \\\\ &\\beta_1(x) = (x-x_1)(\\frac{x-x_0}{x_1-x_0})^2, \\end{aligned}三次 $Hermite$ 插值多项式 为： H_3(x)=\\alpha_0(x)f_0+\\alpha_1(x)f_1+\\beta_0(x)f{}'_0+\\beta_1(x)f{}'_1,插值余项为： R_3(x)=f(x)-H_3(x) =\\frac{f^{(4)}(\\xi)}{4!}(x-x_0)^2(x-x_1)^2, \\quad \\xi = \\xi(x) \\in (a,b)🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"CentOS 7 安装配置 SSH 并允许 root 登录","slug":"centos7-ssh","date":"2018-11-14T13:56:36.000Z","updated":"2019-09-01T13:04:11.029Z","comments":true,"path":"2018/11/14/centos7-ssh/","link":"","permalink":"https://abelsu7.top/2018/11/14/centos7-ssh/","excerpt":"待更新~ 初次安装好 CentOS 7 系统后，还需对 SSH 进行简单配置，才可使用 root 或其他用户远程登录。 检查是否已安装 openssh-server行内代码 inline yum list installed | grep openssh-server something cd /usr/local/etc cp php.ini php.ini.bak vi php.ini /usr/local/etc uname -a # comment .example-gradient { background: -moz-linear-gradient(left, #cb60b3 0%, #c146a1 50%, #a80077 51%, #db36a4 100%); /* FF3.6+ */ background: -webkit-linear-gradient(left, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* Chrome10+,Safari5.1+ */ background: -o-linear-gradient(left, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* Opera 11.10+ */ background: -ms-linear-gradient(left, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* IE10+ */ background: linear-gradient(to right, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* W3C */ } .example-angle { transform: rotate(10deg); } .example-color { color: rgba(255, 0, 0, 0.2); background: purple; border: 1px solid hsl(100,70%,40%); } .example-easing { transition-timing-function: linear; } .example-time { transition-duration: 3s; }","text":"待更新~ 初次安装好 CentOS 7 系统后，还需对 SSH 进行简单配置，才可使用 root 或其他用户远程登录。 检查是否已安装 openssh-server行内代码 inline yum list installed | grep openssh-server something cd /usr/local/etc cp php.ini php.ini.bak vi php.ini /usr/local/etc uname -a # comment .example-gradient { background: -moz-linear-gradient(left, #cb60b3 0%, #c146a1 50%, #a80077 51%, #db36a4 100%); /* FF3.6+ */ background: -webkit-linear-gradient(left, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* Chrome10+,Safari5.1+ */ background: -o-linear-gradient(left, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* Opera 11.10+ */ background: -ms-linear-gradient(left, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* IE10+ */ background: linear-gradient(to right, #cb60b3 0%,#c146a1 50%,#a80077 51%,#db36a4 100%); /* W3C */ } .example-angle { transform: rotate(10deg); } .example-color { color: rgba(255, 0, 0, 0.2); background: purple; border: 1px solid hsl(100,70%,40%); } .example-easing { transition-timing-function: linear; } .example-time { transition-duration: 3s; } 查看 SELinux 状态及关闭 SELinux1. 查看 SELinux 状态 /usr/sbin/sestatus -v SELinux status: disabled getenforce Disabled 2. 临时关闭 SELinux使用下列命令设置 SELinux 为 permissive 模式： setenforce 0 # setenforce 1 设置 SELinux 为 enforcing 模式 3. 永久关闭 SELinux永久关闭 SELinux 需要修改配置文件并重启机器。 首先编辑 /etc/selinux/config 文件，将 SELINUX=enforcing 改为 SELINUX=disabled： # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted 之后重启机器，即可关闭 SELinux。 SSH Keys配置 VNC关闭防火墙更新 Yum 源 相关资料 CentOS 7 安装和配置 SSH | 开源中国 虚拟机下 CentOS 7 开启 SSH 连接 | CSDN SSH 原理与运用（一）：远程登录 | 阮一峰 SSH 原理与运用（二）：远程操作与端口转发 | 阮一峰 OpenSSH ssh(1) - Linux man page SSH 命令 | Linux 命令大全 查看 SELinux状态及关闭SELinux | 51 CTO 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"},{"name":"SSH","slug":"SSH","permalink":"https://abelsu7.top/tags/SSH/"}]},{"title":"5 分钟 Docker 笔记 2：镜像","slug":"docker-5mins-notes-2","date":"2018-11-05T08:32:57.000Z","updated":"2019-09-01T13:04:11.128Z","comments":true,"path":"2018/11/05/docker-5mins-notes-2/","link":"","permalink":"https://abelsu7.top/2018/11/05/docker-5mins-notes-2/","excerpt":"镜像内部结构、构建镜像、镜像命名、Registry 《每天5分钟玩转Docker容器技术》","text":"镜像内部结构、构建镜像、镜像命名、Registry 《每天5分钟玩转Docker容器技术》 第 3 章 Docker 镜像3.1 镜像的内部结构3.1.1 最小的镜像 hello-world docker pull hello-world docker images docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. hello-world 的 Dockerfile 内容如下： FROM scratch COPY hello / CMD [&quot;/hello&quot;] FROM scratch：此镜像是从白手起家，从 0 开始构建 COPY hello /：将文件 hello 复制到镜像的根目录 CMD [&quot;/hello&quot;]：容器启动时，执行 /hello hello-world 虽然是一个完整的镜像，但它并没有什么实际用途。通常来说，我们希望镜像能提供一个基本的操作系统环境，用户可以根据需要安装和配置软件。这样的镜像我们称作 base 镜像。 3.1.2 base 镜像base 镜像有两层含义： 不依赖其他镜像，从 scratch 构建 其他镜像可在其基础上进行扩展 所以，能称作 base 镜像的通常都是各种 Linux 发行版的 Docker 镜像，比如 Ubuntu, Debian, CentOS 等。 使用 docker pull centos命令下载 centos 镜像并查看其镜像信息，发现大小仅为 200 MB，为什么会这么小？ Linux 操作系统由内核空间和用户空间组成，如下图所示： Linux 的内核空间与用户空间 rootfs内核空间是 Kernel，Linux 刚启动时会加载 bootfs 文件系统，之后 bootfs 会被卸载掉。 用户空间的文件系统是 rootfs，包含我们熟悉的 /dev, /proc, /bin 等目录。 对于 base 镜像而言，底层直接用 Host 的 kernel，自己只需提供 rootfs。 而对于一个精简的 OS，rootfs 可以很小，只需要包括最基本的命令、工具和程序库就可以了。 base 镜像提供最小安装的 Linux 发行版CentOS 镜像的 Dockerfile 文件内容如下： FROM scratch ADD centos-7-docker.tar.xz / CMD [&quot;/bin/bash&quot;] 第二行 ADD 指令添加到镜像的 tar 包就是 CentOS 7 的 rootfs。在制作镜像时，这个 tar 包会自动解压到 / 目录下，生成 /dev, /porc, /bin 等目录。 支持运行多种 Linux OS不同 Linux 发行版的区别主要就是 rootfs。 比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。 所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。 Debian 和 BusyBox 容器共用 Host Kernel 上图 Debian 和 BusyBox（一种嵌入式 Linux）上层提供各自的 rootfs，底层共用 Docker Host 的 kernel。 需要说明的是： base 镜像只是用户空间与发行版一致，Kernel 版本与发行版是不同的。 容器只能使用 Host 的 Kernel，并且不能修改。 3.1.3 镜像的分层结构Docker 支持通过扩展现有镜像，创建新的镜像。 实际上，Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的。例如我们现在构建一个新的镜像，Dockerfile 如下： FROM debian RUN apt-get install emacs RUN apt-get install apache2 CMD [&quot;/bin/bash&quot;] 构建过程如下图所示： 构建过程示意 可以看到，新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。 Docker 镜像采用这种分层结构最大的好处就是 共享资源。 比如：有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享，我们将在后面更深入地讨论这个特性。 如果多个容器共享一份基础镜像，当某个容器修改了基础镜像的内容，比如 /etc 目录下的文件时，修改会被限制在单个容器内，这就是容器的 Copy-on-Write 特性。 可写的容器层当容器启动时，一个新的可写层会被加载到镜像的顶部。这一层通常被称作容器层，容器层之下的都叫镜像层。 可写的容器层会被加载到镜像顶部 所有对容器的改动——无论是添加、删除还是修改文件，都只会发生在容器层中。 并且，只有容器层是可写的，容器层下面的所有镜像层都是只读的。 镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。在容器层中，用户看到的是一个叠加之后的文件系统。 添加文件：在容器中创建文件时，新文件被添加到容器层中。 读取文件：在容器中读取某个文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，打开并读入内存。 修改文件：在容器中修改已存在的文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后修改之。 删除文件：在容器中删除文件时，Docker 也是从上往下依次在镜像层中查找此文件。找到后，会在容器层中记录下此删除操作。 Copy-on-Write只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。 这样就解释了之前的问题：容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改。所以镜像可以被多个容器共享。 3.2 构建镜像对于 Docker 用户来说，最好的情况是不需要自己创建镜像。使用现成镜像的好处除了省去自己做镜像的工作量外，更重要的是可以利用前人的经验。 当然，某些情况下我们也不得不自己构建镜像，比如： 找不到现成的镜像，比如自己开发的应用程序 需要在镜像中加入特定的功能，比如官方镜像几乎都不提供 ssh Docker 提供了两种构建镜像的方法： docker commit 命令 Dockerfile 构建文件 3.2.1 docker commitdocker commit 命令是创建新镜像最直观的方法，其过程包含三个步骤： 运行容器 修改容器 将容器保存为新的镜像 (1) 运行容器 docker run -it ubuntu (2) 安装 vi vim bash: vim: command not found apt-get install vim Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: file libexpat1 libgpm2 libmagic-mgc libmagic1 libmpdec2 libpython3.6... (3) 保存为新镜像 在新窗口中查看当前运行的容器： docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1abe6e7341ca ubuntu \"/bin/bash\" 8 minutes ago Up 8 minutes laughing_leavitt laughing_leavitt 是 Docker 为我们的容器随机分配的名字。 执行 docker commit 命令将容器保存为镜像： docker commit laughing_leavitt ubuntu-with-vi sha256:9d2fac08719de640df6a923bd6c1dc82d73817d29e9c287d024b6cd2a7235683 查看新镜像 ubuntu-with-vi 的属性： docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu-with-vi latest 9d2fac08719d About a minute ago 169MB ubuntu latest ea4c82dcd15a 2 weeks ago 85.8MB 从 SIZE 属性看到镜像因为安装了软件而变大了。从新镜像启动容器，验证 vi 已经可以使用： which vim /usr/bin/vim 以上演示了如何通过 docker commit 创建新镜像。然而，Docker 并不建议用户通过这种方式构建镜像。原因如下： 这是一种手工创建镜像的方式，容易出错，效率低且可重复性弱。 更重要的是，使用者并不知道镜像是如何创建出来的，里面是否有恶意程序。也就是说无法对镜像进行审计，存在安全隐患。 3.2.2 DockerfileDockerfile 是一个文本文件，记录了镜像构建的所有步骤。 第一个 Dockerfile用 Dockerfile 创建上节的 ubuntu-with-vi，其内容为： FROM ubuntu RUN apt-get update &amp;&amp; apt-get install -y vim 下面运行 docker build 命令构建镜像，并分析其细节： pwd (1) /root ls (2) Dockerfile docker build -t ubuntu-with-vi-dockerfile . (3) Sending build context to Docker daemon 32.26 kB (4) Step 1 : FROM ubuntu (5) ---> f753707788c5 Step 2 : RUN apt-get update && apt-get install -y vim (6) ---> Running in 9f4d4166f7e3 (7) ...... Setting up vim (2:7.4.1689-3ubuntu1.1) ... ---> 35ca89798937 (8) Removing intermediate container 9f4d4166f7e3 (9) Successfully built 35ca89798937 (10) (1) 当前目录为 /root。 (2) Dockerfile 准备就绪。 (3) 运行 docker build 命令，-t 命名新镜像，末尾的 . 表明 build context 为当前目录。Docker 默认会从 build context 中查找 Dockerfile 文件，也可以通过 -f 参数指定 Dockerfile 的位置。 (4) 从这步开始就是镜像真正的构建过程。首先 Docker 将 build context 中的所有文件发送给 Docker daemon。build context 为镜像构建提供所需要的文件或目录。 Dockerfile 中的 ADD、COPY 等命令可以将 build context 中的文件添加到镜像。此例中，build context 为当前目录 /root，该目录下的所有文件和子目录都会被发送给 Docker daemon。 注意不要将多余的文件放到 build context 中，特别不要把 /、/usr 等目录作为 build context，否则构建过程会相当缓慢甚至失败。 (5) Step 1：执行 FROM，将 Ubuntu 作为 base 镜像。 (6) Step 2：执行 RUN，安装 vi，具体步骤为 (7) (8) (9)。 (7) 启动 ID 为 9f4d4166f7e3 的临时容器，在容器中通过 apt-get 安装 vim。 (8) 安装成功后，将容器保存为镜像，其 ID 为 35ca89798937。这一步底层使用的是类似 docker commit 的命令。 (9) 删除临时容器 9f4d4166f7e3。 (10) 镜像构建成功。 查看镜像分层结构docker history会显示镜像的构建历史，也就是 Dockerfile 的执行过程。 镜像的缓存特性Docker 会缓存已有镜像的镜像层，构建新镜像时，如果某镜像层已经存在，就直接使用，无需重新创建。 调试 Dockerfile如果 Dockerfile 由于某种原因执行到某个指令失败了，我们也将能够得到前一个指令成功执行构建出的镜像，这对调试 Dockerfile 非常有帮助。可以通过docker run -it启动镜像的一个容器，手动执行目标命令，查看错误信息。 Dockerfile 常用指令 FROM：指定 base 镜像 MAINTAINER：设置镜像的作者，可以是任意字符串 COPY：将文件从 build context 复制到镜像，支持COPY src dest或COPY [&quot;src&quot;, &quot;dest&quot;] ADD：与 COPY 类似，从 build context 复制文件到镜像。不同的是，如果 src 是归档文件（tar、zip、tgz、xz 等），那么文件会被自动解压到 dest。 ENV：设置环境变量，可以被后面的指令使用。例如： ENV MY_VERSION 1.3 RUN apt-get install -y mypackage=$MY_VERSION ... EXPOSE：指定容器中的进程会监听某个端口，Docker 可以将该端口暴露出来。 VOLUME：将文件或目录声明为 volume WORKDIR：设置镜像中的当前工作目录 RUN：在容器中运行指定的命令 CMD：容器启动时运行指定的命令。Dockerfile 中可以有多个 CMD 命令，但只有最后一个生效。CMD 可以被docker run之后的参数替换。 ENTRYPOINT：设置容器启动时运行的命令。CMD 或docker run之后的参数会被当做参数传递给 ENTRYPOINT。 下面是一个较为全面的 Dockerfile： # my dockerfile FROM busybox MAINTAINER abelsu7@gmail.com WORKDIR /testdir RUN touch tmpfile1 COPY [&quot;tmpfile2&quot;, &quot;.&quot;] ADD [&quot;bunch.tar.gz&quot;, &quot;.&quot;] ENV WELCOME &quot;You are in my container, welcome!&quot; 运行容器，验证镜像内容： &gt; docker run -it my-image /testdir &gt; ls bunch tmpfile1 tmpfile2 /testdit &gt; echo $WELCOME You are in my container, welcome! RUN vs CMD vs ENTRYPOINT这三个 Dockerfile 指令看上去很类似，但也有不同之处。简单来说： RUN 执行命令并创建新的镜像层，经常用于安装软件包。 CMD 设置容器启动后默认执行的命令及其参数，但 CMD 能够被docker run后面跟的命令行参数替换。 ENTRYPOINT 配置容器启动时运行的命令 Shell 和 Exec 格式 可以用两种方式指定 RUN、CMD 和 ENTRYPOINT 要运行的命令：Shell 格式和 Exec 格式。 Shell 格式： &lt;instruction&gt; &lt;command&gt; RUN apt-get install python3 CMD echo &quot;Hello World&quot; ENTRYPOINT echo &quot;Hello World&quot; 当指令执行时，shell 格式底层会调用/bin/sh -c &lt;command&gt;。 Exec 格式： &lt;instruction&gt; [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;, ...] RUN [&quot;apt-get&quot;, &quot;install&quot;, &quot;python3&quot;] CMD [&quot;/bin/echo&quot;, &quot;Hello world&quot;] ENTRYPOINT [&quot;/bin/ehco&quot;, &quot;Hello world&quot;] 当指令执行时，会直接调用&lt;command&gt;，不会被 Shell 解析。 CMD 和 ENTRYPOINT 推荐使用 Exec 格式，因为指令可读性更强，更容易理解。RUN 则两种格式都可以。 RUN RUN 指令通常用于安装应用和软件包。 RUN 在当前镜像的顶部执行命令，并创建新的镜像层。Dockerfile 中常常包含多个 RUN 指令。 注意：apt-get update和apt-get install被放在一个 RUN 指令中执行，这样能够保证每次安装的是最新的包。如果apt-get install在单独的 RUN 中执行，则会使用apt-get update创建的镜像层，而这一层可能是很久之前缓存的。 CMD CMD 指令允许用户指定容器默认执行的命令。 此命令会在容器启动且docker run没有指定其他命令时运行。 如果docker run指定了其他命令，则 CMD 指定的默认命令将被忽略 如果 Dockerfile 中有多个 CMD 指令，只有最后一个 CMD 有效 ENTRYPOINT ENTRYPOINT 指令可让容器以应用程序或服务的形式运行。 ENTRYPOINT 看上去与 CMD 很像，它们都可以指定要执行的命令及其参数。不同的地方在于 ENTRYPOINT 不会被忽略，一定会被执行，即使运行 docker run 时指定了其他命令。 ENTRYPOINT 的 Exec 格式用于设置要执行的命令及其参数，同时可通过 CMD 提供额外的参数。 例如下面的 Dockerfile 片段： ENTRYPOINT [&quot;/bin/echo&quot;, &quot;Hello&quot;] CMD [&quot;world&quot;] 当容器通过docker run -it [image]启动时，输出为：Hello world。 当容器通过docker run -it [image] CloudMan启动时，输出为：Hello CloudMan ENTRYPOINT 的 Shell 格式会忽略任何 CMD 或docker run提供的参数。 最佳实践 使用 RUN 指令安装应用和软件包，构建镜像。 如果 Docker 镜像的用途是运行应用程序或服务，例如运行一个 MySQL 实例，则应该优先使用 Exec 格式的 ENTRYPOINT 指令。CMD 可为 ENTRYPOINT 提供额外的默认参数，同时利用docker run命令行替换默认参数。 如果想为容器设置默认的启动命令，可使用 CMD 指令。用户可在docker run命令行中替换此默认命令。 3.3 镜像命名一个特定镜像的名字由两部分组成：repository 和 tag： [image name] = [repository]:[tag] 如果执行docker build时没有指定 tag，则会使用默认值 latest，其效果相当于： docker build -t ubuntu-with-vi:latest 3.4 镜像仓库 Registry3.4.1 使用公共 Registry：Docker HubDocker Hub 是 Docker 公司维护的公共 Registry。用户可以将自己的镜像保存到 Docker Hub 免费的 repository 中。如果不希望别人访问自己的镜像，也可以购买私有 repository。 除了 Docker Hub，quay.io 是另一个公共 Registry，提供与 Docker Hub 类似的服务。 通过 Docker Hub 存取镜像的步骤如下： 首先在 Docker Hub 上注册账号 在 Docker Host 上登录：docker login -u [username] 修改镜像的 repository 使之与 Docker Hub 账号匹配。Docker Hub 为了区分不同用户的同名镜像，镜像的 registry 中要包含用户名，完整格式为：[username]/xxx:tag。通过docker tag命令重命名镜像：docker tag httpd cloudman6/httpd:v1 通过docker push将镜像上传到 Docker Hub：docker push cloudman6/httpd:v1。省略 tag 部分即可上传同一 repository 中的所有镜像 登录 https://hub.docker.com，在 Public Repository 中就可以看到上传的镜像 在其他 Docker Host 上可通过docker pull命令下载使用该镜像 3.4.2 搭建本地 RegistryDocker Hub 虽然非常方便，但还是有些限制： 需要互联网连接，而且下载上传速度较慢 上传到 Docker Hub 的镜像任何人都能够访问。虽然可以使用私有 repository，但不是免费的 安全原因使得很多组织不允许将镜像放到外网 解决方案就是搭建本地的 Registry。 Docker 已经将 Registry 开源了，同时在 Docker Hub 上也有官方的镜像 Registry。 1) 启动 registry 容器： docker run -d -p 5000:5000 -v /myregistry:/var/lib/registry registry:2 2) 通过docker tag重命名镜像，使之与 registry 匹配： docker tag cloudman6/httpd:v1 registry.example.net:5000/cloudman6:httpd:v1 只有 Docker Hub 上的镜像可以省略[registry-host]:[port] 3) 通过docker push上传镜像： docker push registry.example.net:5000/cloudman6/httpd:v1 4) 现在就可以通过docker pull从本地 registry 下载镜像了： docker pull registry.example.net:5000/cloudman6/httpd:v1 本地 registry 也支持认证、HTTPS 安全传输等特性，具体可参考官方文档。 3.5 Docker 镜像小结镜像的常用操作子命令如下： images：显示镜像列表 history：显示镜像构建历史 commit：从容器创建新镜像 build：从 Dockerfile 构建镜像 tag：给镜像打 tag pull：从 registry 下载镜像 push：将镜像上传到 registry rmi：删除 Docker Host 中的镜像 search：搜索 Docker Hub 中的镜像 参考文章 《每天5分钟玩转 Docker 容器技术》教程目录 | CloudMan 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Linux 内核笔记 1：绪论影响力数学之美：不能再凑了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"}]},{"title":"数值分析笔记 1：基础概念","slug":"math-analysis","date":"2018-10-31T02:11:40.000Z","updated":"2019-09-01T13:04:11.527Z","comments":true,"path":"2018/10/31/math-analysis/","link":"","permalink":"https://abelsu7.top/2018/10/31/math-analysis/","excerpt":"误差分析、最值、谱半径、范数 《应用数值分析》","text":"误差分析、最值、谱半径、范数 《应用数值分析》 目录 目录 1. 基本概念 1.2 误差分析 1.2.1 绝对误差/相对误差 1.2.2 有效数字 1.2.3 截断误差/舍入误差/初始数据误差 1.3 病态问题与条件数/数值稳定性 1.3.1 病态问题与条件数 1.3.2 算法数值稳定性 1.4 数值算法设计与实现 1.5 数学分析中的几个重要概念 1.5.1 $Taylor$ 公式 1.5.2 大 $O$ 记号 1.5.3 上确界与下确界 1.5.4 函数序列的一致收敛性 1.6 几种重要矩阵及相关性质 1.6.1 对称正定矩阵 1.6.2 正交矩阵/相似矩阵 1.6.3 初等矩阵与初等变换 1.6.4 矩阵特征值/矩阵谱半径 1.7 线性空间概要 1.7.1 线性空间 1.7.2 范数/赋范线性空间 1.7.3 内积/内积空间 1.9 向量范数/矩阵范数 1.9.1 向量范数 1.9.2 矩阵范数 1. 基本概念1.2 误差分析1.2.1 绝对误差/相对误差 绝对误差：准确值与近似值之差，e\\left ( x^{*} \\right ) = x - x^{*} 相对误差：e_r(x^*)=\\frac{e(x^*)}{x}=\\frac{x-x^*}{x} 绝对误差界：\\left| e \\right|=\\left | x-x^* \\right |\\leqslant \\varepsilon 相对误差界：\\left| e_r \\right|=\\frac{\\left | x-x^* \\right |}{\\left | x^*\\right|}\\leqslant \\varepsilon_r 1.2.2 有效数字 定义：设 $x$ 的近似值 $x^*$ 表示成规格化形式： x^* = \\pm 10^k \\times 0.a_1a_2 \\cdots a_n \\cdots如果有 \\left| x-x^* \\right| \\leqslant \\frac{1}{2} \\times 10^{k-n}，则称 $x^*$ 有 $n$ 位有效数字。 有效数字的位数与小数点无关 有效数字位数与相对误差有下列关系： (1) 如果 $x^*$ 有 $n$ 位有效数字，则 \\left| e_r(x^*) \\right| = \\frac{\\left| x-x^* \\right|}{\\left| x^* \\right|} \\leqslant \\frac{1}{2a_1} \\times 10^{1-n}(2) 如果下式成立，则 $x^*$ 至少有 $n$ 位有效数字： \\left| e_r(x^*) \\right| = \\frac{\\left| x-x^* \\right|}{\\left| x^* \\right|} \\leqslant \\frac{1}{2(a_1+1)} \\times 10^{1-n}1.2.3 截断误差/舍入误差/初始数据误差 截断误差：或称方法误差，指在构造数值计算方法时，用有限过程代替无限过程，其计算结果所存在的误差。 舍入误差：或称计算误差，进行舍入操作所引起的误差 初始数据误差：或称输入数据误差，可能是物理数据测量不准确、初始数据只能取近似值引起的。为简明起见，把这些误差归入舍入误差范围处理。 1.3 病态问题与条件数/数值稳定性1.3.1 病态问题与条件数条件数 条件数记为 $C$ 或 $Cond$ 误差 $e(x^*)$ 的条件数：\\left| {f}'(x) \\right| 相对误差 $e_r(x^*)$ 的条件数：\\left| \\frac{x{f}'(x)}{f(x)} \\right| 病态/良态 对于一个数值问题，当输入数据（初始数据）有微小扰动时，计算结果对之很敏感，即条件数很大，就称这个问题是病态的 当初始数据有微小扰动时，计算结果对之不敏感，即条件数不大，就称这个问题是良态的 1.3.2 算法数值稳定性 一个算法在执行过程中，某阶段所产生的小误差在随后的阶段中不会被积累或放大，就称这个算法过程是数值稳定的 否则，称这个算法过程是数值不稳定的 不稳定有时也叫病态 所谓严重降低计算精确度，确切地说，设由且仅由 $\\varepsilon$ 引起的、$n$ 步运算之后的误差为 $e_n$： 如果 \\left| e_n \\right| \\approx cn\\varepsilon（$c$ 是与 $n$ 无关的常数），即误差是线性增长的，从而可通过 $\\varepsilon$ 来控制 $e_n$，故算法是稳定的 如果 \\left| e_n \\right| \\approx k^n \\left| \\varepsilon \\right|（$k &gt; 1$ 的常数），即误差是指数增长的，或者如果 \\left| e_n \\right| \\approx c(n!) \\cdot \\varepsilon，从而无论 $\\left| \\varepsilon \\right|$ 多么小，均难以通过 $\\varepsilon$ 来控制 $e_n$，故算法是不稳定的 1.4 数值算法设计与实现对于数值算法设计来说，主要强调以下两方面： 尽量简化计算步骤，减少运算次数 尽量减少舍入误差的影响，避免有效数字的损失，保证算法的数值稳定性 秦九韶算法：$n$ 次加法，$n$ 次乘法 1.5 数学分析中的几个重要概念1.5.1 $Taylor$ 公式 设 $f$ 在含有点 $x_0$ 的某个开区间 $( a,b )$ 内具有 $n+1$ 阶导数，则 $\\forall x \\in (a,b) $，有： \\begin{aligned} f(x) =& f(x_0) + {f}'(x_0)(x-x_0) + \\frac{f''(x_0)}{2!}(x-x_0)^2 + \\\\ & \\cdots + \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + \\frac{f^{(n+1)}(\\xi )}{(n+1)!}(x-x_0)^{n+1} \\end{aligned}其中，$\\xi$ 在 $x_0$ 与 $x$ 之间，前 $n+1$ 项称为 $n$ 次 $Taylor$ 多项式，最后一项称为 $n$ 次 $Taylor$ 多项式的余项（即截断误差）。为了方便作误差估计，有时还假定 $f$ 的 $n+1$ 阶导数连续。 1.5.2 大 $O$ 记号定义 大 $O$ 记号是为表示近似值而允许我们用 “$=$” 号替代 “$\\approx$” 的方便符号。 设变量 $X, Y$（其中 $X \\neq 0$），如果在变化过程的某一时刻以后，有： \\left| \\frac{Y}{X} \\right| \\leqslant M 或 \\left| Y \\right| \\leqslant M \\left| X \\right|（$M$ 为大于 $0$ 的常数）便记成 $Y=O(X)$。 性质 当 $X$ 变化到某一时刻后，$\\left| O(X) \\right|$ 总是不会超过 $M\\left| (X) \\right|$ 大 $O$ 记号具有单向相等性，等式的右端只是左端的粗略化 运算法则 $O(X) \\pm O(X) = O(X)$ $mO(X) = O(X)$，$m$ 为不等于 $0$ 的常数 $O(X) \\cdot O(X) = O(X^2)$ $O(O(X)) = O(X)$ 1.5.3 上确界与下确界最大值/最小值 设 $S$ 是一个非空的实数集，$S \\subset \\mathbf{R}$（$\\mathbf{R} \\equiv \\mathbf{R}^1 = (-\\infty,+\\infty)$ 是实数的全体）， 如果有 $M \\in \\mathbf{R}$，使得：$x \\leqslant M, \\forall x \\in S$，则称集 $S$ 上有界，$M$ 是 $S$ 的一个上界 如果有 $m \\in \\mathbf{R}$，使得：$x \\geqslant m, \\forall x \\in S$，则称集 $S$ 下有界, $m$ 是 $S$ 的一个下界 如果 $S$ 上、下有界，则称 $S$ 为有界集 当上界 $M \\in S$，则称 $M$ 是 $S$ 的最大值，记为 $M = \\max S$ 或 $M = \\max \\limits_{x \\in S} x$ 当下界 $m \\in S$，则称 $m$ 是 $S$ 的最小值，记为 $m = \\min S$ 或 $m = \\min \\limits_{x \\in S} x$ 最小上界公理 任何有上界的非空实数集都有一个最小上界 上确界/下确界 设 $S \\subset \\mathbf{R}$， 如果 $\\mu \\in \\mathbf{R}$ 是 $S$ 的最小上界，则称 $\\mu$ 是 $S$ 的上确界（supremum），记作 $\\mu = \\sup S$ 或 $\\mu = \\sup \\limits_{x \\in S} x$ 如果 $\\nu \\in \\mathbf{R}$ 是 $S$ 的最大下界，则称 $\\nu$ 是 $S$ 的下确界（infimum），记作 $\\nu = \\inf S$ 或 $\\nu = \\inf \\limits_{x \\in S} x$ 当 $S$ 上无界时，规定 $\\sup S = + \\infty$ 当 $S$ 下无界时，规定 $\\inf S = - \\infty$ 若 $S \\subset \\mathbf{R}$ 上有界，则必存在上确界，但不一定存在最大值；如果 $S$ 存在最大值，则最大值就是上确界 若 $S \\subset \\mathbf{R}$ 下有界，则必存在下确界，但不一定存在最小值；如果 $S$ 存在最小值，则最小值就是下确界 1.5.4 函数序列的一致收敛性设数列 $\\left \\{ x_n \\right \\}$，如果存在常数 $a$，对任意给定的正数 $\\varepsilon$（无论它多小），总存在正整数 $N$，使得当 $n &gt; N$ 时，有 \\left| x_n - a \\right| < \\varepsilon则称 $a$ 为数列 $\\left \\{ x_n \\right \\}$ 的极限，记为 $\\lim \\limits_{n \\to \\infty} x_n = a$，或称为数列 $\\left \\{ x_n \\right \\}$ 收敛于 $a$。 1.6 几种重要矩阵及相关性质1.6.1 对称正定矩阵定义 设 $\\pmb{A} = (a_{ij}) \\in \\mathbf{R^{n \\times n}}$ (1) 如果 $\\pmb{A}^T = \\pmb{A}$，即 $a^{ij} = a^{ji}$，则称 $\\pmb{A}$ 为对称矩阵 (2) 如果对称矩阵 $\\pmb{A}$ 满足对于 $\\forall x \\neq 0, x \\in \\mathbf{R}^{n \\times n}$，有 x^T \\pmb{A} x = \\sum_{i,j=1}^{n} a_{ij}x_ix_j > 0则称 $\\pmb{A}$ 为对称正定矩阵 性质 对称矩阵和对称正定矩阵有如下性质： 若 $\\pmb{A}$ 对称，则 $\\pmb{A}$ 的特征值皆为实数，且有 $n$ 个线性无关的特征向量 $\\pmb{A} \\in \\mathbf{R}^{n \\times n}$ 对称正定的充要条件是 $\\pmb{A}$ 的所有顺序主子式 \\Delta_i = \\det A_i = \\begin{vmatrix} a_{11} &\\cdots &a_{1i} \\\\ \\vdots & &\\vdots \\\\ a_{1i} &\\cdots &a_{ii} \\end{vmatrix} > 0 \\quad (i=1,2,\\cdots,n) $\\pmb{A}$ 对称正定的充要条件是 $\\pmb{A}$ 的所有特征值 $\\lambda^i &gt; 0 \\quad (i=1,2,\\cdots,n)$ $\\pmb{A}$ 对称正定，则 $\\pmb{A}$ 非奇异，且 $\\pmb{A}^{-1}$ 也对称正定 $\\pmb{A}$ 对称正定，则 $\\pmb{A}$ 的对角元素 $a_{ij} &gt; 0$ 1.6.2 正交矩阵/相似矩阵正交矩阵定义 设 $\\pmb{A} = (a_{ij}) \\in \\mathbf{R^{n \\times n}}$ 且成立 $\\pmb{A}^T \\pmb{A} = I$，则称 $\\pmb{A}$ 为正交矩阵。 定义式 $\\pmb{A}^T \\pmb{A} = I$ 可以写成： \\sum_{k=1}^n a_{ki}a_{kj} = \\delta_{ij} \\quad (i,j=1,2,\\cdots,n)其中， \\delta_{ij}=\\begin{cases} 1, & \\text{当$ i = j $}\\\\ 0, & \\text{当$ i \\neq j $} \\end{cases}称为 $Kronecker$（克罗内克尔）符号。 正交矩阵性质 正交矩阵有如下性质： 单位矩阵是正交矩阵 若 $\\pmb{A}$ 是正交矩阵，则 $\\pmb{A}^T$、$\\pmb{A}^{-1}$ 也是正交矩阵 若 $\\pmb{A}$ 是正交矩阵，则 $\\pmb{A}$ 非奇异，且 $(\\det \\pmb{A})^2 = 1$，即 $\\det \\pmb{A}$ 等于 $1$ 或 $-1$ 若 $\\pmb{A},\\pmb{B}$ 同阶且为正交矩阵，则 $\\pmb{A}\\pmb{B}$ 与 $\\pmb{B}\\pmb{A}$ 为正交矩阵 相似矩阵定义 设 $\\pmb{A}$ 与 $\\pmb{B}$ 为 $n$ 阶方阵，如果有非奇异的 $n$ 阶方阵 $\\pmb{S}$，使得 \\pmb{A} = \\pmb{S}^{-1}\\pmb{B}\\pmb{S}则称 $\\pmb{A}$ 与 $\\pmb{B}$ 相似，记作 $\\pmb{A} \\sim \\pmb{B}$ 相似矩阵性质 矩阵相似关系有如下三个性质： 反身性：$\\pmb{A} \\sim \\pmb{A}$ 对称性：$\\pmb{A} \\sim \\pmb{B} \\Rightarrow \\pmb{B} \\sim \\pmb{A}$ 传递性：$\\pmb{A} \\sim \\pmb{B}, \\pmb{B} \\sim \\pmb{C} \\Rightarrow \\pmb{A} \\sim \\pmb{C}$ 应用中，常常不是判断两个矩阵是否相似，而是对给定的矩阵 $\\pmb{B}$，寻找合适的可逆矩阵 $\\pmb{S}$ 按 $\\pmb{A} = \\pmb{S}^{-1}\\pmb{B}\\pmb{S}$ 来产生一个矩阵 $\\pmb{A}$。 矩阵的相似变换：对一个矩阵两边分别乘以某可逆矩阵及其逆 矩阵的正交表换：对给定矩阵利用正交矩阵作相似变换 1.6.3 初等矩阵与初等变换初等矩阵 下面三种形式的 $n$ 阶矩阵称为初等矩阵： $\\pmb{E}(i,j)$ $\\pmb{E}(i(\\alpha))$ $\\pmb{E}(i,j(\\alpha))$ 初等矩阵性质 $\\pmb{E}(i,j)^{-1}=\\pmb{E}(i,j)$ $\\pmb{E}(i(\\alpha))^{-1}=\\pmb{E}(i(\\frac{1}{\\alpha}))$ $\\pmb{E}(i,j(\\alpha))^{-1}=\\pmb{E}(i,j(-\\alpha))$ 1.6.4 矩阵特征值/矩阵谱半径矩阵特征值定义 设 $\\pmb{A}=(a_{ij}) \\in \\mathbf{R}^{n \\times n}$。若存在一个数 $\\lambda$（实数或复数）和非零向量 $\\pmb{x}=(x_1,x_2,\\cdots,x_n)^T \\in \\mathbf{R}^n$，使得： \\pmb{A}\\pmb{x}=\\lambda\\pmb{x}则称 $\\lambda$ 为 $\\pmb{A}$ 的特征值，$\\pmb{x}$ 为 $\\pmb{A}$ 对应 $\\lambda$ 的特征向量。 矩阵特征值求解 应用中主要对给定的 $\\pmb{A}$ 求其特征值 $\\lambda$，为此将定义式改写为齐次方程 $(\\lambda\\pmb{I} - \\pmb{A})\\pmb{x}=0$，即 \\begin{aligned} \\pmb{p}(\\lambda) = \\det(\\lambda\\pmb{I}-\\pmb{A}) &=\\begin{vmatrix} \\lambda-a_{11} &-a_{12} &\\cdots &-a_{1n} \\\\ -a_{21} &\\lambda-a_{22} &\\cdots &-a_{2n} \\\\ \\vdots &\\vdots & &\\vdots \\\\ -a_{n1} &-a_{n2} &\\cdots &\\lambda-a_{nn} \\end{vmatrix} \\\\ &= \\lambda^n+c_1 \\lambda^{n-1}+\\cdots+c_{n-1}\\lambda+c_n \\\\ &=0 \\end{aligned} $\\pmb{p}(\\lambda)$ 称为 $\\pmb{A}$ 的特征多项式 $\\pmb{p}(\\lambda)=0$ 称为相应的特征方程 在复数域内有 $n$ 个根即为 $n$ 个特征值 求 $\\pmb{A}$ 的特征值即为求 $\\pmb{A}$ 的特征方程的根 矩阵谱半径定义 设 $\\pmb{A} \\in \\mathbf{R}^{n \\times n}$，$\\pmb{A}$ 的特征值 $\\lambda_1,\\lambda_2,\\cdots,\\lambda_n$，则有： $\\pmb{A}$ 的全体特征值 $\\left \\{ \\lambda_1,\\lambda_2,\\cdots,\\lambda_n \\right \\}$ 称为 $\\pmb{A}$ 的谱 这些特征值的模的最大值 $\\max\\limits_{1\\leqslant i\\leqslant n}\\left| \\lambda_i \\right|$ 称为 $\\pmb{A}$ 的谱半径，记为 $\\rho(A)$，即 \\rho(A) = \\max\\limits_{1\\leqslant i\\leqslant n}\\left| \\lambda_i \\right|矩阵特征值性质 若 $\\pmb{A} \\in \\mathbf{R}^{n \\times n}$ 是对称矩阵，则 $\\pmb{A}$ 的特征值均为实数，且有 $n$ 个线性无关的特征向量 $\\pmb{A} \\in \\mathbf{R}^{n \\times n}$ 对称正定的充要条件是 $\\pmb{A}$ 的所有特征值 $\\lambda_i &gt; 0$，$(i=1,2,\\cdots,n)$ 若 $\\lambda_1,\\lambda_2,\\cdots,\\lambda_m$ 是矩阵 $\\pmb{A}$ 的单重特征值，$\\pmb{x}_1,\\pmb{x}_2,\\cdots,\\pmb{x}_m$ 依次是相应的特征向量，则 $\\pmb{x}_1,\\pmb{x}_2,\\cdots,\\pmb{x}_m$ 线性无关 相似矩阵有相同的特征多项式，因而也有相同的特征值 1.7 线性空间概要1.7.1 线性空间 $\\pmb{R}^n$：$n$ 维实向量的全体 $\\pmb{R}^{n \\times m}$：$n$ 行 $m$ 列实矩阵的全体 $C[a,b]$：定义在区间 $[a,b]$ 上连续实值函数的全体 $P_n[a,b]$：定义在区间 $[a,b]$ 上次数 $\\leqslant n$ 的实系数多项式全体 $C^n[a,b]$：定义在区间 $[a,b]$ 上的具有连续 $n$ 阶导数的实值函数全体 线性相关 对数域 $K$ 上的线性空间 $X$，有 $u_1, u_2, \\cdots, u_n \\in X$，若存在不全为零的数 $\\alpha_1, \\alpha_2, \\cdots, \\alpha_n \\in K$，使得下列等式成立： \\alpha_1 u_1 + \\alpha_2 u_2 + \\cdots + \\alpha_n u_n = 0则称 $u_1, u_2, \\cdots, u_n$ 是线性相关的，否则，等式只对 $\\alpha_1 = \\alpha_2 = \\cdots = \\alpha_n = 0$ 才能成立，则称 $u_1, u_2, \\cdots, u_n$ 是线性无关的。 基、维数、坐标 称 $S$ 是由线性空间 $X$ 中的 $n$ 个线性无关元素 $u_1, u_2, \\cdots, u_n \\in X$生成的，即 $\\forall s \\in S$，都有： s = \\alpha_1 u_1 + \\alpha_2 u_2 + \\cdots + \\alpha_n u_n 记 $S = Span \\left \\{ u_1, u_2, \\cdots, u_n \\right \\}$ 称 $u_1, u_2, \\cdots, u_n$ 是 $S$ 的一组基 称 $S$ 是 $n$ 维的 系数 $\\alpha_1, \\alpha_2, \\cdots, \\alpha_n$ 称为 $S$ 在基 $u_1, u_2, \\cdots, u_n$ 下的坐标，并记为 $(\\alpha_1, \\alpha_2, \\cdots, \\alpha_n)$ 1.7.2 范数/赋范线性空间设 $X$ 是数域 $K$ 上的线性空间，若 $\\forall u \\in X$，存在唯一的实数 \\| \\cdot \\|，满足条件： 正定性：\\| u \\| \\geqslant 0，其中 \\| u \\| = 0 当且仅当 $u = 0$ 齐次性：\\| \\alpha u \\| = | \\alpha | \\| u \\|, \\forall \\alpha \\in K 三角不等式：\\| u + v \\| \\leqslant \\| u \\| + \\| v \\| 则称 \\| \\cdot \\| 为线性空间 $X$ 上的范数，并且称 $X$ 为赋范线性空间，仍记为 $X$ 对于连续函数空间 $C[a,b]$，可以定义 $f \\in C[a,b]$ 的如下两种范数： $\\infty$-范数：\\| f \\|_{\\infty} = \\max \\limits_{a \\leqslant x \\leqslant b} |f(x)| $1$ - 范数：\\| f \\|_1 = \\int_{a}^{b} |f(x)|dx 以及稍后在内积空间中还要定义： $2$ - 范数：\\| f \\|_2 = \\left [ \\int_a^b{f^2 (x) dx} \\right ]^{\\frac{1}{2}} 1.7.3 内积/内积空间内积：线性空间 $\\pmb{R}^n$ 中，任意两个向量 $\\pmb{x},\\pmb{y}$ 的数量积，记为 $(\\pmb{x},\\pmb{y})$： \\begin{aligned} (\\pmb{x},\\pmb{y}) &= x_1y_1 + x_2y_2 + \\cdots + x_ny_n \\\\ &= \\sum \\limits_{i=1}^n x_iy_i \\\\ &= \\pmb{x}^T \\pmb{y} \\end{aligned}内积空间：设 $X$ 是数域 $K$（如实数域 $\\pmb{R}$ 或复数域 $\\pmb{C}$）上的线性空间，若对 $\\forall u,v \\in X$，有 $K$ 中一个数与之对应，记为 $(u,v)$，且满足条件： $(u,u) \\geqslant 0$，其中 $(u,u) = 0 \\Leftrightarrow u = 0$ $(u,v) = \\overline{(v,u)}$，$\\overline{(v,u)}$ 为 $(v,u)$ 的共轭 $(\\alpha u,v)=\\alpha(u,v), \\alpha \\in K$ $(u + v, \\omega) = (u,\\omega) + (v,\\omega),\\omega \\in X$ 则 $(u,v)$ 称为 $u$ 与 $v$ 的内积，定义了内积的线性空间 $X$ 称为 内积空间 正交：设 $X$ 为内积空间，若对任意的 $u,v \\in X$，有： (u,v) = 0则称 $u$ 与 $v$ 正交。 1.9 向量范数/矩阵范数1.9.1 向量范数设向量 $\\pmb{x} \\in \\pmb{R}^n$，若与 $\\pmb{x}$ 对应的一个实值函数 \\| \\pmb{x} \\| 满足： 正定性：\\| \\pmb{x} \\geqslant 0 \\|，其中 \\| \\pmb{x} \\|=0 当且仅当 $\\pmb{x}=0$ 齐次性：\\| \\alpha \\pmb{x} \\| = |\\alpha| \\| \\pmb{x} \\|,\\forall \\alpha \\in \\pmb{R} 三角不等式：\\| \\pmb{x} + \\pmb{y} \\| \\leqslant \\| \\pmb{x} \\| + \\| \\pmb{y} \\|, \\forall \\pmb{x},\\pmb{y} \\in \\pmb{R}^n 则称 \\| \\pmb{x} \\| 为 $\\pmb{R}^n$ 上 $\\pmb{x}$ 的一个向量范数。 3 种常用的向量范数 $1$ - 范数：\\| \\pmb{x} \\|_1 = \\sum \\limits_{i=1}^n| \\pmb{x}_i | $\\infty$-范数：\\| \\pmb{x} \\|_{\\infty} = \\max \\limits_{1 \\leqslant i \\leqslant n} |x_i| $2$ - 范数：\\| \\pmb{x} \\|_2 = \\sqrt{\\sum \\limits_{i=1}^n \\pmb{x}_i^2 } 或一般地定义 $p$ - 范数：\\| \\pmb{x} \\|_p = (\\sum \\limits_{i=1}^n|x_i|^p)^{\\frac{1}{p}},\\forall p \\in [1,+ \\infty) 向量范数基本性质 连续性：设 $\\pmb{x} = (x_1,x_2,\\cdots,x_n)^T \\in \\pmb{R}^n$，其范数 \\|\\pmb{x}\\| 是 $\\pmb{x}$ 的分量 $x_1,x_2,\\cdots,x_n$ 的 $n$ 元连续函数 等价性：设 \\|\\pmb{x}\\|_r 和 \\|\\pmb{x}\\|_s 为 $ \\pmb{R}^n$ 上任意两种范数，则存在常数 $m,M&gt;0$，使得： m \\|\\pmb{x}\\|_r \\leqslant \\|\\pmb{x}\\|_s \\leqslant M \\|\\pmb{x}\\|_r, \\quad \\forall \\pmb{x} \\in \\pmb{R}^n 按范数收敛性：设向量序列 $\\left\\{ \\pmb{x}^{(k)} \\right\\}$ 收敛于向量 \\pmb{x}^{*}，即 \\lim \\limits_{k \\to \\infty} \\pmb{x}^{(k)} = \\pmb{x}^{*}，则等价于： \\lim \\limits_{k \\to \\infty} \\| \\pmb{x}^{(k)} - \\pmb{x}^{*} \\| = 0 其中，\\| \\cdot \\| 为向量的任一种范数，并称向量序列 $\\left\\{ \\pmb{x}^{(k)} \\right\\}$ 按该函数收敛于向量 $\\pmb{x}^*$。 1.9.2 矩阵范数设矩阵 $\\pmb{A} \\in \\pmb{R}^{n \\times n}$，若与 $\\pmb{A}$ 对应的一个实值函数 \\| A \\| 满足： 正定性：\\| \\pmb{A} \\| \\geqslant 0，其中 \\| \\pmb{A} \\| = 0 \\Leftrightarrow \\pmb{A} = 0 齐次性：\\| \\alpha \\pmb{A} \\| = |\\alpha| \\|\\pmb{A}\\|, \\forall \\alpha \\in \\pmb{R} 三角不等式：\\| \\pmb{A} + \\pmb{B} \\| \\leqslant \\| \\pmb{A} \\| + \\| \\pmb{B} \\|, \\forall \\pmb{A},\\pmb{B} \\in \\pmb{R}^{n \\times n} 相容性：\\| \\pmb{A} \\pmb{B} \\| \\leqslant \\| \\pmb{A} \\| \\| \\pmb{B} \\|, \\forall \\pmb{A},\\pmb{B} \\in \\pmb{R}^{n \\times n} 则称 \\| \\pmb{A} \\| 为 $\\pmb{R}^{n \\times n}$ 上 $\\pmb{A}$ 的一个矩阵范数。 几种常用的矩阵范数 $F$ 范数（$Frobenius$）：\\| \\pmb{A} \\|_F = [\\sum \\limits_{i=1}^n(\\sum \\limits_{j=1}^n a_{ij}^2)]^{\\frac{1}{2}} 行范数：\\| \\pmb{A} \\|_{\\infty} = \\max \\limits_{1 \\leqslant i \\leqslant n} \\sum \\limits_{j=1}^n | a_{ij} | 列范数：\\| \\pmb{A} \\|_{1} = \\max \\limits_{1 \\leqslant j \\leqslant n} \\sum \\limits_{i=1}^n | a_{ij} | $2$-范数：\\| \\pmb{A} \\|_{2} = \\sqrt{\\rho (\\pmb{A}^T\\pmb{A})}，其中 $\\rho (\\pmb{A}^T\\pmb{A})$ 为 $\\pmb{A}^T\\pmb{A}$ 的谱半径 当 $\\pmb{A}$ 是对称矩阵时，有： \\begin{aligned} \\| \\pmb{A} \\|_{2} = \\sqrt{\\rho (\\pmb{A}^T\\pmb{A})} &= \\sqrt{\\lambda_{\\max} (\\pmb{A}^T\\pmb{A})} \\\\ &= \\sqrt{\\lambda_{\\max} (\\pmb{A}^2)} \\\\ &= \\sqrt{\\lambda_{\\max}^2 (\\pmb{A})} \\\\ &= \\rho (\\pmb{A}) \\end{aligned} 参考文章 向量范数和矩阵范数 | 博客园 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/categories/数学/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"数值分析","slug":"数值分析","permalink":"https://abelsu7.top/tags/数值分析/"}]},{"title":"在 Hexo 中使用 MathJax 渲染数学公式","slug":"hexo-mathjax","date":"2018-10-29T11:58:35.000Z","updated":"2019-09-01T13:04:11.285Z","comments":true,"path":"2018/10/29/hexo-mathjax/","link":"","permalink":"https://abelsu7.top/2018/10/29/hexo-mathjax/","excerpt":"最近在复习万恶的数值分析，原本手抄的公式笔记阅读起来不太方便，打算用 MathJax 重写公式再整理到 Hexo 博客上。奇怪的是，公式在本地 Typora 上渲染的完全 OK，搬 Hexo 上咋就出问题了？（重启喝水都试过了）","text":"最近在复习万恶的数值分析，原本手抄的公式笔记阅读起来不太方便，打算用 MathJax 重写公式再整理到 Hexo 博客上。奇怪的是，公式在本地 Typora 上渲染的完全 OK，搬 Hexo 上咋就出问题了？（重启喝水都试过了） 例如e_r(x^{*})=\\frac{x-x^*}{x^*}，讲道理它应该长成下面的样子： e_r(x^{*})=\\frac{x-x^*}{x^*}然而实际上它是这个样子：$e_r(x^{})=\\frac{x-x^}{x^*}$ 又或者f_n=f_{n-1}+f_{n-2}，讲道理它应该生的和下边一样俊俏： f_n=f_{n-1}+f_{n-2}然而也不幸长残了：$f_n=f_{n-1}+f_{n-2}$ What are you 弄啥嘞?😡 注：针对两个单独的_的语义冲突已在后文中修复，因此上面的行内公式显示正常。未修复之前，Markdown 渲染器仍然会将两个单独的_之间的内容渲染为&lt;em&gt;标签，显示效果为：$fn=f{n-1}+f_{n-2}$ 问题分析不难发现，上边既然有成功的渲染，就说明 MathJax 本身没有罢工。而且，仔细观察还会发现，第一个公式中最开始两个*中间的字体变成了斜体；第二个公式中最开始两个_也是同样的情况。审查元素发现，第一个公式中的斜体部分被渲染成了&lt;em&gt;标签： &lt;em&gt;})=\\frac{x-x^&lt;/em&gt; 这样来看答案就很清楚了：这个错误是由 Markdown 渲染器（默认的是 hexo-renderer-marked ）引起的。Markdown 本身并不支持 Latex，在渲染时正则匹配到两个_或*就会把下划线替换成了&lt;em&gt;，于是到了 MathJax 渲染公式时就彻底懵了。 解决办法也很简单：使用 hexo-renderer-kramed 替换 Hexo 默认的渲染器 hexo-renderer-marked。 替换默认渲染引擎hexo-renderer-kramed 是 hexo-renderer-marked 的 Fork 修改版，仅针对 MathJax 渲染的语义冲突问题进行了修改，因此可以放心使用。在 Hexo 根目录下执行以下命令替换默认渲染引擎： npm uninstall hexo-renderer-marked --save npm install hexo-renderer-kramed --save 更换渲染引擎后，整行公式就可以正常显示了，然而行内公式还是会遇到&lt;em&gt;标签语义冲突的问题。在 Markdown 语法中，用$$包括起来的内容表示整行公式，用$包括起来的内容表示行内公式。之所以行内公式的渲染依然存在问题，是因为 hexo-renderer-kramed 引擎同样存在语义冲突的问题。 解决语义冲突在博客根目录下，找到node_modules/kramed/lib/rules/inline.js文件，在inline变量中做出如下修改： var inline = { // escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_&gt;])/, 第 11 行, 将其修改为 escape: /^\\\\([`*\\[\\]()#$+\\-.!_&gt;])/, autolink: /^&lt;([^ &gt;]+(@|:\\/)[^ &gt;]+)&gt;/, url: noop, html: /^&lt;!--[\\s\\S]*?--&gt;|^&lt;(\\w+(?!:\\/|[^\\w\\s@]*@)\\b)*?(?:&quot;[^&quot;]*&quot;|&#39;[^&#39;]*&#39;|[^&#39;&quot;&gt;])*?&gt;([\\s\\S]*?)?&lt;\\/\\1&gt;|^&lt;(\\w+(?!:\\/|[^\\w\\s@]*@)\\b)(?:&quot;[^&quot;]*&quot;|&#39;[^&#39;]*&#39;|[^&#39;&quot;&gt;])*?&gt;/, link: /^!?\\[(inside)\\]\\(href\\)/, reflink: /^!?\\[(inside)\\]\\s*\\[([^\\]]*)\\]/, nolink: /^!?\\[((?:\\[[^\\]]*\\]|[^\\[\\]])*)\\]/, reffn: /^!?\\[\\^(inside)\\]/, strong: /^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/, // em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 第 20 行，将其修改为 em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, code: /^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/, br: /^ {2,}\\n(?!\\s*$)/, del: noop, text: /^[\\s\\S]+?(?=[\\\\&lt;!\\[_*`$]| {2,}\\n|$)/, math: /^\\$\\$\\s*([\\s\\S]*?[^\\$])\\s*\\$\\$(?!\\$)/, }; 第 11 行的修改去掉了\\\\和{}，目的是在原基础上去掉对\\、{、}的转义 (escape)。 第 20 行的修改去掉了\\b_((?:__|[\\s\\S])+?)_\\b，目的是去掉对两个_之间内容的&lt;em&gt;标签转义。 也就是说，依然可以在 Hexo 中使用*表示斜体，但用_表示_斜体_就不会生效了。 另外在行内公式中，针对两个*的语义冲突依旧存在，目前来看没什么比较好的解决办法（摊手）。 按需加载 MathJaxhexo-theme-indigo 默认集成了 MathJax，然而只在主题配置文件中定义了 MathJax 的开关。这样就会造成一个问题： 只要theme.mathjax为true，所有文章页面都会引入 MathJax.js，在不需要使用 MathJax 的页面中会带来毫无必要的时间和资源开销。 因此需要修改主题模板文件，使其按需加载 MathJax.js。 还是以 hexo-theme-indigo 为例，首先在主题配置文件theme/_config.yaml中，将MathJax设置为true： mathjax: true 随后修改主题模板文件中的判定条件。以 hexo-theme-indigo 为例，其判定是否引入MathJax.js的代码在layout/_partial/plugins/mathjax.ejs文件中： &lt;% if (theme.mathjax){ %&gt; &lt;!-- mathjax config similar to math.stackexchange --&gt; &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&quot;\\\\(&quot;,&quot;\\\\)&quot;] ], processEscapes: true, skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;, &#39;code&#39;] } }); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i &lt; all.length; i += 1) { all[i].SourceElement().parentNode.className += &#39; has-jax&#39;; } }); &lt;/script&gt; &lt;script async src=&quot;//cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&quot; async&gt;&lt;/script&gt; &lt;% } %&gt; 显然，只需修改第一行的判定条件为双重判定： &lt;% if ( theme.mathjax &amp;&amp; page.mathjax ){ %&gt; 最后在需要使用 MathJax 文章的 Front-matter 中，将Mathjax设置为true，即可在该页面中引入 MathJax.js 而不影响其他页面： --- title: 测试Mathjax category: - 前端 tags: - Hexo - MathJax date: 2018-10-29 19:58:35 mathjax: true --- 这里还有一个小问题：博客的首页也可能会调用 MathJax.js 渲染公式，而按照以上设置，非文章页面是不会引入 MathJax.js 的。这里给出两种解决办法： 合理设置&lt;!-- more --&gt;标签位置，确保首页不会展示公式。 修改mathjax.ejs的判定条件如下，首页同样引入 MathJax.js： &lt;% if ( theme.mathjax &amp;&amp; ( page.mathjax || is_home() ) ){ %&gt; 问题解决~最后来测试一下😎 \\mathop{x} \\limits_a^b e_r( x^{*} ) = \\frac{x-x^*}{x^*} a_x+b_x=c_x f(n)=\\begin{cases} n/2, & \\text{如果$ x \\leqslant 2 $}\\\\ 3n+1, & \\text{如果$ x>2 $} \\end{cases} e\\left ( x^{*} \\right ) = x - x^{*} R{m \\times n} = U{m \\times m} S{m \\times n} V{n \\times n}’ e\\left ( x^{*} \\right ) = x - x^{*}x = a_0 + \\frac{1}{a_1 +\\sqrt{a^2+b^2} \\frac{1}{a_2 + \\frac{1}{a_3 + a_4}}}\\sqrt{a^2+b^2} \\min_{\\mathbf{w},b} \\frac{1}{2} \\Vert \\mathbf{w} \\Vert^2 \\quad s.t. \\quad y_i(\\mathbf{w}^T\\phi(\\mathbf{x})+b) \\geq 1, \\quad i=1,2,...,m\\qquad(9)e_r(x^*)=\\frac{e(x^*)}{x}=\\frac{x-x^*}{x}\\left| e \\right|=\\left | x-x^* \\right |\\leq \\varepsilon 参考文章 常用数学符号的 LaTex 表示方法 一份不太简短的 LaTex 2 介绍.pdf Online LaTex Equation Editor | CODECOGS 在 Hexo 中渲染 MathJax 数学公式 | 码迷 Hexo 博客 MathJax 公式渲染问题 | 博客园 Hexo 博客 MathJax 公式渲染问题 | 衡仔的技术小窝 如何处理 Hexo 和 MathJax 的兼容问题 | 林肯先生的 Blog 在 Hexo 中渲染 MathJax 数学公式 | 简书 在 Hexo 博客中使用 MathJax 写 LaTex 数学公式 | CSDN Hexo 中插入数学公式 | Steven’s Space 前端整合 MathjaxJS 配置笔记 | 博客园 hexo-renderer-kramed | Github hexo-renderer-marked | Github MathJax.org The LaTex project 🚩推荐阅读（由hexo文章推荐插件驱动）Hexo 实现自定义文章置顶利用 Valine 搭建 Hexo 无后端评论系统解决 RSS 报错：Input is not proper UTF-8, indicate encodingHexo 博客安装 RSS 插件Hexo博客文末添加网站地图Hexo博客文末添加网站地图","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://abelsu7.top/tags/Hexo/"},{"name":"MathJax","slug":"MathJax","permalink":"https://abelsu7.top/tags/MathJax/"},{"name":"LaTex","slug":"LaTex","permalink":"https://abelsu7.top/tags/LaTex/"},{"name":"数学","slug":"数学","permalink":"https://abelsu7.top/tags/数学/"}]},{"title":"Ubuntu 18.04 使用 Netplan 配置网络","slug":"ubuntu-1804-netplan","date":"2018-10-29T03:29:08.000Z","updated":"2019-09-01T13:04:11.752Z","comments":true,"path":"2018/10/29/ubuntu-1804-netplan/","link":"","permalink":"https://abelsu7.top/2018/10/29/ubuntu-1804-netplan/","excerpt":"Updating…","text":"Updating… 参考文章 如何在 Ubuntu 18.04 下正确配置网络 | 技术啦 Ubuntu 18.04 修改 IP 地址 | CSDN Ubuntu 配置静态 IP 与 动态 IP | CSDN Ubuntu 18.04 网络图标不见的问题解决方案 | CSDN Ubuntu 18.04 网卡配置 IP | CSDN ubuntu18.04 server配置静态ip，新的网络工具netplan的使用方法 | Ubutnu Forum Netplan Reference | Netplan.io 🚩推荐阅读（由hexo文章推荐插件驱动）解决 Ubuntu apt-get install 错误：未满足的依赖关系Ubuntu 18.04 配置阿里云 OPSX APT 安装源Ubuntu 18.04 安装 Nvidia 显卡驱动【译】使用 Apache Guacamole 连接虚拟云桌面虚拟机 VMware 中安装 Ubuntu 操作系统虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Netplan","slug":"Netplan","permalink":"https://abelsu7.top/tags/Netplan/"}]},{"title":"Java 语言推荐书单","slug":"java-book-list","date":"2018-10-26T07:34:05.000Z","updated":"2019-09-01T13:04:11.406Z","comments":true,"path":"2018/10/26/java-book-list/","link":"","permalink":"https://abelsu7.top/2018/10/26/java-book-list/","excerpt":"点击查看我的豆列 Java 语言学习推荐书单，欢迎留言补充。 Write Once, Run Anywhere. Java 作为目前全球最流行的高级语言，在 TIOBE 常年霸榜。Write Once, Run Anywhere. 下面推荐几本 Java 语言的经典著作，学海无涯，与君共勉。","text":"点击查看我的豆列 Java 语言学习推荐书单，欢迎留言补充。 Write Once, Run Anywhere. Java 作为目前全球最流行的高级语言，在 TIOBE 常年霸榜。Write Once, Run Anywhere. 下面推荐几本 Java 语言的经典著作，学海无涯，与君共勉。 Head First Java 《Head First Java》 作者 出版社 出版时间 豆瓣评分 [美]Kathy Sierra / [美]Bert Bates 中国电力出版社 2007-2 8.7 Head First 系列，轻松入门 Java。豆瓣传送门 Java 核心技术·卷 1：基础知识 《Core Java Volume Ⅰ——Fundamentals》 作者 出版社 出版时间 豆瓣评分 [美]Cay S. Horstmann / [美]Gary Cornell 机械工业出版社 2013-11 8.3 经典著作《Core Java》基础篇。豆瓣传送门 Java 核心技术·卷 2：高级特性 《Core Java Volume Ⅱ——Advanced Features》 作者 出版社 出版时间 豆瓣评分 [美]Cay S. Horstmann / [美]Gary Cornell 机械工业出版社 2014-3 8.5 经典著作《Core Java》进阶篇。豆瓣传送门 Java 语言程序设计：基础篇 《Introduction to Java Programming》 作者 出版社 出版时间 豆瓣评分 [美]Y.Daniel Liang (梁勇) 机械工业出版社 2011-6 8.7 Java入门基础篇，大学教材，相比而言更加推荐《Core Java》系列。豆瓣传送门 Java 语言程序设计：进阶篇 《Introduction to Java Programming》 作者 出版社 出版时间 豆瓣评分 [美]Y.Daniel Liang (梁勇) 机械工业出版社 2011-6 8.2 Java入门进阶篇，大学教材，相比而言更加推荐《Core Java》系列。豆瓣传送门 数据结构与算法分析：Java 语言描述 《Data Structures and Algorithm Analysis in Java》 作者 出版社 出版时间 豆瓣评分 [美]Mark Allen Weiss 机械工业出版社 2009-1 8.6 最好的 Java 数据结构与算法分析入门教程，兼顾广度和深度。豆瓣传送门 深入理解 Java 虚拟机 《深入理解 Java 虚拟机（第 2 版）》 作者 出版社 出版时间 豆瓣评分 周志明 机械工业出版社 2013-9 8.9 Java 进阶必看，可能是最好的 JVM 中文书籍之一。豆瓣传送门 Effective Java 《Effective Java》 作者 出版社 出版时间 豆瓣评分 [美]Joshua Bloch 机械工业出版社 2009-1 9.0 经典进阶著作，有条件的推荐去看英文原版。豆瓣传送门 Java 编程思想 《Thinking in Java》 作者 出版社 出版时间 豆瓣评分 [美]Bruce Eckel 机械工业出版社 2007-6 9.1 与《Core Java》齐名的《Thinking in Java》。需要具备一定的 Java 基础，Java 进阶必备。豆瓣传送门 Java 并发编程之美 《Java 并发编程之美》 作者 出版社 出版时间 豆瓣评分 翟陆续 (加多) / 薛宾田 电子工业出版社 2018-11 暂无 深度剖析 Java 并发编程原理。作者加多，淘宝高级开发。豆瓣传送门 Java 并发编程实战 《Java Concurrency in Practice》 作者 出版社 出版时间 豆瓣评分 [美]Brian Goetz / [美]Tim Peierls 等 机械工业出版社 2012-2 9.0 Java 并发编程必读，条理清晰，偏工程实践性质。豆瓣传送门 🚩推荐阅读（由hexo文章推荐插件驱动）Python 速查C++ 速查Linux 内核笔记 1：绪论Java 笔记 5：集合后端开发 - Java开发环境配置 - 入门篇技术博客的重要性","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"编程","slug":"编程","permalink":"https://abelsu7.top/tags/编程/"},{"name":"学习","slug":"学习","permalink":"https://abelsu7.top/tags/学习/"}]},{"title":"C 语言推荐书单","slug":"c-book-list","date":"2018-10-25T12:48:10.000Z","updated":"2019-09-01T13:04:10.998Z","comments":true,"path":"2018/10/25/c-book-list/","link":"","permalink":"https://abelsu7.top/2018/10/25/c-book-list/","excerpt":"点击查看我的豆列 C 语言学习推荐书单，欢迎留言补充。 Dennis Ritchie Steve Jobs 和 Dennis Ritchie 是在同年同月离世的。之后每年的这段时间，很多媒体都会纪念 Jobs，但很少会提到 Dennis Ritchie。 如果没有丹尼斯·里奇( Dennis Ritchie )，就不会有我们现在所熟知的现代计算。他是 C 语言之父和 UNIX 操作系统的联合发明人。 C 语言是里奇在 1969-1973 年间开发的，他被认为是第一个真正意义上可移植的现代编程语言。自它诞生差不多 45 年以来，它已经被移植到几乎每一个出现过的系统架构和操作系统上。 另外，现在常年霸占 TIOBE 榜单前三甲的正是Java、C、C++这三种语言。除了 C 语言本身以外，另外两种语言 Java 和 C++ 正是在 C 语言的基础之上发展而来。因此对于现代软件工程师而言，学好 C 语言是非常重要的。下面推荐几本 C 语言的经典著作，学海无涯，与君共勉。","text":"点击查看我的豆列 C 语言学习推荐书单，欢迎留言补充。 Dennis Ritchie Steve Jobs 和 Dennis Ritchie 是在同年同月离世的。之后每年的这段时间，很多媒体都会纪念 Jobs，但很少会提到 Dennis Ritchie。 如果没有丹尼斯·里奇( Dennis Ritchie )，就不会有我们现在所熟知的现代计算。他是 C 语言之父和 UNIX 操作系统的联合发明人。 C 语言是里奇在 1969-1973 年间开发的，他被认为是第一个真正意义上可移植的现代编程语言。自它诞生差不多 45 年以来，它已经被移植到几乎每一个出现过的系统架构和操作系统上。 另外，现在常年霸占 TIOBE 榜单前三甲的正是Java、C、C++这三种语言。除了 C 语言本身以外，另外两种语言 Java 和 C++ 正是在 C 语言的基础之上发展而来。因此对于现代软件工程师而言，学好 C 语言是非常重要的。下面推荐几本 C 语言的经典著作，学海无涯，与君共勉。 C 程序设计语言 《The C Programming Language》 作者 出版社 出版时间 豆瓣评分 [美]Brian W. Kernighan / [美]Dennis M. Ritchie 机械工业出版社 2004-1 9.4 C 语言设计者的权威经典著作，K&amp;R C。最后包括 C 语言参考手册及标准库的详细介绍，推荐配合习题解答同步学习。豆瓣传送门 明解 C 语言 《明解 C 语言》 作者 出版社 出版时间 豆瓣评分 [日]柴田望洋 人民邮电出版社 2013-5 8.8 对于初学编程的非 CS 专业的读者而言，会是本不错的入门书。豆瓣传送门 数据结构与算法分析：C 语言描述 《Data Structures and Algorithm Analysis in C》 作者 出版社 出版时间 豆瓣评分 [美]Mark Allen Weiss 机械工业出版社 2004-1 8.9 数据结构与算法入门经典。豆瓣传送门 C 和指针 《Pointers on C》 作者 出版社 出版时间 豆瓣评分 [美]Kenneth A·Reek 人民邮电出版社 2008-4 9.0 C 语言进阶三部曲之一。深入理解 C 指针的运作原理，全面而不失细致。豆瓣传送门 C 专家编程 《Expert C Programming: Deep C Secrets》 作者 出版社 出版时间 豆瓣评分 [荷]Peter van der Linden 人民邮电出版社 2008-2 9.2 C 语言进阶三部曲之一。讲解 C 编程的高级技巧，并简单介绍 C++ 的特性。豆瓣传送门 C 陷阱与缺陷 《C Traps and Pitfalls》 作者 出版社 出版时间 豆瓣评分 [美]Andrew Koenig 人民邮电出版社 2008-2 8.9 C 语言进阶三部曲之一。出版于 ANSI C 规范制定之前，因此某些书中提到的缺陷已经不复存在了。豆瓣传送门 🚩推荐阅读（由hexo文章推荐插件驱动）使用 GNU Global 在 VS Code 中阅读内核源码Python 速查C++ 速查Linux 内核笔记 1：绪论归并排序(递归)快速排序(递归)","categories":[{"name":"C/C++","slug":"C-C","permalink":"https://abelsu7.top/categories/C-C/"}],"tags":[{"name":"C","slug":"C","permalink":"https://abelsu7.top/tags/C/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"编程","slug":"编程","permalink":"https://abelsu7.top/tags/编程/"},{"name":"学习","slug":"学习","permalink":"https://abelsu7.top/tags/学习/"}]},{"title":"《The C Programming Language》读书笔记","slug":"c-notes","date":"2018-10-24T13:55:23.000Z","updated":"2019-09-01T13:04:11.004Z","comments":true,"path":"2018/10/24/c-notes/","link":"","permalink":"https://abelsu7.top/2018/10/24/c-notes/","excerpt":"Updating…温故而知新，可以为师矣。 《The C Programming Language》","text":"Updating…温故而知新，可以为师矣。 《The C Programming Language》 引言 C 语言是在 UNIX 系统上开发的 无论是 UNIX 系统本身还是其上运行的大部分程序，都是用 C 语言编写的 除了由函数局部变量提供的静态定义和堆栈外，C 语言没有定义任何存储器分配工具，也不提供堆和无用内存回收工具 C 语言本身没有提供输入/输出功能，没有READ或WRITE语句，也没有内置的文件访问方法 C 语言只提供简单的单线程控制流，不提供多道程序设计、并行操作、同步和协同例程 1983 年，美国国家标准协会（ANSI）成立了一个委员会以制定一个现代的、全面的 C 语言定义，最后的结果就是 1988 年完成的 ANSI 标准，即ANSI C 第 1 章 导言符号常量#define指令可以把符号名（或称为符号常量）定义为一个特定的字符串： #include &lt;stdio.h&gt; #define LOWER 0 /* 表的下限 */ #define UPPER 300 /* 表的上限 */ #define STEP 20 /* 步长 */ EOF定义在头文件&lt;stdio.h&gt;中，是一个整型数。其具体数值是什么并不重要，只要它与任何char类型的值都不相同即可。 传值调用在 C 语言中，传递给被调用函数的参数值存放在临时变量中，而不是存放在原来的变量中。被调用函数不能直接修改主调函数中变量的值，而只能修改其私有的临时副本的值。 字符数组getline函数把字符\\0（即空字符，其值为 0 ）插入到它创建的数组的末尾，以标记字符串的结束。这一约定已被 C 语言采用：当在 C 语言程序中出现类似于&quot;hello\\n&quot;的字符串常量时，它将以字符数组的形式存储。 h e l l 0 \\n \\0 换行符 空字符 外部变量与作用域除自动变量外，还可以定义位于所有函数外部的变量。 外部变量必须定义在所有函数之外，且只能定义一次，定义后编译程序将为它分配存储单元。在每个需要访问外部变量的函数中，必须声明相应的外部变量，此时说明其类型。声明时可以用extern语句显式声明。 #include &lt;stdio.h&gt; #define MAXLINE 1000 int max; char line[MAXLINE]; char longest[MAXLINE]; int getline(void); void copy(void); main() { int len; extern int max; extern char longest[]; ... } 某些情况下可以省略extern声明：在源文件中，如果外部变量的定义出现在使用它的函数之前，那么在那个函数中就没有必要使用extern声明。 第 2 章 类型、运算符与表达式变量名 名字是由字母和数字组成的序列，但其第一个字符必须为字母 由于库例程的名字通常以_开头，因此变量名不要以_开头 在传统 C 语言用法中，变量名使用小写字母，符号常量全部使用大写字母 数据类型及长度 数据类型 说明 char 字符型，占用一个字节，可以存放本地字符集中的一个字符 int 整型，通常反映了所用机器中整数的最自然长度 float 单精度浮点类型 double 双精度浮点类型 short和long两个限定符用于限定整型。short类型通常为 16 位，long类型通常为 32 位，而int类型通常为 16 位或 32 位。 short与int类型至少为 16 位 long类型至少为 32 位 short类型不得长于int类型 int类型不得长于long类型 类型限定符signed与unsigned可用于限定char类型或任何整型。unsigned类型的数总是正值或 0。 例如，如果char对象占用 8 位，那么unsigned char类型变量的取值范围为 0~255，而signed char类型变量的取值范围为 -128~127（在采用对二的补码的机器上）。 🚩推荐阅读（由hexo文章推荐插件驱动）使用 GNU Global 在 VS Code 中阅读内核源码Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志归并排序(递归)快速排序(递归)","categories":[{"name":"C/C++","slug":"C-C","permalink":"https://abelsu7.top/categories/C-C/"}],"tags":[{"name":"C","slug":"C","permalink":"https://abelsu7.top/tags/C/"},{"name":"ANSI","slug":"ANSI","permalink":"https://abelsu7.top/tags/ANSI/"},{"name":"K&R C","slug":"K-R-C","permalink":"https://abelsu7.top/tags/K-R-C/"},{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"}]},{"title":"HTTP 笔记 4：HTTPS 及用户身份认证","slug":"http-notes-part-4","date":"2018-10-23T02:55:39.000Z","updated":"2019-09-01T13:04:11.380Z","comments":true,"path":"2018/10/23/http-notes-part-4/","link":"","permalink":"https://abelsu7.top/2018/10/23/http-notes-part-4/","excerpt":"《图解HTTP》","text":"《图解HTTP》 目录 目录 第 7 章 确保 Web 安全的 HTTPS 7.1 HTTP 的缺点 7.1.1 通信使用明文可能会被窃听 7.1.2 不验证通信方的身份就可能遭遇伪装 7.1.3 无法证明报文完整性，可能已遭篡改 7.2 HTTP + 加密 + 认证 + 完整性保护 = HTTPS 7.2.1 HTTP 加上加密处理和认证以及完整性保护后即是 HTTPS 7.2.2 HTTPS 是身披 SSL 外壳的 HTTP 7.2.3 相互交换密钥的公开密钥加密技术 7.2.4 证明公开密钥正确性的证书 7.2.5 HTTPS 的安全通信机制 第 8 章 确认访问用户身份的认证 8.1 何为认证 8.2 BASIC 认证 8.3 DIGEST 认证 8.4 SSL 客户端认证 8.4.1 SSL 客户端认证的认证步骤 8.4.2 SSL 客户端认证采用双因素认证 8.5 基于表单认证 8.5.1 认证多半为基于表单认证 8.5.2 Session 管理及 Cookie 应用 第 7 章 确保 Web 安全的 HTTPS在 HTTP 协议中有可能存在信息窃听或身份伪装等安全问题。使用 HTTPS 通信机制可以有效地防止这些问题。 7.1 HTTP 的缺点HTTP 主要有这些不足，列举如下， 通信使用明文（不加密），内容可能会被窃听 不验证通信方的身份，因此有可能遭遇伪装 无法证明报文的完整性，所以有可能已遭篡改 这些问题不仅在 HTTP 上出现，其他未加密的协议中也会存在这类问题。 7.1.1 通信使用明文可能会被窃听由于 HTTP 本身不具备加密的功能，所以也无法做到对通信整体（使用 HTTP 协议通信的请求和响应的内容）进行加密。即，HTTP 报文使用明文方式发送。 TCP/IP 是可能被窃听的网络 如果要问为什么通信时不加密是一个缺点，这是因为，按 TCP/IP 协议族的工作机制，通信内容在所有的通信线路上都有可能遭到窥视。 即使已经过加密处理的通信，也会被窥视到通信内容，这点和未加密的通信是相同的。只是说如果通信经过加密，就有可能让人无法破解报文信息的含义，但加密处理后的报文信息本身还是会被看到的。 加密处理防止被窃听 如何防止窃听保护信息的几种对策中，最为普及的就是加密技术。加密的对象可以有这么几个。 通信的加密 一种方式就是将通信加密。HTTP 协议中没有加密机制，但可以通过和 SSL（Secure Socket Layer，安全套接层）或 TLS（Transport Layer Security，安全传输层协议）的组合使用，加密 HTTP 的通信内容。 用 SSL 建立安全通信线路之后，就可以在这条线路上进行 HTTP 通信了。与 SSL 组合使用的 HTTP 被称为 HTTPS（HTTP Secure，超文本传输安全协议）或 HTTP over SSL。 内容的加密 还有一种将参与通信的内容本身加密的方式。由于 HTTP 协议中没有加密机制，那么就对 HTTP 协议传输的内容本身加密。即把 HTTP 报文里所含的内容进行加密处理。 在这种情况下，客户端需要对 HTTP 报文进行加密处理后再发送请求。 对HTTP报文进行加密 诚然，为了做到有效的内容加密，前提是要求客户端和服务器同时具备加密和解密机制。主要应用在 Web 服务中。有一点必须引起注意，由于该方式不同于 SSL 或 TLS 将整个通信线路加密处理，所以内容仍有被篡改的风险。 7.1.2 不验证通信方的身份就可能遭遇伪装HTTP 协议中的请求和响应不会对通信方进行确认。 任何人都可发起请求 在 HTTP 协议通信时，由于不存在确认通信方的处理步骤，任何人都可以发起请求。另外，服务器只要接收到请求，不管对方是谁都会返回一个响应。 • 无法确定请求发送至目标的 Web 服务器是否是按真实意图返回响应的那台服务器。有可能是已伪装的 Web 服务器。• 无法确定响应返回到的客户端是否是按真实意图接收响应的那个客户端。有可能是已伪装的客户端。• 无法确定正在通信的对方是否具备访问权限。因为某些 Web 服务器上保存着重要的信息，只想发给特定用户通信的权限。• 无法判定请求是来自何方、出自谁手。• 即使是无意义的请求也会照单全收。无法阻止海量请求下的 DoS 攻击（Denial of Service，拒绝服务攻击）。 查明对手的证书 虽然使用 HTTP 协议无法确定通信方，但如果使用 SSL 则可以。SSL 不仅提供加密处理，而且还使用了一种被称为证书的手段，可用于确定方。 证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件事。所以只要能够确认通信方（服务器或客户端）持有的证书，即可判断通信方的真实意图。这对使用者个人来讲，也减少了个人信息泄露的危险性。 使用证书以证明通信方就是意料中的服务器 7.1.3 无法证明报文完整性，可能已遭篡改接收到的内容可能有误 由于 HTTP 协议无法证明通信的报文完整性，因此，在请求或响应送出之后直到对方接收之前的这段时间内，即使请求或响应的内容遭到篡改，也没有办法获悉。 像这样，请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击称为中间人攻击（Man-in-the-Middle attack，MITM）。 如何防止篡改 虽然有使用 HTTP 协议确定报文完整性的方法，但事实上并不便捷、可靠。其中常用的是 MD5 和 SHA-1 等散列值校验的方法，以及用来确认文件的数字签名方法。 提供文件下载服务的 Web 网站也会提供相应的以 PGP（Pretty Good Privacy，完美隐私）创建的数字签名及 MD5 算法生成的散列值。PGP 是用来证明创建文件的数字签名，MD5 是由单向函数生成的散列值。不论使用哪一种方法，都需要操纵客户端的用户本人亲自检查验证下载的文件是否就是原来服务器上的文件。浏览器无法自动帮用户检查。 可惜的是，用这些方法也依然无法百分百保证确认结果正确。因为 PGP 和 MD5 本身被改写的话，用户是没有办法意识到的。 7.2 HTTP + 加密 + 认证 + 完整性保护 = HTTPS7.2.1 HTTP 加上加密处理和认证以及完整性保护后即是 HTTPS为了防止通信线路遭到窃听导致数据泄露，需要在 HTTP 上再加入加密处理和认证等机制。我们把添加了加密及认证机制的 HTTP 称为 HTTPS（HTTP Secure）。 7.2.2 HTTPS 是身披 SSL 外壳的 HTTPHTTPS 并非是应用层的一种新协议。只是 HTTP 通信接口部分用 SSL（Secure Socket Layer）和 TLS（Transport Layer Security）协议代替而已。 通常，HTTP 直接和 TCP 通信。当使用 SSL 时，则演变成先和 SSL 通信，再由 SSL 和 TCP 通信了。简言之，所谓 HTTPS，其实就是身披 SSL 协议这层外壳的 HTTP。 HTTP与HTTPS对比 在采用 SSL 后，HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。 SSL 是独立于 HTTP 的协议，所以不光是 HTTP 协议，其他运行在应用层的 SMTP 和 Telnet 等协议均可配合 SSL 协议使用。可以说 SSL 是当今世界上应用最为广泛的网络安全技术。 7.2.3 相互交换密钥的公开密钥加密技术SSL 采用一种叫做公开密钥加密（Public-key cryptography）的加密处理方式。 近代的加密方法中加密算法是公开的，而密钥却是保密的。通过这种方式得以保持加密方法的安全性。 加密和解密都会用到密钥。没有密钥就无法对密码解密，反过来说，任何人只要持有密钥就能解密了。如果密钥被攻击者获得，那加密也就失去了意义。 共享密钥加密的困境 加密和解密同用一个密钥的方式称为共享密钥加密（Common key crypto system），也被叫做对称密钥加密。 以共享密钥方式加密时必须将密钥也发给对方。可究竟怎样才能安全地转交？在互联网上转发密钥时，如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥。 发送密钥就有被窃听的风险，但不发送，对方就不能解密。再说，若密钥能够安全发送，那数据也应该能安全送达。 使用两把密钥的公开密钥加密 公开密钥加密方式很好地解决了共享密钥加密的困难。 公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。 使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。 另外，要想根据密文和公开密钥，恢复到信息原文是异常困难的，因为解密过程就是在对离散对数进行求值，这并非轻而易举就能办到。退一步讲，如果能对一个非常大的整数做到快速地因式分解，那么密码破解还是存在希望的。但就目前的技术来看是不太现实的。 公开密钥加密使用非对称的加密方式 HTTPS 采用混合加密机制 HTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制。若密钥能够实现安全交换，那么有可能会考虑仅使用公开密钥加密来通信。但是公开密钥加密与共享密钥加密相比，其处理速度要慢。 所以应充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。 7.2.4 证明公开密钥正确性的证书遗憾的是，公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。 为了解决上述问题，可以使用由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书。 认证机关的公开密钥必须安全地转交给客户端，然而如何安全转交是一件很困难的事。因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。 使用公开密钥证书证明密钥真实性 可证明组织真实性的 EV SSL 证书 证书的一个作用是用来证明作为通信一方的服务器是否规范，另外一个作用是可确认对方服务器背后运营的企业是否真实存在。拥有该特性的证书就是 EV SSL 证书（Extended Validation SSL Certificate）。 EV SSL 证书是基于国际标准的认证指导方针颁发的证书。其严格规定了对运营组织是否真实的确认方针，因此，通过认证的 Web 网站能够获得更高的认可度。 用以确认客户端的客户端证书 HTTPS 中还可以使用客户端证书。以客户端证书进行客户端认证，证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙。 但客户端证书仍存在几处问题点。其中的一个问题点是证书的获取及发布。 现状是，安全性极高的认证机构可颁发客户端证书但仅用于特殊用途的业务。例如网上银行就采用了客户端证书，在登录网银时不仅要求用户确认输入 ID 和密码，还会要求用户的客户端证书，以确认用户是否从特定的终端访问网银。 7.2.5 HTTPS 的安全通信机制 HTTPS的通信步骤 步骤 1：客户端通过发送Client Hello报文开始 SSL 通信。报文中包含客户端支持的 SSL 的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。 步骤 2：服务器可进行 SSL 通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含 SSL 版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 步骤 3：之后服务器发送Certificate报文。报文中包含公开密钥证书。 步骤 4：最后服务器发送Server Hello Done报文通知客户端，最初阶段的 SSL 握手协商部分结束。 步骤 5：SSL 第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master secret 的随机密码串。该报文已用步骤 3 中的公开密钥进行加密。 步骤 6：接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。 步骤 7：客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 步骤 8：服务器同样发送Change Cipher Spec报文。 步骤 9：服务器同样发送Finished报文。 步骤 10： 服务器和客户端的Finished报文交换完毕之后，SSL 连接就算建立完成。当然，通信会受到 SSL 的保护。从此处开始进行应用层协议的通信，即发送 HTTP 请求。 步骤 11：应用层协议通信，即发送 HTTP 响应。 步骤 12：最后由客户端断开连接。断开连接时，发送close_notify报文，这步之后再发送TCP FIN报文来关闭与 TCP 的通信。 在以上流程中，应用层发送数据时会附加一种叫做 MAC（Message Authentication Code）的报文摘要。MAC 能够查知报文是否遭到篡改，从而保护报文的完整性。 下面是对整个流程的图解。图中说明了从仅使用服务器端的公开密钥证书（服务器证书）建立 HTTPS 通信的整个过程。 HTTPS通信过程 SSL 和 TLS HTTPS 使用 SSL（Secure Socket Layer） 和 TLS（Transport Layer Security）这两个协议。 SSL 技术最初是由浏览器开发商网景通信公司（Netscape）率先倡导的，开发过 SSL3.0 之前的版本。目前主导权已转移到 IETF（Internet Engineering Task Force，Internet 工程任务组）的手中。 IETF 以 SSL3.0 为基准，后又制定了 TLS1.0、TLS1.1 和 TLS1.2。TSL 是以 SSL 为原型开发的协议，有时会统一称该协议为 SSL。当前主流的版本是 SSL3.0 和 TLS1.0。 由于 SSL1.0 协议在设计之初被发现出了问题，就没有实际投入使用。SSL2.0 也被发现存在问题，所以很多浏览器直接废除了该协议版本。 SSL 速度慢吗 HTTPS 也存在一些问题，那就是当使用 SSL 时，它的处理速度会变慢。 SSL 的慢分两种： 通信慢 和使用 HTTP 相比，网络负载可能会变慢 2 到 100 倍。除去和 TCP 连接、发送 HTTP 请求 • 响应以外，还必须进行 SSL 通信，因此整体上处理通信量不可避免会增加。 由于大量消耗 CPU 及内存等资源，导致处理速度变慢 SSL 必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增加。 为什么不一直使用 HTTPS 与纯文本通信相比，加密通信会消耗更多的 CPU 及内存资源。如果每次通信都加密，会消耗相当多的资源，平摊到一台计算机上时，能够处理的请求数量必定也会随之减少。 因此，如果是非敏感信息则使用 HTTP 通信，只有在包含个人信息等敏感数据时，才利用 HTTPS 加密通信。 第 8 章 确认访问用户身份的认证某些 Web 页面只想让特定的人浏览，或者干脆仅本人可见。为达到这个目标，必不可少的就是认证功能。 8.1 何为认证计算机本身无法判断坐在显示器前的使用者的身份。为确认正在访问服务器的对方是否真的具有访问系统的权限，就需要核对登陆者本人才知道、才会有的信息。 核对的信息通常是指以下这些： 密码：只有本人才会知道的字符串信息 动态令牌：仅限本人持有的设备内显示的一次性密码 数字证书：仅限本人（终端）持有的信息 生物认证：指纹和虹膜等本人的生理信息 IC 卡等：仅限本人持有的信息 HTTP 使用的认证方式 HTTP/1.1 使用的认证方式如下所示： BASIC 认证（基本认证） DIGEST 认证（摘要认证） SSL 客户端认证 FormBase 认证（基于表单认证） 8.2 BASIC 认证BASIC 认证（基本认证）是从 HTTP/1.0 就定义的认证方式。即便是现在仍有一部分的网站会使用这种认证方式。是 Web 服务器与通信客户端之间进行的认证方式。 BASIC认证概要 步骤 1：当请求的资源需要 BASIC 认证时，服务器会随状态码401 Authorization Required，返回带WWW-Authenticate首部字段的响应。该字段内包含认证的方式（BASIC） 及Request-URI安全域字符串（realm）。 步骤 2：接收到状态码 401 的客户端为了通过 BASIC 认证，需要将用户 ID 及密码发送给服务器。发送的字符串内容是由用户 ID 和密码构成，两者中间以:连接后，再经过 Base64 编码处理。 步骤 3：接收到包含首部字段Authorization请求的服务器，会对认证信息的正确性进行验证。如验证通过，则返回一条包含Request-URI资源的响应。 BASIC 认证虽然采用 Base64 编码方式，但这不是加密处理。不需要任何附加信息即可对其解码。 另外，除此之外想再进行一次 BASIC 认证时，一般的浏览器却无法实现认证注销操作，这也是问题之一。 BASIC 认证使用上不够便捷灵活，且达不到多数 Web 网站期望的安全性等级，因此它并不常用。 8.3 DIGEST 认证为弥补 BASIC 认证存在的弱点，从 HTTP/1.1 起就有了 DIGEST 认证。 DIGEST 认证同样使用质询 / 响应的方式（challenge/response），但不会像 BASIC 认证那样直接发送明文密码。 所谓质询响应方式是指，一开始一方会先发送认证要求给另一方，接着使用从另一方那接收到的质询码计算生成响应码。最后将响应码返回给对方进行认证的方式。 DIGEST认证概要 步骤 1：请求需认证的资源时，服务器会随着状态码401 Authorization Required，返回带WWW-Authenticate首部字段的响应。该字段内包含质问响应方式认证所需的临时质询码（随机数，nonce）。 步骤 2：接收到 401 状态码的客户端，返回的响应中包含 DIGEST 认证必须的首部字段Authorization信息。首部字段Authorization内必须包含username、realm、nonce、uri 和 response 的字段信息。其中，realm和nonce就是之前从服务器接收到的响应中的字段。 步骤 3： 接收到包含首部字段Authorization请求的服务器，会确认认证信息的正确性。认证通过后则返回包含Request-URI资源的响应，并且会在首部字段Authentication-Info写入一些认证成功的相关信息。 DIGEST 认证提供了高于 BASIC 认证的安全等级，但是和 HTTPS 的客户端认证相比仍旧很弱。DIGEST 认证提供防止密码被窃听的保护机制，但并不存在防止用户伪装的保护机制。 DIGEST 认证和 BASIC 认证一样，使用上不那么便捷灵活，且仍达不到多数 Web 网站对高度安全等级的追求标准。因此它的适用范围也有所受限。 8.4 SSL 客户端认证SSL 客户端认证是借由 HTTPS 的客户端证书完成认证的方式。凭借客户端证书认证，服务器可确认访问是否来自已登录的客户端。 8.4.1 SSL 客户端认证的认证步骤为达到 SSL 客户端认证的目的，需要事先将客户端证书分发给客户端，且客户端必须安装此证书。 步骤 1：接收到需要认证资源的请求，服务器会发送 Certificate Request报文，要求客户端提供客户端证书。 步骤 2：用户选择将发送的客户端证书后，客户端会把客户端证书信息以Client Certificate报文方式发送给服务器。 步骤 3：服务器验证客户端证书验证通过后方可领取证书内客户端的公开密钥，然后开始 HTTPS 加密通信。 8.4.2 SSL 客户端认证采用双因素认证在多数情况下，SSL 客户端认证不会仅依靠证书完成认证，一般会和基于表单认证组合形成一种双因素认证（Two-factor authentication）来使用。 所谓双因素认证就是指，认证过程中不仅需要密码这一个因素，还需要申请认证者提供其他持有信息，从而作为另一个因素，与其组合使用的认证方式。 8.5 基于表单认证基于表单的认证方法并不是在 HTTP 协议中定义的。客户端会向服务器上的 Web 应用程序发送登录信息（Credential），按登录信息的验证结果认证。 8.5.1 认证多半为基于表单认证由于使用上的便利性及安全性问题，HTTP 协议标准提供的 BASIC 认证和 DIGEST 认证几乎不怎么使用。另外，SSL 客户端认证虽然具有高度的安全等级，但因为导入及维持费用等问题，还尚未普及。 不具备共同标准规范的表单认证，在每个 Web 网站上都会有各不相同的实现方式。如果是全面考虑过安全性能而实现的表单认证，那么就能够具备高度的安全等级。但在表单认证的实现中存在问题的 Web 网站也是屡见不鲜。 8.5.2 Session 管理及 Cookie 应用基于表单认证的标准规范尚未有定论，一般会使用 Cookie 来管理 Session（会话）。 基于表单认证本身是通过服务器端的 Web 应用，将客户端发送过来的用户 ID 和密码与之前登录过的信息做匹配来进行认证的。 但鉴于 HTTP 是无状态协议，之前已认证成功的用户状态无法通过协议层面保存下来。即，无法实现状态管理，因此即使当该用户下一次继续访问，也无法区分他与其他的用户。于是我们会使用 Cookie 来管理 Session，以弥补 HTTP 协议中不存在的状态管理功能。 Session管理和Cookie状态管理 步骤 1：客户端把用户 ID 和密码等登录信息放入报文的实体部分，通常是以 POST 方法把请求发送给服务器。而这时，会使用 HTTPS 通信来进行 HTML 表单画面的显示和用户输入数据的发送。 步骤 2：服务器会发放用以识别用户的Session ID。通过验证从客户端发送过来的登录信息进行身份认证，然后把用户的认证状态与Session ID绑定后记录在服务器端。向客户端返回响应时，会在首部字段Set-Cookie内写入Session ID。 步骤 3：客户端接收到从服务器端发来的Session ID后，会将其作为 Cookie 保存在本地。下次向服务器发送请求时，浏览器会自动发送 Cookie，所以Session ID也随之发送到服务器。服务器端可通过验证接收到的Session ID识别用户和其认证状态。 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储HTTPS协议 & TLS协议影响力","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"HTTP","slug":"HTTP","permalink":"https://abelsu7.top/tags/HTTP/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://abelsu7.top/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://abelsu7.top/tags/SSL/"},{"name":"TLS","slug":"TLS","permalink":"https://abelsu7.top/tags/TLS/"}]},{"title":"HTTP 笔记 3：Web 服务器及 HTTP 首部","slug":"http-notes-part-3","date":"2018-10-22T07:34:42.000Z","updated":"2019-09-01T13:04:11.359Z","comments":true,"path":"2018/10/22/http-notes-part-3/","link":"","permalink":"https://abelsu7.top/2018/10/22/http-notes-part-3/","excerpt":"《图解HTTP》","text":"《图解HTTP》 目录 目录 第 5 章 与 HTTP 协作的 Web 服务器 5.1 用单台虚拟主机实现多个域名 5.2 通信数据转发程序：代理、网关、隧道 5.2.1 代理 5.2.2 网关 5.2.3 隧道 5.3 保存资源的缓存 5.3.1 缓存的有效期限 5.3.2 客户端的缓存 第 6 章 HTTP 首部 6.1 HTTP 报文首部 6.2 HTTP 首部字段 6.2.1 HTTP 首部字段传递重要信息 6.2.2 HTTP 首部字段结构 6.2.3 4 种 HTTP 首部字段类型 6.2.4 HTTP/1.1 首部字段一览 6.2.5 非 HTTP/1.1 首部字段 6.2.6 End-to-end 首部和 Hop-by-hop 首部 6.3 HTTP/1.1 通用首部字段 6.3.1 Cache-Control 6.3.2 Connection 6.3.3 Date 6.3.4 Pragma 6.3.5 Trailer 6.3.6 Transfer-Encoding 6.3.7 Upgrade 6.3.8 Via 6.3.9 Warning 6.4 请求首部字段 6.4.1 Accept 6.4.2 Accept-Charset 6.4.3 Accept-Encoding 6.4.4 Accept-Language 6.4.5 Authorization 6.4.6 Expect 6.4.7 From 6.4.8 Host 6.4.9 If-Match 6.4.10 If-Modified-Since 6.4.11 If-None-Match 6.4.12 If-Range 6.4.13 If-Unmodified-Since 6.4.14 Max-Forwards 6.4.15 Proxy-Authorization 6.4.16 Range 6.4.17 Referer 6.4.18 TE 6.4.19 User-Agent 6.5 响应首部字段 6.5.1 Accept-Ranges 6.5.2 Age 6.5.3 ETag 6.5.4 Location 6.5.5 Proxy-Authenticate 6.5.6 Retry-After 6.5.7 Server 6.5.8 Vary 6.5.9 WWW-Authenticate 6.6 实体首部字段 6.6.1 Allow 6.6.2 Content-Encoding 6.6.3 Content-Language 6.6.4 Content-Length 6.6.5 Content-Location 6.6.6 Content-MD5 6.6.7 Content-Range 6.6.8 Content-Type 6.6.9 Expires 6.6.10 Last-Modified 6.7 为 Cookie 服务的首部字段 6.7.1 Set-Cookie 6.7.2 Cookie 6.8 其他首部字段 6.8.1 X-Frame-Options 6.8.2 X-XSS-Protection 6.8.3 DNT 6.8.4 P3P 第 5 章 与 HTTP 协作的 Web 服务器一台 Web 服务器可搭建多个独立域名的 Web 网站，也可作为通信路径上的中转服务器提升传输效率。 5.1 用单台虚拟主机实现多个域名HTTP/1.1 规范允许一台 HTTP 服务器搭建多个 Web 站点。比如，提供 Web 托管服务（Web Hosting Service）的供应商，可以用一台服务器为多位客户服务，也可以以每位客户持有的域名运行各自不同的网站。这是因为利用了虚拟主机（Virtual Host，又称虚拟服务器）的功能。 在互联网上，域名通过 DNS 服务映射到 IP 地址（域名解析）之后访问目标网站。可见，当请求发送到服务器时，已经是以 IP 地址形式访问了。 所以，如果一台服务器内托管了www.tricorder.jp和www.hackr.jp这两个域名，当收到请求时就需要弄清楚究竟要访问哪个域名。 多个域名解析至同一IP 在相同的 IP 地址下，由于虚拟主机可以寄存多个不同主机名和域名的 Web 网站，因此在发送 HTTP 请求时，必须在 Host 首部内完整指定主机名或域名的 URI。 5.2 通信数据转发程序：代理、网关、隧道HTTP 通信时，除客户端和服务器以外，还有一些用于通信数据转发的应用程序，例如代理、网关和隧道。它们可以配合服务器工作。 这些应用程序和服务器可以将请求转发给通信线路上的下一站服务器，并且能接收从那台服务器发送的响应再转发给客户端。 代理 代理是一种有转发功能的应用程序，它扮演了位于服务器和客户端“中间人”的角色，接收由客户端发送的请求并转发给服务器，同时也接收服务器返回的响应并转发给客户端。 网关 网关是转发其他服务器通信数据的服务器，接收从客户端发送来的请求时，它就像自己拥有资源的源服务器一样对请求进行处理。有时客户端可能都不会察觉，自己的通信目标是一个网关。 隧道 隧道是在相隔甚远的客户端和服务器两者之间进行中转，并保持双方通信连接的应用程序。 5.2.1 代理 代理服务器的基本行为 代理服务器的基本行为就是接收客户端发送的请求后转发给其他服务器。代理不改变请求 URI，会直接发送给前方持有资源的目标服务器。 持有资源实体的服务器被称为源服务器。从源服务器返回的响应经过代理服务器后再传给客户端。 多台代理服务器级联，追加写入Via首部信息 在 HTTP 通信过程中，可级联多台代理服务器。请求和响应的转发会经过数台类似锁链一样连接起来的代理服务器。转发时，需要附加Via首部字段以标记出经过的主机信息。 使用代理服务器的理由有：利用缓存技术减少网络带宽的流量，组织内部针对特定网站的访问控制，以获取访问日志为主要目的，等等。 代理有多种使用方法，按两种基准分类。一种是是否使用缓存，另一种是是否会修改报文。 缓存代理 代理转发响应时，缓存代理（Caching Proxy）会预先将资源的副本（缓存）保存在代理服务器上。当代理再次接收到对相同资源的请求时，就可以不从源服务器那里获取资源，而是将之前缓存的资源作为响应返回。 透明代理 转发请求或响应时，不对报文做任何加工的代理类型被称为透明代理（Transparent Proxy）。反之，对报文内容进行加工的代理被称为非透明代理。 5.2.2 网关 利用网关可以由HTTP请求转化为其他协议通信 网关的工作机制和代理十分相似。而网关能使通信线路上的服务器提供非 HTTP 协议服务。 利用网关能提高通信的安全性，因为可以在客户端与网关之间的通信线路上加密以确保连接的安全。比如，网关可以连接数据库，使用 SQL 语句查询数据。另外，在 Web 购物网站上进行信用卡结算时，网关可以和信用卡结算系统联动。 5.2.3 隧道隧道可按要求建立起一条与其他服务器的通信线路，届时使用 SSL 等加密手段进行通信。隧道的目的是确保客户端能与服务器进行安全的通信。 隧道本身不会去解析 HTTP 请求。也就是说，请求保持原样中转给之后的服务器。隧道会在通信双方断开连接时结束。 5.3 保存资源的缓存缓存是指代理服务器或客户端本地磁盘内保存的资源副本。利用缓存可减少对源服务器的访问，因此也就节省了通信流量和通信时间。 缓存服务器是代理服务器的一种，并归类在缓存代理类型中。换句话说，当代理转发从服务器返回的响应时，代理服务器将会保存一份资源的副本。 缓存服务器的优势在于利用缓存可避免多次从源服务器转发资源。因此客户端可就近从缓存服务器上获取资源，而源服务器也不必多次处理相同的请求了。 5.3.1 缓存的有效期限即便缓存服务器内有缓存，也不能保证每次都会返回对同资源的请求。因为这关系到被缓存资源的有效性问题。 当遇上源服务器上的资源更新时，如果还是使用不变的缓存，那就会演变成返回更新前的“旧”资源了。 即使存在缓存，也会因为客户端的要求、缓存的有效期等因素，向源服务器确认资源的有效性。若判断缓存失效，缓存服务器将会再次从源服务器上获取“新”资源。 5.3.2 客户端的缓存缓存不仅可以存在于缓存服务器内，还可以存在客户端浏览器中，客户端缓存称为临时网络文件（Temporary Internet File）。 浏览器缓存如果有效，就不必再向服务器请求相同的资源了，可以直接从本地磁盘内读取。 另外，和缓存服务器相同的一点是，当判定缓存过期后，会向源服务器确认资源的有效性。若判断浏览器缓存失效，浏览器会再次请求新资源。 第 6 章 HTTP 首部6.1 HTTP 报文首部 HTTP报文的结构 HTTP 协议的请求和响应报文中必定包含 HTTP 首部。首部内容为客户端和服务器分别处理请求和响应提供所需要的信息。 HTTP 请求报文 在请求中，HTTP 报文由方法、URI、HTTP 版本、HTTP 首部字段等部分构成。 HTTP请求报文 下面的示例是访问http://hackr.jp时，请求报文的首部信息。 GET / HTTP/1.1 Host: hackr.jp User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:13.0) Gecko/20100101 Firefox/13.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*; q=0.8 Accept-Language: ja,en-us;q=0.7,en;q=0.3 Accept-Encoding: gzip, deflate DNT: 1 Connection: keep-alive If-Modified-Since: Fri, 31 Aug 2007 02:02:20 GMT If-None-Match: &quot;45bae1-16a-46d776ac&quot; Cache-Control: max-age=0 HTTP 响应报文 在响应中，HTTP 报文由 HTTP 版本、状态码、HTTP 首部字段 3 部分构成。 HTTP响应报文 以下示例是之前请求访问http://hackr.jp/时，返回的响应报文的首部信息。 HTTP/1.1 304 Not Modified Date: Thu, 07 Jun 2012 07:21:36 GMT Server: Apache Connection: close Etag: &quot;45bae1-16a-46d776ac&quot; 6.2 HTTP 首部字段6.2.1 HTTP 首部字段传递重要信息HTTP 首部字段是构成 HTTP 报文的要素之一。在客户端与服务器之间以 HTTP 协议进行通信的过程中，无论是请求还是响应都会使用首部字段，它能起到传递额外重要信息的作用。 使用首部字段是为了给浏览器和服务器提供报文主体大小、所使用的语言、认证信息等内容。 6.2.2 HTTP 首部字段结构 首部字段名: 字段值 字段值对应单个 HTTP 首部字段可以有多个值 Content-Type: text/html Keep-Alive: timeout=15, max=100 6.2.3 4 种 HTTP 首部字段类型HTTP 首部字段根据实际用途被分为以下 4 种类型。 通用首部字段（General Header Fields） 请求报文和响应报文两方都会使用的首部。 请求首部字段（Request Header Fields） 从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息。 响应首部字段（Response Header Fields） 从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。 实体首部字段（Entity Header Fields） 针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。 6.2.4 HTTP/1.1 首部字段一览HTTP/1.1 规范定义了如下 47 种首部字段。 通用首部字段 请求首部字段 响应首部字段 实体首部字段 6.2.5 非 HTTP/1.1 首部字段在 HTTP 协议通信交互中使用到的首部字段，不限于 RFC2616 中定义的 47 种首部字段。还有Cookie、Set-Cookie、Content-Disposition等在其他 RFC 中定义的首部字段，它们的使用频率也很高。 这些非正式的首部字段统一归纳在RFC4229 HTTP Header Field Registrations中。 6.2.6 End-to-end 首部和 Hop-by-hop 首部HTTP 首部字段将定义成缓存代理和非缓存代理的行为，分成 2 种类型。 端到端首部（End-to-end Header） 分在此类别中的首部会转发给请求 / 响应对应的最终接收目标，且必须保存在由缓存生成的响应中，另外规定它必须被转发。 逐跳首部（Hop-by-hop Header） 分在此类别中的首部只对单次转发有效，会因通过缓存或代理而不再转发。HTTP/1.1 和之后版本中，如果要使用 hop-by-hop 首部，需提供Connection首部字段。 下面列举了 HTTP/1.1 中的逐跳首部字段。除这 8 个首部字段之外，其他所有字段都属于端到端首部。 Keep-Alive Proxy-Authenticate Proxy-Authorization Trailer TE Transfer-Encoding Upgrade 6.3 HTTP/1.1 通用首部字段通用首部字段是指，请求报文和响应报文双方都会使用的首部。 6.3.1 Cache-Control通过指定首部字段Cache-Control的指令，就能操作缓存的工作机制。 首部字段Cache-Control能够控制缓存的行为 指令的参数是可选的，多个指令之间通过,分隔。首部字段Cache-Control的指令可用于请求及响应时。 Cache-Control 指令一览 可用的指令按请求和响应分类如下所示。 缓存请求指令 缓存响应指令 表示是否能缓存的指令 public 指令 Cache-Control: public 当指定使用public指令时，则明确表明其他用户也可利用缓存。 private 指令 Cache-Control: private 当指定private指令后，响应只以特定的用户作为对象，这与public指令的行为相反。 缓存服务器会对该特定用户提供资源缓存的服务，对于其他用户发送过来的请求，代理服务器则不会返回缓存。 no-cache 指令 Cache-Control: no-cache 使用no-cache指令的目的是为了防止从缓存中返回过期的资源。 客户端发送的请求中如果包含no-cache指令，则表示客户端将不会接收缓存过的响应。于是，“中间”的缓存服务器必须把客户端请求转发给源服务器。 如果服务器返回的响应中包含no-cache指令，那么缓存服务器不能对资源进行缓存。源服务器以后也将不再对缓存服务器请求中提出的资源有效性进行确认，且禁止其对响应资源进行缓存操作。 Cache-Control: no-cache=Location 由服务器返回的响应中，若报文首部字段Cache-Control中对no-cache字段名具体指定参数值，那么客户端在接收到这个被指定参数值的首部字段对应的响应报文后，就不能使用缓存。 控制可执行缓存的对象的指令 no-store指令 Cache-Control: no-store 当使用no-store指令 时，暗示请求（和对应的响应）或响应中包含机密信息。因此，该指令规定缓存不能在本地存储请求或响应的任一部分。 指定缓存期限和认证的指令 s-maxage 指令 Cache-Control: s-maxage=604800（单位 ：秒） s-maxage指令的功能和max-age指令的相同，它们的不同点是s-maxage指令只适用于供多位用户使用的公共缓存服务器（一般指代理服务器）。也就是说，对于向同一用户重复返回响应的服务器来说，这个指令没有任何作用。 另外，当使用s-maxage指令后，则直接忽略对Expires首部字段及max-age指令的处理。 max-age 指令 max-age指令 Cache-Control: max-age=604800（单位：秒） 当客户端发送的请求中包含max-age指令时，如果判定缓存资源的缓存时间数值比指定时间的数值更小，那么客户端就接收缓存的资源。另外，当指定max-age值为 0，那么缓存服务器通常需要将请求转发给源服务器。 当服务器返回的响应中包含max-age指令时，缓存服务器将不对资源的有效性再作确认，而max-age数值代表资源保存为缓存的最长时间。 应用 HTTP/1.1 版本的缓存服务器遇到同时存在Expires首部字段的情况时，会优先处理max-age指令，而忽略掉Expires首部字段。而 HTTP/1.0 版本的缓存服务器的情况却相反，max-age指令会被忽略掉。 min-fresh 指令 Cache-Control: min-fresh=60（单位：秒） min-fresh指令要求缓存服务器返回至少还未过指定时间的缓存资源。比如，当指定min-fresh为 60 秒后，过了 60 秒的资源都无法作为响应返回了。 max-stale 指令 Cache-Control: max-stale=3600（单位：秒） 使用max-stale可指示缓存资源，即使过期也照常接收。 only-if-cached 指令 Cache-Control: only-if-cached 使用only-if-cached指令表示客户端仅在缓存服务器本地缓存目标资源的情况下才会要求其返回。换言之，该指令要求缓存服务器不重新加载响应，也不会再次确认资源有效性。若发生请求缓存服务器的本地缓存无响应，则返回状态码504 Gateway Timeout。 must-revalidate 指令 Cache-Control: must-revalidate 使用must-revalidate指令，代理会向源服务器再次验证即将返回的响应缓存目前是否仍然有效。 若代理无法连通源服务器再次获取有效资源的话，缓存必须给客户端一条 504（Gateway Timeout）状态码。 另外，使用must-revalidate指令会忽略请求的max-stale指令（即使已经在首部使用了max-stale，也不会再有效果）。 proxy-revalidate 指令 Cache-Control: proxy-revalidate proxy-revalidate指令要求所有的缓存服务器在接收到客户端带有该指令的请求返回响应之前，必须再次验证缓存的有效性。 no-transform 指令 Cache-Control: no-transform 使用no-transform指令规定无论是在请求还是响应中，缓存都不能改变实体主体的媒体类型。这样做可防止缓存或代理压缩图片等类似操作。 6.3.2 ConnectionConnection首部字段具备如下两个作用： 控制不再转发给代理的首部字段 Connection: 不再转发的首部字段名 管理持久连接 Connection: close HTTP/1.1 版本的默认连接都是持久连接。为此，客户端会在持久连接上连续发送请求。当服务器端想明确断开连接时，则指定Connection首部字段的值为Close。 Connection: Keep-Alive HTTP/1.1 之前的 HTTP 版本的默认连接都是非持久连接。为此，如果想在旧版本的 HTTP 协议上维持持续连接，则需要指定Connection首部字段的值为Keep-Alive。 6.3.3 Date首部字段Date表明创建 HTTP 报文的日期和时间。 HTTP/1.1 协议使用在 RFC1123 中规定的日期时间的格式，如下示例： Date: Tue, 03 Jul 2012 04:40:59 GMT 之前的 HTTP 协议版本中使用在 RFC850 中定义的格式，如下所示： Date: Tue, 03-Jul-12 04:40:59 GMT 除此之外，还有一种格式。它与 C 标准库内的 asctime() 函数的输出格式一致： Date: Tue Jul 03 04:40:59 2012 6.3.4 PragmaPragma 是 HTTP/1.1 之前版本的历史遗留字段，仅作为与 HTTP/1.0 的向后兼容而定义。 Pragma: no-cache 所有的中间服务器如果都能以 HTTP/1.1 为基准，那直接采用Cache-Control: no-cache指定缓存的处理方式是最为理想的。但要整体掌握全部中间服务器使用的 HTTP 协议版本却是不现实的。因此，发送的请求会同时含有下面两个首部字段。 Cache-Control: no-cache Pragma: no-cache 6.3.5 Trailer首部字段Trailer会事先说明在报文主体后记录了哪些首部字段。该首部字段可应用在 HTTP/1.1 版本分块传输编码时。 HTTP/1.1 200 OK Date: Tue, 03 Jul 2012 04:40:56 GMT Content-Type: text/html ... Transfer-Encoding: chunked Trailer: Expires ...(报文主体)... 0 Expires: Tue, 28 Sep 2004 23:59:59 GMT 以上用例中，指定首部字段Trailer的值为Expires，在报文主体之后（分块长度 0 之后）出现了首部字段Expires。 6.3.6 Transfer-Encoding首部字段Transfer-Encoding规定了传输报文主体时采用的编码方式。HTTP/1.1 的传输编码方式仅对分块传输编码有效。 HTTP/1.1 200 OK Date: Tue, 03 Jul 2012 04:40:56 GMT Cache-Control: public, max-age=604800 Content-Type: text/javascript; charset=utf-8 Expires: Tue, 10 Jul 2012 04:40:56 GMT X-Frame-Options: DENY X-XSS-Protection: 1; mode=block Content-Encoding: gzip Transfer-Encoding: chunked Connection: keep-alive cf0 ←16进制(10进制为3312) ...3312字节分块数据... 392 ←16进制(10进制为914) ...914字节分块数据... 0 以上用例中，正如在首部字段Transfer-Encoding中指定的那样，有效使用分块传输编码，且分别被分成 3312 字节和 914 字节大小的分块数据。 6.3.7 Upgrade首部字段Upgrade用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议。 首部字段Upgrade 上图用例中，首部字段Upgrade指定的值为TLS/1.0。请注意此处两个字段首部字段的对应关系，Connection的值被指定为Upgrade。Upgrade首部字段产生作用的Upgrade对象仅限于客户端和邻接服务器之间。因此，使用首部字段Upgrade时，还需要额外指定Connection:Upgrade。 对于附有首部字段Upgrade的请求，服务器可用101 Switching Protocols状态码作为响应返回。 6.3.8 Via使用首部字段Via是为了追踪客户端与服务器之间的请求和响应报文的传输路径。 首部字段Via不仅用于追踪报文的转发，还可避免请求回环的发生。所以必须在经过代理时附加该首部字段内容。 报文经过代理时会被添加Via字段 6.3.9 WarningHTTP/1.1 的Warning首部是从 HTTP/1.0 的响应首部Retry-After演变过来的。该首部通常会告知用户一些与缓存相关的问题的警告。 Warning: 113 gw.hackr.jp:8080 &quot;Heuristic expiration&quot; Tue, 03 Jul 2012 05:09:44 GMT Warning首部的格式如下。最后的日期时间部分可省略。 Warning: [警告码][警告的主机:端口号]“[警告内容]”([日期时间]) HTTP/1.1 中定义了 7 种警告。警告码对应的警告内容仅推荐参考。另外，警告码具备扩展性，今后有可能追加新的警告码。 HTTP/1.1警告码 6.4 请求首部字段请求首部字段是从客户端往服务器端发送请求报文中所使用的字段，用于补充请求的附加信息、客户端信息、对响应内容相关的优先级等内容。 6.4.1 AcceptAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用type/subtype这种形式，一次指定多种媒体类型。 当服务器提供多种内容时，将会首先返回权重值最高的媒体类型。 6.4.2 Accept-CharsetAccept-Charset: iso-8859-5, unicode-1-1;q=0.8 Accept-Charset首部字段可用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。另外，可一次性指定多种字符集。与首部字段Accept相同的是可用权重q值来表示相对优先级。 6.4.3 Accept-EncodingAccept-Encoding: gzip, deflate Accept-Encoding首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。可一次性指定多种内容编码。 gzip：由文件压缩程序 gzip（GNU zip）生成的编码格式（RFC1952） compress：由 UNIX 文件压缩程序 compress 生成的编码格式 deflate：组合使用 zlib 格式（RFC1950）及由 deflate 压缩算法（RFC1951）生成的编码格式 identity：不执行压缩或不会变化的默认编码格式 6.4.4 Accept-LanguageAccept-Language: zh-cn,zh;q=0.7,en-us,en;q=0.3 6.4.5 Authorization 首部字段Authorization Authorization: Basic dWVub3NlbjpwYXNzd29yZA== 首部字段Authorization是用来告知服务器，用户代理的认证信息（证书值）。 6.4.6 ExpectExpect: 100-continue 客户端使用首部字段Expect来告知服务器，期望出现的某种特定行为。因服务器无法理解客户端的期望作出回应而发生错误时，会返回状态码417 Expectation Failed。 6.4.7 From首部字段From用来告知服务器使用用户代理的用户的电子邮件地址。通常，其使用目的就是为了显示搜索引擎等用户代理的负责人的电子邮件联系方式。 6.4.8 HostHost: www.hackr.jp 首部字段Host会告知服务器，请求的资源所处的互联网主机名和端口号。Host 首部字段在 HTTP/1.1 规范内是唯一一个必须被包含在请求内的首部字段。 首部字段Host和以单台服务器分配多个域名的虚拟主机的工作机制有很密切的关联，这是其必须存在的意义。 若服务器未设定主机名，那直接发送一个空值即可。如下所示。 Host: 6.4.9 If-Match形如If-xxx这种样式的请求首部字段，都可称为条件请求。服务器接收到附带条件的请求后，只有判断指定条件为真时，才会执行请求。 If-Match: &quot;123456&quot; 服务器会比对If-Match的字段值和资源的 ETag 值，仅当两者一致时，才会执行请求。反之，则返回状态码412 Precondition Failed的响应。 6.4.10 If-Modified-SinceIf-Modified-Since: Thu, 15 Apr 2004 00:00:00 GMT If-Modified-Since用于确认代理或客户端拥有的本地资源的有效性。获取资源的更新日期时间，可通过确认首部字段Last-Modified来确定。 6.4.11 If-None-Match首部字段If-None-Match属于附带条件之一。它和首部字段If-Match作用相反。用于指定If-None-Match字段值的实体标记（ETag）值与请求资源的 ETag 不一致时，它就告知服务器处理该请求。 在 GET 或 HEAD 方法中使用首部字段If-None-Match可获取最新的资源。因此，这与使用首部字段If-Modified-Since时有些类似。 6.4.12 If-Range首部字段If-Range属于附带条件之一。它告知服务器若指定的If-Range字段值（ETag 值或者时间）和请求资源的 ETag 值或时间相一致时，则作为范围请求处理。反之，则返回全体资源。 6.4.13 If-Unmodified-SinceIf-Unmodified-Since: Thu, 03 Jul 2012 00:00:00 GMT 首部字段If-Unmodified-Since和首部字段If-Modified-Since的作用相反。它的作用的是告知服务器，指定的请求资源只有在字段值内指定的日期时间之后，未发生更新的情况下，才能处理请求。如果在指定日期时间后发生了更新，则以状态码412 Precondition Failed作为响应返回。 6.4.14 Max-ForwardsMax-Forwards: 10 通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段Max-Forwards的请求时，该字段以十进制整数形式指定可经过的服务器最大数目。 6.4.15 Proxy-AuthorizationProxy-Authorization: Basic dGlwOjkpNLAGfFY5 接收到从代理服务器发来的认证质询时，客户端会发送包含首部字段Proxy-Authorization的请求，以告知服务器认证所需要的信息。 6.4.16 RangeRange: bytes=5001-10000 对于只需获取部分资源的范围请求，包含首部字段Range即可告知服务器资源的指定范围。上面的示例表示请求获取从第 5001 字节至第 10000 字节的资源。 6.4.17 RefererReferer: http://www.hackr.jp/index.htm 首部字段Referer会告知服务器请求的原始资源的 URI。 客户端一般都会发送Referer首部字段给服务器。但当直接在浏览器的地址栏输入 URI，或出于安全性的考虑时，也可以不发送该首部字段。 因为原始资源的 URI 中的查询字符串可能含有 ID 和密码等保密信息，要是写进 Referer 转发给其他服务器，则有可能导致保密信息的泄露。 6.4.18 TETE: gzip, deflate;q=0.5 首部字段TE会告知服务器客户端能够处理响应的传输编码方式及相对优先级。它和首部字段Accept-Encoding的功能很相像，但是用于传输编码。 6.4.19 User-AgentUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:13.0) Gecko/20100101 Firefox/13.0.1 首部字段User-Agent会将创建请求的浏览器和用户代理名称等信息传达给服务器。 6.5 响应首部字段响应首部字段是由服务器端向客户端返回响应报文中所使用的字段，用于补充响应的附加信息、服务器信息，以及对客户端的附加要求等信息。 6.5.1 Accept-RangesAccept-Ranges: bytes 首部字段Accept-Ranges是用来告知客户端服务器是否能处理范围请求，以指定获取服务器端某个部分的资源。 可指定的字段值有两种，可处理范围请求时指定其为bytes，反之则指定其为none。 6.5.2 AgeAge: 600 首部字段Age能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。 若创建该响应的服务器是缓存服务器，Age值是指缓存后的响应再次发起认证到认证完成的时间值。 代理创建响应时必须加上首部字段Age。 6.5.3 ETagETag: &quot;82e22293907ce725faf67773957acd12&quot; 首部字段 ETag 能告知客户端实体标识。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag 值。 另外，当资源更新时，ETag 值也需要更新。生成 ETag 值时，并没有统一的算法规则，而仅仅是由服务器来分配。 强 ETag 值和弱 ETag 值 强 ETag 值，不论实体发生多么细微的变化都会改变其值 ETag: &quot;usagi-1234&quot; 弱 ETag 值只用于提示资源是否相同。只有资源发生了根本改变，产生差异时才会改变 ETag 值。这时，会在字段值最开始处附加W/ ETag: W/&quot;usagi-1234&quot; 6.5.4 LocationLocation: http://www.usagidesign.jp/sample.html 使用首部字段Location可以将响应接收方引导至某个与请求 URI 位置不同的资源。 基本上，该字段会配合3xx ：Redirection的响应，提供重定向的 URI。 6.5.5 Proxy-AuthenticateProxy-Authenticate: Basic realm=&quot;Usagidesign Auth&quot; 首部字段Proxy-Authenticate会把由代理服务器所要求的认证信息发送给客户端。 6.5.6 Retry-AfterRetry-After: 120 首部字段Retry-After告知客户端应该在多久之后再次发送请求。主要配合状态码503 Service Unavailable响应，或3xx Redirect响应一起使用。 字段值可以指定为具体的日期时间（Wed, 04 Jul 2012 06：34：24 GMT 等格式），也可以是创建响应后的秒数。 6.5.7 ServerServer: Apache/2.2.17 (Unix) 首部字段Server告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息。不单单会标出服务器上的软件应用名称，还有可能包括版本号和安装时启用的可选项。 Server: Apache/2.2.6 (Unix) PHP/5.2.5 6.5.8 Vary 响应首部字段Vary Vary: Accept-Language 首部字段Vary可对缓存进行控制。源服务器会向代理服务器传达关于本地缓存使用方法的命令。 从代理服务器接收到源服务器返回包含Vary指定项的响应之后，若再要进行缓存，仅对请求中含有相同Vary指定首部字段的请求返回缓存。即使对相同资源发起请求，但由于Vary指定的首部字段不相同，因此必须要从源服务器重新获取资源。 6.5.9 WWW-AuthenticateWWW-Authenticate: Basic realm=&quot;Usagidesign Auth&quot; 首部字段WWW-Authenticate用于 HTTP 访问认证。它会告知客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge）。状态码401 Unauthorized响应中，肯定带有首部字段WWW-Authenticate。 6.6 实体首部字段实体首部字段是包含在请求报文和响应报文中的实体部分所使用的首部，用于补充内容的更新时间等与实体相关的信息。 6.6.1 AllowAllow: GET, HEAD 首部字段Allow用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。 当服务器接收到不支持的 HTTP 方法时，会以状态码405 Method Not Allowed作为响应返回。与此同时，还会把所有能支持的 HTTP 方法写入首部字段Allow后返回。 6.6.2 Content-EncodingContent-Encoding: gzip 首部字段Content-Encoding会告知客户端服务器对实体的主体部分选用的内容编码方式。内容编码是指在不丢失实体信息的前提下所进行的压缩。 主要采用以下四种内容编码的方式： gzip compress deflate identity 6.6.3 Content-LanguageContent-Language: zh-CN 首部字段Content-Language会告知客户端，实体主体使用的自然语言。 6.6.4 Content-LengthContent-Length: 15000 首部字段Content-Length表明了实体主体部分的大小（单位是字节）。 对实体主体进行内容编码传输时，不能再使用Content-Length首部字段。 6.6.5 Content-LocationContent-Location: http://www.hackr.jp/index-ja.html 首部字段Content-Location给出与报文主体部分相对应的 URI。和首部字段Location不同，Content-Location表示的是报文主体返回资源对应的 URI。 6.6.6 Content-MD5Content-MD5: OGFkZDUwNGVhNGY3N2MxMDIwZmQ4NTBmY2IyTY== 首部字段Content-MD5是一串由 MD5 算法生成的值，其目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。 对报文主体执行 MD5 算法获得的 128 位二进制数，再通过 Base64 编码后将结果写入Content-MD5字段值。由于 HTTP 首部无法记录二进制值，所以要通过 Base64 编码处理。为确保报文的有效性，作为接收方的客户端会对报文主体再执行一次相同的 MD5 算法。计算出的值与字段值作比较后，即可判断出报文主体的准确性。 采用这种方法，对内容上的偶发性改变是无从查证的，也无法检测出恶意篡改。其中一个原因在于，内容如果能够被篡改，那么同时意味着Content-MD5也可重新计算然后被篡改。所以处在接收阶段的客户端是无法意识到报文主体以及首部字段Content-MD5是已经被篡改过的。 6.6.7 Content-RangeContent-Range: bytes 5001-10000/10000 针对范围请求，返回响应时使用的首部字段Content-Range，能告知客户端作为响应返回的实体的哪个部分符合范围请求。字段值以字节为单位，表示当前发送部分及整个实体大小。 6.6.8 Content-TypeContent-Type: text/html; charset=UTF-8 首部字段Content-Type说明了实体主体内对象的媒体类型。和首部字段Accept一样，字段值用type/subtype形式赋值。 参数charset使用iso-8859-1或euc-jp等字符集进行赋值。 6.6.9 ExpiresExpires: Wed, 04 Jul 2012 08:26:05 GMT 首部字段Expires会将资源失效的日期告知客户端。缓存服务器在接收到含有首部字段Expires的响应后，会以缓存来应答请求，在Expires字段值指定的时间之前，响应的副本会一直被保存。当超过指定的时间后，缓存服务器在请求发送过来时，会转向源服务器请求资源。 源服务器不希望缓存服务器对资源缓存时，最好在Expires字段内写入与首部字段Date相同的时间值。 但是，当首部字段Cache-Control有指定max-age指令时，比起首部字段Expires，会优先处理max-age指令。 6.6.10 Last-ModifiedLast-Modified: Wed, 23 May 2012 09:59:55 GMT 首部字段Last-Modified指明资源最终修改的时间。 一般来说，这个值就是Request-URI指定资源被修改的时间。但类似使用 CGI 脚本进行动态数据处理时，该值有可能会变成数据最终修改时的时间。 6.7 为 Cookie 服务的首部字段管理服务器与客户端之间状态的 Cookie，虽然没有被编入标准化 HTTP/1.1 的 RFC2616 中，但在 Web 网站方面得到了广泛的应用。 Cookie 的工作机制是用户识别及状态管理。Web 网站为了管理用户的状态会通过 Web 浏览器，把一些数据临时写入用户的计算机内。接着当用户访问该Web网站时，可通过通信方式取回之前发放的 Cookie。 调用 Cookie 时，由于可校验 Cookie 的有效期，以及发送方的域、路径、协议*等信息，所以正规发布的 Cookie 内的数据不会因来自其他 Web 站点和攻击者的攻击而泄露。 下面的表格列举了与 Cookie 有关的首部字段。 首部字段名 说明 首部类型 Set-Cookie 开始状态管理所使用的 Cookie 信息 响应首部字段 Cookie 服务器接收到的 Cookie 信息 请求首部字段 6.7.1 Set-CookieSet-Cookie: status=enable; expires=Tue, 05 Jul 2011 07:26:31 GMT; path=/; domain=.hackr.jp; 当服务器准备开始管理客户端的状态时，会事先告知各种信息。 下面的表格列举了Set-Cookie的字段值。 属性 说明 NAME=VALUE 赋予 Cookie 的名称和其值（必需项） expires=DATE Cookie 的有效期 path=PATH 将服务器上的文件目录作为 Cookie 的适用对象 domain=域名 作为 Cookie 适用对象的域名 Secure 仅在 HTTPS 安全通信时才会发送 Cookie HttpOnly 加以限制，使 Cookie 不能被 JavaScript 脚本访问 6.7.2 CookieCookie: status=enable 首部字段Cookie会告知服务器，当客户端想获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的Cookie。 接收到多个Cookie时，同样可以以多个Cookie形式发送。 6.8 其他首部字段6.8.1 X-Frame-OptionsX-Frame-Options: DENY 首部字段X-Frame-Options属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。 6.8.2 X-XSS-ProtectionX-XSS-Protection: 1 首部字段X-XSS-Protection属于 HTTP 响应首部，它是针对跨站脚本攻击（XSS）的一种对策，用于控制浏览器 XSS 防护机制的开关。 6.8.3 DNTDNT: 1 首部字段DNT属于 HTTP 请求首部，其中DNT是 Do Not Track（请勿跟踪） 的简称，意为拒绝个人信息被收集，是表示拒绝被精准广告追踪的一种方法。 6.8.4 P3PP3P: CP=&quot;CAO DSP LAW CURa ADMa DEVa TAIa PSAa PSDa IVAa IVDa OUR BUS IND UNI COM NAV INT&quot; 首部字段P3P属于 HTTP 响应首部，通过利用 P3P（The Platform for Privacy Preferences，在线隐私偏好平台）技术，可以让 Web 网站上的个人隐私变成一种仅供程序可理解的形式，以达到保护用户隐私的目的。 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"HTTP","slug":"HTTP","permalink":"https://abelsu7.top/tags/HTTP/"}]},{"title":"HTTP 笔记 2：HTTP 报文信息及状态码","slug":"http-notes-part-2","date":"2018-10-22T02:36:10.000Z","updated":"2019-09-01T13:04:11.347Z","comments":true,"path":"2018/10/22/http-notes-part-2/","link":"","permalink":"https://abelsu7.top/2018/10/22/http-notes-part-2/","excerpt":"《图解HTTP》","text":"《图解HTTP》 目录 目录 第 3 章 HTTP 报文内的 HTTP 信息 3.1 HTTP 报文 3.2 请求报文和响应报文的结构 3.3 编码提升传输速率 3.3.1 报文主体和实体主体的差异 3.3.2 压缩传输的内容编码 3.3.3 分割发送的分块传输编码 3.4 发送多种数据的多部分对象集合 3.5 获取部分内容的范围请求 3.6 内容协商返回最合适的内容 第 4 章 返回结果的 HTTP 状态码 4.1 状态码告知从服务器端返回的请求结果 4.2 2XX 成功 4.2.1 200 OK 4.2.2 204 No Content 4.2.3 206 Partial Content 4.3 3XX重定向 4.3.1 301 Moved Permanently 4.3.2 302 Found 4.3.3 303 See Other 4.3.4 304 Not Modified 4.3.5 307 Temporary Redirect 4.4 4XX 客户端错误 4.4.1 400 Bad Request 4.4.2 401 Unauthorized 4.4.3 403 Forbidden 4.4.4 404 Not Found 4.5 5XX 服务器错误 4.5.1 500 Internal Server Error 4.5.2 503 Service Unavailable 第 3 章 HTTP 报文内的 HTTP 信息3.1 HTTP 报文用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的 HTTP 报文叫做请求报文，响应端（服务器端）的叫做响应报文。HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。 HTTP 报文大致可分为报文首部和报文主体两块。两者由最初出现的空行（CR+LF）来划分。通常，并不一定要有报文主体。 HTTP报文的结构 3.2 请求报文和响应报文的结构 请求报文(上)和响应报文(下)的结构 请求报文和响应报文的首部内容由以下数据组成： 请求行：包含用于请求的方法，请求 URI 和 HTTP 版本 状态行：包含表明响应结果的状态码，原因短语和 HTTP 版本 首部字段：包含表示请求和响应的各种条件和属性的各类首部 其他：可能包含 HTTP 的 RFC 里未定义的首部（Cookie 等） 3.3 编码提升传输速率HTTP 在传输数据时可以按照数据原貌直接传输，但也可以在传输过程中通过编码提升传输速率。通过在传输时编码，能有效地处理大量的访问请求。但是，编码的操作需要计算机来完成，因此会消耗更多的 CPU 等资源。 3.3.1 报文主体和实体主体的差异 报文（message） 是 HTTP 通信中的基本单位，由 8 位组字节流（octet sequence，其中 octet 为 8 个比特）组成，通过 HTTP 通信传输。 实体（entity） 作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成。 HTTP 报文的主体用于传输请求或响应的实体主体。 通常，报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异。 3.3.2 压缩传输的内容编码向待发送邮件内增加附件时，为了使邮件容量变小，我们会先用 ZIP 压缩文件之后再添加附件发送。HTTP 协议中有一种被称为内容编码的功能也能进行类似的操作。 内容编码指明应用在实体内容上的编码格式，并保持实体信息原样压缩。内容编码后的实体由客户端接收并负责解码。 常用的内容编码有以下几种： gzip（GNU zip） compress（UNIX 系统的标准压缩） deflate（zlib） identity（不进行编码） 3.3.3 分割发送的分块传输编码在 HTTP 通信过程中，请求的编码实体资源尚未全部传输完成之前，浏览器无法显示请求页面。在传输大容量数据时，通过把数据分割成多块，能够让浏览器逐步显示页面。 这种把实体主体分块的功能称为分块传输编码（Chunked Transfer Coding）。 分块传输编码 分块传输编码会将实体主体分成多个部分（块）。每一块都会用十六进制来标记块的大小，而实体主体的最后一块会使用0(CR+LF)来标记。 使用分块传输编码的实体主体会由接收的客户端负责解码，恢复到编码前的实体主体。 HTTP/1.1 中存在一种称为传输编码（Transfer Coding）的机制，它可以在通信时按某种编码方式传输，但只定义作用于分块传输编码中。 3.4 发送多种数据的多部分对象集合 MIME多部分对象集和 发送邮件时，我们可以在邮件里写入文字并添加多份附件，这时因为采用了 MIME（Multipurpose Internet Mail Extensions，多用途因特网邮件扩展）机制，它允许邮件处理文本、图片、视频等多个不同类型的数据。 例如，图片等二进制数据以 ASCII 码字符串编码的方式指明，就是利用 MIME 来描述标记数据类型。而在 MIME 扩展中会使用一种称为多部分对象集合（Multipart）的方法，来容纳多份不同类型的数据。 相应地，HTTP 协议中也采纳了多部分对象集合，发送的一份报文主体内可含有多类型实体。通常是在图片或文本文件等上传时使用。 多部分对象集合包含的对象如下： multipart/form-data：在Web表单文件上传时使用 Content-Type: multipart/form-data; boundary=AaB03x --AaB03x Content-Disposition: form-data; name=&quot;field1&quot; Joe Blow --AaB03x Content-Disposition: form-data; name=&quot;pics&quot;; filename=&quot;file1.txt&quot; Content-Type: text/plain ...（file1.txt的数据）... --AaB03x-- multipart/byteranges：状态码206（Partial Content，部分内容）。响应报文包含了多个范围的内容时使用。 HTTP/1.1 206 Partial Content Date: Fri, 13 Jul 2012 02:45:26 GMT Last-Modified: Fri, 31 Aug 2007 02:02:20 GMT Content-Type: multipart/byteranges; boundary=THIS_STRING_SEPARATES --THIS_STRING_SEPARATES Content-Type: application/pdf Content-Range: bytes 500-999/8000 ...（范围指定的数据）... --THIS_STRING_SEPARATES Content-Type: application/pdf Content-Range: bytes 7000-7999/8000 ...（范围指定的数据）... --THIS_STRING_SEPARATES-- 在 HTTP 报文中使用多部分对象集合时，需要在首部字段里加上Content-type。 3.5 获取部分内容的范围请求以前如果下载过程遇到网络中断的情况，必须重头开始。为了解决上述问题，需要一种可恢复的机制。所谓的恢复是指能从之前下载中断处恢复下载。 要实现该功能需要指定下载的实体范围。像这样，指定范围发送的请求叫做范围请求（Range Request）。 对一份 10000 字节大小的资源，如果使用范围请求，可以只请求 5001~10000 字节内的资源。 执行范围请求时，会用到首部字段Range来指定资源的byte范围 byte 范围的指定形式如下， 5001~10000字节： Range: bytes=5001-10000 从5001字节之后全部的： Range: bytes=5001- 从一开始到3000字节和5000~7000字节的多重范围： Range: bytes=-3000, 5000-7000 针对范围请求，响应会返回状态码为206 Partial Content的响应报文。另外，对于多重范围的范围请求，响应会在首部字段 Content-Type 标明 multipart/byteranges 后返回响应报文。 如果服务器端无法响应范围请求，则会返回状态码 200 OK 和完整的实体内容。 3.6 内容协商返回最合适的内容当浏览器的默认语言为英语或中文，访问相同 URI 的 Web 页面时，则会显示对应的英语版或中文版的 Web 页面。这样的机制称为内容协商（Content Negotiation）。 内容协商机制是指客户端和服务器端就响应的资源内容进行交涉，然后提供给客户端最为适合的资源。内容协商会以响应资源的语言、字符集、编码方式等作为判断的基准。 包含在请求报文中的以下首部字段就是判断的基准： Accept Accept-Charset Accept-Encoding Accept-Language Content-Language 内容协商技术有以下三种类型： 服务器驱动协商（Server-driven Negotiation） 由服务器端进行内容协商。以请求的首部字段为参考，在服务器端自动处理。但对用户来说，以浏览器发送的信息作为判定的依据，并不一定能筛选出最优内容。 客户端驱动协商（Agent-driven Negotiation） 由客户端进行内容协商的方式。用户从浏览器显示的可选项列表中手动选择。还可以利用 JavaScript 脚本在 Web 页面上自动进行上述选择。比如按 OS 的类型或浏览器类型，自行切换成 PC 版页面或手机版页面。 透明协商（Transparent Negotiation） 是服务器驱动和客户端驱动的结合体，是由服务器端和客户端各自进行内容协商的一种方法。 第 4 章 返回结果的 HTTP 状态码4.1 状态码告知从服务器端返回的请求结果状态码的职责是当客户端向服务器端发送请求时，描述返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了错误。 状态码如200 OK，以 3 位数字和原因短语组成。 数字中的第一位指定了响应类别，后两位无类别。响应类别有以下 5 种： 状态码 响应类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 只要遵守状态码类别的定义，即使改变 RFC2616 中定义的状态码，或服务器端自行创建状态码都没问题。 仅记录在 RFC2616 上的 HTTP 状态码就达 40 种，若再加上 WebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）（RFC4918、5842） 和附加 HTTP 状态码（RFC6585）等扩展，数量就达 60 余种。别看种类繁多，实际上经常使用的大概只有 以下14 种。 4.2 2XX 成功2XX的响应结果表示请求被正常处理了。 4.2.1 200 OK200 OK表示从客户端发来的请求在服务器端被正常处理了。 在响应报文内，随状态码一起返回的信息会因方法的不同而发生改变。比如，使用 GET 方法时，对应请求资源的实体会作为响应返回；而使用 HEAD 方法时，对应请求资源的实体首部不随报文主体作为响应返回（即在响应中只返回首部，不会返回实体的主体部分）。 4.2.2 204 No Content204 No Content代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。比如，当从浏览器发出请求处理后，返回204 No Content响应，那么浏览器显示的页面不发生更新。 一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。 4.2.3 206 Partial Content206 Partial Content表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。响应报文中包含由Content-Range指定范围的实体内容。 4.3 3XX重定向3XX响应结果表明浏览器需要执行某些特殊的处理以正确处理请求。 4.3.1 301 Moved Permanently 301 Moved Permanently 永久性重定向。该状态码表示请求的资源已被分配了新的 URI，以后应使用资源现在所指的 URI。 4.3.2 302 Found 302 Found 临时性重定向。该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。 和 301 Moved Permanently 状态码相似，但 302 状态码代表的资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URI 将来还有可能发生改变。比如，用户把 URI 保存成书签，但不会像 301 状态码出现时那样去更新书签，而是仍旧保留返回 302 状态码的页面对应的 URI。 4.3.3 303 See Other 303 See Other 303 See Other表示由于请求对应的资源存在着另一个 URI，应使用GET方法定向获取请求的资源。 303 See Other状态码和302 Found状态码有着相同的功能，但 303 状态码明确表示客户端应当采用 GET 方法获取资源，这点与 302 状态码有区别。 当 301、302、303 响应状态码返回时，几乎所有的浏览器都会把 POST 改成 GET，并删除请求报文内的主体，之后请求会自动再次发送。 301、302 标准是禁止将 POST 方法改变成 GET 方法的，但实际使用时大家都会这么做。 4.3.4 304 Not Modified 304 Not Modified 该状态码表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。 附带条件的请求是指采用GET方法的请求报文中包含If-Match、If-Modified-Since、If-None-Match、If-Range、If-Unmodified-Since中任一首部。 304 状态码返回时，不包含任何响应的主体部分。304 虽然被划分在 3XX 类别中，但是和重定向没有关系。 4.3.5 307 Temporary Redirect临时重定向。该状态码与302 Found有着相同的含义。尽管 302 标准禁止POST变换成GET，但实际使用时大家并不遵守。 307 会遵照浏览器标准，不会从 POST 变成 GET。但是，对于处理响应时的行为，每种浏览器有可能出现不同的情况。 4.4 4XX 客户端错误4XX的响应结果表明客户端是发生错误的原因所在。 4.4.1 400 Bad Request该状态码表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。另外，浏览器会像200 OK一样对待该状态码。 4.4.2 401 Unauthorized 401 Unauthorized 该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。另外若之前已进行过 1 次请求，则表示用 户认证失败。 4.4.3 403 Forbidden该状态码表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出拒绝的详细理由，但如果想作说明的话，可以在实体的主体部分对原因进行描述，这样就能让用户看到了。 未获得文件系统的访问授权，访问权限出现某些问题（从未授权的发送源 IP 地址试图访问）等列举的情况都可能是发生 403 的原因。 4.4.4 404 Not Found该状态码表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使用。 4.5 5XX 服务器错误5XX的响应结果表明服务器本身发生错误。 4.5.1 500 Internal Server Error该状态码表明服务器端在执行请求时发生了错误。也有可能是 Web 应用存在的 bug 或某些临时的故障。 4.5.2 503 Service Unavailable该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入RetryAfter首部字段再返回给客户端。 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志5 分钟 Docker 笔记 5：存储影响力数学之美：不能再凑了","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"HTTP","slug":"HTTP","permalink":"https://abelsu7.top/tags/HTTP/"},{"name":"状态码","slug":"状态码","permalink":"https://abelsu7.top/tags/状态码/"}]},{"title":"HTTP 笔记 1：Web 基础及简单的 HTTP 协议","slug":"http-notes-part-1","date":"2018-10-18T15:10:36.000Z","updated":"2019-09-01T13:04:11.334Z","comments":true,"path":"2018/10/18/http-notes-part-1/","link":"","permalink":"https://abelsu7.top/2018/10/18/http-notes-part-1/","excerpt":"《图解HTTP》","text":"《图解HTTP》 目录 目录 第 1 章 了解 Web 及网络基础 1.1 使用 HTTP 协议访问 Web 1.2 HTTP 的诞生 1.3 网络基础 TCP/IP 1.3.1 TCP/IP 协议族 1.3.2 TCP/IP 的分层管理 1.3.3 TCP/IP 通信传输流 1.4 与 HTTP 关系密切的协议 : IP、TCP 和 DNS 1.4.1 负责传输的 IP 协议 1.4.2 确保可靠性的 TCP 协议 1.5 负责域名解析的 DNS 服务 1.6 各种协议与 HTTP 协议的关系 1.7 URI 和 URL 1.7.1 统一资源标识符 1.7.2 URI 格式 第 2 章 简单的 HTTP 协议 2.1 HTTP 协议用于客户端和服务器端之间的通信 2.2 通过请求和相应的交换达成通信 2.3 HTTP 是不保存状态的协议 2.4 请求 URI 定位资源 2.5 告知服务器意图的 HTTP 方法 2.6 使用方法下达命令 2.7 持久连接节省通信量 2.7.1 持久连接 2.7.2 管线化 2.8 使用 Cookie 的状态管理 第 1 章 了解 Web 及网络基础1.1 使用 HTTP 协议访问 WebWeb 使用一种名为HTTP（HyperText Transfer Protocol，超文本传输协议 ）的协议作为规范，完成从客户端到服务器端等一系列运作流程。而协议是指规则的约定。可以说，Web 是建立在 HTTP 协议上通信的。 1.2 HTTP 的诞生 HTTP/0.9 HTTP 于 1990 年问世。那时的 HTTP 并没有作为正式的标准被建立。现在的 HTTP 其实含有 HTTP1.0 之前版本的意思，因此被称为 HTTP/0.9。 HTTP/1.0 HTTP 正式作为标准被公布是在 1996 年的 5 月，版本被命名为 HTTP/1.0，并记载于 RFC1945。虽说是初期标准，但该协议标准至今仍被广泛使用在服务器端。 RFC1945 - Hypertext Transfer Protocol — HTTP/1.0 HTTP/1.1 1997 年 1 月公布的 HTTP/1.1 是目前主流的 HTTP 协议版本。当初的标准是 RFC2068，之后发布的修订版 RFC2616 就是当前的最新版本。 RFC2616 - Hypertext Transfer Protocol — HTTP/1.1 1.3 网络基础 TCP/IP1.3.1 TCP/IP 协议族 TCP/IP是互联网相关的各类协议族的总称 像这样把与互联网相关联的协议集合起来总称为 TCP/IP。也有说法认为，TCP/IP 是指 TCP 和 IP 这两种协议。还有一种说法认为，TCP/ IP 是在 IP 协议的通信过程中，使用到的协议族的统称。 1.3.2 TCP/IP 的分层管理TCP/IP 协议族里重要的一点就是分层。TCP/IP 协议族按层次分别分为以下 4 层：应用层、传输层、网络层和数据链路层。 把 TCP/IP 层次化是有好处的。比如，如果互联网只由一个协议统筹，某个地方需要改变设计时，就必须把所有部分整体替换掉。而分层之后只需把变动的层替换掉即可。把各层之间的接口部分规划好之后，每个层次内部的设计就能够自由改动了。 应用层：决定了向用户提供应用服务时通信的活动。 TCP/IP 协议族内预存了各类通用的应用服务。比如，FTP（File Transfer Protocol，文件传输协议）和 DNS（Domain Name System，域名系统）服务就是其中两类。 HTTP 协议也处于该层。 传输层：对上层应用层，提供处于网络连接中的两台计算机之间的数据传输。 在传输层有两个性质不同的协议：TCP（Transmission Control Protocol，传输控制协议）和 UDP（User Data Protocol，用户数据报协议）。 网络层（又名网络互连层）：用来处理在网络上流动的数据包。 数据包是网络传输的最小数据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方。 数据包是网络传输的最小数据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方。 链路层（又名数据链路层、网络接口层）：用来处理连接网络的硬件部分。 包括控制操作系统、硬件的设备驱动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等物理可见部分（还包括连接器等一切传输媒介）。 硬件上的范畴均在链路层的作用范围之内。 1.3.3 TCP/IP 通信传输流 TCP/IP通信传输流 发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层时会把对应的首部消去。这种把数据信息包装起来的做法称为封装（encapsulate）。 HTTP协议请求中的封装过程 1.4 与 HTTP 关系密切的协议 : IP、TCP 和 DNS1.4.1 负责传输的 IP 协议 按层次分，IP（Internet Protocol）网际协议位于网络层 几乎所有使用网络的系统都会用到 IP 协议 TCP/IP 协议族中的 IP 指的就是网际协议 IP 协议的作用是把各种数据包传送给对方。而要保证确实传送到对方那里，则需要满足各类条件。其中两个重要的条件是 IP 地址和 MAC 地址（Media Access Control Address）。 IP 地址指明了节点被分配到的地址，MAC 地址是指网卡所属的固定地址。IP 地址可以和 MAC 地址进行配对。IP 地址可变换，但 MAC 地址基本上不会更改。 使用 ARP 协议凭借 MAC 地址进行通信 IP 间的通信依赖 MAC 地址。在网络上，通信的双方在同一局域网（LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的 MAC 地址来搜索下一个中转目标。这时，会采用 ARP 协议（Address Resolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。 ARP协议解析过程 1.4.2 确保可靠性的 TCP 协议 按层次分，TCP 位于传输层，提供可靠的字节流服务 所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。 而可靠的传输服务是指，能够把数据准确可靠地传给对方。 一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。 确保数据能到达目标 TCP 协议采用了三次握手（three-way handshaking）策略 握手过程中使用了 TCP 的标志（flag） —— SYN（synchronize） 和 ACK（acknowledgement） TCP协议的三次握手 发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。 若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。 1.5 负责域名解析的 DNS 服务 DNS（Domain Name System）服务和 HTTP 协议一样位于应用层 提供域名到 IP 地址之间的解析服务 DNS解析过程 1.6 各种协议与 HTTP 协议的关系 DNS 服务：解析域名至对应的IP地址 HTTP 协议：生成针对目标Web服务器的HTTP请求报文 TCP 协议：将请求报文按序号分割成多个报文段 IP 协议：搜索对方的地址，一边中转一边传送 TCP 协议：按序号以原来的顺序重组请求报文 请求的处理结果也同样利用TCP/IP协议向用户进行回传 各种协议与HTTP协议的关系 1.7 URI 和 URL URI（Uniform Resource Identifier）：统一资源标识符 URL（Uniform Resource Locator）：统一资源定位符 1.7.1 统一资源标识符URI 是 Uniform Resource Identifier 的缩写，RFC2396 分别对这 3 个单词进行了如下定义。 Uniform 规定统一的格式可方便处理多种不同类型的资源，而不用根据上下文环境来识别资源指定的访问方式。 另外，加入新增的协议方案（如 http: 或 ftp:）也更容易。 Resource 资源的定义是“可标识的任何东西”。除了文档文件、图像或服务（例如当天的天气预报）等能够区别于其他类型的，全都可作为资源。 另外，资源不仅可以是单一的，也可以是多数的集合体。 Identifier 表示可标识的对象。也称为标识符。 综上所述，URI 就是由某个协议方案表示的资源的定位标识符。协议方案是指访问资源所使用的协议类型名称。 “RFC3986：统一资源标识符（URI）通用语法”中列举了几种 URI 例子，如下所示。 ftp://ftp.is.co.za/rfc/rfc1808.txt http://www.ietf.org/rfc/rfc2396.txt ldap://[2001:db8::7]/c=GB?objectClass?one mailto:John.Doe@example.com news:comp.infosystems.www.servers.unix tel:+1-816-555-1212 telnet://192.0.2.16:80/ urn:oasis:names:specification:docbook:dtd:xml:4.1.2 1.7.2 URI 格式表示指定的 URI，要使用涵盖全部必要信息的绝对 URI、绝对 URL 以及相对 URL。相对 URL，是指从浏览器中基本 URI 处指定的 URL，形如 /image/logo.gif。 绝对URI的格式 登陆信息（认证） 指定用户名和密码作为从服务器端获取资源时必要的登录信息（身份认证）。此项是可选项。 服务器地址 使用绝对 URI 必须指定待访问的服务器地址。地址可以是类似 hackr.jp 这种 DNS 可解析的域名，或是 192.168.1.1 这类 IPv4 地址 名，还可以是 [0:0:0:0:0:0:0:1] 这样用方括号括起来的 IPv6 地址名。 服务器端口号 指定服务器连接的网络端口号。此项也是可选项，若用户省略则自动使用默认端口号。 带层次的文件路径 指定服务器上的文件路径来定位特指的资源。这与 UNIX 系统的文件目录结构相似。 查询字符串 针对已指定的文件路径内的资源，可以使用查询字符串传入任意参数。此项可选。 片段标识符 使用片段标识符通常可标记出已获取资源中的子资源（文档内的某个位置）。但在 RFC 中并没有明确规定其使用方法。该项也为可选项。 第 2 章 简单的 HTTP 协议2.1 HTTP 协议用于客户端和服务器端之间的通信请求访问文本或图像等资源的一端称为客户端，而提供资源响应的一端称为服务器端。 在两台计算机之间使用 HTTP 协议通信时，在一条通信线路上必定有一端是客户端，另一端则是服务器端。 有时候，按实际情况，两台计算机作为客户端和服务器端的角色有可能会互换。但就仅从一条通信路线来说，服务器端和客户端的角色是确定的，而用 HTTP 协议能够明确区分哪端是客户端，哪端是服务器端。 2.2 通过请求和相应的交换达成通信HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。 简单的HTTP请求示例 下面是从客户端发送给某个 HTTP 服务器端的请求报文中的内容。 GET /index.htm HTTP/1.1 Host: hackr.jp GET 表示请求访问服务器的类型，称为方法（method） /index.htm指明了请求访问的资源对象，称为请求URI（request-URI） HTTP/1.1 表示HTTP的版本号，用来提示客户端使用的 HTTP 协议功能 综合来看，这段请求内容的意思是：请求访问某台 HTTP 服务器上的 /index.htm 页面资源。 请求报文是由请求方法、请求 URI、协议版本、可选的请求首部字段和内容实体构成的。 请求报文的构成 接收到请求的服务器，会将请求内容的处理结果以响应的形式返回。 HTTP/1.1 200 OK Date: Tue, 10 Jul 2012 06:50:15 GMT Content-Length: 362 Content-Type: text/html &lt;html&gt; …… HTTP/1.1 表示服务器对应的HTTP版本 200 OK 表示请求的处理结果的状态码（status code）和原因短语（reason-phrase） Date 是首部字段（header filed）内的一个属性 之后的内容称为资源实体的主体（entity body） 响应报文基本上由协议版本、状态码、用以解释状态码的原因短语、可选的响应首部字段以及实体主体构成。 响应报文的构成 2.3 HTTP 是不保存状态的协议HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。 HTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。 2.4 请求 URI 定位资源HTTP 协议使用 URI 定位互联网上的资源。正是因为 URI 的特定功能，在互联网上任意位置的资源都能访问到。 当客户端请求访问资源而发送请求时，URI 需要将作为请求报文中的请求 URI 包含在内。指定请求 URI 的方式有很多。 URI为完整的请求URI 除此之外，如果不是访问特定资源而是对服务器本身发起请求，可以用一个 * 来代替请求 URI。下面这个例子是查询 HTTP 服务器端支持 的 HTTP 方法种类。 OPTIONS * HTTP/1.1 2.5 告知服务器意图的 HTTP 方法下面介绍 HTTP/1.1 中可使用的方法。 GET：获取资源 GET 方法用来请求访问已被 URI 识别的资源，指定的资源经服务器端解析后返回响应内容。 POST：传输实体主体 虽然用 GET 方法也可以传输实体的主体，但一般不用 GET 方法进行传输，而是用 POST 方法。 虽说 POST 的功能与 GET 很相似，但 POST 的主要目的并不是获取响应的主体内容。 PUT：传输文件 PUT 方法用来传输文件。就像 FTP 协议的文件上传一样，要求在请求报文的主体中包含文件内容，然后保存到请求 URI 指定的位置。 但是，鉴于 HTTP/1.1 的 PUT 方法自身不带验证机制，任何人都可以上传文件 , 存在安全性问题，因此一般的 Web 网站不使用该方法。 若配合 Web 应用程序的验证机制，或架构设计采用 REST（REpresentational State Transfer，表征状态转移）标准的同类 Web 网站，就可能会开放使用 PUT 方法。 HEAD：获得报文首部 HEAD 方法和 GET 方法一样，只是不返回报文主体部分。用于确认 URI 的有效性及资源更新的日期时间等。 DELETE：删除文件 DELETE 方法用来删除文件，是与 PUT 相反的方法。DELETE 方法按请求 URI 删除指定的资源。 但是，HTTP/1.1 的 DELETE 方法本身和 PUT 方法一样不带验证机制，所以一般的 Web 网站也不使用 DELETE 方法。当配合 Web 应用程序的验证机制，或遵守 REST 标准时还是有可能会开放使用的。 OPTIONS：询问支持的方法 OPTIONS 方法用来查询针对请求 URI 指定的资源支持的方法。 TRACE：追踪路径 TRACE 方法是让 Web 服务器端将之前的请求通信环回给客户端的方法。 发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器端就将该数字减 1，当数值刚好减到 0 时，就停止继续传输，最后接收到请求的服务器端则返回状态码 200 OK 的响应。 客户端通过 TRACE 方法可以查询发送出去的请求是怎样被加工修改 / 篡改的。这是因为，请求想要连接到源目标服务器可能会通过代理中转，TRACE 方法就是用来确认连接过程中发生的一系列操作。 但是，TRACE 方法本来就不怎么常用，再加上它容易引发 XST（Cross-Site Tracing，跨站追踪）攻击，通常就更不会用到了。 使用TRACE方法的请求·响应的例子 CONNECT：要求用隧道协议连接代理 CONNECT 方法要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信。主要使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加 密后经网络隧道传输。 2.6 使用方法下达命令向请求 URI 指定的资源发送请求报文时，采用称为方法的命令。 方法的作用在于，可以指定请求的资源按期望产生某种行为。方法中有 GET、POST 和 HEAD 等。 下表列出了 HTTP/1.0 和 HTTP/1.1 支持的方法。另外，方法名区分大小写，注意要用大写字母。 方法 说明 支持的 HTTP 协议版本 GET 获取资源 1.0、1.1 POST 传输实体主体 1.0、1.1 PUT 传输文件 1.0、1.1 HEAD 获得报文首部 1.0、1.1 DELETE 删除文件 1.0、1.1 OPTIONS 询问支持的方法 1.1 TRACE 追踪路径 1.1 CONNECT 要求用隧道协议连接代理 1.1 LINK 建立和资源之间的联系 1.1 UNLINE 断开连接关系 1.1 LINK 和 UNLINK 已被 HTTP/1.1 废弃，不再支持。 2.7 持久连接节省通信量HTTP 协议的初始版本中，每进行一次 HTTP 通信就要断开一次 TCP 连接。 以当年的通信情况来说，因为都是些容量很小的文本传输，所以即使这样也没有多大问题。可随着 HTTP 的普及，文档中包含大量图片的情况多了起来。 比如，使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问 HTML 页面资源的同时，也会请求该 HTML 页面里包含的其他资源。因此，每次的请求都会造成无谓的 TCP 连接建立和断开，增加通信量的开销。 2.7.1 持久连接为解决上述 TCP 连接的问题，HTTP/1.1 和一部分的 HTTP/1.0 想出了持久连接（HTTP Persistent Connections，也称为 HTTP keep-alive 或 HTTP connection reuse）的方法。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。 持久连接的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。另外，减少开销的那部分时间，使 HTTP 请求和响应能够更早地结束，这样 Web 页面的显示速度也就相应提高了。 2.7.2 管线化持久连接使得多数请求以管线化（pipelining）方式发送成为可能。从前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。 这样就能够做到同时并行发送多个请求，而不需要一个接一个地等待响应了。 比如，当请求一个包含 10 张图片的 HTML Web 页面，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。 2.8 使用 Cookie 的状态管理HTTP 是无状态协议，它不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。 保留无状态协议这个特征的同时又要解决类似的矛盾问题，于是引入了 Cookie 技术。Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。 Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。 服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。 在发生 Cookie 交互的场景中，HTTP 请求报文和响应报文的内容如下。 请求报文（没有 Cookie 信息的状态） GET /reader/ HTTP/1.1 Host: hackr.jp *首部字段内没有Cookie的相关信息 响应报文（服务器端生成 Cookie 信息） HTTP/1.1 200 OK Date: Thu, 12 Jul 2012 07:12:20 GMT Server: Apache ＜Set-Cookie: sid=1342077140226724; path=/; expires=Wed, 10-Oct-12 07:12:20 GMT＞ Content-Type: text/plain; charset=UTF-8 请求报文（自动发送保存着的 Cookie 信息） GET /image/ HTTP/1.1 Host: hackr.jp Cookie: sid=1342077140226724 🚩推荐阅读（由hexo文章推荐插件驱动）Linux 内核笔记 1：绪论Java 笔记 5：集合Java 笔记 6：异常、断言和日志网络协议笔记 4：传输层之 TCP 协议转载《一次完整的HTTP网络请求过程详解》转载《一次完整的HTTP网络请求过程详解》","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://abelsu7.top/categories/计算机网络/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"HTTP","slug":"HTTP","permalink":"https://abelsu7.top/tags/HTTP/"},{"name":"TCP","slug":"TCP","permalink":"https://abelsu7.top/tags/TCP/"}]},{"title":"历史上 12 位伟大的程序员","slug":"awesome-coder","date":"2018-09-28T09:06:48.000Z","updated":"2019-09-01T13:04:10.982Z","comments":true,"path":"2018/09/28/awesome-coder/","link":"","permalink":"https://abelsu7.top/2018/09/28/awesome-coder/","excerpt":"所谓程序员，是指那些能够创造、编写计算机程序的人。不论一个人是什么样的程序员，或多或少，他都在为我们这个社会贡献着什么东西。然而，有些程序员的贡献却超过了一个普通人一辈子能奉献的力量。这些程序员是先驱，受人尊重，他们贡献的东西改变了我们人类的整个文明进程。下面就让我们看看历史上12位伟大的程序员。","text":"所谓程序员，是指那些能够创造、编写计算机程序的人。不论一个人是什么样的程序员，或多或少，他都在为我们这个社会贡献着什么东西。然而，有些程序员的贡献却超过了一个普通人一辈子能奉献的力量。这些程序员是先驱，受人尊重，他们贡献的东西改变了我们人类的整个文明进程。下面就让我们看看历史上12位伟大的程序员。 1. 第一位计算机程序员：Ada Lovelace Ada Lovelace Ada Lovelace，原名August Ada Byron，数学爱好者，被后人公认为第一位计算机程序员。 在1842年至1843年期间，Ada花了9个月时间翻译了意大利数学家Luigi Federico Menabrea讲述Charles Babbage计算机分析机（Analytical Engine）的论文。在译文后面，她增加了许多注记，详细说明用该机器计算伯努利数（Bernoulli number）的方法，被认为是世界上第一个计算机程序。因此，Ada也被认为是世界上第一位程序员。 2. Linux之父：Linus Torvalds Linus Torvalds Linus Benedict Torvalds，著名的电脑程序员、黑客，Linux内核的发明人及该计划的合作者。Linux利用个人时间创造出了这套当今全球最流行的操作系统内核之一。他还发起了Git这个开源项目并成为主要开发者。 因为成功开发了Linux内核而荣获2014年计算机先驱奖。他的获奖创造了计算机先驱奖历史上的多个第一：第一次授予一位芬兰人；第一次授予一位“60后”（其实只差3天就是“70后”）；获奖成果是在学生时期取得的。 Linus在网上邮件列表中也以脾气火爆而著称。例如，有一次在和人争论Git为何不使用C++开发时，与对方用“bullshit”互骂。他更曾以“OpenBSD crowd is a bunch of masturbating monkeys”来称呼OpenBSD团队。 3. Pascal之父：Niklaus Wirth Niklaus Wirth Niklaus Emil Wirth生于瑞士温特图尔，瑞士计算机科学家。 在1963年到1967期间，他担任斯坦福大学的计算机科学部助理教授，之后又在苏黎世大学担任相同的职位。1968年，他担任苏黎世联邦理工学院的信息学教授，又往施乐帕洛阿尔托研究中心进修了两年。 他是好几种编程语言的主设计师，包括Algol W，Modula，Pascal，Modula-2，Oberon等。 他亦是Euler语言的发明者之一。1984年，他因发展了这些语言而获图灵奖。此外他还是Lilith电脑和Oberon系统的设计和运行队伍的重要成员。 4. 苹果联合创始人：Steve Wozniak Steve Wozniak Stephen Gary Wozniak，美国电脑工程师，曾与Steve Jobs合伙创立苹果公司。 Wozniak在1970年代中期创造出苹果一号和苹果二号，苹果二号风靡普及后成为1970年代及1980年代初期销量最佳的个人电脑，他本人也被誉为是使电脑从“旧时王谢堂前燕”到“飞入寻常百姓家”的工程师。 5. Java之父：James Gosling James Gosling James Gosling，出生于加拿大，软件专家，Java编程语言的共同创始人之一，被公认为“Java之父”。 在12岁时，Gosling已经能设计电子游戏机，帮忙邻居修理收割机。1981年开发在Unix上运行的类Emacs编辑器Gosling Emacs（以C语言编写，使用Mocklisp作为扩展语言）。1983年获得卡耐基·梅隆大学计算机科学博士学位。毕业后到IBM工作，设计IBM第一代工作站NeWS系统，但不受重视，后来转投Sun公司。1990年，与Patrick Naughton和Mike Sheridan等人合作“绿色计划”，开发了一套语言Oak，后改名为Java。1994年底，James Gosling在硅谷召开的大会上展示Java程序。2000年，Java成为世界上最流行的电脑语言。 6. B语言、C语言和Unix创始人：Ken Thompson Ken Thompson Ken Thompson生于美国新奥尔良，计算机科学学者与软件工程师。他与Dennis Ritchie一同设计了B语言、C语言，并创建了Unix和Plan 9操作系统。Thompson也是编程语言Go的共同作者，与Dennis Ritchie同为1983年图灵奖得主。 Ken Thompson的贡献还包括发明正则表达式，开发早期的电脑文字编辑器QED与ed，定义UTF-8编码，以及开发电脑象棋。 7. PHP之父：Rasmus Lerdorf Rasmus Lerdorf Rasmus Lerdorf出生于加拿大，并在早年搬到丹麦。1994年，Rasmus开发了PHP，刚开始只是一个简单的用Perl语言编写的程序，用来统计他自己网站的访问者。后来又用C语言重新编写，并可以访问数据库。 在1995年以Personal Home Page Tools（PHP Tools）开始对外发表第一个版本，Lerdorf写了一些介绍此程序的文档，并且发布了PHP1.0。在这早期的版本中，提供了访客留言本、访客计数器等简单的功能。以后越来越多的网站使用了PHP，并且强烈要求增加一些特性，比如循环语句和数组变量等等。 在新的成员加入开发行列之后，在1995年中，PHP2.0发布了。第二版定名为PHP/FI(Form Interpreter)。PHP/FI加入了对MySQL的支持，从此建立了PHP在动态网页开发上的地位。 8.《C程序设计语言》作者：Brian Kernighan Brian Kernighan Brian Wilson Kernighan是一位加拿大计算机科学家。在贝尔实验室，他与Unix的创造者Thompson以及C语言之父Dennis Ritchie一起工作，同时他也是开发Unix的主要贡献者。他是AWK和AMPL编程语言的作者之一，AWK中的K说的就是Kernighan。同时，它也是《C程序设计语言》的作者之一，他与C语言的发明人Dennis Ritchie共同合作了这本书，该书被很多人简称为“K&amp;R C”，K&amp;R就是两人名字的缩写。Brian Kernighan现在是普林斯顿大学计算机学院的教授，同时也是本科学部的代表。 9. Ruby脚本语言的开创者：松本行弘（Yukihiro Matsumoto） 松本行弘 松本行弘，日本计算机科学家、软件工程师，筑波大学毕业，在1995年首次发布Ruby脚本语言的第一个版本。 Ruby是一种功能强大的面向对象的脚本语言，它综合了Perl，Python，Java等语言的特点写成，有强大的文字处理能力，简单的语法，完全的面向对象。同时，Ruby是解释型语言，不需编译即可快捷地编程，擅长于文本处理、系统管理等任务。 10. C++之父：Bjarne Stroustrup Bjarne Stroustrup Bjarne Stroustrup生于1950年，丹麦计算机科学家，最著名的便是创造并开发了如今被广泛使用的C++编程语言。Bjarne是哥伦比亚大学的客座教授，目前在摩根士丹利工作。 用他自己的话来说，Bjarne“发明了C++，写下了它的早期定义并做出了首个实现……选择制定了C++的设计标准，设计了C++主要的辅助支持环境，并负责处理C++标准委员会的扩展提案。”此外，他还写了一本《C++程序设计语言》，被许多人认为是C++的范本经典，最新的第四版于2013年出版，并囊括了C++ 11所引进的一些新特性。 11. C语言和Unix之父：Dennis Ritchie Dennis Ritchie Steve Jobs和Dennis Ritchie是在同年同月离世的。之后每年的这段时间，很多媒体都会纪念Jobs，但很少会提到Dennis Ritchie。 如果没有丹尼斯·里奇（Dennis Ritchie），就不会有我们现在所熟知的现代计算。他是C语言之父和UNIX操作系统的联合发明人。 Dennis Ritchie with Doug McIlroy (left) in May 2011 不可否认，乔布斯带给我们世上从未见过的创新和标志性的产品，还有一大批对他顶礼膜拜的狂热消费者和终端用户。诸如此类的事情可能再也看不到了。 但是苹果和乔布斯以及很多其他公司所创造的“神奇的”产品，和所有现在我们了解和写在现代计算里的东西，都要归功于丹尼斯·里奇，他于2011年10月12号离开人世，享年70岁。 C语言是里奇在1969-1973年间开发的，他被认为是第一个真正意义上可移植的现代编程语言。自它诞生差不多45年以来，它已经被移植到几乎每一个出现过的系统架构和操作系统上。 除此之外，里奇还是UNIX操作系统的联合发明人。当然UNIX的原型是用汇编语言编写的，到七十年代早期就完全用C重写了。看下面这张图，可以更好的理解“Unix家族”。 Unix 家族 关于Dennis Ritchie的其他成就及贡献，推荐阅读以下两篇文章： 丹尼斯·里奇，那个给乔布斯提供肩膀的巨人 | 果壳网 纪念C语言之父丹尼斯·里奇离世 6 周年 | 开源中国 最后，用Ritchie在贝尔实验室的同事兼好友Brian Kernighan的评价做个总结：“牛顿说他是站在巨人的肩膀上，如今，我们都站在里奇的肩膀上。” 这句话，应该是对Dennis Ritchie的一生最有力也是最中肯的评价。 12. Python之父：Guido van Rossum Guido van Rossum Guido van Rossum是一名荷兰的计算机程序员，于1982年获得了阿姆斯特丹大学的数学和计算机科学的硕士学位，并于同年加入一个多媒体组织CWI，做调研员。他作为Python编程语言的作者而为人熟知。在Python社区，Guido被公认为终身仁慈独裁者（Benevolent Dictator For Life，BDFL），意思是他仍然关注Python的开发进程，并在必要的时刻做出决定。 1991年初，Python发布了第一个公开发行版。Guido原居荷兰，1995年移居到美国，并遇到了他现在的妻子。在2003年初，Guido和他的家人，包括他2001年出生的儿子Orlijn一直居住在华盛顿州北弗吉尼亚的郊区，随后他们搬迁到硅谷。从2005年开始Guido就职于Google，其中有一半时间是花在Python上。而现在Guido在为Dropbox工作。 不负责任的出处考据 关于Guido还有一个著名的段子：Guido van Rossum 去 Google 应聘，简历只写了三个词「I wrote Python」。当然事后证明这只是为了调侃Google面试流程冗长复杂，事实上在他2005年加入Google时，Google内部已经有相当一部分工程师在使用Guido发明的Python了，而Google请Guido就是冲着Python去的——条件是允许他用一半的工作时间来维护Python, 版权归他自己。 Google +上Guido的发帖，LOL 另外Google +上Guido自己也发帖称别再找我应聘Python开发，也是很搞笑了…… Notes: To Do Jeff Dean Donald Kruth 楼天城 章亦春 章文嵩 云风 许式伟 - 七牛 CEO 参考文章 历史上最伟大的12位程序员 | Python之禅 Ada Lovelace | 维基百科 Ada Lovelace：19世纪的数学奇女子——计算机之母 | 电子技术设计 Ada Lovelace, the First Tech Visionar | The New Yorker Ada Byron, Lady Lovelace (1815-1852) | Yale CS 苹果联合创始人沃兹尼亚克的那些成就 | 腾讯科技 对Unix40岁的一些感想 | 阮一峰的网络日志 Unix英烈传：图文细数十五位计算先驱 | Linux公社 丹尼斯·里奇，那个给乔布斯提供肩膀的巨人 | 果壳网 纪念C语言之父丹尼斯·里奇离世 6 周年 | 开源中国 世界十大黑客 | 百度百科 务实至上：“PHP之父”Rasmus Lerdorf访谈录 | ITeye C/Unix思想后隐藏的巨人——Brian Kernighan | 图灵社区 [英]Brian W. Kernighan：我与CS的半个世纪（图灵访谈）| 图灵社区 真相暴露帖：本人采访Ruby语言创始人松本行弘（Matz）先生 | 果壳日志 Bjarne Stroustrup | 维基百科 Bjarne Stroustrup’s homepage Guido van Rossum - Personal Home Page 代码世界值得你珍藏的 72 张面孔 | 阿里巴巴中间件 🚩推荐阅读（由hexo文章推荐插件驱动）再见Murex程序员最好的投资：数据结构","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"程序员","slug":"程序员","permalink":"https://abelsu7.top/tags/程序员/"}]},{"title":"【转】Python中排序方法的十条用法总结","slug":"python-sort","date":"2018-09-28T06:45:15.000Z","updated":"2019-09-01T13:04:11.614Z","comments":true,"path":"2018/09/28/python-sort/","link":"","permalink":"https://abelsu7.top/2018/09/28/python-sort/","excerpt":"Python中sorted函数用于对集合进行排序，它的功能非常强大，今天来介绍一下sorted的各种使用场景。 这里说的集合是对可迭代对象的一个统称，他们可以是列表、字典、set、甚至是字符串。","text":"Python中sorted函数用于对集合进行排序，它的功能非常强大，今天来介绍一下sorted的各种使用场景。 这里说的集合是对可迭代对象的一个统称，他们可以是列表、字典、set、甚至是字符串。 1、默认情况，sorted函数将按列表升序进行排序，并返回一个新列表对象，原列表保持不变，最简单的排序。 &gt;&gt;&gt; nums = [3,4,5,2,1] &gt;&gt;&gt; sorted(nums) [1, 2, 3, 4, 5] 2、降序排序。如果要按照降序排列，只需指定参数reverse=True即可。 &gt;&gt;&gt; sorted(nums, reverse=True) [5, 4, 3, 2, 1] 3、如果要按照某个规则排序，则需指定参数key。key是一个函数对象，例如对字符串构成的列表进行排序，想要按照字符串长度排序的话： &gt;&gt;&gt; chars = [&#39;Andrew&#39;, &#39;This&#39;, &#39;a&#39;, &#39;from&#39;, &#39;is&#39;, &#39;string&#39;, &#39;test&#39;] &gt;&gt;&gt; sorted(chars, key=len) [&#39;a&#39;, &#39;is&#39;, &#39;from&#39;, &#39;test&#39;, &#39;This&#39;, &#39;Andrew&#39;, &#39;string&#39;] len是内建函数，sorted函数在排序的时候会用len去获取每个字符串的长度来排序。 4、如果是一个复合的列表结构，例如由元组构成的列表，要按照元组中的第二个元素排序，那么可以用lambda定义一个匿名函数。 &gt;&gt;&gt; students = [(&#39;zhang&#39;, &#39;A&#39;), (&#39;li&#39;, &#39;D&#39;), (&#39;wang&#39;, &#39;C&#39;)] &gt;&gt;&gt; sorted(students, key=lambda x: x[1]) [(&#39;zhang&#39;, &#39;A&#39;), (&#39;wang&#39;, &#39;C&#39;), (&#39;li&#39;, &#39;D&#39;)] 这里将按照字母A-C-D的顺序排列。 5、如果要排序的元素是自定义类，例如Student类按照年龄来排序，则可以写成： &gt;&gt;&gt; class Student: def __init__(self, name, grade, age): self.name = name self.grade = grade self.age = age def __repr__(self): return repr((self.name, self.grade, self.age)) &gt;&gt;&gt; student_objects = [ Student(&#39;john&#39;, &#39;A&#39;, 15), Student(&#39;jane&#39;, &#39;B&#39;, 12), Student(&#39;lily&#39;, &#39;A&#39;, 12), Student(&#39;dave&#39;, &#39;B&#39;, 10), ] &gt;&gt;&gt; sorted(student_objects, key=lambda t:t.age) [(&#39;dave&#39;, &#39;B&#39;, 10), (&#39;jane&#39;, &#39;B&#39;, 12), (&#39;lily&#39;, &#39;A&#39;, 12), (&#39;john&#39;, &#39;A&#39;, 15)] 6、和数据库的排序一样，sorted也可以根据多个字段来排序。例如要先根据age排序，如果age相同则根据grade排序，则可以使用元组： &gt;&gt;&gt; sorted(student_objects, key=lambda t:(t.age, t.grade)) [(&#39;dave&#39;, &#39;B&#39;, 10), (&#39;lily&#39;, &#39;A&#39;, 12), (&#39;jane&#39;, &#39;B&#39;, 12), (&#39;john&#39;, &#39;A&#39;, 15)] 7、前面碰到的排序场景都是建立在两个元素可以互相比较的前提下，例如数值按大小比较，字母按顺序比较。如果遇到本身是不可比较的，需要我们自己来定义比较规则的情况如何处理呢？ 举个简单的例子： &gt;&gt;&gt; nums = [2, 1.5, 2.5, &#39;2&#39;, &#39;2.5&#39;] &gt;&gt;&gt; sorted(nums) TypeError: &#39;&lt;&#39; not supported between instances of &#39;str&#39; and &#39;int&#39; 一个整数列表中，可能有数字、字符串，在Python 3中，字符串和数值是不能比较的，而Python 2中任何类型都可以比较。这是两个版本中一个很大的区别。 # python 2.7 &gt;&gt;&gt; &quot;2.5&quot; &gt; 2 True # python 3.6 &gt;&gt;&gt; &quot;2.5&quot; &gt; 2 TypeError: &#39;&gt;&#39; not supported between instances of &#39;str&#39; and &#39;int&#39; 我们需要使用functools模块中的cmp_to_key来指定比较函数是什么。 import functools def compare(x1, x2): if isinstance(x1, str): x1 = float(x1) if isinstance(x2, str): x2 = float(x2) return x1 - x2 &gt;&gt;&gt; sorted(nums, key=functools.cmp_to_key(compare)) [1.5, 2, &#39;2&#39;, 2.5, &#39;2.5&#39;] 8、关于sorted函数，Python 2和Python 3之间的区别是Python 2中的sorted可以指定cmp关键字参数。就是说当遇到需要自定义比较操作的数据时，可以通过cmp=compare来实现，不需要像Python 3一样还要导入functools.cmp_to_key实现。 nums = [2, 1.5, 2.5, &#39;2&#39;, &#39;2.5&#39;] def compare(x1, x2): if isinstance(x1, str): x1 = float(x1) if isinstance(x2, str): x2 = float(x2) return 1 if x1 - x2 &gt; 0 else -1 if x1 - x2 &lt; 0 else 0 &gt;&gt;&gt; sorted(nums, cmp=compare) [1.5, 2, &#39;2&#39;, 2.5, &#39;2.5&#39;] 其实，在Python 2中，上面这种情况就算不指定cmp，默认也会按照这种方式排序。需要记住的是，在Python 2中，任何类型都可以比较，而Python 3只有同类型数据可以比较。 9、对于集合构成的列表，有一种更高效的方法指定这个key： &gt;&gt;&gt; from operator import itemgetter &gt;&gt;&gt; sorted(students, key=itemgetter(1)) [(&#39;zhang&#39;, &#39;A&#39;), (&#39;wang&#39;, &#39;C&#39;), (&#39;li&#39;, &#39;D&#39;)] 10、同样的，对于自定义类，也有一种更高效的方法指定key： &gt;&gt;&gt; from operator import attrgetter &gt;&gt;&gt; sorted(student_objects, key=attrgetter(&#39;age&#39;)) [(&#39;dave&#39;, &#39;B&#39;, 10), (&#39;jane&#39;, &#39;B&#39;, 12), (&#39;john&#39;, &#39;A&#39;, 15)] 如果参与排序的字段有两个怎么办？可以这样操作： &gt;&gt;&gt; sorted(student_objects, key=attrgetter(&#39;grade&#39;, &#39;age&#39;)) [(&#39;john&#39;, &#39;A&#39;, 15), (&#39;dave&#39;, &#39;B&#39;, 10), (&#39;jane&#39;, &#39;B&#39;, 12)] 参考文章 史上最全关于sorted函数的10条总结 | Python之禅 Python中排序方法的十条用法总结 | 进击的Coder 🚩推荐阅读（由hexo文章推荐插件驱动）Python 速查使用 pingtop 同时 ping 多台服务器Leetcode 118. 杨辉三角使用virtualenv创建隔离环境奇异值分解的原理与使用","categories":[{"name":"Python","slug":"Python","permalink":"https://abelsu7.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://abelsu7.top/tags/Python/"}]},{"title":"Linux 归档工具 tar 命令详解","slug":"linux-tar","date":"2018-09-27T08:59:24.000Z","updated":"2019-09-01T13:04:11.511Z","comments":true,"path":"2018/09/27/linux-tar/","link":"","permalink":"https://abelsu7.top/2018/09/27/linux-tar/","excerpt":"Updating… XKCD上关于tar的一则漫画 Linux下的压缩包，最常见的格式是.tar.gz以及.tar.bz2。而Linux平台最常用的压缩解压命令就是tar命令，相信不少人都有面对不同格式压缩包的各种参数抓狂的经历，今天就来总结学习一下tar命令的基本操作。 tar -zxvf ***.tar.gz tar -xvf ***.gz # tar.xz xz -d ***.tar.xz tar -xvf ***.tar # 或直接 tar -xvJf ***.tar.xz","text":"Updating… XKCD上关于tar的一则漫画 Linux下的压缩包，最常见的格式是.tar.gz以及.tar.bz2。而Linux平台最常用的压缩解压命令就是tar命令，相信不少人都有面对不同格式压缩包的各种参数抓狂的经历，今天就来总结学习一下tar命令的基本操作。 tar -zxvf ***.tar.gz tar -xvf ***.gz # tar.xz xz -d ***.tar.xz tar -xvf ***.tar # 或直接 tar -xvJf ***.tar.xz 什么是tar 参考文章 tar解压缩命令详解 | CSDN Linux中tar命令 | CSDN tar命令详解 | CSDN Tar | 维基百科 GNU Tar Manual | man7.org tar命令 | Linux命令大全 Linux tar命令 | 菜鸟教程 GNU Tar | GNU Operating System TAR | xkcd 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"tar","slug":"tar","permalink":"https://abelsu7.top/tags/tar/"}]},{"title":"程序员学习之路","slug":"how-to-learn-coding","date":"2018-09-21T02:50:50.000Z","updated":"2019-09-01T13:04:11.292Z","comments":true,"path":"2018/09/21/how-to-learn-coding/","link":"","permalink":"https://abelsu7.top/2018/09/21/how-to-learn-coding/","excerpt":"更新中… 程序员学习之路","text":"更新中… 程序员学习之路 目录 目录 1 基础知识 1-1 编程语言 1-1-1 C/C++ 1-1-2 Java 1-1-3 Shell 1-1-4 Go 1-1-5 Python 1-1-6 JavaScript 1-1-7 SQL 1-2 数据结构 1-3 算法 1-3-1 刷题OJ 1-3-2 排序 1-3-3 Leetcode题解 1-4 计算机网络 1-5 操作系统 1-6 计算机组成原理 1-7 数据库 1-7-1 MySQL 1-7-2 Redis 1-7-3 MariaDB 1-8 版本控制 1-8-1 Git 1-9 设计模式 2 技术方向 2-1 前端 2-1-1 教程 2-1-2 图标 2-1-3 框架 2-1-4 资源 2-2 后端 2-3 移动端 2-3-1 Android 2-3-2 Flutter 2-3-3 微信小程序 2-4 Linux 2-4-1 教程 2-4-2 资源 2-4-3 工具 2-5 云计算/虚拟化 2-5-1 虚拟化 2-5-2 容器技术 2-5-3 云计算 2-5-4 分布式架构 2-5-5 微服务 2-6 机器学习与人工智能 2-7 运维 3 工具技能 3-1 画图 3-2 写文档 3-3 做笔记 3-4 建站 3-4-1 Hexo 3-4-2 Jekyll 3-4-3 VuePress 3-4-4 WordPress 3-4-5 Bitcron 3-4-6 Grav 3-4-7 Hugo 3-5 私有云盘 3-6 CDN加速 3-7 开源镜像站 3-8 IDE 3-8-1 VS Code 3-9 图片处理 3-10 各种排名 3-11 装机刷系统 3-12 追剧 3-13 下载工具 3-14 格式转换 3-15 网址导航 4 资源收集 4-1 博客 4-2 技术文章 4-3 技术社区 4-4 微信公众号 4-5 Github Awesome系列 4-6 各种插件 4-7 必备软件 跨平台 Windows Mac Linux 4-8 面试 4-9 简历 4-10 漫画 5 最近阅读 1 基础知识1-1 编程语言 Programming Notes for Professionals books | GoalKicker.com 1-1-1 C/C++ 谷歌C++编程规范 C语言总结 — 知识点导论图 | CSDN yafeilinux | Qt开源社区 1-1-2 Java教程 Java Core Sprout: basic, concurrent, algorithm interviews - Java工程师面试指南 | Github JavaGuide - Java学习+面试指南 | Github 框架 Netty 规范 阿里巴巴Java开发手册 文章 Java 和 Python：哪一个更适合你？| 计蒜客 JVM难学？那是因为你没认真看完这篇文章 | 51CTO Ubuntu16.04 LTS的Java环境配置总结 | CSDN 我终于搞清楚了和String有关的那点事儿 | Hollis Java开发必会的Linux命令 | Hollis Java面试题史上最强整理 | Java技术栈 1-1-3 Shell Linux命令大全 Shell正则表达式 | Linux命令大全 Linux Shell脚本攻略 | Linux命令大全 1-1-4 Go 创建最小的Go docker 镜像 | 鸟窝 1-1-5 Python Java 和 Python：哪一个更适合你？| 计蒜客 PyQt5 tutorial | fman build system Python and Qt: simplified! | fman build system 1-1-6 JavaScript1-1-7 SQL1-2 数据结构 看图轻松理解数据结构与算法系列(B+树) | 掘金 1-3 算法 KMP 算法 | 衡仔的技术小窝 JavaScript 算法与数据结构 | Github 学习算法，看这篇就够了-书籍推荐 | Leetcode 领扣 面试 | 2019 校园招聘算法面试概率题 | Leetcode 领扣 1-3-1 刷题OJ Leetcode Project Euler 牛客网 剑指Offer编程练习 | 牛客网 计蒜客 各大刷题网站OJ | CSDN Virtual Judge 1-3-2 排序 十大经典排序算法（动图演示，收藏好文）| 算法与数据结构 排序算法总结（多图）| 芋道源码 1-3-3 Leetcode题解 gf&amp;zjの盗梦空间 - Leetcode题解 1-4 计算机网络 DNS 深度理解 [ 一 ] | klion’s blog Nginx 学习 —— 正向代理与反向代理 | 芋道源码 1-5 操作系统 OS Tutorial - How to create an OS from scratch | Github 1-6 计算机组成原理1-7 数据库1-7-1 MySQL MySQL双主复制 MySQL 主从复制 完全上手指南 | klion’s blog 去 BAT 面试，总结了这 55 道 MySQL 面试题！| Java技术栈 1-7-2 Redis Try Redis Try Redis Redis云端架构深入浅出 | 腾讯云+社区 Nosql简介 Redis，Memchche,MongoDb的区别 | 博客园 关系型和非关系型数据库的区别? | CSDN 1-7-3 MariaDBMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。 1-8 版本控制1-8-1 Git Github Status | 监控Github状态 分享 | 一些有意思的 Github 项目 | Leetcode 领扣 permission denied (publickey)问题的解决 和 向github添加ssh key | CSDN git出现错误：Permission denied (publickey).解决方法 | CSDN 解决方案 git@github.com出现Permission denied (publickey) | CSDN git ssh Permission denied | CSDN Git教程 | 廖雪峰 SourceTree lazygit | simple terminal UI for git commands 1-9 设计模式 java-design-patterns | Github 2 技术方向2-1 前端2-1-1 教程 w3schools.com | THE WORLD’S LARGEST WEB DEVELOPER SITE W3School 在线教程 Bootstrap 中文网 The figure &amp; figcaption elements | HTML5 Doctor 2-1-2 图标 Font Awesome IconFont Favicon.ico Generator 2-1-3 框架 Electron | 跨平台桌面应用框架 NUXT | Vue.js通用应用框架 Ant Design | 企业级产品设计语言，基于React Chart.js | JavaScript charting for designers &amp; developers Chartist.js | Simple Responsive Charts D3.js | Data-Driven-Documents Storybook | The UI Development Environment GoJS | Interactive JavaScript Diagrams in HTML Material-UI | React components that implement Google’s Material Design 2-1-4 资源 Codrops | Useful resouces for Front-end Caption Hover Effects | Codrops CaptionHoverEffects | Github Finec – Html Theme for Designers &amp; Photographers | themeraid 轻松建站神器！15个超精致的Bootstrap网站模板下载 | 优设-UISDC 在线PS vuegg | vuejs GUI generator RxDB | A realtime Database for the Web Awsome-Front-End-learning-resource - 前端资源汇总仓库 | Github 大前端工具集 | Github Material Design Palette Material Design Palette Yarn | 依赖管理工具 WebIDE社区版 | Coding.net WebIDE社区版 JavaScript 中是如何比较两个元素是否 “相同” 的 | Github 2-2 后端 OpenResty最佳实践 | Gitbook 2-3 移动端2-3-1 Android Loop Habit Tracker Loop Habit Tracker | Github Android Studio 打包时 Signature Version 选择 V1 V2 说明 | 博客园 Android：这是一份很详细的Socket使用攻略 | CSDN | Carson_Ho，何家成，华工 Try Kotlin | JetBrains 2-3-2 Flutter2-3-3 微信小程序2-4 Linux2-4-1 教程 一言不合就改成 777 权限？会出人命的！-崔庆才 | 掘金 在Linux的环境安装shadowsocksR客户端 | Django’s Blog Linux上的10个超级方便的Bash别名 | 云技术之家 简明 VIM 练级攻略 | 酷壳 一起来说 Vim 语 | 简书 Nova 带你快速入门 Vim | LeetCode领扣 2-4-2 资源 2018 最佳 Linux 发行版排行榜 | 开源工厂 The Linux Kernel Archives The Linux Programming Interface | man7.org Linux命令大全搜索工具 | Github Linux命令大全搜索工具 | 在线版 vim-web - 搞得像IDE一样的Vim，安装配置自己的Vim | Github 2-4-3 工具Systemd Systemd 入门教程：命令篇 | 阮一峰的网络日志 Lsyncd rsync命令 | Linux命令大全 Lsyncd - Live Syncing (Mirror) Daemon lsyncd+rsync 实现实时自动同步 | 开源中国 利用lsyncd和rsync实现实时文件同步 | 简书 用Lsyncd实现本地和远程服务器之间实时同步 | 挖站否 Lsyncd：负载均衡之后，服务器的文件双向同步 | CSDN CentOS 7.2 部署Rsync + Lsyncd服务实现文件实时同步/备份 （一）| 博客园 CentOS 7.2 部署Rsync + Lsyncd服务实现文件实时同步/备份 （二）| 博客园 CentOS 7.2 部署Rsync + Lsyncd服务实现文件实时同步/备份 （三）| 博客园 比较不错的几篇 如何实时同步大量小文件 | 内存·溢出 使用lsyncd同步文件目录 | Clavin Li’s Blog lsyncd + rsync 实时同步海量小文件 | klion’s blog 服务安全 [ rsync ] | klion’s blog inotify + rsync 快速实现 ‘小剂量’ 实时同步 | klion’s blog lsyncd实时同步搭建指南——取代rsync+inotify | Sean’s Notes lsyncd 实时同步 - 几大实时同步工具比较 | 博客园 Lsyncd：负载均衡之后，服务器的文件双向同步 | CSDN Lsyncd搭建同步镜像-用Lsyncd实现本地和远程服务器之间实时同步 | 博客园 大神教你：Lsyncd复制并实时同步到远程服务器 | CSDN VNC CentOS 7安装TigerVNC Server | CSDN NFS CentOS 6 配置NFS服务 | Clavin Li’s Blog FTP Pure-FTPd 2-5 云计算/虚拟化51CTO | 虚拟化频道 什么是存储虚拟化？它与软件定义存储有何区别？ 存储虚拟化和服务器虚拟化紧密相关 VDI桌面虚拟化四大协议—虚拟化魔鬼象限 桌面虚拟化：集中还是分布？ 了解用户才能选择正确的VDI用例 VDI与IDV 并非几个字母组合这么简单 说一说虚拟化绕不开的IO半虚拟化 聊一聊虚拟化基础知识 虚拟化技术在移动便携设备中的应用 你不需要服务虚拟化的10个原因？ VPS虚拟化架构OpenVZ、KVM、Xen、Hyper-V的区别 浅谈GPU虚拟化技术：GPU图形渲染虚拟化 为什么要选择虚拟化？它在网管工作中有什么效果？虚拟化技术在各厂商的对比！ 虚拟化：我们如何看历史和现状 容量管理在虚拟化环境中至关重要 桌面虚拟化与服务器虚拟化的区别 Docker容器与虚拟机有什么区别？ IDV和VDI，桌面虚拟化选哪种好？ 漫谈虚拟化之三-虚拟化类型 虚拟化技术深度解密（下） 我们来谈谈虚拟化备份 云存储的核心技术：虚拟化存储 漫谈虚拟化之一虚拟化综述 桌面虚拟化的最佳业务模型 云原生桌面：虚拟桌面的解构与重新定义 VDI与DaaS：如何抉择？ 虚拟化存储逆袭传统 分布式成云中主流 虚拟化和云计算：孟不离焦 焦不离孟 无服务器vs.容器：无服务器将会获胜 网络虚拟化及网络功能虚拟化介绍 虚拟化是由虚拟镜像组成的，如何创建基本的虚拟镜像？ 云计算存储虚拟化技术三个层次上的实现 云原生桌面：虚拟桌面的解构与重新定义 2-5-1 虚拟化 微软虚拟化文档 微软虚拟化文档 .Net 大户的选择： Windows Container 在携程的应用 BUILD AND RUN YOUR FIRST DOCKER WINDOWS SERVER CONTAINER | docker blog 如何在 Docker 容器里装 windows，并且访问系统桌面？| V2EX Docker: Ubuntu使用VNC运行基于Docker容器里的桌面系统 | CSDN CentOS7 haproxy+keepalived实现高可用集群搭建 | CSDN 使用 PXE 環境建置區域網路安裝伺服器系統 | 鸟哥的Linux私房菜 在CentOS7实现PXE支持系统安装 | 阿里云栖社区 QEMU-KVM (KVM连载)4.3.2 QEMU-IMG命令详解 | 笑遍世界 差分磁盘 差分磁盘（Differencing disks）| 51CTO qemu之差分盘（差异磁盘）| CSDN VBox快照、VM快照和VPC差分磁盘之比较及差分盘详解 | 卡饭论坛 声卡模拟 QEMU下虚拟机内的声卡模拟方法总结 | CSDN 2-5-2 容器技术 Docker文档 Docker中文社区 Docker 和 Kubernetes 从听过到略懂：给程序员的旋风教程 | 1 Byte 浙江大学SEL实验室 PouchContainer | 阿里开源富容器平台 使Kubernetes管理更容易的7个工具 | 开源最前线 谷歌开源 Java 容器化工具，名字就叫——Jib | 开源最前线 从 Docker 到 Kubernetes 中的容器网络图书资料分享 | Jimmy Song Kubernetes Handbook | Jimmy Song Kubernetes Handbook——Kubernetes中文指南/云原生应用架构实践手册 Kubernetes中文社区 | 中文文档 容器云平台 青云 灵雀云 2-5-3 云计算公有云 Amazon AWS免费套餐 Google Cloud Microsoft Azure 阿里云 腾讯云 LeanCloud 金山云 华为云 京东云 七牛云 灵雀云 青云QingCloud 又拍云 | 加速在线服务 ZStack | 混合云、私有云 文章教程 用 CloudStack 配置和管理一个简单云 | IBM developerWorks 2-5-4 分布式架构 图解分布式架构的演进 | Java技术栈 keepalived + nginx 初步实现高可用 | klion’s blog 2-5-5 微服务 Istio Naftis | 小米开源 Istio 管理面版 小米正式开源 Istio 管理面板 Naftis | 开源最前线 2-6 机器学习与人工智能 TensowFlow 机器学习速成课程 | Google 100 Days of ML Coding | Github Machine Learning | Coursera 台大-李宏毅（B站有） 深度学习pdf 2-7 运维 SpeedTest - 云测速 宝塔面版 - 简单好用的Linux/Windows服务器管理面版 UptimeRobot | Downtime Happens. Get Notified! 技术选型 | 柒’s Blog 如何使用siege测试服务器性能 | 博客园 3 工具技能3-1 画图 StarUML 百度脑图 ProcessOn | 免费在线作图，实时协作 Mermaid | Gitbook Mermaid Live Editor Lucidchart | Online Diagram Software &amp; Visual Solution Graphviz - Graph Virtualization Software PlantUML - Open-source tool for drawing UML diagrams PlantUML Web Server Xmind Microsoft Office Visio 3-2 写文档 Docsify | 强烈推荐 Gitbook | 可下载Editor客户端 VuePress | Vue驱动的静态网站生成器 看云KanCloud | 专注于文档在线创作、协作和托管 MkDocs Material for MkDocs Read the Docs docz | It has never been so easy to document your things! LeanCloud Docs | Github 徽章 Badgen | Fast badge generating service. Shields.io | SVG badges 3-3 做笔记 Typora | 美观优雅的Markdown编辑器 StackEdit | In-browser Markdown editor Cmd Markdown编辑阅读器 | 作业部落 Md2All | 颜家大少 VNote | Vim风格的Markdown编辑器 Overleaf | Online LaTeX Editor Editor.md | 开源在线Markdown编辑器 有道云笔记 印象笔记 Dillinger 3-4 建站 Gravatar | A Global Recognized Avatar 批量下载与空间备份 | 七牛开发者中心 命令行工具 qshell | 七牛开发者中心 qshell | Github 3-4-1 Hexo主题 Minos Hexo Theme Minos BeanTech Hexo Theme BeanTech HuxBlog Hexo Theme HuxBlog Pure 教程 Hexo的SEO方法 | triplebee搞事情 hexo中禁止渲染文件的方法 | Qupid and Monkey’s Blog Hexo不渲染.md或者.html | CSDN 给你的网站加把锁 — Let’s Encrypt 完全体验 | 云淡风轻 3-4-2 Jekyll Huxpro | 黄玄 Hux Blog 3-4-3 VuePress VuePress | Vue驱动的静态网站生成器 3-4-4 WordPress Crayon Syntax Highlighter | WordPress.org 3-4-5 Bitcron Bitcron 3-4-6 Grav Grav 3-4-7 Hugo Hugo | The world’s fastest framework for building websites 3-5 私有云盘 Kod Cloud | 可道云 Seafile ownCloud 3-6 CDN加速 BootCDN | 前端开源项目CDN加速 BootCDN 3-7 开源镜像站 MSDN | I Tell You 阿里巴巴开源镜像站 网易开源镜像站 上海交通大学 北京交通大学 兰州大学 清华大学 清华大学 - 备用 中国科学技术大学 网站HTTP、HTTPS、HTTP/2支持情况 | 中科大 东北大学 浙江大学开源镜像站 东软信息学院 3-8 IDE3-8-1 VS Code 30个极大提高开发效率的VSCode插件 | 知乎 30个极大提高开发效率的VSCode插件 CodeSandbox 3-9 图片处理 智图 - 图片优化平台 | 腾讯ISUX前端团队 在线PS MPic - 图床神器 Favicon.ico Generator 3-10 各种排名 中国Github开源人排行榜 | 内存·溢出 Gartner魔力象限 TIOBE DB-Engines Alexa.cn Computer History | Cambridge Google Trends PopularitY of Programming Language | PYPL 10 Top IDE | PYPL 10 Top ODE | PYPL 10 TOP DB | PYPL Web Serve Survey | Netcraft 3-11 装机刷系统 【分享】利用WMITool解决浏览器主页被hao123劫持问题 | 吾爱破解 如何一招永久删除hao123流氓网页挟持 | CSDN Firefox主页被hao123挟持 | CSDN 使用小马KMS10激活，主页被劫持到 hao123 | 百度经验 win10 被KMS 篡改主页 hao123 | CSDN 小马 KMS10激活系统后的浏览器小尾巴分析与清除 | CSDN 使用小马激活工具KMS10激活win10后，主页被劫持跳转hao123解决方法大全 | 光的传人 利用WMI打造完美三无后门(scrcons.exe) | 脚本之家 为什么 Chrome 浏览器的主页会被篡改为 hao123 ？遇到这种情况要如何修复？| 知乎 免 SHSH 从 iOS 9.0 ~ 9.3.5 降级到 iOS 8.4.1 | 威锋网 台电win10重力感应失效解决教程 | Windows之家 Etcher | Flash OS images to SD cards &amp; USB drives, safely and easily. 3-12 追剧 【日本/时代剧】李香兰（2007年）上户彩（日菁字幕组）全 | Novipnoad 人人影视 追新番 猪猪日部落 Novipnoad 3-13 下载工具 aria2 proxyee-down | http下载工具，基于http代理，支持多连接分块下载 ytdl-webserver | Webserver for downloading youtube videos. Ready for docker. 3-14 格式转换 智图 - 图片优化平台 | 腾讯ISUX前端团队 Cloud Convert | Convert Anything to Anything Aconvert.com | 在线格式转换 证书格式转换 | MySSL.com DER、CRT、CER、PEM格式的证书及转换 | CSDN Favicon.ico Generator 3-15 网址导航 即刻导航 | 技术啦 创造师导航 创造师导航 - 科学上网 分享个性化网址导航《收库 123·导航网》| V2EX 收库 123 | 个性化可定制网址导航 收库 123 | 码农版 收库 123 | 娱乐版 4 资源收集4-1 博客 名称 博主 备注 张砷镓 张砷镓 14岁大学毕业，Web开发 陈沙克日志 陈沙克 招银，容器，OpenShift 酷壳 COOLSHELL 陈皓 20年软件开发经验，底层技术平台 Some 云计算 Links metaboy’s blog wangyuxiong 阿里云工程师 笑遍世界 任永杰 《KVM虚拟化技术：实战与原理解析》作者，华工09届校友 Deserts Deserts Valine-Admin作者 Hux Blog 黄玄 前端 Hollis HollisChuang 《成神之路系列文章》，阿里资深工程师 1 Byte 江宏 LeanCloud创始人，CEO crossoverJie’s Blog crossoverJie JCSprout发起者，JVM、并发、分布式 RUO DOJO 潘小鶸（潘家邦） 云数据库平台技术专家，阿里ApsaraDB 阮一峰的网络日志 阮一峰 上财世界经济博士，支付宝前端 廖雪峰的官方网站 廖雪峰 技术作家，JS、Python、Git教程 纯洁的微笑 一线技术总监 Java后端、微服务 小弟调调 jaywcjlove 前端、各类awesome项目 鸟窝 colobu 《Scala集合技术手册》作者，中科大毕业，现在微博做架构和开发 CyC2018 郑永川 中山大学 klion’s blog klionsec 网络安全，博客已停止更新 Sean’s Notes seanlook 腾讯互娱，游戏DBA Jimmy Song 宋净超 蚂蚁金服，Cloud Native，ServiceMesh 我的博客圈 | Myths 4-2 技术文章 简明 VIM 练级攻略 | 酷壳 GO语言、DOCKER 和新技术 | 酷壳 OpenStack七年之痒 | 陈沙克日志 谈谈创作共用许可证（Creative Commons licenses）| 阮一峰的网络日志 GPG入门教程 | 阮一峰的网络日志 RSA算法原理（一）| 阮一峰的网络日志 RSA算法原理（二）| 阮一峰的网络日志 4-3 技术社区 开源工厂 伯乐在线 开源中国 并发编程网 51CTO V2EX 掘金 4-4 微信公众号 搜狗微信搜索 【 综合社区 】 程序员头条 【 云计算 】 CloudMan 纯洁的微笑 - 微服务，Spring Boot 世民谈云计算 波波微课 - 架构师杨波，微服务，Java 并发 云技术之家 云技术实践 【 Linux 与后台开发 】 码农翻身 - IBM架构师刘欣 码农有道 程序员良许 良许Linux 民工哥Linux运维 Linux 中国 Linux 开源社区 【 Java 】 技术原始积累 - 淘宝加多 Hollis crossoverJie 芋道源码 Java技术栈 精讲Java 占小狼的博客 - Java进阶 Java高级架构 程序猿DD 波波微课 - 架构师杨波，微服务，Java 并发 【 Python 】 进击的Coder - 微软崔庆才 Python之禅 【 Android 】 stormzhang 郭霖Guolin 吴小龙同学 nanchen 【 数据结构与算法 】 编程珠玑 【 人工智能与机器学习 】 机器之心 【 开源 】 开源最前线 开源工厂 【 编程漫画 】 程序员小灰 神秘的程序员们 互联网侦察 - 面试现场 漫画编程 【 百家杂谈 】 刘润 浅黑科技 4-5 Github Awesome系列 编程类中文开源电子书合集 | 开源工厂 经典编程书籍大全 - 伯乐在线 | Github handbook - 笔记/搜集/摘录/实践 | jaywcjlove Awsome-Front-End-learning-resource - 前端资源汇总仓库 | Github 大前端工具集 | Github Algorithm_Interview_Notes-Chinese - 2018-2019校招面试笔记 | Github The System Design Primer - 系统设计入门 | Github InterviewMap - 打造最好的面试图谱 CS-Notes - Computer Science Learning Notes | Github Awesome-Python | Github Awesome-Go | Github Awesome-Cloud-Native | Github 4-6 各种插件4-7 必备软件跨平台 Putty VS Code navicat Typora Caffine Etcher | Flash OS images to SD cards &amp; USB drives, safely and easily. Windows Wox + Everything Mac Alfred Linux WineHQ uGet 4-8 面试 InterviewMap - 打造最好的面试图谱 4-9 简历 乔布简历 冷熊简历 MY GITHUB RÉSUMÉ 简历怎么写？国庆期间正好准备一下 | Leetcode ResumeSample - 程序员简历模板 | Github 4-10 漫画 MonkeyUser.com 神秘的程序员 程序员小灰 互联网侦察 漫画编程 | mhcoding xkcd | A webcomic of romance, sarcasm, math, and language. What if? | xkcd Containers | xkcd Tar | xkcd 5 最近阅读 Hexo不渲染.md或者.html | CSDN alpine linux填坑之路（一）| CSDN Alpine Docker 安装 bash | CSDN Docker系列之（三）：Docker微容器Alpine Linux | CSDN Git中的一些骚操作 | 云淡风轻 CentOS部署kodexplorer可道云搭建私有网盘 | KodCloud 可道云 在Ubuntu中搭建Guacamole | 博客园 MySQL双主复制详解 | Linux公社 大型网站架构技术一览 | Hollis 基础命令使用 [ win篇 ] | klion’s blog 不同的国家/地区与语言缩写代码 | 云淡风轻 🚩推荐阅读（由hexo文章推荐插件驱动）Python 速查C++ 速查Java 语言推荐书单C 语言推荐书单技术博客的重要性技术博客的重要性","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://abelsu7.top/tags/编程/"},{"name":"学习","slug":"学习","permalink":"https://abelsu7.top/tags/学习/"}]},{"title":"JavaScript获取网页滚动距离及DOM元素宽高属性","slug":"js-get-dom-height-and-width","date":"2018-09-19T13:26:43.000Z","updated":"2019-09-01T13:04:11.418Z","comments":true,"path":"2018/09/19/js-get-dom-height-and-width/","link":"","permalink":"https://abelsu7.top/2018/09/19/js-get-dom-height-and-width/","excerpt":"AnimateScroll 在前端开发中，我们经常需要获取网页中滚动条滚过的长度。获取该值的方法一般是通过scrollTop属性，如document.body.scrollTop，但同时也有document.documentElement.scrollTop。这两者都是经常用来获取文档滚动条滚过距离的方式，它们又有什么区别呢？","text":"AnimateScroll 在前端开发中，我们经常需要获取网页中滚动条滚过的长度。获取该值的方法一般是通过scrollTop属性，如document.body.scrollTop，但同时也有document.documentElement.scrollTop。这两者都是经常用来获取文档滚动条滚过距离的方式，它们又有什么区别呢？ 什么是DTDDTD（Document Type Definition，文档类型定义 ）是一套为了进行程序间的数据交换而建立的关于标记符的语法规则，它使用一系列的合法元素来定义文档结构。 DTD告诉浏览器当前文档用的是什么标记语言，之后浏览器才能正确的根据W3C标准解析文档代码。 目前HTML DTD共有三种类型： Strict DTD：严格的文档类型定义，不能包含已过时的元素（或属性）和框架元素 Transitional DTD：过渡的文档类型定义，可以包含已过时的元素（或属性）但不能包含框架元素 Frameset DTD：框架集文档类型定义，可以包含已过时的元素（或属性）和框架元素 HTML文档就是通过&lt;!DOCTYPE ...&gt;定义的。下面是一个HTML4.0的过渡DTD HTML文档： &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt; 或在HTML5中： &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt; document.body与document.documentElement的区别 document代表的是整个文档（对于一个网页来说，包括整个网页结构），document.documentElement是整个文档节点树的根节点，在网页中即html标签元素 而document.body是整个文档DOM节点树里的body节点，在网页中即body标签元素 我们常看见如下写法来获取页面滚动条滚动的长度， var top = document.documentElement.scrollTop || document.body.scrollTop; // 或者 var top = document.documentElement.scrollTop ? document.documentElement.scrollTop : document.body.scrollTop; 当使用了DTD来定义文档时，document.body.scrollTop的值为0，此时需要使用document.documentElement.scrollTop来获取滚动条滚过的长度 当未使用DTD时，使用document.body.scrollTop来获取滚动条滚过的长度 获取网页相关属性// 网页可见区域宽 var clientWidth = document.body.clientWidth; // 网页可见区域高 var clientHeight = document.body.clientHeight; // 网页可见区域宽(包括边线的宽) var offsetWidth = document.body.offsetWidth; // 网页可见区域高(包括边线的高) var offsetHeight = document.body.offsetHeight; // 网页正文全文宽 var scrollWidth = document.body.scrollWidth; // 网页正文全文高 var scrollHeight = document.body.scrollHeight; // 网页被卷去的高 var scrollTop = document.body.scrollTop || document.documentElement.scrollTop; // 网页被卷去的左 var scrollLeft = document.body.scrollLeft || document.documentElement.scrollLeft; 获取DOM元素相关属性// 元素的实际高度 var offsetHeight = document.getElementById(&quot;div&quot;).offsetHeight; // 元素的实际宽度 var offsetWidth = document.getElementById(&quot;div&quot;).offsetWidth; // 元素距离左边界的距离 var offsetLeft = document.getElementById(&quot;div&quot;).offsetLeft; // 元素距离上边界的距离 var offsetTop = document.getElementById(&quot;div&quot;).offsetTop; 参考文章 javascript中获取dom元素的高度和宽度 | 零度逍遥的博客 漫谈document.documentElement与document.body | 简书 document.body 和 document.documentElement 的区别 | CSDN AnimateScroll 🚩推荐阅读（由hexo文章推荐插件驱动）Vue.js 学习笔记HTML5 词云 wordcloud2.js 初体验监听物理回退与展开占满全屏归并排序(递归)","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://abelsu7.top/tags/JavaScript/"}]},{"title":"【译】使用 Kubernetes 管理 Docker 集群","slug":"manage-a-docker-cluster-with-k8s","date":"2018-09-19T09:57:34.000Z","updated":"2019-09-01T13:04:11.514Z","comments":true,"path":"2018/09/19/manage-a-docker-cluster-with-k8s/","link":"","permalink":"https://abelsu7.top/2018/09/19/manage-a-docker-cluster-with-k8s/","excerpt":"译自 Manage a Docker Cluster with Kubernetes | Linode 使用 Kubernetes 管理 Docker 集群","text":"译自 Manage a Docker Cluster with Kubernetes | Linode 使用 Kubernetes 管理 Docker 集群 什么是Kubernetes集群？Kubernetes是一个来管理容器化应用程序的开源平台。如果您使用Docker将应用部署到多个服务器节点上，Kubernetes集群就可以管理您的服务器和应用，包括扩展、部署和滚动更新等操作。 Kubernetes集群由至少一个主节点和多个工作节点组成。主节点运行API服务器、调度程序和控制器管理器，并在集群中动态部署应用程序。 系统要求要完成本指南的操作，您需要三台运行Ubuntu 16.04 LTS的服务器，每台服务器内存需在4GB以上。 开始前的准备本文需要您首先完成如何在Kubernetes集群上安装，配置和部署NGINX指南的相关操作，并按照其中的步骤配置一个主节点和两个工作节点。 设置三台服务器主机名如下： 主节点：kube-master 第一个工作节点：kube-worker-1 第二个工作节点：kube-worker-2 除非另有说明，否则以下的所有命令都将在kube-master节点上执行。 Kubernetes Pods每个Pod由一个或多个紧密耦合的容器组成，这些容器共享存储和网络等资源。Pod中的容器以Pod为单位启动、停止或复制。 Kubernetes Pods 创建部署部署（Deployments）是可以管理Pod创建的高级对象，并支持声明性扩展和滚动升级等功能。 1.在文本编辑器中，创建nginx.yaml配置文件并添加以下内容。 ~/nginx.yaml： apiVersion: apps/v1 kind: Deployment metadata: name: nginx-server labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.13-alpine ports: - containerPort: 80 该文件包含了定义一个部署所需的所有必要信息，包括要使用的Docker镜像、副本数量以及容器端口。要了解关于配置部署的更多信息，请参阅官方文档。 2.创建您的第一个部署： kubectl create -f nginx.yaml --record 3.查看部署列表： kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-server 1 1 1 1 13s 4.检查Pod状态： kubectl get pods NAME READY STATUS RESTARTS AGE nginx-server-b9bc6c6b5-d2gqv 1/1 Running 0 58 5.要查看部署的创建节点，请添加-o wide参数： kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-server-b9bc6c6b5-d2gqv 1/1 Running 0 1m 192.168.255.197 kube-worker-02 扩展部署Kubernetes可以轻松扩展部署以添加或删除副本。 1.将副本的数量增加到8： kubectl scale deployment nginx-server --replicas=8 2.检查新副本的可用性： kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-server-b9bc6c6b5-4mdf6 1/1 Running 0 41s 192.168.180.10 kube-worker-1 nginx-server-b9bc6c6b5-8mvrd 1/1 Running 0 3m 192.168.180.9 kube-worker-1 nginx-server-b9bc6c6b5-b99pt 1/1 Running 0 40s 192.168.180.12 kube-worker-1 nginx-server-b9bc6c6b5-fjg2c 1/1 Running 0 40s 192.168.127.12 kube-worker-2 nginx-server-b9bc6c6b5-kgdq5 1/1 Running 0 41s 192.168.127.11 kube-worker-2 nginx-server-b9bc6c6b5-mhb7s 1/1 Running 0 40s 192.168.180.11 kube-worker-1 nginx-server-b9bc6c6b5-rlf9w 1/1 Running 0 41s 192.168.127.10 kube-worker-2 nginx-server-b9bc6c6b5-scwgj 1/1 Running 0 40s 192.168.127.13 kube-worker-2 3.可以使用同样的命令减少副本的数量： kubectl scale deployment nginx-server --replicas=3 滚动更新通过部署来管理Pod允许您使用滚动更新（Rolling Upgrades）的功能。滚动更新是一种允许您在不停机的情况下更新应用程序版本的机制。Kubernetes确保至少有25%的Pod可随时提供服务，并会在删除旧Pod之前先创建新的Pod。 1.将容器的NGINX版本从 1.13 升级到 1.13.8： kubectl set image deployment/nginx-server nginx=nginx:1.13.8-alpine 与扩展过程类似，set命令使用声明性方法：您只需指定所需的目标状态，控制器会管理完成该目标所需的所有任务。 2.检查更新状态： kubectl rollout status deployment/nginx-server Waiting for rollout to finish: 1 out of 3 new replicas have been updated... Waiting for rollout to finish: 1 out of 3 new replicas have been updated... Waiting for rollout to finish: 1 out of 3 new replicas have been updated... Waiting for rollout to finish: 2 out of 3 new replicas have been updated... Waiting for rollout to finish: 2 out of 3 new replicas have been updated... Waiting for rollout to finish: 2 out of 3 new replicas have been updated... Waiting for rollout to finish: 1 old replicas are pending termination... Waiting for rollout to finish: 1 old replicas are pending termination... deployment \"nginx-server\" successfully rolled out 3.你可以使用describe命令手动检查应用程序版本： kubectl describe pod &lt;pod-name&gt; 4.如果发生错误，回滚（Rollout）将被挂起，系统将强制要求用户输入 CTRL + C 以取消更新。通过设置无效的NGINX版本来测试： kubectl set image deployment/nginx-server nginx=nginx:1.18. 5.查看当前Pod状态： kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-server-76976d4555-7nv6z 1/1 Running 0 3m 192.168.127.15 kube-worker-2 nginx-server-76976d4555-wg785 1/1 Running 0 3m 192.168.180.13 kube-worker-1 nginx-server-76976d4555-ws4vf 1/1 Running 0 3m 192.168.127.14 kube-worker-2 nginx-server-7ddd985dd6-mpn9h 0/1 ImagePullBackOff 0 2m 192.168.180.16 kube-worker-1 可以看到名为nginx-server-7ddd985dd6-mpn9h的Pod正在试图将NGINX更新到一个不存在的版本。 6.检查此Pod以获取该错误的更多详细信息： kubectl describe pod nginx-server-7ddd985dd6-mpn9h 7.由于在创建部署时使用了--record参数，您可以通过以下命令检索完整的历史记录： kubectl rollout history deployment/nginx-server REVISION CHANGE-CAUSE 1 kubectl scale deployment nginx-server --replicas=3 2 kubectl set image deployment/nginx-server nginx=nginx:1.13.8-alpine 3 kubectl set image deployment/nginx-server nginx=nginx:1.18 8.您可以使用undo命令回滚到之前的工作版本： kubectl rollout undo deployment/nginx-server 9.要回滚到特定的版本，请使用--to-revision选项以指定要回滚的目标版本： kubectl rollout undo deployment/nginx-server --to-revision=1 Kubernetes服务您现在已经有了一个运行三个Pod的部署，每个Pod都运行了一个NGINX应用。要将Pod发布到互联网，您需要创建一个 服务。在Kubernetes中，服务是一种抽象，允许随时访问Pod。服务会自动处理IP更改，更新以及扩展，因此在启用该服务后，只要运行的Pod保持活动状态，就可通过互联网访问您的应用程序。 1.配置一个测试服务。 ~/nginx-service.yaml： apiVersion: v1 kind: Service metadata: name: nginx-service labels: run: nginx spec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP name: http selector: app: nginx 2.创建服务： kubectl create -f nginx-service.yaml 3.检查新服务的状态： kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 443/TCP 2d nginx-service NodePort 10.97.41.31 80:31738/TCP 38m 服务正在运行并接受31738端口上的连接。 4.测试服务： curl &lt;MASTER_LINODE_PUBLIC_IP_ADDRESS&gt;:&lt;PORT(S)&gt; 5.使用describe命令查看此服务的其他信息： kubectl describe service nginx-service Name: nginx-service Namespace: default Labels: run=nginx Annotations: Selector: app=nginx Type: NodePort IP: 10.97.41.31 Port: http 80/TCP TargetPort: 80/TCP NodePort: http 31738/TCP Endpoints: 192.168.127.14:80,192.168.127.15:80,192.168.180.13:80 Session Affinity: None External Traffic Policy: Cluster Events: Kubernetes命名空间命名空间是是一个逻辑环境，可以灵活的在多个团队或用户之间划分集群资源。 1.查看可用的命名空间： kubectl get namespaces default Active 7h kube-public Active 7h kube-system Active 7h 顾名思义，如果未指定其他的命名空间，则您的部署将会放置在default命名空间下。kube-system为Kubernetes创建的对象保留，而kube-public则对所有用户可用。命名空间可以通过.json文件创建，也可以直接在命令行创建。 2.为 development 环境新建名为dev-namespace.json的文件。 ~/home/dev-namespace.json： { &quot;kind&quot;: &quot;Namespace&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: { &quot;name&quot;: &quot;development&quot;, &quot;labels&quot;: { &quot;name&quot;: &quot;development&quot; } } } 3.在集群中创建命名空间： kubectl create -f dev-namespace.json 4.再次查看命名空间： kubectl get namespaces 上下文要使用命名空间，您需要定义使用命名空间的 上下文（Context）。Kubernetes上下文保存在kubectl配置文件中。 1.查看当前的配置： kubectl config view 2.检查您当前正在使用的上下文： kubectl config current-context 3.使用以下命令添加dev上下文： kubectl config set-context dev --namespace=development \\ --cluster=kubernetes \\ --user=kubernetes-admin 4.切换至dev上下文/命名空间： kubectl config use-context dev 5.验证更改是否生效： kubectl config current-context 6.查看新的配置： kubectl config view 7.命名空间中的Pod对其他命名空间不可见。列出您的Pod来检查该特性： kubectl get pods 系统提示“No resources found”，是因为您未在此命名空间中创建Pod或部署，不过您仍然可以添加--all-namespaces参数来查看这些对象： kubectl get services --all-namespaces 标签Kubernetes中的任何对象都可以添加标签。标签是一组键值对，可以帮助用户基于各种特征更加轻松的组织、过滤并选择对象。 1.在此命名空间中创建一个测试部署，此部署将包含nginx标签。 ~/my-app.yaml： apiVersion: apps/v1 kind: Deployment metadata: name: my-app labels: app: my-app spec: replicas: 4 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.12-alpine ports: - containerPort: 80 2.创建部署： kubectl create -f my-app.yaml --record 3.如果您只需在集群中查找特定的Pod，而不是列出所有Pod，那么在命令中添加-l选项以按标签搜索通常更有效率： kubectl get pods --all-namespaces -l app=nginx 这里仅列出了default和development命名空间中的Pod，因为它们的定义中包含nginx标签。 Kubernetes节点Kubernetes节点可以是物理机或虚拟机。可以将节点视为Kubernetes抽象模型中的最高级别。 1.列出您当前的节点： kubectl get nodes NAME STATUS ROLES AGE VERSION kube-master Ready master 21h v1.9.2 kube-worker-1 Ready 19h v1.9.2 kube-worker-2 Ready 17h v1.9.2 2.要查看更多信息，添加-o参数： kubectl get nodes -o wide 3.显示的信息大部分是自解释的，对于检查全部节点是否准备就绪而言非常有用。您可以使用describe命令以获取特定节点的详细信息： kubectl describe node kube-worker-1 节点维护Kubernetes提供了一种非常直接的办法使节点安全离线。 1.返回您正在运行NGINX服务的默认命名空间： kubectl config use-context kubernetes-admin@kubernetes 2.检查您的Pod： kubectl get pods -o wide 3.在kube-worker-2节点上禁止新Pod的创建： kubectl cordon kube-worker-2 4.检查您的节点状态： kubectl get nodes NAME STATUS ROLES AGE VERSION kube-master Ready master 4h v1.9.2 kube-worker-1 Ready 4h v1.9.2 kube-worker-2 Ready,SchedulingDisabled 4h v1.9.2 5.要测试Kubernetes控制器和调度程序，请扩展您的部署： kubectl scale deployment nginx-server --replicas=10 6.再次查看您的Pod： kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-server-b9bc6c6b5-2pnbk 1/1 Running 0 11s 192.168.188.146 kube-worker-1 nginx-server-b9bc6c6b5-4cls5 1/1 Running 0 11s 192.168.188.148 kube-worker-1 nginx-server-b9bc6c6b5-7nw5m 1/1 Running 0 3d 192.168.255.220 kube-worker-2 nginx-server-b9bc6c6b5-7s7w5 1/1 Running 0 44s 192.168.188.143 kube-worker-1 nginx-server-b9bc6c6b5-88dvp 1/1 Running 0 11s 192.168.188.145 kube-worker-1 nginx-server-b9bc6c6b5-95jgr 1/1 Running 0 3d 192.168.255.221 kube-worker-2 nginx-server-b9bc6c6b5-md4qd 1/1 Running 0 3d 192.168.188.139 kube-worker-1 nginx-server-b9bc6c6b5-r5krq 1/1 Running 0 11s 192.168.188.144 kube-worker-1 nginx-server-b9bc6c6b5-r5nd6 1/1 Running 0 44s 192.168.188.142 kube-worker-1 nginx-server-b9bc6c6b5-ztgmr 1/1 Running 0 11s 192.168.188.147 kube-worker-1 现在总共有10个Pod，但新Pod只在第一个节点中创建。 7.通知kube-worker-2节点停止其运行的Pod： kubectl drain kube-worker-2 --ignore-daemonsets node \"kube-worker-2\" already cordoned WARNING: Ignoring DaemonSet-managed pods: calico-node-9mgc6, kube-proxy-2v8rw pod \"my-app-68845b9f68-wcqsb\" evicted pod \"nginx-server-b9bc6c6b5-7nw5m\" evicted pod \"nginx-server-b9bc6c6b5-95jgr\" evicted pod \"my-app-68845b9f68-n5kpt\" evicted node \"kube-worker-2\" drained 8.检查上述命令对您Pod产生的效果： kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-server-b9bc6c6b5-2pnbk 1/1 Running 0 9m 192.168.188.146 kube-worker-1 nginx-server-b9bc6c6b5-4cls5 1/1 Running 0 9m 192.168.188.148 kube-worker-1 nginx-server-b9bc6c6b5-6zbv6 1/1 Running 0 3m 192.168.188.152 kube-worker-1 nginx-server-b9bc6c6b5-7s7w5 1/1 Running 0 9m 192.168.188.143 kube-worker-1 nginx-server-b9bc6c6b5-88dvp 1/1 Running 0 9m 192.168.188.145 kube-worker-1 nginx-server-b9bc6c6b5-c2c5c 1/1 Running 0 3m 192.168.188.150 kube-worker-1 nginx-server-b9bc6c6b5-md4qd 1/1 Running 0 3d 192.168.188.139 kube-worker-1 nginx-server-b9bc6c6b5-r5krq 1/1 Running 0 9m 192.168.188.144 kube-worker-1 nginx-server-b9bc6c6b5-r5nd6 1/1 Running 0 9m 192.168.188.142 kube-worker-1 nginx-server-b9bc6c6b5-ztgmr 1/1 Running 0 9m 192.168.188.147 kube-worker-1 9.您现在已经可以在不中断服务的情况下安全关闭kube-worker-2节点。 10.完成维护后，通知控制器此节点可以再次进行调度： kubectl uncordon kube-worker-2 参考资料 Manage a Docker Cluster with Kubernetes | Linode 使用Kubernetes管理Docker集群 | 腾讯云+社区 Kubernetes Handbook | Gitbook Kubernetes官方文档 Calico官方文档 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Kubernetes 实践简明指南","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/categories/Kubernetes/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"}]},{"title":"【译】使用 Apache Guacamole 连接虚拟云桌面","slug":"remote-desktop-using-apache-guacamole-on-docker","date":"2018-09-14T14:54:14.000Z","updated":"2019-09-01T13:04:11.657Z","comments":true,"path":"2018/09/14/remote-desktop-using-apache-guacamole-on-docker/","link":"","permalink":"https://abelsu7.top/2018/09/14/remote-desktop-using-apache-guacamole-on-docker/","excerpt":"使用Apache Guacamole连接虚拟云桌面 Apache Guacamole是一款HTML5应用程序，可通过RDP，VNC和其他协议访问远程桌面。您可以创建一个虚拟云桌面，用户通过Web浏览器即可访问。本指南将介绍如何通过Docker安装Apache Guacamole，并借助其访问托管在Linode上的远程桌面。","text":"使用Apache Guacamole连接虚拟云桌面 Apache Guacamole是一款HTML5应用程序，可通过RDP，VNC和其他协议访问远程桌面。您可以创建一个虚拟云桌面，用户通过Web浏览器即可访问。本指南将介绍如何通过Docker安装Apache Guacamole，并借助其访问托管在Linode上的远程桌面。 安装Docker这里介绍的方法将安装最新版本的Docker。如需安装特定版本Docker，或需要Docker EE环境，请参阅官方文档寻求帮助。 以下步骤将使用Ubuntu官方软件库安装Docker社区版（Community Edition，CE）。如需在其他Linux发行版上安装，请参阅官网的安装说明。 1.卸载系统上可能存在的旧版本Docker： sudo apt remove docker docker-engine docker.io 2.确保您已安装了使用Docker仓库所需的如下依赖： sudo apt install apt-transport-https ca-certificates curl software-properties-common 3.添加Docker的GPG密钥： curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 4.验证GPG密钥指纹： sudo apt-key fingerprint 0EBFCD88 您应该看到类似以下内容的输出： pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid Docker Release (CE deb) &lt;docker@docker.com&gt; sub 4096R/F273FCD8 2017-02-22 5.添加Dockerstable仓库： sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; 6.更新软件包索引并安装Docker社区版： sudo apt update sudo apt install docker-ce 7.将受限的Linux用户账户添加到docker用户组： sudo usermod -aG docker exampleuser 您需要重启Shell会话才能使此更改生效。 8.运行内置的“Hello World”程序以检查Docker是否成功安装： docker run hello-world 使用MySQL初始化Guacamole身份验证本指南将使用MySQL作为参考，但PostgreSQL以及MariaDB也同样适用。 1.拉取Guacamole服务器、Guacamole客户端和MySQL的Docker镜像： docker pull guacamole/guacamole docker pull guacamole/guacd docker pull mysql/mysql-server 2.创建数据库初始化脚本以创建用于验证身份的数据表： docker run --rm guacamole/guacamole /opt/guacamole/bin/initdb.sh --mysql &gt; initdb.sql 3.为MySQL的root用户生成一次性密码，可在日志中查看： docker run --name example-mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes -e MYSQL_ONETIME_PASSWORD=yes -d mysql/mysql-server docker logs example-mysql Docker日志会在终端中打印密码： [Entrypoint] Database initialized [Entrypoint] GENERATED ROOT PASSWORD: &lt;password&gt; 4.重命名并将initdb.sql移动到MySQL容器中： docker cp initdb.sql example-mysql:/guac_db.sql 5.在MySQL的Docker容器中打开bash终端： docker exec -it example-mysql bash 6.使用一次性密码登录。在重新设定root用户密码之前，终端不会接受任何命令。创建一个新的数据库和用户，如下所示： bash-4.2# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 11 Server version: 5.7.20 Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;new_root_password&#39;; Query OK, 0 rows affected (0.00 sec) mysql&gt; CREATE DATABASE guacamole_db; Query OK, 1 row affected (0.00 sec) mysql&gt; CREATE USER &#39;guacamole_user&#39;@&#39;%&#39; IDENTIFIED BY &#39;guacamole_user_password&#39;; Query OK, 0 rows affected (0.00 sec) mysql&gt; GRANT SELECT,INSERT,UPDATE,DELETE ON guacamole_db.* TO &#39;guacamole_user&#39;@&#39;%&#39;; Query OK, 0 rows affected (0.00 sec) mysql&gt; FLUSH PRIVILEGES; Query OK, 0 rows affected (0.00 sec) mysql&gt; quit Bye 7.在bash终端中，使用初始化脚本为新数据库创建数据表： cat guac_db.sql | mysql -u root -p guacamole_db 验证数据表是否已成功添加。如果guacamole数据库中不存在新建的表，请再次确认之前的步骤均已正确执行。 mysql&gt; USE guacamole_db; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&gt; SHOW TABLES; +---------------------------------------+ | Tables_in_guacamole_db | +---------------------------------------+ | guacamole_connection | | guacamole_connection_group | | guacamole_connection_group_permission | | guacamole_connection_history | | guacamole_connection_parameter | | guacamole_connection_permission | | guacamole_sharing_profile | | guacamole_sharing_profile_parameter | | guacamole_sharing_profile_permission | | guacamole_system_permission | | guacamole_user | | guacamole_user_password_history | | guacamole_user_permission | +---------------------------------------+ 13 rows in set (0.00 sec) 退出bash终端： exit 在浏览器中访问Guacamole1.在Docker中启动guacd： docker run --name example-guacd -d guacamole/guacd 2.连接容器，以便Guacamole验证存储在MySQL数据库中的凭证： docker run --name example-guacamole --link example-guacd:guacd --link example-mysql:mysql -e MYSQL_DATABASE=&#39;guacamole_db&#39; -e MYSQL_USER=&#39;guacamole_user&#39; -e MYSQL_PASSWORD=&#39;guacamole_user_password&#39; -d -p 127.0.0.1:8080:8080 guacamole/guacamole 注意 可通过以下命令查看所有正在运行和未运行的Docker容器： docker ps -a 3.example-guacamole、example-guacd和example-mysql都已运行后，请在浏览器中访问localhost:8080/guacamole/。默认的登录账户是guacadmin，默认登录密码guacadmin。登录后应尽快修改登录账户及密码。 登录Apache Guacamole 在Linode上搭建VNC服务器在共享远程桌面之前，必须在Linode上安装桌面环境以及VNC服务器。本指南将使用Xfce桌面，因为Xfce是轻量级的，不会过度消耗系统资源。 1.在Linode上安装Xfce： sudo apt install xfce4 xfce4-goodies 如果系统资源的限制较少，则可使用Unity桌面作为替代： sudo apt install --no-install-recommends ubuntu-desktop gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal 2.安装VNC服务器。启动VNC服务器时，系统将提示用户输入密码： sudo apt install tightvncserver vncserver 除了提示输入密码外，系统还会提供“仅可查看”的选项。密码最大长度为8位字符。对于需要更高安全性的设置，我们强烈建议您将Guacamole部署为使用SSL加密的反向代理。 You will require a password to access your desktops. Password: Verify: Would you like to enter a view-only password (y/n)? 3.确保在.vnc/xstartup的最后启动桌面环境，否则只会显示灰色屏幕： echo &#39;startxfce4 &amp;&#39; | tee -a .vnc/xstartup 若使用Unity桌面作为替代，则配置示例如下： #!/bin/sh xrdb $HOME/.Xresources xsetroot -solid grey #x-terminal-emulator -geometry 80x24+10+10 -ls -title &quot;$VNCDESKTOP Desktop&quot; &amp; #x-window-manager &amp; # Fix to make GNOME work export XKL_XMODMAP_DISABLE=1 /etc/X11/Xsession gnome-panel &amp; gnome-settings-daemon &amp; metacity &amp; nautilus &amp; 在Guacamole中新建连接Guacamole支持VNC，RDP，SSH和Telnet协议。本章节将介绍如何在浏览器界面中添加新的连接。 1.在连接到VNC服务器之前，创建一个SSH隧道，并将user和example.com替换为Linode的用户名和公网IP： ssh -L 5901:localhost:5901 -N -f -l user example.com 2.在Guacamole控制面板中，点击右上角的下拉菜单，然后选择 Settings 。在 Connections 选项卡中，点击 New Connection 按钮。 在Guacamole中新建连接 3.在 Edit Connection 设置中，输入连接名。在 Parameters 设置中，主机名即为Linode的公网IP地址。端口号为5900 + 显示编号——这里以5901为例。最后输入8位密码。 Guacamole编辑连接设置 官方文档详细描述了所有参数的具体含义。 注意 如果您在同一Linode服务器上有多个VNC连接，请增加连接所用的端口号：5902，5903……以此类推。如果您的远程连接托管在不同的Linode服务器上，则仍应继续使用5901端口。 4.在右上角的下拉菜单中，点击 Home。新建的连接现在应该已经可以使用。 使用快捷键 CTRL + ALT + SHIFT 可以打开剪贴板、键盘/鼠标设置以及导航菜单。 剪贴板及输入设置 5.点击浏览器的后退按钮，回到 Home 菜单。 6.可以连接至其他桌面，并且可在新的浏览器选项卡中同时连接多个远程桌面。 近期连接入口 本指南旨在通过Docker简化安装过程，并演示如何使用Apache Guacamole快速连接至远程桌面。除此之外Apache Guacamole还提供了许多功能，如屏幕录制、Duo双重身份认证、SFTP文件传输等。Guacamole作为Apache的孵化项目，我们期待在不久的将来看到其进一步的发展。 参考文章 Virtual Cloud Desktop Using Apache Guacamole | Linode 使用Apache Guacamole连接虚拟云桌面 | 腾讯云+社区 Apache Guacamole Apache Tomcat 🚩推荐阅读（由hexo文章推荐插件驱动）半虚拟化 I/O 框架 virtio单独编译 KVM 内核模块Kernel 2.6.32 中的 KVM API 概述QEMU 1.2.0 入口 main() 函数调用流程分析虚拟机 VMware 中安装 Ubuntu 操作系统虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"VNC","slug":"VNC","permalink":"https://abelsu7.top/tags/VNC/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://abelsu7.top/tags/虚拟化/"}]},{"title":"利用 Valine 搭建 Hexo 无后端评论系统","slug":"valine-with-hexo","date":"2018-09-13T12:32:36.000Z","updated":"2019-09-01T13:04:11.760Z","comments":true,"path":"2018/09/13/valine-with-hexo/","link":"","permalink":"https://abelsu7.top/2018/09/13/valine-with-hexo/","excerpt":"Valine诞生于2017年8月7日，由@云淡风轻开发，是一款基于LeanCloud的快速、简洁且高效的无后端评论系统。理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo等博客程序在使用Valine。 @Deserts在此基础上对Valine进行了二次开发，并利用LeanCloud搭建简易评论管理后台。 Valine前端效果","text":"Valine诞生于2017年8月7日，由@云淡风轻开发，是一款基于LeanCloud的快速、简洁且高效的无后端评论系统。理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo等博客程序在使用Valine。 @Deserts在此基础上对Valine进行了二次开发，并利用LeanCloud搭建简易评论管理后台。 Valine前端效果 Valine的特点 无后端实现 高速，使用国内后端云服务提供商 LeanCloud 提供的存储服务 开源，自定义程度高 支持邮件通知 支持验证码 支持Markdown 参考文章 Valine Docs | Valine.js.org Valine — 一款极简的评论系统 | 云淡风轻 Valine：独立博客评论系统 | Deserts 🚩推荐阅读（由hexo文章推荐插件驱动）Hexo 实现自定义文章置顶在 Hexo 中使用 MathJax 渲染数学公式解决 RSS 报错：Input is not proper UTF-8, indicate encodingHexo 博客安装 RSS 插件Hexo博客文末添加网站地图Hexo博客文末添加网站地图","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://abelsu7.top/tags/Hexo/"}]},{"title":"【译】搭建高可用 WordPress 网站托管","slug":"high-availability-wordpress-hosting","date":"2018-09-11T13:39:08.000Z","updated":"2019-09-01T13:04:11.289Z","comments":true,"path":"2018/09/11/high-availability-wordpress-hosting/","link":"","permalink":"https://abelsu7.top/2018/09/11/high-availability-wordpress-hosting/","excerpt":"本指南将使用双Linode集群配置高可用的WordPress站点，数据库采用MySQL双主复制（Master-Master replication），并使用Linode NodeBalancer作为前端管理工具。","text":"本指南将使用双Linode集群配置高可用的WordPress站点，数据库采用MySQL双主复制（Master-Master replication），并使用Linode NodeBalancer作为前端管理工具。 先决条件本指南基于Debian 7或Ubuntu 14.04编写。要完成该指南，请确保您的账户中至少存在两个Linode节点和一个NodeBalancer。两个Linode节点都需要私有IP地址。同时还要确保已经在Linode节点上配置了SSH密钥，并且还需将另一台Linode主机的SSH密钥添加在本机的/.ssh/authorized_keys文件中。 注意 本指南是为非root用户编写的，会在需要提升权限的命令之前加上sudo。如果您不熟悉sudo命令，请参阅Linux用户和用户组指南。 安装所需软件包使用以下命令在每个Linode节点上安装Apache，PHP和MySQL： sudo apt-get update sudo apt-get upgrade -y sudo apt-get install apache2 php5 php5-mysql mysql-server mysql-client 编辑MySQL配置文件以设置双主复制1.编辑每个Linode节点上的/etc/mysql/my.cnf配置文件，添加或修改以下值： Server 1： server_id = 1 log_bin = /var/log/mysql/mysql-bin.log log_bin_index = /var/log/mysql/mysql-bin.log.index relay_log = /var/log/mysql/mysql-relay-bin relay_log_index = /var/log/mysql/mysql-relay-bin.index expire_logs_days = 10 max_binlog_size = 100M log_slave_updates = 1 auto-increment-increment = 2 auto-increment-offset = 1 Server 2： server_id = 2 log_bin = /var/log/mysql/mysql-bin.log log_bin_index = /var/log/mysql/mysql-bin.log.index relay_log = /var/log/mysql/mysql-relay-bin relay_log_index = /var/log/mysql/mysql-relay-bin.index expire_logs_days = 10 max_binlog_size = 100M log_slave_updates = 1 auto-increment-increment = 2 auto-increment-offset = 2 2.对于每个Linode节点，编辑bind-address配置以使用私有IP地址： bind-address = x.x.x.x 3.修改完配置文件后，重启MySQL应用： sudo service mysql restart 创建复制用户1.在每台Linode节点上登录MySQL： mysql -u root -p 2.在每台Linode节点上配置复制用户。将x.x.x.x替换为另一台Linode节点的私有IP地址，并将password修改为强密码： GRANT REPLICATION SLAVE ON *.* TO &#39;replication&#39;@&#39;x.x.x.x&#39; IDENTIFIED BY &#39;password&#39;; 3.返回终端，运行以下命令以测试配置。使用另一台Linode节点的私有IP地址： mysql -ureplication -p -h x.x.x.x -P 3306 此时您应该可以通过以上命令连接到远程服务器的MySQL实例。 配置数据库同步复制1.在第一台服务器上登录MySQL，查询主节点状态： SHOW MASTER STATUS; 请注意显示的文件名和所在位置： mysql&gt; SHOW MASTER STATUS; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000001 | 277 | | | +------------------+----------+--------------+------------------+ 1 row in set (0.00 sec) 2.在第二台服务器上，根据MySQL的提示，为该数据库设置从属功能。将x.x.x.x替换为第一台服务器的私有IP。还要将master_log_file和master_log_pos替换为上一步中对应的值： SLAVE STOP; CHANGE MASTER TO master_host=&#39;x.x.x.x&#39;, master_port=3306, master_user=&#39;replication&#39;, master_password=&#39;password&#39;, master_log_file=&#39;mysql-bin.000001&#39;, master_log_pos=277; SLAVE START; 3.在第二台服务器上，查询主节点状态。注意文件名及其所在位置： SHOW MASTER STATUS; 4.在第一台服务器上设置从属数据库状态，重复步骤2，并将需要修改的值替换为第一台服务器上相对应的值： SLAVE STOP; CHANGE MASTER TO master_host=&#39;x.x.x.x&#39;, master_port=3306, master_user=&#39;replication&#39;, master_password=&#39;password&#39;, master_log_file=&#39;mysql-bin.000001&#39;, master_log_pos=277; SLAVE START; 5.在两台Linode节点上退出MySQL： exit 配置Apache两台Linode服务器均需要执行本章节的以下步骤。 注意 请将之后出现的example.com替换为您的域名。 1.输入以下命令禁用默认的Apache虚拟主机： sudo a2dissite *default 2.切换至/var/www目录： cd /var/www 3.输入以下命令，创建用来保存网站的文件夹： sudo mkdir example.com 4.在您刚刚创建的文件夹中创建一组文件夹，以存储您网站的文件、日志和备份： sudo mkdir example.com/public_html sudo mkdir example.com/log 5.为网站创建虚拟主机文件： /etc/apache2/sites-available/example.com.conf： # domain: example.com # 域名: example.com # public: /var/www/example.com/public_html/ # 网站根目录: /var/www/example.com/public_html/ &lt;VirtualHost *:80&gt; # Admin email, Server Name (domain name), and any aliases # 管理员邮箱地址, 服务器名 (域名), 服务器别名 ServerAdmin webmaster@example.com ServerName www.example.com ServerAlias example.com # Index file and Document Root (where the public files are located) # 索引文件以及根目录 (网站页面文件存放位置) DirectoryIndex index.html index.php DocumentRoot /var/www/example.com/public_html # Log file locations # 日志文件存放位置 LogLevel warn ErrorLog /var/www/example.com/log/error.log CustomLog /var/www/example.com/log/access.log combined &lt;/VirtualHost&gt; 警告 在Apache 2.4（Ubuntu 14.04使用的版本）及之后的版本中，虚拟主机文件必须以.conf扩展名作为结尾。.conf扩展名在之前版本的Apache兼容。 6.输入以下命令启用新网站： sudo a2ensite example.com.conf 7.重启Apache： sudo service apache2 restart 安装WordPress1.在Linode主节点上，下载并安装最新版本的WordPress。请根据您的实际配置替换以下命令中列出的所有路径： cd /var/www wget https://wordpress.org/latest.tar.gz tar -xvf latest.tar.gz cp -R wordpress/* /var/www/example.com/public_html 2.配置MySQL数据库以安装WordPress。您需要将wordpressuser和password替换为您自己的设置： mysql -u root -p CREATE DATABASE wordpress; GRANT ALL PRIVILEGES ON wordpress.* TO &#39;wordpressuser&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;password&#39;; FLUSH PRIVILEGES; EXIT 3.设置网站根目录权限以确保WordPress能够完成其配置步骤： chmod 777 /var/www/example.com/public_html/ 4.使用Web浏览器访问您Linode的IP地址，并完成配置步骤以安装全功能的WordPress。 警告 为了确保每个WordPress实例都能定位到本地数据库，您需要将此步骤中的 Database Host（数据库主机）值设置为localhost。这也是WordPress的默认值。 5.通过WordPress管理界面中的 General Settings（常规设置）配置WordPress URL和网站地址，并确保在两个字段中都配置了您的域。 WordPress管理界面 注意 完成WordPress安装步骤并首次登录后，应重置网站根目录的权限以确保安全。您可以使用以下命令来重置根目录权限： chmod 755 /var/www/example.com/public_html/ 6.完成WordPress安装步骤后，将配置文件复制到另一台Linode节点。将x.x.x.x替换为另一台Linode节点的IP地址： rsync -r /var/www/* x.x.x.x:/var/www/. 7.登录另一台Linode节点并重启Apache： sudo service apache2 restart 使用Lsyncd配置文件夹同步1.在Linode集群主节点安装Lsyncd： sudo apt-get install lsyncd 2.创建配置文件以执行同步操作。将x.x.x.x替换为集群中另一台Linode节点的私有IP地址： settings = { logfile = &quot;/var/log/lsyncd.log&quot;, statusFile = &quot;/var/log/lsyncd-status.log&quot; } sync { default.rsyncssh, delete = false, insist source=&quot;/var/www&quot;, host=&quot;x.x.x.x&quot;, targetdir=&quot;/var/www&quot;, rsync = { archive = true, perms = true, owner = true, _extra = {&quot;-a&quot;}, }, delay = 5, maxProcesses = 4, ssh = { port = 22 } } 3.启动Lsyncd进程： service lsyncd start 4.测试Lsyncd是否已经成功启动： service lsyncd status 如果此命令返回的结果不是lsyncd is running，请仔细检查lsyncd.conf.lua配置文件，并确保RSA公钥位于从属服务器的正确位置。 5.通过在主Linode节点的/var/www文件夹中创建文件来测试同步复制是否生效。几秒钟后您应该能够在从属Linode节点上的相同路径下看到该文件。 配置您的NodeBalancer1.打开Linode管理界面中的NodeBalancer选项卡。 2.如果您之前尚未配置，请添加NodeBalancer，并确保它与后端Linode服务器位于同一数据中心。 3.选择您新添加的NodeBalancer并点击“Create Configuration”。按如下所示，编辑配置文件： Port: 80 Protocol: HTTP Algorithm: Least Connections Session Stickiness: Table Health Check Type: HTTP Valid Status 4.点击“Save Changes”按钮后，系统将提示您添加Linode节点。为每台节点提供唯一的标签，并在每个节点的地址字段中输入私有网络地址和端口号。 5.添加完两个节点后，确保节点运行状况检查功能处于启用状态。等到两个节点都显示为启动状态，返回NodeBalancer主页并记录列出的IP地址。您现在应该能访问该IP地址并查看您的网站。 为了测试高可用性，可以在其中一个节点上停止Apache2/MySQL服务，或者关闭其中一个节点。即使其中一个节点被标记为关闭状态，您的网站仍可以继续提供服务而不会出现问题。 恭喜，您现在已经成功搭建了高可用的WordPress网站！ 参考文章 High Availability WordPress Hosting | Linode 搭建高可用WordPress网站托管 | 腾讯云+社区 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装 MySQL 5.7浅析数据库缓冲池与SQL查询成本MySQL查询","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://abelsu7.top/tags/MySQL/"},{"name":"WordPress","slug":"WordPress","permalink":"https://abelsu7.top/tags/WordPress/"},{"name":"Lsyncd","slug":"Lsyncd","permalink":"https://abelsu7.top/tags/Lsyncd/"}]},{"title":"【译】在 Ubuntu 16.04 上安装 VNC","slug":"install-VNC-on-Ubuntu-1604","date":"2018-09-10T13:58:14.000Z","updated":"2019-09-01T13:04:11.390Z","comments":true,"path":"2018/09/10/install-VNC-on-Ubuntu-1604/","link":"","permalink":"https://abelsu7.top/2018/09/10/install-VNC-on-Ubuntu-1604/","excerpt":"虚拟网络计算（ Virtual Network Computing ），或称作VNC，是一种图形桌面共享系统，允许您从一台计算机远程控制另一台计算机。VNC服务器传输键盘和鼠标事件，并通过网络连接显示远程主机的屏幕，从而允许您在Linode服务器上运行完整的桌面环境。 在Ubuntu 16.04上安装VNC 本指南将介绍如何在运行Ubuntu 16.04的服务器上安装图形桌面环境，以及如何使用VNC从本地计算机连接至该桌面。","text":"虚拟网络计算（ Virtual Network Computing ），或称作VNC，是一种图形桌面共享系统，允许您从一台计算机远程控制另一台计算机。VNC服务器传输键盘和鼠标事件，并通过网络连接显示远程主机的屏幕，从而允许您在Linode服务器上运行完整的桌面环境。 在Ubuntu 16.04上安装VNC 本指南将介绍如何在运行Ubuntu 16.04的服务器上安装图形桌面环境，以及如何使用VNC从本地计算机连接至该桌面。 开始前的准备 熟悉入门指南，并按正确步骤设置好Linode的主机名及时区。 请阅读文档中保护您的服务器安全章节，以创建标准用户账号，加强SSH访问并移除不必要的网络服务。 升级您的系统 sudo apt-get update &amp;&amp; sudo apt-get upgrade 注意 本指南是为非root用户编写的，会在需要提升权限的命令之前加上sudo。如果您不熟悉sudo命令，请参阅Linux用户和用户组指南。 在Linode上安装桌面与VNC服务器1.Ubuntu的软件库中有多个可用的桌面环境。以下命令将会安装Ubuntu系统的默认桌面Unity，以及图形界面正常工作所需的依赖项： sudo apt-get install ubuntu-desktop gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal 注意 这将安装完整的Ubuntu桌面环境，包括办公软件和Web浏览器等工具。要只安装桌面而不安装这些软件包的话，请运行以下命令： sudo apt-get install --no-install-recommends ubuntu-desktop gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal 在安装过程中，系统会询问您是否将系统文件更新为新版本： Configuration file &#39;/etc/init/tty1.conf&#39; ==&gt; File on system created by you or by a script. ==&gt; File also in package provided by package maintainer. What would you like to do about it ? Your options are: Y or I : install the package maintainer&#39;s version N or O : keep your currently-installed version D : show the differences between the versions Z : start a shell to examine the situation The default action is to keep your current version. *** tty1.conf (Y/I/N/O/D/Z) [default=N] ? 输入 y 或 回车 确认更新。 2.安装VNC服务器： sudo apt-get install vnc4server 保护VNC连接安全VNC服务器生成 display （图形输出）编号，该编号在服务器启动时定义。如果未定义display编号，服务器将使用最小的可用编号。VNC连接使用的端口号是5900 + display。本指南将使用1作为display编号；因此，您将连接至远程的5901端口来使用VNC。 默认的VNC连接是非加密的。为了保护您密码和数据的安全，您需要借助SSH隧道将流量传输至本地端口。可以使用相同的本地端口来保持一致性。 Mac OS X和Linux1.在您的桌面环境下，通过以下命令连接至Linode。请务必将user@example.com替换为您的用户名、Linode主机名或IP地址： ssh -L 5901:127.0.0.1:5901 user@example.com 2.在您的Linode上启动VNC服务器并测试连接。系统将提示您设置密码： vncserver :1 3.根据从您的桌面连接至VNC章节的步骤初始化连接。 Windows1.打开PuTTY并导航至菜单中SSH下的Tunnels。按照下图所示新建一个转发端口，并将example.com替换为您Linode的IP地址或主机名： Putty设置 2.点击 Add，之后返回Session（会话）界面。输入您Linode的主机名或IP地址，以及会话的标题。点击 Save 保存设置以供将来使用，之后点击 Open 初始化SSH隧道。 3.启动VNC服务器并测试连接。系统将提示您设置密码： vncserver :1 4.根据从您的桌面连接至VNC章节的步骤初始化连接。 从您的桌面连接至VNC在本章节中，您将使用VNC客户端或 查看器 连接至远程服务器。查看器是绘制VNC服务器生成的图形界面并在本地计算机输出显示的软件。 Mac OS X和Windows在OS X和Windows上有很多查看器的选择，本指南将使用RealVNC Viewer。 1.安装并打开VNC Viewer后，通过VNC客户端连接至本地主机。VNC服务器地址格式为localhost:#，其中#代表我们在保护VNC连接安全章节中使用的display编号： VNC Viewer新建连接 2.系统会警告您连接未加密，但如果您已按照上述步骤确保了VNC连接的安全，则会话将安全的通过SSH隧道连接至您的Linode。点击 Continue 以继续： 警告连接未加密 3.系统将提示您输入首次启动VNC服务器时设定的密码。如果您尚未在Linode上启动VNC服务器，请参阅保护VNC连接安全章节。 设置VNC密码 连接后，您将看到一个空白的灰色屏幕，这是因为服务器的桌面进程尚未启动。在下一章节，我们将配置您的Linode以启动完整的桌面环境。 LinuxUbuntu桌面环境下有多款可用的VNC客户端。您可以在这里找到可供Ubuntu使用的VNC客户端列表。本指南将使用Ubuntu默认安装的Remmina。 1.打开Remmina。 Remmina界面 2.点击Create a new remote desktop profile按钮，新建一个远程桌面配置文件。为您的配置文件命名，指定VNC协议，并在服务器字段中输入localhost:1。服务器字段中的:1和display编号相对应。在密码设置中填写您在保护VNC连接安全章节中设定的密码： Remmina新建远程桌面配置文件 3.点击 Connect。 连接后，您将看到一个空白的灰色屏幕，这是因为服务器的桌面进程尚未启动。在下一章节，我们将配置您的Linode以启动完整的桌面环境。 配置VNC以启动完整桌面环境本章节将配置VNC，使其在启动时启动完整的Unity桌面。 1.成功连接之后，再退出该连接。关闭VNC服务器： vncserver -kill :1 2.根据以下配置编辑~/.vnc/xstartup文件的末尾部分。这将在启动VNC服务器时以后台进程的方式启动桌面依赖项： #!/bin/sh # 在常规模式下运行桌面时请取消掉以下两行的注释: # unset SESSION_MANAGER # exec /etc/X11/xinit/xinitrc [ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup [ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources xsetroot -solid grey vncconfig -iconic &amp; x-terminal-emulator -geometry 80x24+10+10 -ls -title &quot;$VNCDESKTOP Desktop&quot; &amp; x-window-manager &amp; gnome-panel &amp; gnome-settings-daemon &amp; metacity &amp; nautilus &amp; 3.保存并退出文件。重新启动VNC会话： vncserver :1 4.按照之前章节的相同步骤从您本地的VNC客户端连接至VNC服务器。现在您应该可以看见完整的Ubuntu桌面： 本地VNC Viewer连接至远程桌面 开机启动VNC服务器此部分是可选操作。请按以下步骤配置VNC服务器，使其在系统重启后可以自动启动。 1.启动您的crontab。如果您之前从未编辑过crontab配置文件，系统会提示您从可用的文本编辑器中选择一个对该文件进行编辑： crontab -e no crontab for user - using an empty one Select an editor. To change later, run 'select-editor'. 1. /bin/ed 2. /bin/nano 3. /usr/bin/vim.basic 4. /usr/bin/vim.tiny Choose 1-4 [2]: 2.在文件的最后添加@reboot /usr/bin/vncserver :1。您的crontab配置文件应该与以下内容类似： # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use &#39;*&#39; in these fields (for &#39;any&#39;). # # Notice that tasks will be started based on the cron&#39;s system # daemon&#39;s notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command @reboot /usr/bin/vncserver :1 3.保存并退出文件。您可以通过重启Linode服务器并连接VNC服务器来验证上述配置是否生效。 参考文章 Install VNC on Ubuntu 16.04 | Linode 在Ubuntu 16.04上安装VNC | 腾讯云+社区 VNC | Wikipedia RealVNC 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"VNC","slug":"VNC","permalink":"https://abelsu7.top/tags/VNC/"}]},{"title":"【译】如何使用 UFW 配置防火墙","slug":"configure-firewall-with-ufw","date":"2018-09-06T07:43:58.000Z","updated":"2019-09-01T13:04:11.052Z","comments":true,"path":"2018/09/06/configure-firewall-with-ufw/","link":"","permalink":"https://abelsu7.top/2018/09/06/configure-firewall-with-ufw/","excerpt":"UFW是什么？UFW（Uncomplicated Firewall）是Arch Linux、Debian或Ubuntu中管理防火墙规则的前端工具。UFW通常在命令行环境下使用（尽管UFW也提供了图形界面），目的是让配置防火墙变得简单（或者说，没那么复杂）。 使用UFW配置防火墙","text":"UFW是什么？UFW（Uncomplicated Firewall）是Arch Linux、Debian或Ubuntu中管理防火墙规则的前端工具。UFW通常在命令行环境下使用（尽管UFW也提供了图形界面），目的是让配置防火墙变得简单（或者说，没那么复杂）。 使用UFW配置防火墙 开始前的准备 熟悉入门指南，并按正确步骤设置好Linode的主机名及时区。 本指南会尽可能使用sudo权限。请阅读文档中保护您的服务器安全章节部分，以创建标准用户账号，加强SSH访问并移除不必要的网络服务。请不要遵循 创建防火墙 章节的指引——本指南将介绍如何使用UFW来控制防火墙，这是iptables命令之外另一种控制防火墙的方法。 升级您的系统 Arch Linux sudo pacman -Syu Debian / Ubuntu sudo apt-get update &amp;&amp; sudo apt-get upgrade 安装UFWUFW默认包含在Ubuntu中，但在Arch Linux及Debian中必须手动安装。Debian会自动启动UFW的systemd单元并使其在重启时启动，但Arch Linux并不会这样做。这与告诉UFW启用防火墙规则不同，因为通过systemd或upstart启动UFW只会告诉系统初始化程序启动UFW守护进程。 默认情况下，UFW的规则集为空——因此即使守护进程正在运行，也不会启用任何防火墙规则。启用防火墙规则集的内容将在页面下方进行介绍。 Arch Linux安装UFW： sudo pacman -S ufw 启动并启用UFW的systemd单元： sudo systemctl start ufw sudo systemctl enable ufw Debian / Ubuntu安装UFW sudo apt-get install ufw 使用UFW管理防火墙规则设置默认规则大部分系统只需要一小部分端口为传入连接打开，其余所有端口均关闭。先从简单的基础规则开始，ufw default命令可用来设置对传入和传出连接的默认响应。要想拒绝所有传入连接并允许所有传出连接，请运行： sudo ufw default allow outgoing sudo ufw default deny incoming ufw default命令还允许使用reject参数。 警告 除非有明确的允许规则，否则配置默认拒绝或拒绝规则可能会阻止您退出Linode。在应用默认拒绝或拒绝规则之前，请确保已按照以下部分为SSH和其他关键服务配置了允许规则。 添加规则可以通过两种方式添加防火墙规则：声明端口号或声明服务名称。 例如，要允许22端口上的传入和传出连接用于SSH，您可以运行： sudo ufw allow ssh 您还可以运行： sudo ufw allow 22 同样的，要拒绝某个端口上的流量（本例中为111端口），您只需运行： sudo ufw deny 111 要进一步微调规则，您还可以允许基于TCP或UDP的数据包通过。以下命令将允许80端口上的TCP数据包通过： sudo ufw allow 80/tcp sudo ufw allow http/tcp 而以下命令将允许1725端口上的UDP数据包通过： sudo ufw allow 1725/ufw 高级规则除了仅通过指定端口来添加允许或拒绝规则之外，UFW还可让您允许/阻止来自指定IP地址、子网或特定IP地址/子网/端口组合的连接。 允许来自指定IP地址的连接： sudo ufw allow from 123.45.67.89 允许来自指定子网的连接： sudo ufw allow from 123.45.67.89/24 允许来自指定IP地址/端口组合的连接： sudo ufw allow from 123.45.67.89 to any port 22 proto tcp 可根据您的实际需求删除proto tcp参数或替换为proto udp，并且如有需要，所有示例中的allow都可替换为deny。 删除规则要想删除规则，请在规则语句前添加delete。如果您不在希望允许HTTP流量通过，则可运行： sudo ufw delete allow 80 还可以通过指定服务名称来删除规则。 编辑UFW配置文件虽然可以通过命令行添加简单的规则，但有些时候也需要添加或删除更加高级或特定的防火墙规则。在运行通过终端输入的规则之前，UFW会首先运行before.rules文件中的规则，该文件允许本地环回（loopback）、ping以及DHCP通过防火墙。要对这些规则添加修改，请编辑/etc/ufw/before.rules文件。在相同目录下同样存在一个名为before6.rules的文件用来对IPv6的规则进行配置。 同样的，还存在after.rule和after6.rule文件，用来添加在UFW运行从命令行输入的规则后需要添加的任何规则。 另一个配置文件位于/etc/default/ufw。在该配置文件中可以禁用或启用IPv6，设置默认规则，还可以设置UFW来管理内置的防火墙链。 UFW状态您可随时使用sudo ufw status命令查看UFW的状态信息。这将以列表的形式打印出所有的规则信息，并显示UFW是否处于活跃状态： sudo ufw status Status: To Action From -- ------ ---- 22 ALLOW Anywhere 80/tcp ALLOW Anywhere 443 ALLOW Anywhere 22 (v6) ALLOW Anywhere (v6) 80/tcp (v6) ALLOW Anywhere (v6) 443 (v6) ALLOW Anywhere (v6) 启用防火墙根据您设置的规则，首次运行ufw status可能会输出Status: inactive。可通过以下命令启用UFW并强制执行防火墙规则： sudo ufw enable active 同样的，可通过以下命令禁用防火墙规则： sudo ufw disable 注意 系统重启后UFW服务仍会启动并运行。 UFW日志您可使用以下命令启用UFW日志记录： sudo ufw logging on 日志级别可通过sudo ufw logging low|medium|high设置，low、medium、high分别对应从低到高的级别，默认级别为low。 一条正常的日志记录与以下内容类似，它位于/var/logs/ufw： Sep 16 15:08:14 &lt;hostname&gt; kernel: [UFW BLOCK] IN=eth0 OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:00:00 SRC=123.45.67.89 DST=987.65.43.21 LEN=40 TOS=0x00 PREC=0x00 TTL=249 ID=8475 PROTO=TCP SPT=48247 DPT=22 WINDOW=1024 RES=0x00 SYN URGP=0 最开始的值分别表示日期，时间以及您的主机名。其他重要的字段包括： [UFW BLOCK]：此位置表示日志描述所定位的位置。本例中，日志是在阻止连接时记录的 IN：如果该字段有值，表示这是一个传入连接 OUT：如果该字段有值，表示这是一个传出连接 MAC：目的MAC地址和源MAC地址的组合 SRC：数据包的源IP地址 DST：数据包的目的IP地址 LEN：数据包长度 TTL：TTL（Time To Live）包，或称为生存时间。表示在没有找到目的地址的情况下，数据包会在路由器之间传输多久直至过期 PROTO：数据包的协议 SPT：数据包的源端口 DPT：数据包的目标端口 WINDOW：发送方可以接收的数据包大小 SYN URGP：表示是否需要三次握手，0表示不需要 参考文章 How to Configure a Firewall with UFW | Linode 如何使用UFW配置防火墙 | 腾讯云+社区 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"UFW","slug":"UFW","permalink":"https://abelsu7.top/tags/UFW/"}]},{"title":"【译】在 Ubuntu 16.04上安装 Seafile 并配置 Nginx","slug":"install-seafile-with-nginx-on-ubuntu-1604","date":"2018-09-06T06:55:10.000Z","updated":"2019-09-01T13:04:11.402Z","comments":true,"path":"2018/09/06/install-seafile-with-nginx-on-ubuntu-1604/","link":"","permalink":"https://abelsu7.top/2018/09/06/install-seafile-with-nginx-on-ubuntu-1604/","excerpt":"Seafile是一个跨平台的文件托管工具，包含了适用于Linux和Windows的服务器应用程序，以及适用于Android，iOS，Linux，OS X和Windows的GUI客户端。它支持文件版本控制和快照，双重身份验证，WebDAV（Web-based Distributed Authoring and Versioning），并且可以配合Nginx和Apache使用以启用HTTPS。 在Ubuntu 16.04上安装Seafile并配置Nginx Seafile有两个版本：免费的开源社区版和付费的专业版。虽然专业版最多可供3位用户免费使用，本教程还是将使用Seafile的社区版本，使用Nginx作为服务器提供HTTPS连接，后端使用MySQL数据库。","text":"Seafile是一个跨平台的文件托管工具，包含了适用于Linux和Windows的服务器应用程序，以及适用于Android，iOS，Linux，OS X和Windows的GUI客户端。它支持文件版本控制和快照，双重身份验证，WebDAV（Web-based Distributed Authoring and Versioning），并且可以配合Nginx和Apache使用以启用HTTPS。 在Ubuntu 16.04上安装Seafile并配置Nginx Seafile有两个版本：免费的开源社区版和付费的专业版。虽然专业版最多可供3位用户免费使用，本教程还是将使用Seafile的社区版本，使用Nginx作为服务器提供HTTPS连接，后端使用MySQL数据库。 准备Ubuntu环境 注意 本指南是为非root用户编写的，会在需要提升权限的命令之前加上sudo。如果您不熟悉sudo命令，请参阅Linux用户和用户组指南。 升级系统： apt update &amp;&amp; apt upgrade 使用root权限创建标准用户账户。本例中，我们将创建一个名为 sfadmin 的用户： adduser sfadmin adduser sfadmin sudo 注销您已登录Linode的root账户，然后以 sfadmin 的身份重新登录： exit ssh sfadmin@&lt;your_linode&#39;s_ip&gt; 现在您应该已经以 sfadmin 的身份登录到您的Linode服务器。请参考保护您的服务器安全指南以提高SSH访问的安全性。 设置UFW防火墙规则。UFW是Ubuntu的防火墙控制器，它让设置防火墙规则变得更加简单。有关UFW的更多信息，请参阅使用UFW配置防火墙指南。使用以下命令允许SSH和HTTP(S)通过防火墙： sudo ufw allow ssh sudo ufw allow http sudo ufw allow https sudo ufw enable 之后检查防火墙规则的状态，并以标号列表的形式列出： sudo ufw status numbered 输出应与下面的示例相似： Status: active To Action From -- ------ ---- [ 1] 22 ALLOW IN Anywhere [ 2] 80 ALLOW IN Anywhere [ 3] 443 ALLOW IN Anywhere [ 4] 22 (v6) ALLOW IN Anywhere (v6) [ 5] 80 (v6) ALLOW IN Anywhere (v6) [ 6] 443 (v6) ALLOW IN Anywhere (v6) 注意 如果不希望UFW在22端口上允许来自IPv4与IPv6的SSH连接，您可以删除对应的规则。例如，您可以运行sudo ufw delete 4命令来删除允许来自IPv6的SSH连接通过的规则。 设置Linode主机名，这里我们设置为 seafile ： sudo hostnamectl set-hostname seafile 在/etc/hosts中添加新主机名。该文件的第二行应该类似下面的示例： 127.0.1.1 members.linode.com seafile 首次启动时，您的Linode服务器时区会被设置为UTC（Coordinated Universal Time，世界协调时间）。更改时区是可选项，如果您希望这么做，请运行以下命令： sudo dpkg-reconfigure tzdata 安装并配置MySQL安装程序将要求您为MySQL的root用户设置密码。请确保您安装的是mysql-server-5.7，而不是mysql-server。这是因为如果您通过mysql-server包安装MySQL，一个来自上游的问题将导致MySQL服务在启动时出现错误。 sudo apt install mysql-server-5.7 运行 mysql_secure_installation 脚本： sudo mysql_secure_installation 有关MySQL的更多信息，请参阅在Ubuntu上安装MySQL指南。 创建可供Nginx使用的TLS证书如果您还没有SSL/TLS证书，可以现在创建一个。这是一个自签名证书，并让Web浏览器拒绝未经认证的连接。您应该验证浏览器证书的SHA256指纹与服务器证书的SHA256指纹是否相同，并在浏览器中添加例外以永久信任该证书。 切换到证书文件存储的路径，并使用密钥创建服务器证书： cd /etc/ssl sudo openssl genrsa -out privkey.pem 4096 sudo openssl req -new -x509 -key privkey.pem -out cacert.pem 安装并配置Nginx通过Ubuntu的软件库安装Nginx： sudo apt install nginx 创建站点配置文件。您唯一需要修改的一行是server_name。有关HTTPS的更多配置选项，请参阅Nginx的TLS最佳实践指南。 server{ listen 80; server_name example.com; rewrite ^ https://$http_host$request_uri? permanent; proxy_set_header X-Forwarded-For $remote_addr; } server { listen 443 ssl http2; ssl on; ssl_certificate /etc/ssl/cacert.pem; ssl_certificate_key /etc/ssl/privkey.pem; server_name example.com; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; add_header Strict-Transport-Security &quot;max-age=31536000; includeSubdomains&quot;; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options DENY; ssl_session_cache shared:SSL:10m; ssl_ciphers &quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH !RC4&quot;; ssl_prefer_server_ciphers on; fastcgi_param HTTPS on; fastcgi_param HTTP_SCHEME https; location / { fastcgi_pass 127.0.0.1:8000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_script_name; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; fastcgi_param REMOTE_ADDR $remote_addr; access_log /var/log/nginx/seahub.access.log; error_log /var/log/nginx/seahub.error.log; fastcgi_read_timeout 36000; client_max_body_size 0; } location /seafhttp { rewrite ^/seafhttp(.*)$ $1 break; proxy_pass http://127.0.0.1:8082; client_max_body_size 0; proxy_connect_timeout 36000s; proxy_read_timeout 36000s; proxy_send_timeout 36000s; send_timeout 36000s; proxy_request_buffering off; } location /media { root /home/sfadmin/sfroot/seafile-server-latest/seahub; } } 禁用默认的站点配置并启用刚刚创建的站点配置： sudo rm /etc/nginx/sites-enabled/default sudo ln -s /etc/nginx/sites-available/seafile.conf /etc/nginx/sites-enabled/seafile.conf 运行Nginx配置测试并重启Web服务器。如果测试失败，终端会显示简要的错误描述信息，以便您能借此解决问题。 sudo nginx -t sudo systemctl restart nginx 安装并配置SeafileSeafile手册建议使用特定的目录结构来简化日后的升级过程。在这里我们也会这样做，只不过我们把在sfadmin家目录下创建的目录命名为sfroot，而不是Seafile手册示例中的haiwen。 mkdir ~/sfroot &amp;&amp; cd ~/sfroot 下载Seafile CE Linux服务端安装文件的64位版本。您需要从Seafile官网获取对应的下载链接。取得下载URL后，使用wget命令将其下载至~/sfadmin/sfroot。 wget &lt;link&gt; 解压tarball，并将压缩包移动到installed目录： tar -xzvf seafile-server*.tar.gz mkdir installed &amp;&amp; mv seafile-server*.tar.gz installed 安装Seafile的依赖包： sudo apt install python2.7 libpython2.7 python-setuptools python-imaging python-ldap python-mysqldb python-memcache python-urllib3 运行安装脚本： cd seafile-server-* &amp;&amp; ./setup-seafile-mysql.sh 启动服务端程序。 ./seafile.sh start ./seahub.sh start-fastcgi seahub.sh脚本将创建用于登录Seafile的管理员用户账户。系统会要求您输入登录用的电子邮件账户并创建密码。 运行seahub.sh 现在可以通过您Linode服务器的IP地址，或是之前在Nginx的seafile.conf配置文件中设置的server_name，在Web浏览器中访问Seafile。如之前所说，Nginx将重定向至HTTPS连接，由于您创建了自签名证书，因此您的浏览器将警告该HTTPS连接不是私有的。忽略浏览器警告并继续访问该网址，您将看到Seafile的登录界面。 登录Seafile 设置Seafile在服务器启动时自启动seafile.sh与seahub.sh脚本并不会自动在您的Linode服务器重启后运行，需要我们手动进行设置。 创建systemd单元文件： /etc/systemd/system/seafile.service： [Unit] Description=Seafile Server After=network.target mysql.service [Service] Type=oneshot ExecStart=/home/sfadmin/sfroot/seafile-server-latest/seafile.sh start ExecStop=/home/sfadmin/sfroot/seafile-server-latest/seafile.sh stop RemainAfterExit=yes User=sfadmin Group=sfadmin [Install] WantedBy=multi-user.target /etc/systemd/system/seahub.service： [Unit] Description=Seafile Hub After=network.target seafile.service [Service] Type=oneshot ExecStart=/home/sfadmin/sfroot/seafile-server-latest/seahub.sh start-fastcgi ExecStop=/home/sfadmin/sfroot/seafile-server-latest/seahub.sh stop RemainAfterExit=yes User=sfadmin Group=sfadmin [Install] WantedBy=multi-user.target 之后启动服务： sudo systemctl enable seafile sudo systemctl enable seahub 您可以使用以下命令验证服务是否成功启动： sudo systemctl status seafile sudo systemctl status seahub 重新启动Linode服务器验证自启动脚本是否生效。服务器启动后，当运行上一步中的验证命令时，Seafile和Seahub都应处于活跃状态。同样的，此时您应该也可以在浏览器中访问Seafile服务。 升级Seafile有多种方法可供您升级Seafile。请参阅Seafile手册以了解最适合您需求的升级说明。 参考文章 Install Seafile with NGINX on Ubuntu 16.04 | Linode 在Ubuntu 16.04上安装Seafile并配置Nginx | 腾讯云+社区 Seafile Server手册 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书Linux基础笔记","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://abelsu7.top/tags/Nginx/"}]},{"title":"5 分钟 Docker 笔记 1：Docker 生态及核心概念","slug":"docker-5mins-notes-1","date":"2018-08-28T13:15:33.000Z","updated":"2019-09-01T13:04:11.124Z","comments":true,"path":"2018/08/28/docker-5mins-notes-1/","link":"","permalink":"https://abelsu7.top/2018/08/28/docker-5mins-notes-1/","excerpt":"容器生态系统及 Docker 核心概念 《每天5分钟玩转Docker容器技术》","text":"容器生态系统及 Docker 核心概念 《每天5分钟玩转Docker容器技术》 目录 目录 第 1 章 容器生态系统 1.1 容器核心技术 容器规范 容器 runtime 容器管理工具 容器定义工具 Registry 容器 OS 1.2 容器平台技术 容器编排引擎 容器管理平台 基于容器的 PaaS 1.3 容器支持技术 容器网络 服务发现 监控 数据管理 日志管理 安全性 第 2 章 容器核心知识概述 2.1 What-什么是容器 2.2 Why-为什么需要容器 2.3 How-容器是如何工作的 Docker 架构 Docker 客户端 Docker 服务器 Docker 镜像 Docker 容器 仓库 Registry 2.4 Docker 组件是如何协作的 第 1 章 容器生态系统大致看来，容器生态系统包含核心技术、平台技术和支持技术。 1.1 容器核心技术容器核心技术是指能够让 Container 在 host 上运行的那些技术： 容器规范 容器 runtime 容器管理工具 Registry 容器 OS 容器规范容器不光是 Docker，还有其他容器，比如 CoreOS 的 rkt。为了保证容器生态的健康发展，保证不同容器之间能够兼容，包含 Docker、CoreOS、Google在内的若干公司共同成立了一个叫 Open Container Initiative（OCI） 的组织，其目的是制定开放的容器规范。 目前 OCI 发布了两个规范： runtime spec image format spec 容器 runtimeruntime 是容器真正运行的地方。runtime 需要跟操作系统 kernel 紧密协作，为容器提供运行环境。 目前主流的三种容器 runtime： LXC：Linux 上老牌的容器 runtime。Docker 最初也是用 lxc 作为 runtime。 runC：Docker 自己开发的容器 runtime，符合 OCI 规范，也是现在 Docker 的默认 runtime。 rkt：CoreOS 开发的容器 runtime，符合 OCI 规范，因而能够运行 Docker 的容器。 容器管理工具光有 runtime 还不够，用户得有工具来管理容器。容器管理工具对内与 runtime 交互，对外为用户提供 interface，比如 CLI。这就好比除了 JVM，还得提供 java 命令让用户能够启停应用。 LXD 是 LXC 对应的管理工具 Docker Engine 是 runC 的管理工具。Docker Engine 包含后台 Deamon 和 Cli 两个部分。我们通常提到 Docker，一般就是指的 Docker Engine。 rkt CLI 是 rkt 的管理工具 容器定义工具容器定义工具允许用户定义容器的内容和属性，这样容器就能够被保存、共享和创建。 Docker image 是 Docker 容器的模板，runtime 依据 Docker image 创建容器。 Dockerfile 是包含若干命令的文本文件，可以通过这些命令创建出 Docker image。 ACI (App Container Image) 与 Docker image 类似，只不过它是由 CoreOS 开发的 rkt 容器的 image 格式。 Registry容器是通过 image 创建的，需要有一个仓库来统一存放 image，这个仓库就叫做 Registry。 Docker Hub 是 Docker 为公众提供的托管 Registry，上面有很多现成的 image，为 Docker 用户提供了极大的便利。 Quay.io 是另一个公共托管 Registry，提供与 Docker Hub 类似的服务。 容器 OS容器 OS 是专门运行容器的操作系统。与常规 OS 相比，容器 OS 通常体积更小，启动更快。因为是为容器定制的 OS，通常它们运行容器的效率会更高。 目前已经存在不少容器 OS： CoreOS Atomic Ubuntu Core 1.2 容器平台技术容器核心技术使得容器能够在单个 Host 上运行。而容器平台技术能够让容器作为集群在分布式环境中运行。 容器平台技术包括容器编排引擎、容器管理平台和基于容器的 PaaS。 容器编排引擎基于容器的应用一般会采用微服务架构。在这种架构下，应用被划分为不同的组件，并以服务的形式运行在各自的容器中，通过 API 对外提供服务。为了保证应用的高可用，每个组件都可能会运行多个相同的容器。这些容器会组成集群，集群中的容器会根据业务需要被动态地创建、迁移和销毁。 所谓编排（orchestration），通常包括容器管理、调度、集群定义和服务发现等。通过容器编排引擎，容器被有机的组合成微服务应用，实现业务需求。 Docker Swarm 是 Docker 开发的容器编排引擎。 kubernetes 是 Google 领导开发的开源容器编排引擎，同时支持 Docker 和 CoreOS 容器。 Apache Mesos 是一个通用的集群资源调度平台，Mesos 与 Marathon 一起提供容器编排引擎功能。 以上三者是当前主流的容器编排引擎。 容器管理平台容器管理平台是架构在容器编排引擎之上的一个更为通用的平台。通常容器管理平台能够支持多种编排引擎，抽象了编排引擎的底层实现细节，为用户提供更方便的功能，比如 application catalog 和一键应用部署等。 Rancher：开源的企业级 Kubernetes 管理平台 ContainerShip 基于容器的 PaaS基于容器的 PaaS 为微服务应用开发人员和公司提供了开发、部署和管理应用的平台，使用户不必关心底层基础设施而专注于应用的开发。以下是开源容器 PaaS 的代表： Deis（注：已被微软收购） Flynn Dokku 1.3 容器支持技术下面这些技术被用于支持基于容器的基础设施： 容器网络 服务发现 监控 数据管理 日志管理 安全性 容器网络容器的出现使网络拓扑变得更加动态和复杂。用户需要专门的解决方案来管理容器与容器，容器与其他实体之间的连通性和隔离性。 docker network 是 Docker 原生的网络解决方案。除此之外，我们还可以采用第三方开源解决方案，例如 flannel、weave 和 calico。 docker network flannel weave calico 服务发现动态变化是微服务应用的一大特点。当负载增加时，集群会自动创建新的容器；负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同 host 中迁移，容器的 IP 和端口也会随之发生变化。 在这种动态的环境下，必须要有一种机制让 client 能够知道如何访问容器提供的服务。这就是服务发现技术要完成的工作。 服务发现会保存容器集群中所有微服务最新的信息，比如 IP 和端口，并对外提供 API，提供服务查询功能。 etcd consul zookeeper etcd、consul 和 zookeeper 是服务发现的典型解决方案。 监控容器的动态特征对监控提出更多挑战。针对容器环境，已经涌现出很多监控工具和方案： docker ps/top/stats docker stats API sysdig cAdvisor/Heapster Weave Scope docker ps/top/stats 是 Docker 原生的命令行监控工具。除了命令行，Docker 也提供了 stats API，用户可以通过 HTTP 请求获取容器的状态信息。 sysdig、cAdvisor/Heapster 和 Weave Scope 是其他开源的容器监控方案。 数据管理容器经常会在不同的 host 之间迁移，如何保证持久化数据也能够动态迁移，是 Rex-Ray 这类数据管理工具提供的能力。 日志管理日志为问题排查和事件管理提供了重要依据。 docker logs：Docker 原生的日志工具 logspout：对日志提供了路由功能，它可以收集不同容器的日志并转发给其他工具进行后续处理。 安全性OpenSCAP 能够对容器镜像进行扫描，发现潜在的漏洞。 第 2 章 容器核心知识概述2.1 What-什么是容器 虚拟机 VS 容器 如图所示，由于所有的容器共享同一个 Host OS，这使得容器在体积上要比虚拟机小很多。 另外，启动容器不需要启动整个操作系统，所以容器部署和启动速度更快，开销更小，也更容易迁移。 2.2 Why-为什么需要容器 对于开发人员：Build Once, Run Anywhere 对于运维人员：Configure Once, Run Anything 2.3 How-容器是如何工作的Docker 架构Docker 的核心组件包括： Docker 客户端 - Client Docker 服务器 - Docker Daemon Docker 镜像 - Image 仓库 - Registry Docker 容器 - Container Docker 架构图 Docker 采用的是 C/S 架构。客户端向服务器发送请求，服务器负责构建、运行和分发容器。 客户端和服务器可以运行在同一个 Host 上，客户端也可以通过 Socket 或 REST API 与远程的服务器通信。 Docker 客户端最常用的 Docker 客户端是 docker 命令。通过 docker 我们可以方便地在 Host 上构建和运行容器。 除了 docker 命令行工具，用户也可以通过 REST API 与服务器通信。 Docker 服务器Docker daemon 是服务器组件，以 Linux 后台服务的方式运行。 Docker daemon Docker daemon 运行在 Docker host 上，负责创建、运行、监控容器，构建、存储镜像。 默认配置下，Docker daemon 只能响应来自本地 Host 的客户端请求。如果要允许远程客户端请求，需要在配置文件中打开 TCP 监听，步骤如下： (1) 编辑配置文件 /etc/systemd/system/multi-user.target.wants/docker.service，在环境变量 ExecStart 后面添加 -H tcp://0.0.0.0，允许来自任意 IP 的客户端连接。 [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker ExecStart=/usr/bin/dockerd -H fd:// -H tcp://0.0.0.0 ExecReload=/bin/kill -s HUP $MAINPID 注：以上配置文件 Ubuntu 18.04 为例，在其他操作系统中配置文件可能并不相同。 (2) 重启 Docker daemon systemctl daemon-reload systemctl restart docker.service (3) 假设服务器 IP 为 192.168.56.102，客户端在命令行里加上 -H 参数，即可与远程服务器通信。 docker -H 192.168.56.102 info Containers: 1 Running: 0 Paused: 0 Stopped: 1 Images: 1 Server Version: 18.06.1-ce ... Docker 镜像可将 Docker 镜像看作只读模板，通过它可以创建 Docker 容器。 镜像有多种生成方法： 可以从无到有开始创建镜像 也可以下载并使用别人创建好的现成的镜像 还可以在现有镜像上创建新的镜像 我们可以将镜像的内容和创建步骤描述在一个文本文件中，这个文件被称作 Dockerfile，通过执行 docker build &lt;docker-file&gt; 命令可以构建出 Docker 镜像。 Docker 容器Docker 容器就是 Docker 镜像的运行实例。用户可以通过 CLI（docker）或是 API 启动、停止、移动或删除容器。 可以这么认为，对于应用软件，镜像是软件生命周期的构建和打包阶段，而容器则是启动和运行阶段。 仓库 RegistryRegistry 是存放 Docker 镜像的仓库，分私有和公有两种。 Docker Hub 是默认的 Registry，由 Docker 公司维护，上面有数以万计的镜像，用户可以自由下载和使用。 出于对速度或安全的考虑，用户也可以创建自己的私有 Registry。 docker pull 命令可以从 Registry 下载镜像 docker run 命令则是先下载镜像（如果本地没有），然后再启动容器 2.4 Docker 组件是如何协作的一个容器启动过程的示例如下： 容器启动过程示例 Docker 客户端执行 docker run 命令 Docker daemon 发现本地没有 httpd 镜像 daemon 从 Docker Hub 下载镜像 下载完成，镜像 httpd 被保存在本地 Docker daemon 启动容器 另外，使用 docker images 命令可以查看本地已下载的镜像。 使用 docker ps 或 docker container ls 命令显示正在运行的容器及相关信息。 参考文章 《每天5分钟玩转 Docker 容器技术》教程目录 | CloudMan Mesos+Marathon对比Kubernetes | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）微服务编排与容器调度微服务学习资料汇总近期复习合集Linux 内核笔记 1：绪论影响力数学之美：不能再凑了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/categories/Docker/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://abelsu7.top/tags/读书/"},{"name":"容器","slug":"容器","permalink":"https://abelsu7.top/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://abelsu7.top/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://abelsu7.top/tags/Kubernetes/"}]},{"title":"Google 集群管理器 Borg 论文相关","slug":"rsync-and-borg","date":"2018-08-23T07:21:26.000Z","updated":"2019-09-01T13:04:11.668Z","comments":true,"path":"2018/08/23/rsync-and-borg/","link":"","permalink":"https://abelsu7.top/2018/08/23/rsync-and-borg/","excerpt":"To be updated… Borg 论文读后感 | hellojava.info Google 大规模集群管理器 Borg | 枯木","text":"To be updated… Borg 论文读后感 | hellojava.info Google 大规模集群管理器 Borg | 枯木 参考文章 rsync基础及基本使用 | 51CTO博客 译：Google的大规模集群管理工具Borg（一）——— 用户视角的Borg特性 | cnblogs 译：Google的大规模集群管理工具Borg（二）——— Borg架构 | cnblogs 全球发布！阿里云Serverless Kubernetes全球免费公测 | 阿里云 阿里混部技术最佳实践 | InfoQ 阿里混部技术最佳实践 | MySlide 解密阿里“双11”超级工程，混部技术亮了 | CSDN 阿里决战双11核心技术揭秘——混部调度助力云化战略再次突破 | 雷锋网 谷歌Borg论文阅读笔记（一）——分布式架构 | 云栖社区 谷歌Borg论文阅读笔记（二）——任务混部的解决 | 云栖社区","categories":[{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/categories/云计算/"}],"tags":[{"name":"Borg","slug":"Borg","permalink":"https://abelsu7.top/tags/Borg/"}]},{"title":"Java 中 String，StringBuilder，StringBuffer 三者的区别","slug":"java-string-builder-buffer","date":"2018-07-12T06:55:08.000Z","updated":"2019-09-01T13:04:11.417Z","comments":true,"path":"2018/07/12/java-string-builder-buffer/","link":"","permalink":"https://abelsu7.top/2018/07/12/java-string-builder-buffer/","excerpt":"Java中关于字符串有三个相关的类：String,StringBuilder和StringBuffer，那么这三个类之间有什么区别呢？cnblogs博主酥风对此做了整理记录，摘抄过来仅供参考。 简单来说，这三个类之间的区别主要是在两个方面：运行速度和线程安全。 运行速度首先来看运行速度，StringBuilder &gt; StringBuffer &gt; String 。 String最慢的原因在于：String为字符串常量，即String对象一旦创建之后是不可以更改的，但后两者的对象是变量，是可以更改的。以下面的一段代码为例， String str = &quot;abc&quot;; System.out.println(str); str = str + &quot;de&quot;; System.out.println(str); 如果运行这段代码会发现先输出abc，然后又输出abcde，好像是str这个对象被更改了。但其实，这只是一种假象罢了。","text":"Java中关于字符串有三个相关的类：String,StringBuilder和StringBuffer，那么这三个类之间有什么区别呢？cnblogs博主酥风对此做了整理记录，摘抄过来仅供参考。 简单来说，这三个类之间的区别主要是在两个方面：运行速度和线程安全。 运行速度首先来看运行速度，StringBuilder &gt; StringBuffer &gt; String 。 String最慢的原因在于：String为字符串常量，即String对象一旦创建之后是不可以更改的，但后两者的对象是变量，是可以更改的。以下面的一段代码为例， String str = &quot;abc&quot;; System.out.println(str); str = str + &quot;de&quot;; System.out.println(str); 如果运行这段代码会发现先输出abc，然后又输出abcde，好像是str这个对象被更改了。但其实，这只是一种假象罢了。 JVM对于这几行代码是这样处理的： 首先创建一个String对象str，并把&quot;abc&quot;赋值给str 然后在第3行中，JVM又创建了一个新的对象也名为str 然后再把原来的str的值和&quot;de&quot;加起来再赋值给新的str 原来的str最后被JVM的GC机制回收 因此，str实际上并没有被改变，也就是前面提到的：String对象一旦创建之后就不可更改了。换言之，Java中对String对象的操作实际上是一个不断创建新的对象并且将旧的对象回收的一个过程，所以执行速度很慢。 而StringBuilder和StringBuffer的对象是变量，对变量进行操作就是直接对该对象进行更改，而不进行创建和回收的操作，所以速度要比String快很多。 另外，有时候我们会这样对字符串进行赋值， String str = &quot;abc&quot; + &quot;de&quot;; StringBuilder stringBuilder = new StringBuilder().append(&quot;abc&quot;).append(&quot;de&quot;); System.out.println(str); System.out.println(stringBuilder.toString()); 这样输出的结果也是abcde和abcde，但是String的速度却比StringBuilder的反应速度快很多，这是因为第1行中的操作和String str = &quot;abcde&quot;;是完全一样的，所以会很快。如果写成下面的形式， String str1 = &quot;abc&quot;; String str2 = &quot;de&quot;; String str = str1 + str2; 那么JVM就会像之前所提到的，不断的创建、回收对象来进行这个操作，速度就会很慢。 线程安全从线程的角度来看，StringBuilder是线程不安全的，而StringBuffer是线程安全的。 如果一个StringBuffer对象在字符串缓冲区被多个线程使用时，StringBuffer中很多方法可以带有synchronized关键字，所以可以保证线程是安全的；而StringBuilder的方法则没有synchronized关键字，所以不能保证线程安全。 多线程的操作时，需要使用StringBuffer单线程的情况下，建议使用StringBuilder，速度较快 总结 String：适用于操作少量字符串的情况 StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况 StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况 参考文章 Java中的String，StringBuilder，StringBuffer三者的区别 | cnblogs - 酥风 🚩推荐阅读（由hexo文章推荐插件驱动）Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序Java 笔记 4：接口、lambda 表达式与内部类后端开发 - Java开发环境配置 - 入门篇在非GPL应用中使用OpenJDK的法律问题","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"字符串","slug":"字符串","permalink":"https://abelsu7.top/tags/字符串/"}]},{"title":"Java 判断字符串是否为空","slug":"java-check-null-string","date":"2018-07-11T09:06:19.000Z","updated":"2019-09-01T13:04:11.416Z","comments":true,"path":"2018/07/11/java-check-null-string/","link":"","permalink":"https://abelsu7.top/2018/07/11/java-check-null-string/","excerpt":"判断String类型字符串str是否为空有以下几种方法， str == null; // 1. 判断字符串对象是否实例化 &quot;&quot;.equals(str); // 2. 判断空字符串是否与被检验字符串相等 str.length &lt;= 0; // 3. 判断字符串长度是否大于0 str.isEmpty(;) // 4. 调用String类型的isEmpty()方法","text":"判断String类型字符串str是否为空有以下几种方法， str == null; // 1. 判断字符串对象是否实例化 &quot;&quot;.equals(str); // 2. 判断空字符串是否与被检验字符串相等 str.length &lt;= 0; // 3. 判断字符串长度是否大于0 str.isEmpty(;) // 4. 调用String类型的isEmpty()方法 需要注意的是， length是属性，也是一般集合类对象都拥有的属性，取值为集合的大小；而length()是方法，调用后取得集合的长度。 null表示这个字符串不指向任何对象，如果这时候调用它的方法，就会出现空指针异常。 null不是对象，&quot;&quot;是对象，所以null没有分配空间，而&quot;&quot;分配了空间。 所以，判断一个字符串是否为空，首先要确保它不是null，然后再判断它的长度。 参考文章 Java字符串为空的判定 | cnblogs - 毛无语666 🚩推荐阅读（由hexo文章推荐插件驱动）Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序Java 笔记 4：接口、lambda 表达式与内部类后端开发 - Java开发环境配置 - 入门篇在非GPL应用中使用OpenJDK的法律问题","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"字符串","slug":"字符串","permalink":"https://abelsu7.top/tags/字符串/"}]},{"title":"Android 在一个 Activity 中 finish 掉另外一个 Activity","slug":"android-finish-activity","date":"2018-07-11T08:53:36.000Z","updated":"2019-09-01T13:04:10.980Z","comments":true,"path":"2018/07/11/android-finish-activity/","link":"","permalink":"https://abelsu7.top/2018/07/11/android-finish-activity/","excerpt":"static TaskHomeActivity instance; // 在被finish掉的activity中定义 instance = this; // 在被finish掉的activity的onCreate方法中定义 TaskHomeActivity.instance.finish(); // 在其他Activity里调用","text":"static TaskHomeActivity instance; // 在被finish掉的activity中定义 instance = this; // 在被finish掉的activity的onCreate方法中定义 TaskHomeActivity.instance.finish(); // 在其他Activity里调用 参考文章 Android在一个Activity中finish掉另外一个activity | CSDN Android在另一个Activity里怎样finish()掉其他Activity | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序Java 笔记 4：接口、lambda 表达式与内部类移动开发 - Android开发环境配置 - 入门篇后端开发 - Java开发环境配置 - 入门篇","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://abelsu7.top/tags/Android/"},{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"}]},{"title":"开源下载工具aria2使用教程","slug":"aria2","date":"2018-05-11T03:34:44.000Z","updated":"2019-10-12T04:05:17.858Z","comments":true,"path":"2018/05/11/aria2/","link":"","permalink":"https://abelsu7.top/2018/05/11/aria2/","excerpt":"aria2.github.io 是一款开源下载工具","text":"aria2.github.io 是一款开源下载工具 1. 安装简介 下载 aria2：aria2.github.io 下载 Web UI：AriaNg | Github Chrome 插件 &amp; 配置文件：BaiduExporter | Github 启动脚本 2. 启动脚本Start.bat： @echo off &amp; title Aria2 aria2c.exe --conf-path=aria2.conf Start.vbs： CreateObject(&quot;WScript.Shell&quot;).Run &quot;aria2c.exe --conf-path=aria2.conf&quot;,0 Status.bat： @echo off &amp; title Aria2 Status TaskList /FI &quot;IMAGENAME eq aria2c.exe&quot; /FO LIST pause &gt; nul Restart.bat： Taskkill /F /IM aria2c.exe start Start.vbs Stop.bat： @echo off &amp; title Aria2 Stop Taskkill /F /IM aria2c.exe pause &gt; nul Boot.bat： @echo off &amp; title Aria2 开机启动 echo 1.将 Aria2 设为开机启动 echo 2.取消 Aria2 开机启动 set /p aria2= 请输入对应的序号： IF %aria2% EQU 1 (REG ADD HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\\ /v Aria2 /t REG_SZ /d %cd%\\Start.vbs /f) IF %aria2% EQU 2 (REG DELETE HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\\ /v Aria2 /f) pause &gt; nul 参考文章 下载地址 aria2 | Github aria2.github.io 下载工具系列——Aria2（几乎全能的下载神器）| Senraの小窝 Aria2 + Web UI，迅雷倒下之后的替代品 | 白化火柴的博客 PDM - 真·零配置的aria2下载器 | 小众软件 替代迅雷！小白都会用的免配置 Aria2 图形界面版免费开源下载软件 PDM | 异次元 「下载神器」aria2 懒人安装教程 | 小众软件 Mac下使用Aria2实现迅雷离线和百度云下载 | 知乎 Mac下使用Aria2实现迅雷离线和百度云下载 | ChenTalk Mac配置Aria2，高速下载百度云 | YALV的博客 Mac 上使用百度网盘很烦躁？花点时间配置 aria2 吧 | 少数派 Web UI AriaNg | Github webui-aria2 | Github YAAW | Github PDM | Persepolis Download Manager PDM | Github Chrome 插件 BaiduExporter | Github 🚩推荐阅读（由hexo文章推荐插件驱动）Fluent Terminal：Windows 下的炫酷终端Windows 10 终端 PowerShell 外观美化几款监控 CPU 温度的软件推荐Windows 10 彻底删除已配对的蓝牙设备Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"},{"name":"Aria2","slug":"Aria2","permalink":"https://abelsu7.top/tags/Aria2/"}]},{"title":"CentOS 执行 sudo 提示 xxx is not in the sudoers file","slug":"not-in-the-sudoers-file","date":"2018-05-09T08:05:30.000Z","updated":"2019-09-01T13:04:11.593Z","comments":true,"path":"2018/05/09/not-in-the-sudoers-file/","link":"","permalink":"https://abelsu7.top/2018/05/09/not-in-the-sudoers-file/","excerpt":"在新安装的CentOS系统中,使用默认创建的用户执行sudo命令时终端报错： xxx is not in the sudoers file. This incident will be reported. 报错原因CentOS默认创建的用户并没有sudo命令的执行权限，而且CentOS中也并不存在sudo用户组。 不同于CentOS，Ubuntu在安装后默认创建的用户属于sudo用户组，因此可以使用sudo命令。","text":"在新安装的CentOS系统中,使用默认创建的用户执行sudo命令时终端报错： xxx is not in the sudoers file. This incident will be reported. 报错原因CentOS默认创建的用户并没有sudo命令的执行权限，而且CentOS中也并不存在sudo用户组。 不同于CentOS，Ubuntu在安装后默认创建的用户属于sudo用户组，因此可以使用sudo命令。 /etc/sudoers 文件简介错误信息中提到的sudoers file位于/etc/sudoers，root用户使用visudo命令可对其进行查看，最开始的文件介绍内容如下： ## Sudoers allows particular users to run various commands as ## the root user, without needing the root password. ## ## Examples are provided at the bottom of the file for collections ## of related commands, which can then be delegated out to particular ## users or groups. ## ## This file must be edited with the `visudo` command. 概括来说，sudoers文件允许指定用户在运行命令时获取root权限而无需输入root密码。 根据最后一行，必须通过visudo命令来对/etc/sudoers文件进行编辑，该命令需要root权限。 sudoers文件可对多种类型的命令权限及用户组权限进行授权，预设的命令包括网络管理、软件安装与管理、服务管理、数据库升级、存储管理、权限代理、进程管理、驱动管理等，预设的命令如下： ## Networking # Cmnd_Alias NETWORKING = /sbin/route, /sbin/ifconfig, /bin/ping, /sbin/dhclient, /usr/bin/net, /sbin/iptables, /usr/bin/rfcomm, /usr/bin/wvdial, /sbin/iwconfig, /sbin/mii-tool ## Installation and management of software # Cmnd_Alias SOFTWARE = /bin/rom, /usr/bin/up2date, /usr/bin/yum ## Services # Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig ## Updating the locate database # Cmnd_Alias LOCATE = /usr/bin/updatedb ## Storage # Cmnd_Alias STORAGE = /sbin/fdisk, /sbin/sfdisk, /sbin/parted, /sbin/partprobe, /bin/mount, /bin/umount ## Delegating permissions # Cmnd_Alias DELEGATING = /usr/sbin/visudo, /bin/chown, /bin/chmod, /bin/chgrp ## Processes # Cmnd_Alias PROCESSES = /bin/nice, /bin/kill, /usr/bin/kill, /usr/bin/killall ## Drivers # Cmnd_Alias DRIVERS = /sbin/modprobe 解决办法首先使用root用户运行visudo命令，打开/etc/sudoers文件，找到如下所示的片段： ## Next comes the main part: which users can run what software on ## which machines (the sudoers file can be shared between multiple systems). ## Syntax: ## ## user MACHINE=COMMANDS ## ## The COMMANDS section may have other options added to it. ## ## Allow root to run any commands anywhere root ALL=(ALL) ALL 以及 ## Allow people in group wheel to run all commands # %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL 可知有两种方法可让指定用户获取sudo权限。 直接给指定用户授权查阅网上相关博客，大多是基于此方法。例如用户名为test，直接给test用户授权，只需在root用户的授权定义下添加相同的授权定义，将用户名改为test： ## Allow root to run any commands anywhere root ALL=(ALL) ALL ## Allow test to run any commands anywhere test ALL=(ALL) ALL 这种方法虽然简单却也比较极端：例如将test用户删除后忘记删除sudoers中的授权，之后再次新建同名账户的话，test用户就直接获得了sudo权限，存在安全隐患；而且每次新建用户后都需要再次添加授权定义，操作很麻烦，因此推荐使用下面的方法。 将指定用户加入wheel用户组可以注意到，在sudoers文件中可对wheel用户组整体授权，因此可先将用户test加入用户组wheel中： su - root usermod -G wheel test 之后通过visudo命令在sudoers文件中对wheel用户组进行授权，分为需要密码和无需密码两种方式，取消掉任意一种授权前面的注释即可： ## Allow people in group wheel to run all commands %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL 保存文件并退出，问题解决。 测试一下首先创建用户test，并设置用户密码： useradd test id test uid=502(test) gid=502(test) groups=502(test) groups test test : test passwd test 切换至test用户，尝试运行sudo visudo命令，提示无sudo权限： [root@centos ~]$ su - test [test@centos ~]$ sudo visudo test is not in the sudoers file. This incident will be reported. 切换回root用户，将test加入wheel用户组，再次尝试使用test用户运行sudo visudo命令，成功执行，问题解决！ [test@centos ~]$ su - root [root@centos ~]$ usermod -G wheel test [root@centos ~]$ id test uid=502(test) gid=502(test) groups=502(test),10(wheel) [root@centos ~]$ groups test test : test wheel [root@centos ~]$ su - test [test@centos ~]$ sudo visudo 参考文章 Linux配置之解决CentOS中：xx is not in the sudoers file的问题 | CSDN is not in the sudoers file 解决(转) | CSDN 使用sudo时user is not in sudoers file的解决 | CSDN user is not in the sudoers file. This incident will be reported. | StackOverflow 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能在CentOS上使用certbot为nginx添加https证书从零开始搭建CentOS+Python+nodejs开发环境","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/categories/CentOS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"CentOS","slug":"CentOS","permalink":"https://abelsu7.top/tags/CentOS/"}]},{"title":"Linux 网络管理","slug":"linux-network","date":"2018-04-20T08:15:56.000Z","updated":"2019-09-01T13:04:11.501Z","comments":true,"path":"2018/04/20/linux-network/","link":"","permalink":"https://abelsu7.top/2018/04/20/linux-network/","excerpt":"Linux网络管理","text":"Linux网络管理 查看网口的配置# 使用ifconfig查看IP地址、广播地址和掩码等 ifconfig &lt;接口&gt; 修改网口的配置1. 通过命令修改（重启后失效） # ifconfig 网口 [参数] ifconfig eth3 192.168.100.128 broadcast 192.168.100.255 netmask 255.255.255.0 设置网口的参数，如IP、广播地址和掩码等 重启网络服务或操作系统后失效 2. 修改网络配置文件（重启后依然有效） 修改/etc/sysconfig/network/ifcfg-[网口] 编辑配置文件配置网口 使用ifup命令，启动网口 vi ifcfg-eth4 ifup ifcfg-eth4 查询路由表使用route命令查询本机路由表 route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default 172.16.0.1 0.0.0.0 UG 0 0 0 eth0 172.16.0.0 * 255.255.240.0 U 0 0 0 eth0 Destination表示目的网关或目的主机，如果值为default，表示这是一条默认的路由 Gateway表示网关 Genmask表示网段掩码 Flags标记为U，表示这条路由状态是UP，该路由可用 Flags标记为G，表示需要通过网关转发 Flags标记为H，表示目的地址是一个主机 Iface表示该路由的网络出口 新增路由1. 通过命令修改（重启后失效） # route add [-net|-host] [netmask Nm] [gw Gw] [[dev] If] route add -net 192.168.101.0 netmask 255.255.255.0 dev eth3 route add -host 192.168.101.100 dev eth1`` 本命令新增到网段或者主机的路由 新增路由保存在内存中，系统重启后失效 2. 修改路由配置文件（重启后依然有效） 修改/etc/sysconfig/network/routes 用来保存静态路由数据 需要重启网络服务才能生效 侦测网络 侦测网络常用命令 ping命令 # ping [参数] 目的地址 ping -c 5 10.77.215.5 -c：后接执行ping的次数 检查网络是否通常或者检测网络连接速度 traceroute命令 # traceroute &lt;地址 or 主机名&gt; traceroute 10.77.215.5 探测数据包从源到目的经过的路由 配置常用网络服务配置FTP服务 YaST是SUSE Linux中自带的图形化工具，用来设置软件、硬件系统和网络服务 使用root用户登录系统，执行yast命令 在YaST界面，选择Services &gt; Network Services(xinetd)，启动vsftpd服务 修改/etc/vsftpd.conf配置文件，取消下边列出的注释 修改/etc/ftpusers配置文件，在root前添加注释# 重启xinetd服务：/etc/init.d/xinetd restart ascii_upload_enable 上传权限 ascii_download_enable 下载权限 local_enable 本地系统用户FTP权限 write_enable 用户写权限 设置 anonymous_enable=NO 设置 listen=NO 配置Telnet服务 使用root用户登录系统，执行YaST命令 在YaST界面，选择Network Services &gt; Network Services(xinetd)，开启Telnet服务 vi修改/etc/pam.d/login，在auth required pam_securetty.so前添加注释# 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Ubuntu下搭建多用户多权限FTPLinux基础笔记","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"FTP","slug":"FTP","permalink":"https://abelsu7.top/tags/FTP/"},{"name":"Telnet","slug":"Telnet","permalink":"https://abelsu7.top/tags/Telnet/"}]},{"title":"Linux LVM 配置","slug":"linux-LVM","date":"2018-04-20T03:52:40.000Z","updated":"2019-09-01T13:04:11.489Z","comments":true,"path":"2018/04/20/linux-LVM/","link":"","permalink":"https://abelsu7.top/2018/04/20/linux-LVM/","excerpt":"Linux LVM配置 LVM原理LVM是Logical Volume Manager的简写，是建立在硬盘和分区之间的逻辑层，用来提高磁盘分区管理的灵活性 LVM设计的主要目标是实现文件系统存储容量的可扩展性，使对容量的调整更为简易","text":"Linux LVM配置 LVM原理LVM是Logical Volume Manager的简写，是建立在硬盘和分区之间的逻辑层，用来提高磁盘分区管理的灵活性 LVM设计的主要目标是实现文件系统存储容量的可扩展性，使对容量的调整更为简易 LVM架构 LVM架构 PP（Physical Partition）：物理分区，LVM正是构建在物理分区之上的 PV（Physical Volumn）：物理卷，是PP的LVM抽象，维护了PP的基本信息，是组成PG的基本逻辑单元，一般一个PV对应一个PP PE（Physical Extends）：物理扩展单元，每个PV都会以PE为基本单元划分，是LVM的最小存储单元 VG（Volumn Group）：卷组，即LVM的卷组，可以由一个或者数个PV组成，可以看成是LVM组成的大磁盘 LE（Logical Extends）：逻辑扩展单元，是组成LV的基本单元，一个LE对应一个PE LV（Logical Volumn）：逻辑卷，建立在VG之上，文件系统之下，由若干个LE组成，文件系统就是基于逻辑卷的 VG、LV和PE的关系 VG、LV和PE的关系 LVM是通过交换PE的方式来达到弹性变更文件系统大小的功能 将LV中原来的PE移除，就能减小LV的容量 将VG中其他PE添加到LV中，就能扩充LV的容量 可以通过增加PV的方式来扩充VG 一般LVM默认PE的大小是4M，而LVM最多能有65534个PE，所以LVM的VG最大为256G PE是LVM最小的存储区块，类似文件系统的block，所以PE的大小会影响到VG的容量 LV和磁盘的/dev/sda2分区类似，是能够用来格式化的单位 对文件系统而言，对LV的操作与原先对partition的操作是没有区别的 当对LV进行写入操作时，LVM定位相应的LE，通过PV头部的映射表将数据写入到相应的PE上 LV实现的关键在于PE与LE间建立的映射关系，不同的映射规则就决定了不同的LVM存储模型 LVM的优点 文件系统可以跨多个磁盘，大小不会受物理磁盘限制 可系统运行的情况下动态地扩展文件系统大小 可增加新磁盘到LVM的存储池中 LVM使用要点 按需分配文件系统大小 把不同数据放在不同的卷组中 LVM配置流程 LVM配置流程 物理分区阶段：首先通过fdisk将System ID修改为LVM标记（8e） PV阶段：再通过pvcreate、pvdisplay将Linux分区处理成物理卷PV VG阶段：接下来通过vgcreate、vgdisplay将创建好的物理卷PV处理成卷组VG LV阶段：通过lvcreate将卷组分成若干个逻辑卷LV 操作系统使用阶段：再通过mkfs将LV格式化，最后通过fdisk、mount挂载格式化后的LV到文件系统 物理卷（PV）管理相关命令 命令 功能 pvcreate 创建物理卷 pvscan 查看物理卷信息 pvdisplay 查看各个物理卷的详细参数 pvremove 删除物理卷 pvcreate # 将普通的分区加上PV属性 # 例如：将分区/dev/sda6创建为物理卷 pvcreate /dev/sda6 pvremove # 删除分区的PV属性 # 例如：删除分区/dev/sda6的物理卷属性 pvremove /dev/sda6 pvscan、pvdisplay 都是用来查看PV的信息 pvdisplay更为详细 卷组（VG）管理相关命令 命令 功能 vgcreate 创建卷组 vgscan 查看卷组信息 vgdisplay 查看卷组的详细参数 vgreduce 缩小卷组，把物理卷从卷组中删除 vgextend 扩展卷组，把某个物理卷添加到卷组中 vgremove 删除卷组 逻辑卷（LV）管理相关命令 命令 功能 lvcreate 创建逻辑卷 lvscan 查看逻辑卷信息 lvdisplay 查看逻辑卷的具体参数 lvextend 增大逻辑卷大小 lvreduce 减小逻辑卷大小 lvremove 删除逻辑卷 逻辑卷LV管理命令 管理文件系统空间1. 增大文件系统空间 先卸载逻辑卷 然后通过vgextend，lvextend等命令增大LV的空间 再使用resize2fs将逻辑卷容量增加 最后将逻辑卷挂载到目录树 2. 缩小文件系统空间 先卸载逻辑卷 然后使用resize2fs将逻辑卷容量减小 再通过lvreduce等命令减小LV的空间 最后将逻辑卷挂载到目录树 参考文章 一张图让你学会LVM | LinuxProbe LVM | archLinux 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"LVM","slug":"LVM","permalink":"https://abelsu7.top/tags/LVM/"}]},{"title":"腾讯云携手 CODING，云端 IDE —— Cloud Studio 初体验","slug":"try-cloud-studio","date":"2018-04-16T13:30:56.000Z","updated":"2019-09-01T13:04:11.712Z","comments":true,"path":"2018/04/16/try-cloud-studio/","link":"","permalink":"https://abelsu7.top/2018/04/16/try-cloud-studio/","excerpt":"Cloud Studio及Coding WebIDE简介4月16日，腾讯云与CODING宣布达成战略合作，共同发布以腾讯云云服务器为基础的国内第一款完全基于云端的IDE工具：Cloud Studio的beta版本。 4月16日上线的Cloud Studio 有别于Heroku这样的PaaS云计算平台，根据两家在微信推送中的表述，Cloud Studio更接近于SaaS的概念——本质上是一款在线云端开发工具，减少用户安装IDE的成本，并与腾讯云IaaS/PaaS深度结合，从而提供代码编写、调试、上线一站式闭环体验。 Coding提供前端IDE，腾讯云提供后端计算服务","text":"Cloud Studio及Coding WebIDE简介4月16日，腾讯云与CODING宣布达成战略合作，共同发布以腾讯云云服务器为基础的国内第一款完全基于云端的IDE工具：Cloud Studio的beta版本。 4月16日上线的Cloud Studio 有别于Heroku这样的PaaS云计算平台，根据两家在微信推送中的表述，Cloud Studio更接近于SaaS的概念——本质上是一款在线云端开发工具，减少用户安装IDE的成本，并与腾讯云IaaS/PaaS深度结合，从而提供代码编写、调试、上线一站式闭环体验。 Coding提供前端IDE，腾讯云提供后端计算服务 Cloud Studio的前身正是CODING自主研发的Coding WebIDE，CODING的老用户应该会比较熟悉。在Cloud Studio的登录界面仍然保留了旧版WebIDE的访问入口提示，方便老用户继续访问。 Coding WebIDE 值得注意的是，WebIDE的首页明确提到，其底层基于容器技术，可以让系统的预热时间从分钟级降到秒级，配置好的开发环境也可以快捷的保存与分享。 WebIDE基于容器技术 而源于Coding WebIDE的Cloud Studio同样采用了容器技术，这点可以在腾讯云发布的微信推送中得到印证，以下为部分内容摘抄。 “软件研发效率在不断提升，开发工具也需要同步更新迭代，这就对计算资源提出了更高要求。每台 Cloud Studio 的背后，都有腾讯云云服务器、容器服务等服务在提供计算支持，帮助用户升级开发模式、变更应用交付、重构数据管理方式，提速企业应用部署。依托腾讯云的强大弹性能力，还能够做到资源快速伸、容灾等。开发者使用Cloud Studio 时登录浏览器即可进行编程，提供完整的 Linux 环境，并且支持自定义域名指向、动态计算资源调整，可以完成各种应用的开发编译与部署。另外，每个 Cloud Studio 拥有独立的计算资源，支持多环境快速切换、协同编辑、全功能 Terminal 等功能。据悉，下一步，Cloud Studio 将开放调配资源、在线 Terminal 操作云资源等功能。” 话不多说，现在就来初探Cloud Studio吧~ 注册CODING账号Cloud Studio是由CODING和腾讯云共同提供的服务，自然需要我们注册这两家的账号。访问https://studio.coding.net，随即跳转至CODING账号登录界面，因为我之前就是CODING的用户，直接登录，进入下一步。 注册CODING账号 申请Free Trial登录CODING账户之后，系统会首先检测是否已有云主机。首次登录可以申请30天的免费试用。按照官方的说法，到期之后可按低至9.9元/月的价格续费主机，可以说是很划算了。 申请free trial 该界面还有产品介绍和帮助文档的访问链接，正式进入Cloud Studio之前不妨先去逛一逛。 Cloud Studio产品介绍 重点提及的功能包括多环境切换、协同编辑以及全功能Terminal，终端默认使用oh-my-zsh，好评~ 多环境切换 协同编辑 全功能Terminal，默认oh-my-zsh 回到正题，继续我们的Cloud Studio的体验之旅。 腾讯云授权申请Free Trial试用后，系统会自动申请一台1核1GB，10G空间的腾讯云主机作为Cloud Studio的后端服务器，如果之前没有绑定腾讯云的账号，此时会跳转至腾讯云的授权页面，点击授权即可。如无意外，就会进入Cloud Studio的主界面中。 腾讯云授权 开始使用Cloud StudioCloud Studio有着广阔的使用场景。在其官方介绍中，将开发微信小程序作为示例场景进行展示。 开发微信小程序 另外Cloud Studio还支持协同编辑和聊天的功能，以官方介绍图为例。 协同编辑与聊天 而用户初次进入Cloud Studio会创建默认的workspace，也可以创建空项目或从CODING导入已有项目。可以看到IDE的风格和IntelliJ IDEA很相似。 管理Workspaces Cloud Studio预设了包括Node.js、Jekyll、Hexo、PHP、Ruby、Java、Python、.Net、Machine Learning（是的，你没有看错）等多种开发环境，用户可在Environments选项卡中快速切换。 快速切换多种预设开发环境 在General Setting中，可对界面显示语言及文件树隐藏文件进行设置。 General Setting 在Appearance Setting中，可切换亮/暗主题，并设置代码高亮配色，默认为material。 Appearance Setting 在Editor Setting中，可设置缩进风格与缩进宽度。 Editor Setting 在Keymap Setting中，可设置快捷键风格，预设包括Default、Sublime、Vim和Emacs。 Keymap Setting 在Extension Setting中，可搜索并安装各类插件，目前插件数量十分有限，相信日后会逐渐提高数量与质量。 Extension Setting 查看腾讯云专用主机右上角的Environments选项卡中列出了腾讯云专用主机的公网IP地址及硬件参数，点击查看我的专用主机即可跳转至腾讯云主机列表。 腾讯云主机列表 点击该主机查看详细信息，发现其位于成都机房，剩余30天有效期。 主机概览 返回Cloud Studio，继续体验之旅。 体验终端接下来通过Cloud Studio中的集成终端来对这台云主机一探究竟，可以看到配色还是比较舒服的。 云主机系统为Ubuntu 16.04.4 LTS 使用df及uname命令，发现该云主机根目录挂载了40G存储空间，操作系统为Ubuntu 16.04.4 LTS。 使用htop命令查看系统进程 点击终端右上角的图标，可以快速切换终端运行环境。使用htop命令发现该云主机为1核CPU、内存1G。 获取root权限 由于用户未设置密码，使用su命令可直接获取root权限。 查看Java、Python版本 可通过ifconfig命令查看网卡信息，但与硬件相关的命令均无法调用。Java版本为1.8.0_161，Python2版本为2.7.12，Python3版本为3.5.2。 体验官方Demo体验完强大的Terminal之后，就来试跑一下官方提供的Demo吧~ 官方Demo说明文档 在默认的Workspace中，CODING准备了Java、Python、PHP三种语言的小示例帮助用户体验Cloud Studio的基本功能。 Demo代码结构 Python 2 DemoPython 2的Demo功能很简单：获取当前时间与IP，hello.py代码如下。 #!/usr/bin/env python # -*- coding: utf-8 -*- import socket import time def get_time(): return time.strftime(&#39;%Y-%m-%d&#39;,time.localtime(time.time())) def get_host_ip(): try: s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.connect((&#39;8.8.8.8&#39;, 80)) ip = s.getsockname()[0] finally: s.close() return ip print &quot;您好，欢迎来到 Cloud Studio&quot; print &quot;当前时间是：&quot; + get_time() print &quot;您的IP是：&quot; + get_host_ip() 进入python目录，运行python hello.py即可。 Python 2 Demo Python 3 DemoPython 3的Demo要更有趣一些：来自Github上的开源项目Cursed Snake，这是一个由borisuvarov开发、基于Python 3的控制台贪吃蛇游戏，snake.py代码如下。 #!/usr/local/bin/python3 # -*- coding: utf-8 -*- &quot;&quot;&quot; Simple Snake console game for Python 3. From https://github.com/borisuvarov/cursed_snake Use it as introduction to curses module. Warning: curses module available only in Unix. On Windows use UniCurses (https://pypi.python.org/pypi/UniCurses). UniCurses is not installed by default. &quot;&quot;&quot; import curses # https://docs.python.org/3/library/curses.html import time import random def redraw(): # Redraws game field and it&#39;s content after every turn # win.erase() win.clear() draw_food() # Draws food on the game field draw_snake() # Draws snake draw_menu() win.refresh() def draw_menu(): win.addstr(0,0, &quot;Score: &quot; + str(len(snake) - 2) + &quot; Press &#39;q&#39; to quit&quot;, curses.color_pair(5)) def draw_snake(): try: n = 0 # There can be only one head for pos in snake: # Snake is the list of [y, x], so we swap them below if n == 0: win.addstr(pos[1], pos[0], &quot;@&quot;, curses.color_pair(ex_foodcolor)) # Draws head else: win.addstr(pos[1], pos[0], &quot;#&quot;, curses.color_pair(ex_foodcolor)) # Draws segment of the body n += 1 except Exception as drawingerror: print(drawingerror, str(cols), str(rows)) def draw_food(): for pos in food: win.addstr(pos[1], pos[0], &quot;+&quot;, curses.color_pair(foodcolor)) def drop_food(): x = random.randint(1, cols - 2) y = random.randint(1, rows - 2) for pos in snake: # Do not drop food on snake if pos == [x, y]: drop_food() food.append([x, y]) def move_snake(): global snake # List global grow_snake # Boolean global cols, rows # Integers head = snake[0] # Head is the first element of &quot;snake list&quot; if not grow_snake: # Remove tail if food was not eaten on this turn snake.pop() else: # If food was eaten on this turn, we don&#39;t pop last item of list, grow_snake = False # but we restore default state of grow_snake if direction == DIR_UP: # Calculate the position of the head head = [head[0], head[1] - 1] # We will swap x and y in draw_snake() if head[1] == 0: head[1] = rows - 2 # Snake passes through the border elif direction == DIR_DOWN: head = [head[0], head[1] + 1] if head[1] == rows - 1: head[1] = 1 elif direction == DIR_LEFT: head = [head[0] - 1, head[1]] if head[0] == 0: head[0] = cols - 2 elif direction == DIR_RIGHT: head = [head[0] + 1, head[1]] if head[0] == cols - 1: head[0] = 1 snake.insert(0, head) # Insert new head def is_food_collision(): for pos in food: if pos == snake[0]: food.remove(pos) global foodcolor global ex_foodcolor ex_foodcolor = foodcolor foodcolor = random.randint(1, 6) # Pick random color of the next food return True return False def game_over(): global is_game_over is_game_over = True win.erase() win.addstr(10, 20, &quot;Game over! Your score is &quot; + str(len(snake)) + &quot; Press &#39;q&#39; to quit&quot;, curses.color_pair(1)) def is_suicide(): # If snake collides with itself, game is over for i in range(1, len(snake)): if snake[i] == snake[0]: return True return False def end_game(): curses.nocbreak() win.keypad(0) curses.echo() curses.endwin() # Initialisation starts -------------------------------------------- DIR_UP = 0 # Snake&#39;s directions, values are not important, DIR_RIGHT = 1 # they сan be &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot; or something else DIR_DOWN = 2 DIR_LEFT = 3 is_game_over = False grow_snake = False snake = [[10, 5], [9, 5]] # Set snake size and position direction = DIR_RIGHT food = [] foodcolor = 2 ex_foodcolor = 3 win = curses.initscr() # Game field in console initialised with curses module curses.start_color() # Enables colors curses.init_pair(1, curses.COLOR_CYAN, curses.COLOR_BLACK) curses.init_pair(2, curses.COLOR_BLUE, curses.COLOR_BLACK) curses.init_pair(3, curses.COLOR_GREEN, curses.COLOR_BLACK) curses.init_pair(4, curses.COLOR_MAGENTA, curses.COLOR_BLACK) curses.init_pair(5, curses.COLOR_RED, curses.COLOR_BLACK) curses.init_pair(6, curses.COLOR_YELLOW, curses.COLOR_BLACK) win.keypad(1) # Enable arrow keys win.nodelay(1) # Do not wait for keypress curses.curs_set(0) # Hide cursor curses.cbreak() # Read keys instantaneously curses.noecho() # Do not print stuff when keys are pressed rows, cols = win.getmaxyx() # Get terminal window size # Initialisation ends --------------------------------------------- # Main loop starts ------------------------------------------------ drop_food() redraw() while True: if is_game_over is False: redraw() key = win.getch() # Returns a key, if pressed time.sleep(0.1) # Speed of the game if key != -1: # win.getch returns -1 if no key is pressed if key == curses.KEY_UP: if direction != DIR_DOWN: # Snake can&#39;t go up if she goes down direction = DIR_UP elif key == curses.KEY_RIGHT: if direction != DIR_LEFT: direction = DIR_RIGHT elif key == curses.KEY_DOWN: if direction != DIR_UP: direction = DIR_DOWN elif key == curses.KEY_LEFT: if direction != DIR_RIGHT: direction = DIR_LEFT elif chr(key) == &quot;q&quot;: break if is_game_over is False: move_snake() if is_suicide(): game_over() if is_food_collision(): drop_food() grow_snake = True end_game() # Main loop ends -------------------------------------------------- Python 3 Demo 真的可以玩哦！不过貌似在Cloud Studio上有延时（毕竟要与服务器交互），感兴趣的不妨在本地跑一跑哈哈~ PHP Demo PHP Web Demo 一个很简单的PHP Web Demo，配合Cloud Studio中的Access URL选项卡使用，可将来自公网的访问重定向至云主机PHP Web Server的监听端口。这里提示找不到favico.ico，页面图标无法加载，公网通过重定向链接可访问PHP服务。 公网访问PHP Server Java Demo官方提供的Java Demo是一个基于Maven构建的Spring Boot项目，StudioDemoApplication.java代码如下。 package com.coding.studiodemo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.stereotype.Controller; import org.springframework.ui.ModelMap; @SpringBootApplication @Controller public class StudioDemoApplication { @RequestMapping(&quot;/&quot;) public String greeting(ModelMap map) { String jreVersion = System.getProperty(&quot;java.specification.version&quot;); map.addAttribute(&quot;jreVersion&quot;, &quot;v&quot; + jreVersion); return &quot;index&quot;; } public static void main(String[] args) { SpringApplication.run(StudioDemoApplication.class, args); } } 配置文件pom.xml代码如下 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.coding&lt;/groupId&gt; &lt;artifactId&gt;studio-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;studio-demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 查看Maven版本为3.3.9，直接运行mvn spring-boot:run启动服务，由于是第一次运行，需要等待一段时间来下载依赖。 启动Maven服务 依赖下载完成后，服务启动成功，创建Access URL供公网访问。 服务成功启动，创建Access URL 最后访问该链接，成功访问Java Web Demo Page，Cloud Studio初体验结束~ Java Web Demo 总结一下和传统的云主机相比，基于容器技术的Cloud Studio更加轻量快捷，可视化IDE加持大大提升了开发效率，应用场景也更有针对性。如果只是希望在预搭建的环境中跑一些服务或进行一些实验，Cloud Studio会是一个不错的选择。 但是，Free Trial版本中Access URL的有效期仅为1个小时（解除有效期限制须升级CODING钻石会员），并且无法通过公网IP访问腾讯云专用主机，因此如果需要在公网中提供服务又对图形界面没有太大执念的话，各家的云主机仍是开发的第一选择。 参考文章 腾讯云携手 CODING，共同推出云端编辑器 Cloud Studio | 腾讯云 CODING 携手腾讯云：连接，让开发更简单 | 扣钉CODING 深入了解 Cloud Studio 开发在云端 | 扣钉CODING Cloud Studio | Coding.net Coding WebIDE | Coding.net Cloud Studio帮助文档 | Coding.net 🚩推荐阅读（由hexo文章推荐插件驱动）QEMU 3.1.0 源码学习《KVM 实战》笔记 1：构建 KVM 环境腾讯暑期实习常规批笔试 Golang 题解使用 kubeadm 搭建 Kubernetes 集群TFC2017参会速记Heyo，Tencent","categories":[{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/categories/云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/tags/云计算/"},{"name":"腾讯","slug":"腾讯","permalink":"https://abelsu7.top/tags/腾讯/"}]},{"title":"Windows 10 设置开机自动登录","slug":"win10-auto-login","date":"2018-04-16T08:20:42.000Z","updated":"2019-09-01T13:04:11.768Z","comments":true,"path":"2018/04/16/win10-auto-login/","link":"","permalink":"https://abelsu7.top/2018/04/16/win10-auto-login/","excerpt":"日常使用Windows时，大家一般都会选择设置密码来确保安全。然而每次登录都需要输入密码，在绝对安全的场所反而有些麻烦。今天就来介绍一下Win10中开机自动登录的设置方法，早期Windows版本同样适用。 虽然设置自动登录方便了很多，但也存在极大的安全隐患，不需要密码就可以进入你的系统，想想就是件可怕的事。还请务必根据个人需要谨慎开启。","text":"日常使用Windows时，大家一般都会选择设置密码来确保安全。然而每次登录都需要输入密码，在绝对安全的场所反而有些麻烦。今天就来介绍一下Win10中开机自动登录的设置方法，早期Windows版本同样适用。 虽然设置自动登录方便了很多，但也存在极大的安全隐患，不需要密码就可以进入你的系统，想想就是件可怕的事。还请务必根据个人需要谨慎开启。 首先按下Win + R组合键，输入netplwiz或control userpasswords2并运行，打开用户账户界面。 运行netplwiz 之后取消勾选要使用本计算机，用户必须输入用户名和密码，并点击应用。 取消勾选输入用户名和密码 在弹出窗口中输入选中用户的密码并保存，这样就设置完成了。 保存用户密码 另外，有用户在设置自动登录后，遇到开机提示用户名或密码不正确、点击OK后出现两个相同账户的情况， 用户名或密码错误 两个相同的用户账户 出现上述问题的原因可能是你在设置了开机自动登录之后，又更改了计算机的名称。此时需要以任意用户身份登录系统，取消自动登录后再重新设置，问题即可解决。 参考文章 Win10开机提示用户名或密码不正确 | IT百科 Win10开机提示用户名或密码不正确现象的解决办法 | 脚本之家 🚩推荐阅读（由hexo文章推荐插件驱动）Fluent Terminal：Windows 下的炫酷终端Windows 10 终端 PowerShell 外观美化几款监控 CPU 温度的软件推荐Windows 10 彻底删除已配对的蓝牙设备Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"}]},{"title":"Cloudflare 发布公共 DNS——1.1.1.1","slug":"cloudflare-public-dns","date":"2018-04-03T09:21:55.000Z","updated":"2019-09-01T13:04:11.041Z","comments":true,"path":"2018/04/03/cloudflare-public-dns/","link":"","permalink":"https://abelsu7.top/2018/04/03/cloudflare-public-dns/","excerpt":"","text":"Updating… 公共DNS： 1.1.1.1 - Cloudflare 8.8.8.8 - Google 9.9.9.9 - IBM 参考文章 What Is 1.1.1.1? | Cloudflare 地址 1.1.1.1，Cloudflare 推新公共 DNS 服务 | 伯乐在线 Cloudflare 推出更快、更隐秘的 DNS 服务「1.1.1.1」| 运维之美","categories":[{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/categories/云计算/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://abelsu7.top/tags/DNS/"}]},{"title":"Java 开发必须掌握的 5 种加密策略","slug":"java-encryption","date":"2018-03-30T07:32:49.000Z","updated":"2019-09-01T13:04:11.417Z","comments":true,"path":"2018/03/30/java-encryption/","link":"","permalink":"https://abelsu7.top/2018/03/30/java-encryption/","excerpt":"To be updated…","text":"To be updated… 🚩推荐阅读（由hexo文章推荐插件驱动）Java 笔记 5：集合Java 笔记 6：异常、断言和日志排序算法 1：冒泡排序、插入排序、选择排序Java 笔记 4：接口、lambda 表达式与内部类后端开发 - Java开发环境配置 - 入门篇在非GPL应用中使用OpenJDK的法律问题","categories":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://abelsu7.top/tags/Java/"},{"name":"加密","slug":"加密","permalink":"https://abelsu7.top/tags/加密/"}]},{"title":"《死亡诗社》诗歌赏析","slug":"o-captain-my-captain","date":"2018-03-28T03:10:04.000Z","updated":"2019-09-01T13:04:11.594Z","comments":true,"path":"2018/03/28/o-captain-my-captain/","link":"","permalink":"https://abelsu7.top/2018/03/28/o-captain-my-captain/","excerpt":"《死亡诗社》（Dead Poets Society）由澳大利亚导演彼得·威尔（Peter Weir）指导，罗宾·威廉姆斯（Robin Williams）、伊桑·霍克（Ethan Hawke）以及罗伯特·肖恩·莱纳德（Robert Sean Leonard）等人主演。电影讲述了1959年，威尔顿预备学院的新任英文教师John Keating以自由发散式的哲学思维对抗传统教育枷锁，激励学生独立思考求索、勇敢追问人生路途的故事。该片获得1990年第62届奥斯卡金像奖四项提名，并收获最佳原创剧本奖。 《死亡诗社》电影海报 《死亡诗社》引用了多首诗作推动剧情发展，美国著名诗人沃尔特·惠特曼（Walt Whitman）的代表作《O Captain! My Captain!》便是其中之一。虽然影片中只引用了诗名，但却丝毫不妨碍其贯穿全片，见证着Keating对学生们春风化雨般的教育以及润物无声的人格影响。下面就来一起欣赏这首诗。","text":"《死亡诗社》（Dead Poets Society）由澳大利亚导演彼得·威尔（Peter Weir）指导，罗宾·威廉姆斯（Robin Williams）、伊桑·霍克（Ethan Hawke）以及罗伯特·肖恩·莱纳德（Robert Sean Leonard）等人主演。电影讲述了1959年，威尔顿预备学院的新任英文教师John Keating以自由发散式的哲学思维对抗传统教育枷锁，激励学生独立思考求索、勇敢追问人生路途的故事。该片获得1990年第62届奥斯卡金像奖四项提名，并收获最佳原创剧本奖。 《死亡诗社》电影海报 《死亡诗社》引用了多首诗作推动剧情发展，美国著名诗人沃尔特·惠特曼（Walt Whitman）的代表作《O Captain! My Captain!》便是其中之一。虽然影片中只引用了诗名，但却丝毫不妨碍其贯穿全片，见证着Keating对学生们春风化雨般的教育以及润物无声的人格影响。下面就来一起欣赏这首诗。 原诗欣赏 O Captain! my Captain! our fearful trip is done，啊，船长，船长！我的船长！可怕的航程已完成， The ship has weather’d every rack, the prize we sought is won,这船历尽风险，企求的目标已完成， The port is near, the bells I hear, the people all exulting,港口在望，钟声响，人们在欢欣， While follow eyes the steady keel, the vessel grim and daring;千万双眼镜注视着船——平稳，勇敢，坚定； But O heart! heart! heart!但是痛心啊！痛心！痛心！ O the bleeding drops of red,瞧一滴滴鲜红的血， Where on the deck my Captain lies,甲板上躺着我的船长， Fallen cold and dead.他倒下去，冰冷，永别。 O Captain! my Captain! rise up and hear the bells;啊，船长！我的船长！起来吧，倾听钟声； Rise up—for you the flag is flung—for you the bugle trills,起来吧，号角为您长鸣，旌旗为您高悬； For you bouquets and ribbon’d wreaths—for you the shores a-crowding,迎着您，多少花束花圈——候着您，千万人蜂拥岸边， For you they call, the swaying mass, their eager faces turning;他们向您高呼，拥来挤去，扬起殷切的脸； Here Captain! dear father!啊，船长！亲爱的父亲！ This arm beneath your head!我的手臂托着您的头！ It is some dream that on the deck,莫非是一场梦——在甲板上， You’ve fallen cold and dead.您倒下去，冰冷，永别。 My Captain does not answer, his lips are pale and still,我的船长不做声，嘴唇惨白，毫不动弹， My father does not feel my arm, he has no pulse nor will,我的父亲没感觉到我的手臂，没有脉搏，没有遗愿， The ship is anchor’d safe and sound, its voyage closed and done,船舶抛锚停下，平安抵达，航程终了， From fearful trip the victor ship comes in with object won;历经艰险返航，夺得胜利目标； Exult O shores, and ring O bells!啊，岸上钟声齐鸣，啊，人们一片欢腾！ But I with mournful tread,但是，我在甲板上，在船长身旁， Walk the deck my Captain lies,心悲切，步履沉重， Fallen cold and dead.因为他倒下去，冰冷，永别。 关于作者 Walt Whitman 沃尔特·惠特曼（Walt Whitman，1819年5月31日—1892年3月26日）出生于纽约州长岛，美国著名诗人、人文主义者，创造了诗歌的自由体（Free Verse），其代表作品是诗集《草叶集》（Leaves of Grass）。 Notes for a revision 《O Captain! My Captain!》是沃尔特·惠特曼于1865年林肯（Lincoln）总统遇刺之后写下的一首隐喻诗，也可被归为纪念林肯总统的挽歌。船长即象征遭暗杀去世的林肯，而船则象征着刚刚结束南北战争的美国。 An 1887 handwritten draft 这首诗在1867年惠特曼的代表诗集《草叶集》第四次发行时被收录其中，表达了作者强烈的悲痛与哀伤以及美国民众对于林肯遇刺的震惊与伤感的心情。 《死亡诗社》中的引用《O Captain! My Captain!》在影片中的首次出现，始于Keating老师的第一堂课：Keating将学生们带到了陈列室，提到了惠特曼的诗作，并告诉学生可以称呼他为O Captain! My Captain!。此外，Keating还教给学生们怎样去聆听逝者的声音——Carpe Diem，及时行乐，不负芳华。 Keating的第一课 此后，这个称呼就自然而然的贯穿于学生们与Keating之间的对话中。而O Captain! My Captain!的最后一次出现，则是在片尾Keating离开学校的一幕——也是全片最为感人的场景。 O Captain! My Captain! 即使是在Neil开枪自杀后，校方和Neil的父亲也并没有意识到自己的过错。他们将一切罪责都归咎于Keating的教育方式，逼迫学生在指认Keating的文件上签名，Keating成了整件事的替罪羊。 临别之际，在重新回归教条死板的课堂上，总是畏惧发声的Todd不再沉默——就像Keating曾经教过的那样，他站在课桌上高呼”O Captain! My Captain!”，向自己的人生导师致以最崇高的敬意。而古诗人社成员集体站在书桌上高呼”O Captain! My Captain!”的这一幕，必将成为电影史上的经典画面。 Forever The Captain——Robin Williams2014年8月11日，罗宾·威廉姆斯永远离开了我们。 他是《死亡诗社》中的Keating老师，《心灵捕手》中的Sean医生，一个全情投入的伟大演员，一个无与伦比的喜剧天才。 在2014年8月被证实在家中自杀去世后，Robin的粉丝在社交媒体上通过上传模仿《死亡诗社》中”O Captain! My Captain!”的照片或视频的方式，来向The Captain致敬。 Forever the Captain, Robin 《死亡诗社》的结局是开放的——也许学生们会因为站上桌子被罚，也许“地狱学院”的教育会一如既往，也许会有第二个表演天赋超群却不被家庭支持的Neil，也许Dead Poets Society从此成为禁忌而被逐渐遗忘…… 但对Keating来说，有一件事是确定的——他会永远记得离开学校的那天，书桌上站立的学生们异口同声说出的那句： O Captain! My Captain! 参考文章 O Captain！My Captain！| 百度百科 O Captain！My Captain！| Wikipedia O Captain！My Captain！| Poetry Foundation O Captain！My Captain！| poets.org O Captain！My Captain！Introduction | shmoop 《死亡诗社》里的一段话，四首诗 | 豆瓣电影 Dead Poets Society | Wikipedia Dead Poets Society | IMDB 死亡诗社 | Mtime时光网 浅析《死亡诗社》的主题思想 | 论文网 🚩推荐阅读（由hexo文章推荐插件驱动）2016年国产电影分析报告世界这么大，看看地球之盐吧","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://abelsu7.top/tags/电影/"}]},{"title":"Linux Shell 脚本面试25问","slug":"linux-shell-interview","date":"2018-03-27T12:37:37.000Z","updated":"2019-09-01T13:04:11.510Z","comments":true,"path":"2018/03/27/linux-shell-interview/","link":"","permalink":"https://abelsu7.top/2018/03/27/linux-shell-interview/","excerpt":"掌握Shell脚本的编写和使用是Linux工程师和运维人员的必备技能，也是企业面试的必考点，以下是一些在面试过程中经常会遇到的Shell脚本面试问题及解答。 Shell脚本是什么，它是必需的吗？一个Shell脚本是一个文本文件，包含一个或多个命令。作为系统管理员，我们经常需要使用多个命令来完成一项任务，我们可以在一个文本文件（Shell）脚本中添加所有这些命令来完成日常工作任务。 什么是默认登录Shell，如何改变指定用户的登录Shell？在Linux操作系统中，/bin/bash是默认登录Shell，在创建用户时分配。使用chsh命令可以改变默认的Shell，如下所示： chsh &lt;用户名&gt; -s &lt;新shell&gt; chsh abelsu7 -s /bin/sh","text":"掌握Shell脚本的编写和使用是Linux工程师和运维人员的必备技能，也是企业面试的必考点，以下是一些在面试过程中经常会遇到的Shell脚本面试问题及解答。 Shell脚本是什么，它是必需的吗？一个Shell脚本是一个文本文件，包含一个或多个命令。作为系统管理员，我们经常需要使用多个命令来完成一项任务，我们可以在一个文本文件（Shell）脚本中添加所有这些命令来完成日常工作任务。 什么是默认登录Shell，如何改变指定用户的登录Shell？在Linux操作系统中，/bin/bash是默认登录Shell，在创建用户时分配。使用chsh命令可以改变默认的Shell，如下所示： chsh &lt;用户名&gt; -s &lt;新shell&gt; chsh abelsu7 -s /bin/sh 可以在Shell脚本中使用哪些类型的变量？在Shell脚本中，我们可以使用两种类型的变量：系统定义变量和用户定义变量。 系统变量是由系统自己创建的，这些变量通常由大写字母组成，可通过set命令查看。 用户变量是由系统用户生成并定义的，变量的值可以通过命令echo $&lt;变量名&gt;查看。 如何将标准输出和错误输出同时重定向到同一位置？这里有两个方法可以实现： # 方法一 2&gt;&amp;1 ls /usr/share/doc &gt; out.txt 2&gt;&amp;1 # 方法二 &amp;&gt; ls /usr/share/doc &amp;&gt; out.txt Shell脚本中if语法如何嵌套？基础语法如下： if [ 条件 ] then 命令1 命令2 ... else if [ 条件 ] then 命令1 命令2 ... else 命令1 命令2 ... fi fi Shell脚本中“$?”标记的用途是什么？在编写Shell脚本时，如果你想要检查上一条命令是否执行成功，在if条件中使用$?可以来检查上一条命令的结束状态。简单的例子如下： ls /usr/bin/shuf /usr/bin/shuf echo $? 0 如果结束状态是0，说明上一条命令执行成功。 ls /usr/bin/share ls: cannot access /usr/bin/share: No such file or directory echo $? 2 如果结束状态不是0，说明执行失败。 在Shell脚本中如何比较两个数字？在if-then中使用测试命令如-gt来比较两个数字： #!/bin/bash x=10 y=20 if [ $x -gt $y ] then echo &quot;x is greater than y&quot; else echo &quot;y is greater than x&quot; fi Shell脚本中break命令的作用？break命令一个简单的用途是退出执行中的循环，我们可以在while和until循环中使用break命令跳出循环。 Shell脚本中continue命令的作用？continue命令不同于break命令，它只跳出当前循环的迭代，而不是整个循环。continue命令很多时候是非常有用的——例如当有错误发生，但我们依然希望执行上层循环时。 Shell脚本中case语句的语法？基础语法如下： case 变量 in 值1) 命令1 命令2 ... 最后命令 !! 值2) 命令1 命令2 ... 最后命令 ;; esac Shell脚本中for循环语法？基础语法如下： for 变量 in 循环列表 do 命令1 命令2 ... 最后命令 done Shell脚本中while循环语法？如同for循环，while循环只要条件成立就会重复执行命令块。不同于for循环的是，while循环会不断迭代，直到循环条件不为真。 while [ 条件 ] do 命令... done 例如： COUNTER=0 while [ $COUNTER -lt 5 ] do COUNTER=&#39;expr $COUNTER+1&#39; echo $COUNTER done do-while语句的基本格式？do-while语句类似于while语句，但检查条件语句之前先执行命令（意即至少执行一次）： do { 命令 } while (条件) 如何使脚本可执行？使用chmod命令为赋予脚本可执行权限： chmod a+x myscript.sh “#!/bin/bash”的作用？#!/bin/bash是Shell脚本的第一行,称为释伴（shebang）行。这里#符号叫做hash，而!叫做bang。它的意思是命令通过/bin/bash来执行。 如何调试Shell脚本？使用-x参数可以调试Shell脚本： sh -x myscript.sh 另一种方法是使用-nv参数： sh -nv myscript.sh Shell脚本如何比较字符串？test命令可以用来比较字符串，测试命令会通过比较字符串中的每一个字符来进行比较。 Bourne Shell（bash）中有哪些特殊的变量？下表列出了bash中为命令行设置的特殊变量： 内建变量 解释 $0 命令行中脚本名称 $1 第一个命令行参数 $2 第二个命令行参数 … … $9 第九个命令行参数 $# 命令行参数的数量 $* 所有命令行参数，以空格隔开 在Shell脚本中如何测试文件？test命令也可以用来测试文件。下表列出了基础用法： test 用法 -e &lt;文件名&gt; 如果文件存在，返回true -d &lt;文件名&gt; 如果文件存在并且是目录，返回true -f &lt;文件名&gt; 如果文件存在并且是普通文件，返回true -s &lt;文件名&gt; 如果文件存在并且不为空，返回true -r &lt;文件名&gt; 如果文件存在并可读，返回true -w &lt;文件名&gt; 如果文件存在并可写，返回true -x &lt;文件名&gt; 如果文件存在并可执行，返回true 在Shell脚本中如何写入注释？注释可以用来描述一个脚本可以做什么和它是如何工作的，每一行注释以#开头： #!/bin/bash echo &quot;I am logged in as $USER&quot; # This is a command 如何让Shell脚本得到来自终端的输入？read命令可以读取来自终端（使用键盘输入）的数据。read命令得到用户的输入并置于给定的变量中： vi /tmp/test.sh #!/bin/bash echo \"Please enter your name\" read name echo \"My Name is $name\" ./test.sh Please enter your name abelsu7 My Name is abelsu7 如何取消变量或取消变量赋值？unset命令可用于取消变量或取消变量赋值： unset &lt;变量名&gt; 如何执行算术运算？可以使用expr命令： expr 16 + 4 20 或使用$[ 表达式 ]: test = $[ 16 + 4 ] echo $test 20 如何在Shell脚本中定义函数？在Shell中可以通过以下两种语法来定义函数，分别如下： function_name () { statement1 statement2 .... statementn } 或者 function function_name() { statement1 statement2 .... statementn } 当函数定义好了以后，用户就可以通过函数名来调用该函数，函数调用的基本语法如下： function_name param1 param2 ... 下面定义了一个sayhello()方法，并调用： #!/bin/bash function sayhello() { echo &quot;Hello,World&quot; } sayhello 代码调用结果 sh ./hello.sh Hello,World 如何在 Shell 脚本中使用 BC（bash计算器）？在Shell脚本中使用bc的语法如下： var = `echo &quot;options; expression&quot; | bc` 例如下面计算1+2+3+...+10的计算结果 echo $(seq -s \"+\" 10)=`seq -s \"+\" 10 | bc` 1+2+3+4+5+6+7+8+9+10=55 参考文章 Linux Shell脚本面试25问 | Linux中国 25 Linux Shell Scripting Interview Questions and Anwsers | LinuxTechi Linux之Shell算术运算 | cnblogs Shell test命令 | 菜鸟教程 Linux Shell系列教程之（十一）Shell while循环 | CSDN LINUX上的SHEBANG符号(#!) | 笑遍世界 Linux Shell编程学习——test测试比较命令 | CSDN Shell中函数的定义和使用 | CSDN Shell脚本——数学运算和bc命令 | cnblogs 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令2020 届互联网秋季校园招聘汇总 (2019年秋)Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/categories/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"面试","slug":"面试","permalink":"https://abelsu7.top/tags/面试/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"}]},{"title":"HTML5 词云 wordcloud2.js 初体验","slug":"wordcloud2","date":"2018-03-19T11:26:47.000Z","updated":"2019-09-01T13:04:11.788Z","comments":true,"path":"2018/03/19/wordcloud2/","link":"","permalink":"https://abelsu7.top/2018/03/19/wordcloud2/","excerpt":"在信息爆炸、效率为先的今天，分析整理数据的能力对每个人来说都至关重要。由此也衍生出各种数据可视化技术，帮助开发者及用户便捷高效的掌握数据中蕴含的重要信息。 词云就是一种常见的数据可视化格式，它将词语彼此排列堆叠，以词云（又称标签云）的形式将数据直观的呈现给用户。作为开发者，在日常也会有大量制作词云图片的需求。 目前业界已经有ECharts和wordcloud2.js两大利器支持词云组件的编写。前者是百度出品的可视化图表库，词云只是其中的一类图表，相信大部分开发者已经体验过Echarts的魅力，本文不再赘述。今天就来尝试一下专注于词云的wordcloud2.js。 wordcloud2.js生成的词云","text":"在信息爆炸、效率为先的今天，分析整理数据的能力对每个人来说都至关重要。由此也衍生出各种数据可视化技术，帮助开发者及用户便捷高效的掌握数据中蕴含的重要信息。 词云就是一种常见的数据可视化格式，它将词语彼此排列堆叠，以词云（又称标签云）的形式将数据直观的呈现给用户。作为开发者，在日常也会有大量制作词云图片的需求。 目前业界已经有ECharts和wordcloud2.js两大利器支持词云组件的编写。前者是百度出品的可视化图表库，词云只是其中的一类图表，相信大部分开发者已经体验过Echarts的魅力，本文不再赘述。今天就来尝试一下专注于词云的wordcloud2.js。 wordcloud2.js生成的词云 开始前的准备首先页面必须是以HTML5规范编写。以下是在VSCode中以Emmet语句html:5展开得到的页面示例 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt; 引入相关JS库随后需要引入jQuery和wordcloud2.js &lt;script src=&quot;https://cdn.bootcss.com/wordcloud2.js/1.1.0/wordcloud2.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js&quot;&gt;&lt;/script&gt; 定义canvas容器在body中定义一个canvas容器用来显示词云 &lt;div id=&quot;canvas-container&quot; align=&quot;center&quot;&gt; &lt;canvas id=&quot;canvas&quot; width=&quot;600px&quot; height=&quot;400px&quot;&gt;&lt;/canvas&gt; &lt;/div&gt; 检查浏览器是否支持wordcloud2.js提供了验证是否可被当前浏览器支持的API。若当前浏览器不支持运行，则以下语句将返回false &gt; WordCloud.isSupported true 定义options并调用WordCloud 具体API可参考wordcloud2.js官方文档 &lt;script&gt; var options = eval({ &quot;list&quot;: [ [&#39;Google&#39;, 10], [&#39;Tencent&#39;, 9], [&#39;Alibaba&#39;, 7], [&#39;Baidu&#39;, 6], [&#39;NetEase&#39;, 4], [&#39;JD&#39;, 5], [&#39;Youku&#39;, 4], [&#39;Meituan&#39;, 3], [&#39;Douban&#39;, 3] ], &quot;gridSize&quot;: 16, // size of the grid in pixels &quot;weightFactor&quot;: 10, // number to multiply for size of each word in the list &quot;fontWeight&quot;: &#39;normal&#39;, // &#39;normal&#39;, &#39;bold&#39; or a callback &quot;fontFamily&quot;: &#39;Times, serif&#39;, // font to use &quot;color&quot;: &#39;random-light&#39;, // &#39;random-dark&#39; or &#39;random-light&#39; &quot;backgroundColor&quot;: &#39;#333&#39;, // the color of canvas &quot;rotateRatio&quot;: 1 // probability for the word to rotate. 1 means always rotate }); var canvas = document.getElementById(&#39;canvas&#39;); WordCloud(canvas, options); &lt;/script&gt; 至此，一个美观大方的词云就制作完成了。Just enjoy it！ 上述代码生成的词云 参考文章 可能是目前最好的词云解决方案wordcloud2 | 统计之都 简单美观的文字标签云组件 | 不如 HTML5 Word Cloud | timdream.org wordcloud2.js Demo | timdream.org wordcloud | Github wordcloud2.js | Github 🚩推荐阅读（由hexo文章推荐插件驱动）Vue.js 学习笔记JavaScript获取网页滚动距离及DOM元素宽高属性监听物理回退与展开占满全屏归并排序(递归)","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://abelsu7.top/tags/JavaScript/"},{"name":"HTML5","slug":"HTML5","permalink":"https://abelsu7.top/tags/HTML5/"},{"name":"wordcloud2.js","slug":"wordcloud2-js","permalink":"https://abelsu7.top/tags/wordcloud2-js/"}]},{"title":"迅雷极速版任务出错的解决办法","slug":"thunderspeed-task-error","date":"2018-03-16T07:02:11.000Z","updated":"2019-09-01T13:04:11.705Z","comments":true,"path":"2018/03/16/thunderspeed-task-error/","link":"","permalink":"https://abelsu7.top/2018/03/16/thunderspeed-task-error/","excerpt":"今天使用迅雷极速版下载的时候突然提示任务出错。一开始还以为是资源的问题，但尝试下载网页图片等文件时全部提示任务出错。搜索了一下发现果然，迅雷极速版被封禁了。 目前在Windows 10环境下，迅雷极速版最好用的版本是1.0.35.366，可以在迅雷极速版吧找到下载地址。 当然，迅雷9这种居然以浏览器为主打功能设计的产品，打死都不会再去用。好在可以通过修改hosts文件的方法绕过迅雷的解析服务器，继续使用极速版。","text":"今天使用迅雷极速版下载的时候突然提示任务出错。一开始还以为是资源的问题，但尝试下载网页图片等文件时全部提示任务出错。搜索了一下发现果然，迅雷极速版被封禁了。 目前在Windows 10环境下，迅雷极速版最好用的版本是1.0.35.366，可以在迅雷极速版吧找到下载地址。 当然，迅雷9这种居然以浏览器为主打功能设计的产品，打死都不会再去用。好在可以通过修改hosts文件的方法绕过迅雷的解析服务器，继续使用极速版。 首先编辑C:\\Windows\\System32\\drivers\\etc\\hosts，在其中添加规则： # ThunderSpeed DNS Verification Cheat 127.0.0.1 hub5btmain.sandai.net 127.0.0.1 hub5emu.sandai.net 127.0.0.1 upgrade.xl9.xunlei.com 保存并关闭hosts文件，退出迅雷极速版并清掉后台残余进程。 最后使用快捷键win+R并输入cmd回车，在命令行中执行ipconfig /flushdns刷新DNS解析缓存，提示成功后重新打开迅雷，问题解决！ 参考文章 迅雷极速版任务出错的解决办法（亲测可用） | CSDN 【分享】迅雷极速版1.0.35.366免费下载 | 百度贴吧 迅雷极速版任务出错的解决办法 | 百度贴吧 🚩推荐阅读（由hexo文章推荐插件驱动）Fluent Terminal：Windows 下的炫酷终端Windows 10 终端 PowerShell 外观美化几款监控 CPU 温度的软件推荐Windows 10 彻底删除已配对的蓝牙设备Windows笔记Trouble shooting: Windows响应缓慢","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://abelsu7.top/tags/Windows/"},{"name":"迅雷","slug":"迅雷","permalink":"https://abelsu7.top/tags/迅雷/"}]},{"title":"解决 RSS 报错：Input is not proper UTF-8, indicate encoding","slug":"rss-encoding-error","date":"2018-03-15T13:03:09.000Z","updated":"2019-09-01T13:04:11.664Z","comments":true,"path":"2018/03/15/rss-encoding-error/","link":"","permalink":"https://abelsu7.top/2018/03/15/rss-encoding-error/","excerpt":"最近在Hexo上写文章时，部署后发现在Android版Firefox浏览器、Opera浏览器查看atom.xml文件均会报错： RSS encoding error","text":"最近在Hexo上写文章时，部署后发现在Android版Firefox浏览器、Opera浏览器查看atom.xml文件均会报错： RSS encoding error 原因在于内容中存在不完整的UTF-8字符，导致XML解析报错。 为了防止再次出现编码问题，应当避免从Word中直接复制内容到文件中 根据错误信息中的行列号定位到有问题的内容位置，重新以UTF-8编码格式输入，再次部署，问题得以解决。 参考文章 Fix WordPress Feed Error - Input is not proper UTF-8, indicate encoding | WPTF WordPress RSS Feed Error: Input is not proper UTF-8, indicate encoding | Shout Me Loud RSS出现“Input is not proper UTF-8, indicate encoding !”的解决方法 | 枫芸志 wordpress的RSS提示错误：Input is not proper UTF-8, indicate encoding | Jianchihu RSS报错“Input is not proper UTF-8, indicate encoding !”的解决方法 | 搞么子 xml 浏览器打开报错Input is not proper UTF-8, indicate encoding ! | CSDN 🚩推荐阅读（由hexo文章推荐插件驱动）Hexo 实现自定义文章置顶在 Hexo 中使用 MathJax 渲染数学公式利用 Valine 搭建 Hexo 无后端评论系统Hexo 博客安装 RSS 插件Hexo博客文末添加网站地图Hexo博客文末添加网站地图","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://abelsu7.top/tags/Hexo/"}]},{"title":"VS Code 使用指南","slug":"vscode-guide","date":"2018-03-15T06:51:51.000Z","updated":"2019-09-01T13:04:11.764Z","comments":true,"path":"2018/03/15/vscode-guide/","link":"","permalink":"https://abelsu7.top/2018/03/15/vscode-guide/","excerpt":"这里是VS Code的相关介绍，VS Code快捷键文档 Visual Studio Code","text":"这里是VS Code的相关介绍，VS Code快捷键文档 Visual Studio Code 常用快捷键 Keys Function Ctrl+Shift+P, F1 命令面板 Ctrl+P 快速打开，转到文件 Alt+Up/Down 移动当前行 Shift+Alt+Up/Down 复制当前行 Ctrl+Shift+K 删除当前行 Ctrl+Shift+L Select all occurrences of current selection 🚩推荐阅读（由hexo文章推荐插件驱动）VS Code 中使用 gopls 补全 Go 代码VS Code 使用 Settings Sync 插件同步设置使用 GNU Global 在 VS Code 中阅读内核源码VS Code 配置 Go 开发环境","categories":[{"name":"工具软件","slug":"工具软件","permalink":"https://abelsu7.top/categories/工具软件/"}],"tags":[{"name":"VS Code","slug":"VS-Code","permalink":"https://abelsu7.top/tags/VS-Code/"}]},{"title":"Hexo 博客安装 RSS 插件","slug":"hexo-rss","date":"2018-03-07T08:54:00.000Z","updated":"2019-09-01T13:04:11.288Z","comments":true,"path":"2018/03/07/hexo-rss/","link":"","permalink":"https://abelsu7.top/2018/03/07/hexo-rss/","excerpt":"RSS介绍RSS（Really Simple Syndication）是一种描述和同步网站内容的格式，是使用最广泛的XML应用。 RSS目前广泛用于网上新闻频道，博客和Wiki，主要的版本有0.91, 1.0, 2.0。使用RSS订阅能更快地获取信息，网络用户可以在客户端借助于支持RSS的聚合工具软件，在不打开网站内容页面的情况下阅读支持RSS输出的网站内容。 下面将介绍如何安装针对Hexo博客的RSS插件，并借助生成atom.xml文件提供RSS订阅服务。 Atom是一种订阅网志的格式，一种Web feed，与RSS类似但有更大的弹性。值得一提的是，Blogger和Gmail这两个由Google提供的服务都在使用Atom。 安装插件首先打开终端，进入本地Hexo根目录，通过npm安装RSS插件： npm install hexo-generator-feed","text":"RSS介绍RSS（Really Simple Syndication）是一种描述和同步网站内容的格式，是使用最广泛的XML应用。 RSS目前广泛用于网上新闻频道，博客和Wiki，主要的版本有0.91, 1.0, 2.0。使用RSS订阅能更快地获取信息，网络用户可以在客户端借助于支持RSS的聚合工具软件，在不打开网站内容页面的情况下阅读支持RSS输出的网站内容。 下面将介绍如何安装针对Hexo博客的RSS插件，并借助生成atom.xml文件提供RSS订阅服务。 Atom是一种订阅网志的格式，一种Web feed，与RSS类似但有更大的弹性。值得一提的是，Blogger和Gmail这两个由Google提供的服务都在使用Atom。 安装插件首先打开终端，进入本地Hexo根目录，通过npm安装RSS插件： npm install hexo-generator-feed 添加配置编辑本地Hexo根目录下的_config.yml文件，添加以下配置： # Extensions ## Plugins: https://hexo.io/plugins/ # RSS订阅 plugin: - hexo-generator-feed # Feed Atom feed: type: atom path: atom.xml limit: 20 添加主题配置在重新执行hexo generate命令渲染Markdown文件后，根目录下的public/目录中已经生成了所需的atom.xml文件。虽然文件已经存在，还需要在页面上添加订阅RSS的按钮。 不同的Hexo主题对RSS的实现方式不尽相同。博主采用的主题是Indigo，可编辑主题目录下的_config.yml文件，添加新菜单项，链接设为/atom.xml即可（对应你atom.xml文件的绝对路径 ）。如希望在新页面中打开链接，则需要将target属性设置为_blank： # 添加新菜单项遵循以下规则 # menu: # link: fontawesome图标，省略前缀，本主题前缀为 icon-，必须 # text: About 菜单显示的文字，如果省略即默认与图标一致，首字母会转大写 # url: /about 链接，绝对或相对路径，必须。 # target: _blank 是否跳出，省略则在当前页面打开 menu: rss: text: RSS url: /atom.xml target: _blank 重新部署最后，清空已有的静态文件，重新渲染Markdown文件，部署到服务器或pages服务上，大功告成！ hexo clean hexo generate # or hexo g hexo deploy # or hexo d 参考文章 hexo博客安装RSS插件 | CSDN RSS（简易信息聚合 | 百度百科） Atom（XML聚合格式）| 百度百科 🚩推荐阅读（由hexo文章推荐插件驱动）RSSHub + Awesome TTRSS 搭建 RSS 阅读器Hexo 实现自定义文章置顶在 Hexo 中使用 MathJax 渲染数学公式利用 Valine 搭建 Hexo 无后端评论系统Hexo博客文末添加网站地图Hexo博客文末添加网站地图","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://abelsu7.top/tags/Hexo/"},{"name":"RSS","slug":"RSS","permalink":"https://abelsu7.top/tags/RSS/"}]},{"title":"那些你不可不知的编程名言","slug":"famous-saying-of-coding","date":"2018-03-05T02:36:45.000Z","updated":"2019-09-01T13:04:11.233Z","comments":true,"path":"2018/03/05/famous-saying-of-coding/","link":"","permalink":"https://abelsu7.top/2018/03/05/famous-saying-of-coding/","excerpt":"Atwood’s Law Atwood’s Law: “Any application that can be written in JavaScript, will be written in JavaScript.” 著名的Atwood’s Law是Jeff Atwood在2007年提出的。通俗来说就是：任何可以使用JavaScript来实现的应用，最终都会使用JavaScript来实现。","text":"Atwood’s Law Atwood’s Law: “Any application that can be written in JavaScript, will be written in JavaScript.” 著名的Atwood’s Law是Jeff Atwood在2007年提出的。通俗来说就是：任何可以使用JavaScript来实现的应用，最终都会使用JavaScript来实现。 人生苦短，我用Python这句在程序员之间广为流传的经典名言最初翻译自Bruce Eckel的一句话 Bruce Eckel: “Life is short, you need Python.” 但 人生苦短，我用Python 这句中文版见于大牛Guido Van Rossum穿的T恤上印着的话，有待查证： 人生苦短，我用Python Unix哲学根本原则KISS Keep it simple, stupid. Linux设计哲学 Do one thing, and do it well. 废话少说，放码过来 Linus: “Talk is cheap. Show me the code.” 来自LKML Don’t Reinvent the Wheel “Don’t Reinvent the Wheel”这句话，你从哪儿听来的？| Gitchat 参考文章 Atwood定律：“任何可以使用JavaScript来编写的应用，最终会由JavaScript编写。” | 耳朵财经 「人生苦短，我用 Python」这句话最初是谁说的？| 知乎 Life is short, You need Python | CSDN 关于Unix哲学 | 阮一峰的网络日志 各种编程名言名句 | 51CTO Good Programming Quotes | Nabble.com 编程名言名句 | 开源中国 “Don’t Reinvent the Wheel”这句话，你从哪儿听来的？| GitChat","categories":[{"name":"代码之外","slug":"代码之外","permalink":"https://abelsu7.top/categories/代码之外/"}],"tags":[{"name":"编程名言","slug":"编程名言","permalink":"https://abelsu7.top/tags/编程名言/"}]},{"title":"Linux 上的 Shebang 符号(#!)","slug":"linux-shebang","date":"2018-03-01T07:21:00.000Z","updated":"2019-09-01T13:04:11.506Z","comments":true,"path":"2018/03/01/linux-shebang/","link":"","permalink":"https://abelsu7.top/2018/03/01/linux-shebang/","excerpt":"使用Linux或者Unix系统的同学可能都对#!这个符号并不陌生，尤其是在初学bash的时候，第一行一定要加上#!/bin/bash Linux Shebang","text":"使用Linux或者Unix系统的同学可能都对#!这个符号并不陌生，尤其是在初学bash的时候，第一行一定要加上#!/bin/bash Linux Shebang 待更新… 参考文章 LINUX上的SHEBANG符号(#!) | 笑遍世界 🚩推荐阅读（由hexo文章推荐插件驱动）Go 语言使用 os/exec 执行 Shell 命令CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/categories/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://abelsu7.top/tags/Shell/"}]},{"title":"以太坊虚拟机（EVM）底层原理及性能缺陷","slug":"ethereum-virtual-machine","date":"2018-02-28T08:27:11.000Z","updated":"2019-09-01T13:04:11.216Z","comments":true,"path":"2018/02/28/ethereum-virtual-machine/","link":"","permalink":"https://abelsu7.top/2018/02/28/ethereum-virtual-machine/","excerpt":"以太坊是一个开源的有智能合约功能的公共区块链平台，通过提供专用加密货币以太币（Ether）以及去中心化的以太坊虚拟机（EVM）来处理点对点合约。 预备知识以太坊以太坊是一个可编程的区块链，它并没有给用户提供一组预定义的操作（如比特币交易），而是允许用户创建他们自己的操作，这些操作可以任意复杂。这样一来，以太坊就成为了多种不同类型去中心化区块链的平台，包括且不仅限于密码学货币。 以太坊平台对底层区块链技术进行了封装，让区块链应用开发者可以直接基于以太坊平台进行开发。这样一来开发者只需要专注于应用本身的开发，从而大大降低了开发的难度。 E-App 狭义上来说，以太坊是一套可以实现分布式应用的平台协议，它的核心是可以执行任意复杂度算法的以太坊虚拟机（EVM）。","text":"以太坊是一个开源的有智能合约功能的公共区块链平台，通过提供专用加密货币以太币（Ether）以及去中心化的以太坊虚拟机（EVM）来处理点对点合约。 预备知识以太坊以太坊是一个可编程的区块链，它并没有给用户提供一组预定义的操作（如比特币交易），而是允许用户创建他们自己的操作，这些操作可以任意复杂。这样一来，以太坊就成为了多种不同类型去中心化区块链的平台，包括且不仅限于密码学货币。 以太坊平台对底层区块链技术进行了封装，让区块链应用开发者可以直接基于以太坊平台进行开发。这样一来开发者只需要专注于应用本身的开发，从而大大降低了开发的难度。 E-App 狭义上来说，以太坊是一套可以实现分布式应用的平台协议，它的核心是可以执行任意复杂度算法的以太坊虚拟机（EVM）。 和其他区块链一样，以太坊也包含一套P2P协议。以太坊区块链数据由网络上的节点进行维护和更新，网络上的每一个节点都运行着EVM并执行相同的指令。因此，以太坊经常被描述为“世界电脑”。 以太坊网络中大规模的并行计算并不是为了计算更高效——事实上，这个过程让计算速度比传统的计算更为低效。另一方面，以太坊中每一个节点都运行着EVM的目的是保持整个区块链的共识。分散式的共识机制给予了以太坊极高的容错能力，确保零宕机，并且使存储于区块链的数据永远不可更改并且可被审查。 以太坊本质上就是一个保存数字交易永久记录的公共数据库。重要的是，这个数据库不需要任何中央权威机构来维持和保护，这是一个个体在不需要信任任何第三方或对方的情况下进行P2P交易的架构。 智能合约以太坊上的程序 被称为 智能合约，它是 代码和数据（状态）的集合。 比特币的交易是可以编程的，但是比特币脚本有很多的限制，能够编写的程序也有限。而以太坊则是图灵完备的，可以让我们像使用任何高级语言一样来编写几乎可以做任何事情的程序（即智能合约）。 智能合约非常适合对信任、安全和持久性要求较高的应用场景，比如：数字货币、数字资产、投票、保险、金融应用、预测市场、产权所有权管理、物联网、点对点交易等等。但目前除了数字货币之外，真正落地的应用还并不多。 编程语言：SolidityEVM有自己内含的语言——EVM操作码。类似其他高级语言，EVM也有自己的高级语言，当下流行的是 Solidity和 Viper，编译后可在EVM中执行。 智能合约的默认编程语言是Solidity，文件扩展名以.sol结尾。 Browser-Solidity Web IDE是一个基于Web的Solidity IDE。 Solidity是和JavaScript相似的语言，用来开发智能合约并将其编译成以太坊虚拟机字节代码。 运行环境：以太坊虚拟机（EVM）EVM ( Ethereum Virtual Machine ) 即 以太坊虚拟机 是以太坊中智能合约的运行环境。而EVM运行在以太坊节点上，当我们把合约部署到以太坊网络上之后，合约就可以在以太坊网络中运行了。 EVM使用了256比特长度的机器码，是一种基于堆栈的虚拟机，用于执行智能合约，并使用了以太坊账户模型（Account Model）来进行价值传输。 EVM是图灵完备的，由于以太坊系统中引入了Gas的概念，所以原则上在EVM中可执行的计算总量受Gas总量限制。 EVM是一个隔离的环境，在EVM内部运行的代码不能跟外部有任何联系。 EVM采用了基于栈（Stack）的架构，也就是后进先出（LIFO）的方式。 在以太坊设计原理中描述了EVM的设计目标： 简单：操作码尽可能的少并且低级，数据类型尽可能少，虚拟机的结构尽可能少； 结果明确：在VM规范语句中，没有任何可能产生歧义的空间，结果应该是完全确定的。此外，计算步骤应该是精确的，以便可以测量Gas的消耗量； 节约空间：EVM组件应尽可能紧凑； 预期应用应具备专业化能力：在VM上构建的应用应能处理20字节的地址，以及32位的自定义加密值，拥有用于自定义加密的模数运算、读取区块和交易数据与状态交互等能力； 简单安全：为了让VM不被利用，应该能够容易地建立一套Gas消耗成本模型的操作； 优化友好：应该易于优化，以便即时编译（JIT）和VM的加速版本能够构建出来。 同时EVM也有如下特殊设计： 区分临时存储（Memory，存在于VM的每个实例中，并在VM执行结束后消失）和永久存储（Storage，存在于区块链状态层）； 采用基于栈（Stack）的架构； 机器码长度为256比特，即32字节； 使用了可变、可扩展的内存大小； 栈的大小没有限制； 1024调用深度限制； 无类型。 像之前定义的那样，EVM是图灵完备虚拟机器，而EVM本质上是被Gas束缚，因此可以完成的计算总量本质上是被提供的Gas总量限制的。 此外，EVM具有基于堆栈的架构。每个堆栈顶的大小为256位，堆栈有一个最大的大小，为1024位。 EVM有内存（Memory），项目按照可寻址字节数组来存储。内存是易失的，也就是说数据是不持久的。EVM还有一个存储器（Storage），与内存不同，存储器是非易失的，并作为系统状态的一部分进行维护。EVM分开保存程序代码，在虚拟ROM中只能通过特殊指令来访问。 EVM 合约的编译EVM上运行的是合约的字节码形式，需要我们在部署之前先对合约进行编译。可以选择Browser-Solidity Web IDE或者solc编译器。 合约的部署在以太坊上开发应用时，常常要使用到 以太坊客户端（钱包）。其实我们可以把以太坊客户端理解为一个开发者工具，它提供 账户管理、挖矿、转账、智能合约的部署和执行 等功能，EVM也是由以太坊客户端提供的。 以太坊客户端：GethGeth 是典型的开发以太坊时使用的客户端，基于Go语言开发。Geth提供了一个交互式命令控制台，其中包含了以太坊的各种功能（API）。 Geth控制台和 Chrome浏览器开发者工具里的控制台是类似的，不过是跑在终端里。 相对于Geth，Mist则是图形化操作界面的以太坊客户端。 合约如何部署？智能合约的部署是指把合约字节码发布到区块链上，并使用一个特定的地址来表示这个合约，这个地址称为合约账户。 以太坊中有两种不同类型但是共享同一地址空间的账户： 外部账户由一对公私钥控制，没有关联任何代码，其地址是由公钥（经过Hash运算）决定的 合约账户由账户内部的合约代码控制，该类账户被它们的合约代码控制且有代码与之关联，其地址在此合约被创建的时候决定。每个账户都有一个持久的Key-Value类型的存储，并将256位的Key映射到256位的Value上 合约的运行合约部署后，当需要调用这个智能合约的方法时，只需要向这个合约账户发送消息（交易）即可。通过交易消息触发后，智能合约的代码就会在EVM中执行了。 Gas机制和云计算类似，占用区块链的资源需要付出相应的费用。 以太坊上用Gas机制来计费，可以将其看作一个工作量单位。智能合约越复杂（计算步骤的数量和类型、占用的内存等），用来完成运行就需要越多的Gas。 任何特定的合约所需的运行合约的Gas数量是固定的，由合约的复杂度决定。而 Gas价格由运行合约的人在提交运行合约请求的时候规定，以确定他愿意为这次交易付出的费用：Gas价格 × Gas数量。 Gas的目的是限制执行交易所需的工作量，同时为执行支付费用。 如果没有Gas机制，就会有人写出无法停止（如死循环）的合约来阻塞网络。 当EVM执行交易时，Gas将按照特定规则被逐渐消耗，无论执行到什么位置，一旦Gas被耗尽，将会触发异常，当前调用帧所做的所有状态修改都将被回滚。如果执行结束还有Gas剩余，这些Gas将被返还给发送账户。 以太坊网络要进行智能合约的开发，需要有以太币，可以选择以下方式： 以太坊官网测试网络Testnet在该测试网络中，很容易就可以获得免费的以太币，缺点是需要花很长时间对节点进行初始化。 使用私有链创建自己的以太币私有测试网络，通常也成为私有链，我们可以用它来作为一个测试环境来开发、调试和测试智能合约。 通过之前提到的Geth很容易就可以创建一个属于自己的测试网络，以太币想挖多少挖多少，也免去了同步正式网络整个区块链数据所耗费的时间。 使用开发者网络相比私有链，开发者网络下会自动分配一个有大量余额的开发者账户供我们使用。 使用模拟环境另一个创建测试网络的方法是使用testrpc，testrpc是在本地使用内存模拟的一个以太坊环境，对于开发调试来说，更方便快捷。而且testrpc可以在启动时帮我们创建10个存有资金的测试账户。 进行合约开发时，可以先在testrpc中测试通过后，再部署到Geth节点中去。 testrpc现在已经并入到 Truffle开发框架中，现在的名字是 Ganache CLI。 Dapp：去中心化的应用程序以太坊社区把基于智能合约的应用称为去中心化的应用程序（Decentralized App）。 如果我们把区块链理解为一个不可篡改的数据库，把智能合约理解为和数据库打交道的程序，那就很容易理解Dapp了。 总结以太坊是平台，它让我们方便的使用区块链技术开发去中心化的应用。 在这个应用中，使用Solidity来编写和区块链交互的智能合约。 合约编写好之后，我们需要用以太坊客户端和一个有余额的账户去部署及运行合约。 使用Truffle框架可以更好的帮助我们做这些事情。 为了开发方便，我们可以用Geth或testrpc来搭建一个测试网络。 EVM的缺陷与不足机器码长度为256位目前大多数的处理器主要由以下4种选择来实现快速的数学运算： 8bit整数 16bit整数 32bit整数 64bit整数 虽然在一些情况下32bit比16bit快，并且在x86架构中8bit数学运算并不是完全支持，但基本上如果你采用以上的任意一种，都可以保证数学运算在若干个时钟周期内完成，并且这个过程非常迅速，往往是纳秒级的。因此，可以说这些位长的整数是目前主流处理器能够原生支持且不需要额外操作的。 EVM处于所谓运算速度和效率方面考虑，采用了非主流的256bit整数。x86汇编码运算的比较实验，证明了采用256bit整数远比采用处理器原生支持的整数长度要复杂，即EVM的运算效率并不高。 缺少标准库在开发Solidity智能合约时就会碰到这个问题，因为Solidity中根本没有标准库。目前的情况是，人们只能不断的从一些开源软件中复制粘贴代码。首先这些代码的安全性无法保证，再加上人们会为了更小的Gas消耗而不断修改代码，这就有可能对他们的合约引入更严重的安全性问题。 难以调试和测试这个问题不仅仅是EVM的设计缺陷，也和其实现方式有关。EVM唯一能抛出的异常就是OutOfGas，并且没有调试日志，也无法调用外部代码。同时，以太坊本身很难生成一条测试网络的私链，即使成功，私链的参数和行为也与公链不同。 不支持浮点数浮点数有很多应用实例，比如风险建模、科学计算，以及其他一些范围和近似值比准确值更加重要的情况。EVM将浮点数排除在外的做法有潜在的局限性。 不可修改的代码智能合约在设计时需要考虑的重要问题之一就是是可升级性，因为合约的升级是必然的。 在EVM中代码是完全不可修改的，并且由于其采用哈佛计算机结构，也就不可能将代码在内存中加载并执行，代码和数据是被完全分离的。 目前只能够通过部署新的合约来达到升级的目的，这可能需要复制原合约中的所有代码，并将老的合约重定向到新的合约地址。给合约打补丁或是部分升级合约代码在EVM中是完全不可能的。 参考文章 以太坊设计原理 | ETHFANS 深入理解以太坊系列(8)：以太坊虚拟机EVM 以太坊虚拟机EVM是什么 | 金色百科 以太坊虚拟机 | Oriovo的博客 详解以太坊的工作原理 | CSDN 以太坊源码分析 Ⅰ. 区块和交易，合约和虚拟机 | CSDN 【区块链】以太坊源码学习-EVM | CSDN Solidity中文文档——1.3 以太坊虚拟机 Diving Into The Ethereum VM Part One | Qtum’s Blog 深入了解以太坊虚拟机 | 简书 What is the Ethereum Virtual Machine? | The Merkle What is Ethereum? | Ethereum Docs 以太坊是什么？| CnBlogs 深入浅出区块链 以太坊是什么？| 以太坊开发入门指南 智能合约开发环境搭建及Hello World合约 | 深入浅出区块链 也来谈一谈以太坊虚拟机EVM的缺陷和不足 | BITKAN How Ethereum Works? | coindesk Optimizing the Ethereum Virtual Machine | Medium.com 🚩推荐阅读（由hexo文章推荐插件驱动）比特币—-挖矿比特币—-挖矿","categories":[{"name":"云计算","slug":"云计算","permalink":"https://abelsu7.top/categories/云计算/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"https://abelsu7.top/tags/区块链/"},{"name":"以太坊","slug":"以太坊","permalink":"https://abelsu7.top/tags/以太坊/"},{"name":"EVM","slug":"EVM","permalink":"https://abelsu7.top/tags/EVM/"}]},{"title":"Hexo 操作指南","slug":"hexo-cheatsheet","date":"2018-02-14T05:14:00.000Z","updated":"2019-09-01T13:04:11.285Z","comments":true,"path":"2018/02/14/hexo-cheatsheet/","link":"","permalink":"https://abelsu7.top/2018/02/14/hexo-cheatsheet/","excerpt":"Hexo素质三连hexo new &quot;My New Post&quot; hexo g hexo d More info: Writing","text":"Hexo素质三连hexo new &quot;My New Post&quot; hexo g hexo d More info: Writing Run serverhexo server More info: Server Generate static fileshexo generate More info: Generating Deploy to remote siteshexo deploy More info: Deployment 渲染drafthexo s --draft 发布drafthexo publish [layout] &lt;title&gt; 生成后直接部署hexo g -d # or hexo d -g 评论插件 Valine Gitment Gitalk Disqus Livere 来必力 畅言 Hexo的SEO技巧 Hexo插件之百度主动提交链接 | 王辉的博客 如何在 Google 和百度里搜索到自己的网站 | 笑话人生 参考文章 Hexo Hexo Documentation 🚩推荐阅读（由hexo文章推荐插件驱动）Hexo 实现自定义文章置顶在 Hexo 中使用 MathJax 渲染数学公式利用 Valine 搭建 Hexo 无后端评论系统解决 RSS 报错：Input is not proper UTF-8, indicate encodingHexo博客文末添加网站地图Hexo博客文末添加网站地图","categories":[{"name":"前端","slug":"前端","permalink":"https://abelsu7.top/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://abelsu7.top/tags/Hexo/"}]},{"title":"Ubuntu 文件管理器卡死无法打开","slug":"ubuntu-nautilus-no-response","date":"2018-02-05T09:30:34.000Z","updated":"2019-09-01T13:04:11.754Z","comments":true,"path":"2018/02/05/ubuntu-nautilus-no-response/","link":"","permalink":"https://abelsu7.top/2018/02/05/ubuntu-nautilus-no-response/","excerpt":"当Ubuntu文件管理器卡死时，首先运行 ps -A | grep nautilus 查找文件管理器进程对应的pid，或者直接运行 killall nautilus 即可杀死文件管理器进程。之后点击任意文件夹，即可重新运行该进程，文件管理器可正常打开。","text":"当Ubuntu文件管理器卡死时，首先运行 ps -A | grep nautilus 查找文件管理器进程对应的pid，或者直接运行 killall nautilus 即可杀死文件管理器进程。之后点击任意文件夹，即可重新运行该进程，文件管理器可正常打开。 参考文章 解决Ubuntu中文件管理器死掉的情况 Ubuntu主文件夹打不开 🚩推荐阅读（由hexo文章推荐插件驱动）CentOS 7 安装配置 NFSLinux 系统常用监控命令Linux 终端修改 ls 命令目录显示颜色Linux 下使用 Perf 分析系统性能Linux基础笔记虚拟机 VMware 中安装 Ubuntu 操作系统","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://abelsu7.top/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"https://abelsu7.top/tags/Linux/"}]}]}